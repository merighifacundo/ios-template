{"version":3,"names":[],"mappings":"","sources":["scripts/npm-c1e8447cfd.js"],"sourcesContent":["/******/ (function(modules) { // webpackBootstrap\n/******/ \t// install a JSONP callback for chunk loading\n/******/ \tvar parentJsonpFunction = window[\"webpackJsonp\"];\n/******/ \twindow[\"webpackJsonp\"] = function webpackJsonpCallback(chunkIds, moreModules, executeModules) {\n/******/ \t\t// add \"moreModules\" to the modules object,\n/******/ \t\t// then flag all \"chunkIds\" as loaded and fire callback\n/******/ \t\tvar moduleId, chunkId, i = 0, resolves = [], result;\n/******/ \t\tfor(;i < chunkIds.length; i++) {\n/******/ \t\t\tchunkId = chunkIds[i];\n/******/ \t\t\tif(installedChunks[chunkId]) {\n/******/ \t\t\t\tresolves.push(installedChunks[chunkId][0]);\n/******/ \t\t\t}\n/******/ \t\t\tinstalledChunks[chunkId] = 0;\n/******/ \t\t}\n/******/ \t\tfor(moduleId in moreModules) {\n/******/ \t\t\tif(Object.prototype.hasOwnProperty.call(moreModules, moduleId)) {\n/******/ \t\t\t\tmodules[moduleId] = moreModules[moduleId];\n/******/ \t\t\t}\n/******/ \t\t}\n/******/ \t\tif(parentJsonpFunction) parentJsonpFunction(chunkIds, moreModules, executeModules);\n/******/ \t\twhile(resolves.length) {\n/******/ \t\t\tresolves.shift()();\n/******/ \t\t}\n/******/ \t\tif(executeModules) {\n/******/ \t\t\tfor(i=0; i < executeModules.length; i++) {\n/******/ \t\t\t\tresult = __webpack_require__(__webpack_require__.s = executeModules[i]);\n/******/ \t\t\t}\n/******/ \t\t}\n/******/ \t\treturn result;\n/******/ \t};\n/******/\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// objects to store loaded and loading chunks\n/******/ \tvar installedChunks = {\n/******/ \t\t4: 0\n/******/ \t};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId]) {\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\ti: moduleId,\n/******/ \t\t\tl: false,\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.l = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// define getter function for harmony exports\n/******/ \t__webpack_require__.d = function(exports, name, getter) {\n/******/ \t\tif(!__webpack_require__.o(exports, name)) {\n/******/ \t\t\tObject.defineProperty(exports, name, {\n/******/ \t\t\t\tconfigurable: false,\n/******/ \t\t\t\tenumerable: true,\n/******/ \t\t\t\tget: getter\n/******/ \t\t\t});\n/******/ \t\t}\n/******/ \t};\n/******/\n/******/ \t// getDefaultExport function for compatibility with non-harmony modules\n/******/ \t__webpack_require__.n = function(module) {\n/******/ \t\tvar getter = module && module.__esModule ?\n/******/ \t\t\tfunction getDefault() { return module['default']; } :\n/******/ \t\t\tfunction getModuleExports() { return module; };\n/******/ \t\t__webpack_require__.d(getter, 'a', getter);\n/******/ \t\treturn getter;\n/******/ \t};\n/******/\n/******/ \t// Object.prototype.hasOwnProperty.call\n/******/ \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"\";\n/******/\n/******/ \t// on error function for async loading\n/******/ \t__webpack_require__.oe = function(err) { console.error(err); throw err; };\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(__webpack_require__.s = 362);\n/******/ })\n/************************************************************************/\n/******/ ([\n/* 0 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar global = __webpack_require__(3);\nvar core = __webpack_require__(26);\nvar hide = __webpack_require__(16);\nvar redefine = __webpack_require__(17);\nvar ctx = __webpack_require__(27);\nvar PROTOTYPE = 'prototype';\n\nvar $export = function (type, name, source) {\n  var IS_FORCED = type & $export.F;\n  var IS_GLOBAL = type & $export.G;\n  var IS_STATIC = type & $export.S;\n  var IS_PROTO = type & $export.P;\n  var IS_BIND = type & $export.B;\n  var target = IS_GLOBAL ? global : IS_STATIC ? global[name] || (global[name] = {}) : (global[name] || {})[PROTOTYPE];\n  var exports = IS_GLOBAL ? core : core[name] || (core[name] = {});\n  var expProto = exports[PROTOTYPE] || (exports[PROTOTYPE] = {});\n  var key, own, out, exp;\n  if (IS_GLOBAL) source = name;\n  for (key in source) {\n    // contains in native\n    own = !IS_FORCED && target && target[key] !== undefined;\n    // export native or passed\n    out = (own ? target : source)[key];\n    // bind timers to global for call from export context\n    exp = IS_BIND && own ? ctx(out, global) : IS_PROTO && typeof out == 'function' ? ctx(Function.call, out) : out;\n    // extend global\n    if (target) redefine(target, key, out, type & $export.U);\n    // export\n    if (exports[key] != out) hide(exports, key, exp);\n    if (IS_PROTO && expProto[key] != out) expProto[key] = out;\n  }\n};\nglobal.core = core;\n// type bitmap\n$export.F = 1;   // forced\n$export.G = 2;   // global\n$export.S = 4;   // static\n$export.P = 8;   // proto\n$export.B = 16;  // bind\n$export.W = 32;  // wrap\n$export.U = 64;  // safe\n$export.R = 128; // real proto method for `library`\nmodule.exports = $export;\n\n\n/***/ }),\n/* 1 */,\n/* 2 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar isObject = __webpack_require__(5);\nmodule.exports = function (it) {\n  if (!isObject(it)) throw TypeError(it + ' is not an object!');\n  return it;\n};\n\n\n/***/ }),\n/* 3 */\n/***/ (function(module, exports) {\n\n// https://github.com/zloirock/core-js/issues/86#issuecomment-115759028\nvar global = module.exports = typeof window != 'undefined' && window.Math == Math\n  ? window : typeof self != 'undefined' && self.Math == Math ? self\n  // eslint-disable-next-line no-new-func\n  : Function('return this')();\nif (typeof __g == 'number') __g = global; // eslint-disable-line no-undef\n\n\n/***/ }),\n/* 4 */\n/***/ (function(module, exports) {\n\nmodule.exports = function (exec) {\n  try {\n    return !!exec();\n  } catch (e) {\n    return true;\n  }\n};\n\n\n/***/ }),\n/* 5 */\n/***/ (function(module, exports) {\n\nmodule.exports = function (it) {\n  return typeof it === 'object' ? it !== null : typeof it === 'function';\n};\n\n\n/***/ }),\n/* 6 */\n/***/ (function(module, exports) {\n\nif (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n\n\n/***/ }),\n/* 7 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar store = __webpack_require__(70)('wks');\nvar uid = __webpack_require__(44);\nvar Symbol = __webpack_require__(3).Symbol;\nvar USE_SYMBOL = typeof Symbol == 'function';\n\nvar $exports = module.exports = function (name) {\n  return store[name] || (store[name] =\n    USE_SYMBOL && Symbol[name] || (USE_SYMBOL ? Symbol : uid)('Symbol.' + name));\n};\n\n$exports.store = store;\n\n\n/***/ }),\n/* 8 */\n/***/ (function(module, exports) {\n\n// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n\n\n/***/ }),\n/* 9 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// Thank's IE8 for his funny defineProperty\nmodule.exports = !__webpack_require__(4)(function () {\n  return Object.defineProperty({}, 'a', { get: function () { return 7; } }).a != 7;\n});\n\n\n/***/ }),\n/* 10 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar anObject = __webpack_require__(2);\nvar IE8_DOM_DEFINE = __webpack_require__(145);\nvar toPrimitive = __webpack_require__(30);\nvar dP = Object.defineProperty;\n\nexports.f = __webpack_require__(9) ? Object.defineProperty : function defineProperty(O, P, Attributes) {\n  anObject(O);\n  P = toPrimitive(P, true);\n  anObject(Attributes);\n  if (IE8_DOM_DEFINE) try {\n    return dP(O, P, Attributes);\n  } catch (e) { /* empty */ }\n  if ('get' in Attributes || 'set' in Attributes) throw TypeError('Accessors not supported!');\n  if ('value' in Attributes) O[P] = Attributes.value;\n  return O;\n};\n\n\n/***/ }),\n/* 11 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 7.1.15 ToLength\nvar toInteger = __webpack_require__(32);\nvar min = Math.min;\nmodule.exports = function (it) {\n  return it > 0 ? min(toInteger(it), 0x1fffffffffffff) : 0; // pow(2, 53) - 1 == 9007199254740991\n};\n\n\n/***/ }),\n/* 12 */\n/***/ (function(module, exports) {\n\nvar g;\r\n\r\n// This works in non-strict mode\r\ng = (function() {\r\n\treturn this;\r\n})();\r\n\r\ntry {\r\n\t// This works if eval is allowed (see CSP)\r\n\tg = g || Function(\"return this\")() || (1,eval)(\"this\");\r\n} catch(e) {\r\n\t// This works if the window reference is available\r\n\tif(typeof window === \"object\")\r\n\t\tg = window;\r\n}\r\n\r\n// g can still be undefined, but nothing to do about it...\r\n// We return undefined, instead of nothing here, so it's\r\n// easier to handle this case. if(!global) { ...}\r\n\r\nmodule.exports = g;\r\n\n\n/***/ }),\n/* 13 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(Buffer) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\n\nfunction isArray(arg) {\n  if (Array.isArray) {\n    return Array.isArray(arg);\n  }\n  return objectToString(arg) === '[object Array]';\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = Buffer.isBuffer;\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(24).Buffer))\n\n/***/ }),\n/* 14 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 7.1.13 ToObject(argument)\nvar defined = __webpack_require__(31);\nmodule.exports = function (it) {\n  return Object(defined(it));\n};\n\n\n/***/ }),\n/* 15 */\n/***/ (function(module, exports) {\n\nmodule.exports = function (it) {\n  if (typeof it != 'function') throw TypeError(it + ' is not a function!');\n  return it;\n};\n\n\n/***/ }),\n/* 16 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar dP = __webpack_require__(10);\nvar createDesc = __webpack_require__(43);\nmodule.exports = __webpack_require__(9) ? function (object, key, value) {\n  return dP.f(object, key, createDesc(1, value));\n} : function (object, key, value) {\n  object[key] = value;\n  return object;\n};\n\n\n/***/ }),\n/* 17 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar global = __webpack_require__(3);\nvar hide = __webpack_require__(16);\nvar has = __webpack_require__(19);\nvar SRC = __webpack_require__(44)('src');\nvar TO_STRING = 'toString';\nvar $toString = Function[TO_STRING];\nvar TPL = ('' + $toString).split(TO_STRING);\n\n__webpack_require__(26).inspectSource = function (it) {\n  return $toString.call(it);\n};\n\n(module.exports = function (O, key, val, safe) {\n  var isFunction = typeof val == 'function';\n  if (isFunction) has(val, 'name') || hide(val, 'name', key);\n  if (O[key] === val) return;\n  if (isFunction) has(val, SRC) || hide(val, SRC, O[key] ? '' + O[key] : TPL.join(String(key)));\n  if (O === global) {\n    O[key] = val;\n  } else if (!safe) {\n    delete O[key];\n    hide(O, key, val);\n  } else if (O[key]) {\n    O[key] = val;\n  } else {\n    hide(O, key, val);\n  }\n// add fake Function#toString for correct work wrapped methods / constructors with methods like LoDash isNative\n})(Function.prototype, TO_STRING, function toString() {\n  return typeof this == 'function' && this[SRC] || $toString.call(this);\n});\n\n\n/***/ }),\n/* 18 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\nvar fails = __webpack_require__(4);\nvar defined = __webpack_require__(31);\nvar quot = /\"/g;\n// B.2.3.2.1 CreateHTML(string, tag, attribute, value)\nvar createHTML = function (string, tag, attribute, value) {\n  var S = String(defined(string));\n  var p1 = '<' + tag;\n  if (attribute !== '') p1 += ' ' + attribute + '=\"' + String(value).replace(quot, '&quot;') + '\"';\n  return p1 + '>' + S + '</' + tag + '>';\n};\nmodule.exports = function (NAME, exec) {\n  var O = {};\n  O[NAME] = exec(createHTML);\n  $export($export.P + $export.F * fails(function () {\n    var test = ''[NAME]('\"');\n    return test !== test.toLowerCase() || test.split('\"').length > 3;\n  }), 'String', O);\n};\n\n\n/***/ }),\n/* 19 */\n/***/ (function(module, exports) {\n\nvar hasOwnProperty = {}.hasOwnProperty;\nmodule.exports = function (it, key) {\n  return hasOwnProperty.call(it, key);\n};\n\n\n/***/ }),\n/* 20 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// to indexed object, toObject with fallback for non-array-like ES3 strings\nvar IObject = __webpack_require__(62);\nvar defined = __webpack_require__(31);\nmodule.exports = function (it) {\n  return IObject(defined(it));\n};\n\n\n/***/ }),\n/* 21 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar pIE = __webpack_require__(63);\nvar createDesc = __webpack_require__(43);\nvar toIObject = __webpack_require__(20);\nvar toPrimitive = __webpack_require__(30);\nvar has = __webpack_require__(19);\nvar IE8_DOM_DEFINE = __webpack_require__(145);\nvar gOPD = Object.getOwnPropertyDescriptor;\n\nexports.f = __webpack_require__(9) ? gOPD : function getOwnPropertyDescriptor(O, P) {\n  O = toIObject(O);\n  P = toPrimitive(P, true);\n  if (IE8_DOM_DEFINE) try {\n    return gOPD(O, P);\n  } catch (e) { /* empty */ }\n  if (has(O, P)) return createDesc(!pIE.f.call(O, P), O[P]);\n};\n\n\n/***/ }),\n/* 22 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.9 / 15.2.3.2 Object.getPrototypeOf(O)\nvar has = __webpack_require__(19);\nvar toObject = __webpack_require__(14);\nvar IE_PROTO = __webpack_require__(93)('IE_PROTO');\nvar ObjectProto = Object.prototype;\n\nmodule.exports = Object.getPrototypeOf || function (O) {\n  O = toObject(O);\n  if (has(O, IE_PROTO)) return O[IE_PROTO];\n  if (typeof O.constructor == 'function' && O instanceof O.constructor) {\n    return O.constructor.prototype;\n  } return O instanceof Object ? ObjectProto : null;\n};\n\n\n/***/ }),\n/* 23 */\n/***/ (function(module, exports) {\n\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nfunction EventEmitter() {\n  this._events = this._events || {};\n  this._maxListeners = this._maxListeners || undefined;\n}\nmodule.exports = EventEmitter;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nEventEmitter.defaultMaxListeners = 10;\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function(n) {\n  if (!isNumber(n) || n < 0 || isNaN(n))\n    throw TypeError('n must be a positive number');\n  this._maxListeners = n;\n  return this;\n};\n\nEventEmitter.prototype.emit = function(type) {\n  var er, handler, len, args, i, listeners;\n\n  if (!this._events)\n    this._events = {};\n\n  // If there is no 'error' event listener then throw.\n  if (type === 'error') {\n    if (!this._events.error ||\n        (isObject(this._events.error) && !this._events.error.length)) {\n      er = arguments[1];\n      if (er instanceof Error) {\n        throw er; // Unhandled 'error' event\n      } else {\n        // At least give some kind of context to the user\n        var err = new Error('Uncaught, unspecified \"error\" event. (' + er + ')');\n        err.context = er;\n        throw err;\n      }\n    }\n  }\n\n  handler = this._events[type];\n\n  if (isUndefined(handler))\n    return false;\n\n  if (isFunction(handler)) {\n    switch (arguments.length) {\n      // fast cases\n      case 1:\n        handler.call(this);\n        break;\n      case 2:\n        handler.call(this, arguments[1]);\n        break;\n      case 3:\n        handler.call(this, arguments[1], arguments[2]);\n        break;\n      // slower\n      default:\n        args = Array.prototype.slice.call(arguments, 1);\n        handler.apply(this, args);\n    }\n  } else if (isObject(handler)) {\n    args = Array.prototype.slice.call(arguments, 1);\n    listeners = handler.slice();\n    len = listeners.length;\n    for (i = 0; i < len; i++)\n      listeners[i].apply(this, args);\n  }\n\n  return true;\n};\n\nEventEmitter.prototype.addListener = function(type, listener) {\n  var m;\n\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  if (!this._events)\n    this._events = {};\n\n  // To avoid recursion in the case that type === \"newListener\"! Before\n  // adding it to the listeners, first emit \"newListener\".\n  if (this._events.newListener)\n    this.emit('newListener', type,\n              isFunction(listener.listener) ?\n              listener.listener : listener);\n\n  if (!this._events[type])\n    // Optimize the case of one listener. Don't need the extra array object.\n    this._events[type] = listener;\n  else if (isObject(this._events[type]))\n    // If we've already got an array, just append.\n    this._events[type].push(listener);\n  else\n    // Adding the second element, need to change to array.\n    this._events[type] = [this._events[type], listener];\n\n  // Check for listener leak\n  if (isObject(this._events[type]) && !this._events[type].warned) {\n    if (!isUndefined(this._maxListeners)) {\n      m = this._maxListeners;\n    } else {\n      m = EventEmitter.defaultMaxListeners;\n    }\n\n    if (m && m > 0 && this._events[type].length > m) {\n      this._events[type].warned = true;\n      console.error('(node) warning: possible EventEmitter memory ' +\n                    'leak detected. %d listeners added. ' +\n                    'Use emitter.setMaxListeners() to increase limit.',\n                    this._events[type].length);\n      if (typeof console.trace === 'function') {\n        // not supported in IE 10\n        console.trace();\n      }\n    }\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.once = function(type, listener) {\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  var fired = false;\n\n  function g() {\n    this.removeListener(type, g);\n\n    if (!fired) {\n      fired = true;\n      listener.apply(this, arguments);\n    }\n  }\n\n  g.listener = listener;\n  this.on(type, g);\n\n  return this;\n};\n\n// emits a 'removeListener' event iff the listener was removed\nEventEmitter.prototype.removeListener = function(type, listener) {\n  var list, position, length, i;\n\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  if (!this._events || !this._events[type])\n    return this;\n\n  list = this._events[type];\n  length = list.length;\n  position = -1;\n\n  if (list === listener ||\n      (isFunction(list.listener) && list.listener === listener)) {\n    delete this._events[type];\n    if (this._events.removeListener)\n      this.emit('removeListener', type, listener);\n\n  } else if (isObject(list)) {\n    for (i = length; i-- > 0;) {\n      if (list[i] === listener ||\n          (list[i].listener && list[i].listener === listener)) {\n        position = i;\n        break;\n      }\n    }\n\n    if (position < 0)\n      return this;\n\n    if (list.length === 1) {\n      list.length = 0;\n      delete this._events[type];\n    } else {\n      list.splice(position, 1);\n    }\n\n    if (this._events.removeListener)\n      this.emit('removeListener', type, listener);\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.removeAllListeners = function(type) {\n  var key, listeners;\n\n  if (!this._events)\n    return this;\n\n  // not listening for removeListener, no need to emit\n  if (!this._events.removeListener) {\n    if (arguments.length === 0)\n      this._events = {};\n    else if (this._events[type])\n      delete this._events[type];\n    return this;\n  }\n\n  // emit removeListener for all listeners on all events\n  if (arguments.length === 0) {\n    for (key in this._events) {\n      if (key === 'removeListener') continue;\n      this.removeAllListeners(key);\n    }\n    this.removeAllListeners('removeListener');\n    this._events = {};\n    return this;\n  }\n\n  listeners = this._events[type];\n\n  if (isFunction(listeners)) {\n    this.removeListener(type, listeners);\n  } else if (listeners) {\n    // LIFO order\n    while (listeners.length)\n      this.removeListener(type, listeners[listeners.length - 1]);\n  }\n  delete this._events[type];\n\n  return this;\n};\n\nEventEmitter.prototype.listeners = function(type) {\n  var ret;\n  if (!this._events || !this._events[type])\n    ret = [];\n  else if (isFunction(this._events[type]))\n    ret = [this._events[type]];\n  else\n    ret = this._events[type].slice();\n  return ret;\n};\n\nEventEmitter.prototype.listenerCount = function(type) {\n  if (this._events) {\n    var evlistener = this._events[type];\n\n    if (isFunction(evlistener))\n      return 1;\n    else if (evlistener)\n      return evlistener.length;\n  }\n  return 0;\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  return emitter.listenerCount(type);\n};\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\n\n\n/***/ }),\n/* 24 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global) {/*!\n * The buffer module from node.js, for the browser.\n *\n * @author   Feross Aboukhadijeh <feross@feross.org> <http://feross.org>\n * @license  MIT\n */\n/* eslint-disable no-proto */\n\n\n\nvar base64 = __webpack_require__(579)\nvar ieee754 = __webpack_require__(580)\nvar isArray = __webpack_require__(581)\n\nexports.Buffer = Buffer\nexports.SlowBuffer = SlowBuffer\nexports.INSPECT_MAX_BYTES = 50\n\n/**\n * If `Buffer.TYPED_ARRAY_SUPPORT`:\n *   === true    Use Uint8Array implementation (fastest)\n *   === false   Use Object implementation (most compatible, even IE6)\n *\n * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,\n * Opera 11.6+, iOS 4.2+.\n *\n * Due to various browser bugs, sometimes the Object implementation will be used even\n * when the browser supports typed arrays.\n *\n * Note:\n *\n *   - Firefox 4-29 lacks support for adding new properties to `Uint8Array` instances,\n *     See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438.\n *\n *   - Chrome 9-10 is missing the `TypedArray.prototype.subarray` function.\n *\n *   - IE10 has a broken `TypedArray.prototype.subarray` function which returns arrays of\n *     incorrect length in some situations.\n\n * We detect these buggy browsers and set `Buffer.TYPED_ARRAY_SUPPORT` to `false` so they\n * get the Object implementation, which is slower but behaves correctly.\n */\nBuffer.TYPED_ARRAY_SUPPORT = global.TYPED_ARRAY_SUPPORT !== undefined\n  ? global.TYPED_ARRAY_SUPPORT\n  : typedArraySupport()\n\n/*\n * Export kMaxLength after typed array support is determined.\n */\nexports.kMaxLength = kMaxLength()\n\nfunction typedArraySupport () {\n  try {\n    var arr = new Uint8Array(1)\n    arr.__proto__ = {__proto__: Uint8Array.prototype, foo: function () { return 42 }}\n    return arr.foo() === 42 && // typed array instances can be augmented\n        typeof arr.subarray === 'function' && // chrome 9-10 lack `subarray`\n        arr.subarray(1, 1).byteLength === 0 // ie10 has broken `subarray`\n  } catch (e) {\n    return false\n  }\n}\n\nfunction kMaxLength () {\n  return Buffer.TYPED_ARRAY_SUPPORT\n    ? 0x7fffffff\n    : 0x3fffffff\n}\n\nfunction createBuffer (that, length) {\n  if (kMaxLength() < length) {\n    throw new RangeError('Invalid typed array length')\n  }\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    // Return an augmented `Uint8Array` instance, for best performance\n    that = new Uint8Array(length)\n    that.__proto__ = Buffer.prototype\n  } else {\n    // Fallback: Return an object instance of the Buffer class\n    if (that === null) {\n      that = new Buffer(length)\n    }\n    that.length = length\n  }\n\n  return that\n}\n\n/**\n * The Buffer constructor returns instances of `Uint8Array` that have their\n * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of\n * `Uint8Array`, so the returned instances will have all the node `Buffer` methods\n * and the `Uint8Array` methods. Square bracket notation works as expected -- it\n * returns a single octet.\n *\n * The `Uint8Array` prototype remains unmodified.\n */\n\nfunction Buffer (arg, encodingOrOffset, length) {\n  if (!Buffer.TYPED_ARRAY_SUPPORT && !(this instanceof Buffer)) {\n    return new Buffer(arg, encodingOrOffset, length)\n  }\n\n  // Common case.\n  if (typeof arg === 'number') {\n    if (typeof encodingOrOffset === 'string') {\n      throw new Error(\n        'If encoding is specified then the first argument must be a string'\n      )\n    }\n    return allocUnsafe(this, arg)\n  }\n  return from(this, arg, encodingOrOffset, length)\n}\n\nBuffer.poolSize = 8192 // not used by this implementation\n\n// TODO: Legacy, not needed anymore. Remove in next major version.\nBuffer._augment = function (arr) {\n  arr.__proto__ = Buffer.prototype\n  return arr\n}\n\nfunction from (that, value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (typeof ArrayBuffer !== 'undefined' && value instanceof ArrayBuffer) {\n    return fromArrayBuffer(that, value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(that, value, encodingOrOffset)\n  }\n\n  return fromObject(that, value)\n}\n\n/**\n * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError\n * if value is a number.\n * Buffer.from(str[, encoding])\n * Buffer.from(array)\n * Buffer.from(buffer)\n * Buffer.from(arrayBuffer[, byteOffset[, length]])\n **/\nBuffer.from = function (value, encodingOrOffset, length) {\n  return from(null, value, encodingOrOffset, length)\n}\n\nif (Buffer.TYPED_ARRAY_SUPPORT) {\n  Buffer.prototype.__proto__ = Uint8Array.prototype\n  Buffer.__proto__ = Uint8Array\n  if (typeof Symbol !== 'undefined' && Symbol.species &&\n      Buffer[Symbol.species] === Buffer) {\n    // Fix subarray() in ES2016. See: https://github.com/feross/buffer/pull/97\n    Object.defineProperty(Buffer, Symbol.species, {\n      value: null,\n      configurable: true\n    })\n  }\n}\n\nfunction assertSize (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('\"size\" argument must be a number')\n  } else if (size < 0) {\n    throw new RangeError('\"size\" argument must not be negative')\n  }\n}\n\nfunction alloc (that, size, fill, encoding) {\n  assertSize(size)\n  if (size <= 0) {\n    return createBuffer(that, size)\n  }\n  if (fill !== undefined) {\n    // Only pay attention to encoding if it's a string. This\n    // prevents accidentally sending in a number that would\n    // be interpretted as a start offset.\n    return typeof encoding === 'string'\n      ? createBuffer(that, size).fill(fill, encoding)\n      : createBuffer(that, size).fill(fill)\n  }\n  return createBuffer(that, size)\n}\n\n/**\n * Creates a new filled Buffer instance.\n * alloc(size[, fill[, encoding]])\n **/\nBuffer.alloc = function (size, fill, encoding) {\n  return alloc(null, size, fill, encoding)\n}\n\nfunction allocUnsafe (that, size) {\n  assertSize(size)\n  that = createBuffer(that, size < 0 ? 0 : checked(size) | 0)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) {\n    for (var i = 0; i < size; ++i) {\n      that[i] = 0\n    }\n  }\n  return that\n}\n\n/**\n * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.\n * */\nBuffer.allocUnsafe = function (size) {\n  return allocUnsafe(null, size)\n}\n/**\n * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.\n */\nBuffer.allocUnsafeSlow = function (size) {\n  return allocUnsafe(null, size)\n}\n\nfunction fromString (that, string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  var length = byteLength(string, encoding) | 0\n  that = createBuffer(that, length)\n\n  var actual = that.write(string, encoding)\n\n  if (actual !== length) {\n    // Writing a hex string, for example, that contains invalid characters will\n    // cause everything after the first invalid character to be ignored. (e.g.\n    // 'abxxcd' will be treated as 'ab')\n    that = that.slice(0, actual)\n  }\n\n  return that\n}\n\nfunction fromArrayLike (that, array) {\n  var length = array.length < 0 ? 0 : checked(array.length) | 0\n  that = createBuffer(that, length)\n  for (var i = 0; i < length; i += 1) {\n    that[i] = array[i] & 255\n  }\n  return that\n}\n\nfunction fromArrayBuffer (that, array, byteOffset, length) {\n  array.byteLength // this throws if `array` is not a valid ArrayBuffer\n\n  if (byteOffset < 0 || array.byteLength < byteOffset) {\n    throw new RangeError('\\'offset\\' is out of bounds')\n  }\n\n  if (array.byteLength < byteOffset + (length || 0)) {\n    throw new RangeError('\\'length\\' is out of bounds')\n  }\n\n  if (byteOffset === undefined && length === undefined) {\n    array = new Uint8Array(array)\n  } else if (length === undefined) {\n    array = new Uint8Array(array, byteOffset)\n  } else {\n    array = new Uint8Array(array, byteOffset, length)\n  }\n\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    // Return an augmented `Uint8Array` instance, for best performance\n    that = array\n    that.__proto__ = Buffer.prototype\n  } else {\n    // Fallback: Return an object instance of the Buffer class\n    that = fromArrayLike(that, array)\n  }\n  return that\n}\n\nfunction fromObject (that, obj) {\n  if (Buffer.isBuffer(obj)) {\n    var len = checked(obj.length) | 0\n    that = createBuffer(that, len)\n\n    if (that.length === 0) {\n      return that\n    }\n\n    obj.copy(that, 0, 0, len)\n    return that\n  }\n\n  if (obj) {\n    if ((typeof ArrayBuffer !== 'undefined' &&\n        obj.buffer instanceof ArrayBuffer) || 'length' in obj) {\n      if (typeof obj.length !== 'number' || isnan(obj.length)) {\n        return createBuffer(that, 0)\n      }\n      return fromArrayLike(that, obj)\n    }\n\n    if (obj.type === 'Buffer' && isArray(obj.data)) {\n      return fromArrayLike(that, obj.data)\n    }\n  }\n\n  throw new TypeError('First argument must be a string, Buffer, ArrayBuffer, Array, or array-like object.')\n}\n\nfunction checked (length) {\n  // Note: cannot use `length < kMaxLength()` here because that fails when\n  // length is NaN (which is otherwise coerced to zero.)\n  if (length >= kMaxLength()) {\n    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +\n                         'size: 0x' + kMaxLength().toString(16) + ' bytes')\n  }\n  return length | 0\n}\n\nfunction SlowBuffer (length) {\n  if (+length != length) { // eslint-disable-line eqeqeq\n    length = 0\n  }\n  return Buffer.alloc(+length)\n}\n\nBuffer.isBuffer = function isBuffer (b) {\n  return !!(b != null && b._isBuffer)\n}\n\nBuffer.compare = function compare (a, b) {\n  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {\n    throw new TypeError('Arguments must be Buffers')\n  }\n\n  if (a === b) return 0\n\n  var x = a.length\n  var y = b.length\n\n  for (var i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (a[i] !== b[i]) {\n      x = a[i]\n      y = b[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\nBuffer.isEncoding = function isEncoding (encoding) {\n  switch (String(encoding).toLowerCase()) {\n    case 'hex':\n    case 'utf8':\n    case 'utf-8':\n    case 'ascii':\n    case 'latin1':\n    case 'binary':\n    case 'base64':\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return true\n    default:\n      return false\n  }\n}\n\nBuffer.concat = function concat (list, length) {\n  if (!isArray(list)) {\n    throw new TypeError('\"list\" argument must be an Array of Buffers')\n  }\n\n  if (list.length === 0) {\n    return Buffer.alloc(0)\n  }\n\n  var i\n  if (length === undefined) {\n    length = 0\n    for (i = 0; i < list.length; ++i) {\n      length += list[i].length\n    }\n  }\n\n  var buffer = Buffer.allocUnsafe(length)\n  var pos = 0\n  for (i = 0; i < list.length; ++i) {\n    var buf = list[i]\n    if (!Buffer.isBuffer(buf)) {\n      throw new TypeError('\"list\" argument must be an Array of Buffers')\n    }\n    buf.copy(buffer, pos)\n    pos += buf.length\n  }\n  return buffer\n}\n\nfunction byteLength (string, encoding) {\n  if (Buffer.isBuffer(string)) {\n    return string.length\n  }\n  if (typeof ArrayBuffer !== 'undefined' && typeof ArrayBuffer.isView === 'function' &&\n      (ArrayBuffer.isView(string) || string instanceof ArrayBuffer)) {\n    return string.byteLength\n  }\n  if (typeof string !== 'string') {\n    string = '' + string\n  }\n\n  var len = string.length\n  if (len === 0) return 0\n\n  // Use a for loop to avoid recursion\n  var loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'ascii':\n      case 'latin1':\n      case 'binary':\n        return len\n      case 'utf8':\n      case 'utf-8':\n      case undefined:\n        return utf8ToBytes(string).length\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return len * 2\n      case 'hex':\n        return len >>> 1\n      case 'base64':\n        return base64ToBytes(string).length\n      default:\n        if (loweredCase) return utf8ToBytes(string).length // assume utf8\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\nBuffer.byteLength = byteLength\n\nfunction slowToString (encoding, start, end) {\n  var loweredCase = false\n\n  // No need to verify that \"this.length <= MAX_UINT32\" since it's a read-only\n  // property of a typed array.\n\n  // This behaves neither like String nor Uint8Array in that we set start/end\n  // to their upper/lower bounds if the value passed is out of range.\n  // undefined is handled specially as per ECMA-262 6th Edition,\n  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.\n  if (start === undefined || start < 0) {\n    start = 0\n  }\n  // Return early if start > this.length. Done here to prevent potential uint32\n  // coercion fail below.\n  if (start > this.length) {\n    return ''\n  }\n\n  if (end === undefined || end > this.length) {\n    end = this.length\n  }\n\n  if (end <= 0) {\n    return ''\n  }\n\n  // Force coersion to uint32. This will also coerce falsey/NaN values to 0.\n  end >>>= 0\n  start >>>= 0\n\n  if (end <= start) {\n    return ''\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  while (true) {\n    switch (encoding) {\n      case 'hex':\n        return hexSlice(this, start, end)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Slice(this, start, end)\n\n      case 'ascii':\n        return asciiSlice(this, start, end)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Slice(this, start, end)\n\n      case 'base64':\n        return base64Slice(this, start, end)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return utf16leSlice(this, start, end)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = (encoding + '').toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\n// The property is used by `Buffer.isBuffer` and `is-buffer` (in Safari 5-7) to detect\n// Buffer instances.\nBuffer.prototype._isBuffer = true\n\nfunction swap (b, n, m) {\n  var i = b[n]\n  b[n] = b[m]\n  b[m] = i\n}\n\nBuffer.prototype.swap16 = function swap16 () {\n  var len = this.length\n  if (len % 2 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 16-bits')\n  }\n  for (var i = 0; i < len; i += 2) {\n    swap(this, i, i + 1)\n  }\n  return this\n}\n\nBuffer.prototype.swap32 = function swap32 () {\n  var len = this.length\n  if (len % 4 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 32-bits')\n  }\n  for (var i = 0; i < len; i += 4) {\n    swap(this, i, i + 3)\n    swap(this, i + 1, i + 2)\n  }\n  return this\n}\n\nBuffer.prototype.swap64 = function swap64 () {\n  var len = this.length\n  if (len % 8 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 64-bits')\n  }\n  for (var i = 0; i < len; i += 8) {\n    swap(this, i, i + 7)\n    swap(this, i + 1, i + 6)\n    swap(this, i + 2, i + 5)\n    swap(this, i + 3, i + 4)\n  }\n  return this\n}\n\nBuffer.prototype.toString = function toString () {\n  var length = this.length | 0\n  if (length === 0) return ''\n  if (arguments.length === 0) return utf8Slice(this, 0, length)\n  return slowToString.apply(this, arguments)\n}\n\nBuffer.prototype.equals = function equals (b) {\n  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')\n  if (this === b) return true\n  return Buffer.compare(this, b) === 0\n}\n\nBuffer.prototype.inspect = function inspect () {\n  var str = ''\n  var max = exports.INSPECT_MAX_BYTES\n  if (this.length > 0) {\n    str = this.toString('hex', 0, max).match(/.{2}/g).join(' ')\n    if (this.length > max) str += ' ... '\n  }\n  return '<Buffer ' + str + '>'\n}\n\nBuffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {\n  if (!Buffer.isBuffer(target)) {\n    throw new TypeError('Argument must be a Buffer')\n  }\n\n  if (start === undefined) {\n    start = 0\n  }\n  if (end === undefined) {\n    end = target ? target.length : 0\n  }\n  if (thisStart === undefined) {\n    thisStart = 0\n  }\n  if (thisEnd === undefined) {\n    thisEnd = this.length\n  }\n\n  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {\n    throw new RangeError('out of range index')\n  }\n\n  if (thisStart >= thisEnd && start >= end) {\n    return 0\n  }\n  if (thisStart >= thisEnd) {\n    return -1\n  }\n  if (start >= end) {\n    return 1\n  }\n\n  start >>>= 0\n  end >>>= 0\n  thisStart >>>= 0\n  thisEnd >>>= 0\n\n  if (this === target) return 0\n\n  var x = thisEnd - thisStart\n  var y = end - start\n  var len = Math.min(x, y)\n\n  var thisCopy = this.slice(thisStart, thisEnd)\n  var targetCopy = target.slice(start, end)\n\n  for (var i = 0; i < len; ++i) {\n    if (thisCopy[i] !== targetCopy[i]) {\n      x = thisCopy[i]\n      y = targetCopy[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\n// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,\n// OR the last index of `val` in `buffer` at offset <= `byteOffset`.\n//\n// Arguments:\n// - buffer - a Buffer to search\n// - val - a string, Buffer, or number\n// - byteOffset - an index into `buffer`; will be clamped to an int32\n// - encoding - an optional encoding, relevant is val is a string\n// - dir - true for indexOf, false for lastIndexOf\nfunction bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {\n  // Empty buffer means no match\n  if (buffer.length === 0) return -1\n\n  // Normalize byteOffset\n  if (typeof byteOffset === 'string') {\n    encoding = byteOffset\n    byteOffset = 0\n  } else if (byteOffset > 0x7fffffff) {\n    byteOffset = 0x7fffffff\n  } else if (byteOffset < -0x80000000) {\n    byteOffset = -0x80000000\n  }\n  byteOffset = +byteOffset  // Coerce to Number.\n  if (isNaN(byteOffset)) {\n    // byteOffset: it it's undefined, null, NaN, \"foo\", etc, search whole buffer\n    byteOffset = dir ? 0 : (buffer.length - 1)\n  }\n\n  // Normalize byteOffset: negative offsets start from the end of the buffer\n  if (byteOffset < 0) byteOffset = buffer.length + byteOffset\n  if (byteOffset >= buffer.length) {\n    if (dir) return -1\n    else byteOffset = buffer.length - 1\n  } else if (byteOffset < 0) {\n    if (dir) byteOffset = 0\n    else return -1\n  }\n\n  // Normalize val\n  if (typeof val === 'string') {\n    val = Buffer.from(val, encoding)\n  }\n\n  // Finally, search either indexOf (if dir is true) or lastIndexOf\n  if (Buffer.isBuffer(val)) {\n    // Special case: looking for empty string/buffer always fails\n    if (val.length === 0) {\n      return -1\n    }\n    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)\n  } else if (typeof val === 'number') {\n    val = val & 0xFF // Search for a byte value [0-255]\n    if (Buffer.TYPED_ARRAY_SUPPORT &&\n        typeof Uint8Array.prototype.indexOf === 'function') {\n      if (dir) {\n        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)\n      } else {\n        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)\n      }\n    }\n    return arrayIndexOf(buffer, [ val ], byteOffset, encoding, dir)\n  }\n\n  throw new TypeError('val must be string, number or Buffer')\n}\n\nfunction arrayIndexOf (arr, val, byteOffset, encoding, dir) {\n  var indexSize = 1\n  var arrLength = arr.length\n  var valLength = val.length\n\n  if (encoding !== undefined) {\n    encoding = String(encoding).toLowerCase()\n    if (encoding === 'ucs2' || encoding === 'ucs-2' ||\n        encoding === 'utf16le' || encoding === 'utf-16le') {\n      if (arr.length < 2 || val.length < 2) {\n        return -1\n      }\n      indexSize = 2\n      arrLength /= 2\n      valLength /= 2\n      byteOffset /= 2\n    }\n  }\n\n  function read (buf, i) {\n    if (indexSize === 1) {\n      return buf[i]\n    } else {\n      return buf.readUInt16BE(i * indexSize)\n    }\n  }\n\n  var i\n  if (dir) {\n    var foundIndex = -1\n    for (i = byteOffset; i < arrLength; i++) {\n      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {\n        if (foundIndex === -1) foundIndex = i\n        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize\n      } else {\n        if (foundIndex !== -1) i -= i - foundIndex\n        foundIndex = -1\n      }\n    }\n  } else {\n    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength\n    for (i = byteOffset; i >= 0; i--) {\n      var found = true\n      for (var j = 0; j < valLength; j++) {\n        if (read(arr, i + j) !== read(val, j)) {\n          found = false\n          break\n        }\n      }\n      if (found) return i\n    }\n  }\n\n  return -1\n}\n\nBuffer.prototype.includes = function includes (val, byteOffset, encoding) {\n  return this.indexOf(val, byteOffset, encoding) !== -1\n}\n\nBuffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)\n}\n\nBuffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)\n}\n\nfunction hexWrite (buf, string, offset, length) {\n  offset = Number(offset) || 0\n  var remaining = buf.length - offset\n  if (!length) {\n    length = remaining\n  } else {\n    length = Number(length)\n    if (length > remaining) {\n      length = remaining\n    }\n  }\n\n  // must be an even number of digits\n  var strLen = string.length\n  if (strLen % 2 !== 0) throw new TypeError('Invalid hex string')\n\n  if (length > strLen / 2) {\n    length = strLen / 2\n  }\n  for (var i = 0; i < length; ++i) {\n    var parsed = parseInt(string.substr(i * 2, 2), 16)\n    if (isNaN(parsed)) return i\n    buf[offset + i] = parsed\n  }\n  return i\n}\n\nfunction utf8Write (buf, string, offset, length) {\n  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nfunction asciiWrite (buf, string, offset, length) {\n  return blitBuffer(asciiToBytes(string), buf, offset, length)\n}\n\nfunction latin1Write (buf, string, offset, length) {\n  return asciiWrite(buf, string, offset, length)\n}\n\nfunction base64Write (buf, string, offset, length) {\n  return blitBuffer(base64ToBytes(string), buf, offset, length)\n}\n\nfunction ucs2Write (buf, string, offset, length) {\n  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nBuffer.prototype.write = function write (string, offset, length, encoding) {\n  // Buffer#write(string)\n  if (offset === undefined) {\n    encoding = 'utf8'\n    length = this.length\n    offset = 0\n  // Buffer#write(string, encoding)\n  } else if (length === undefined && typeof offset === 'string') {\n    encoding = offset\n    length = this.length\n    offset = 0\n  // Buffer#write(string, offset[, length][, encoding])\n  } else if (isFinite(offset)) {\n    offset = offset | 0\n    if (isFinite(length)) {\n      length = length | 0\n      if (encoding === undefined) encoding = 'utf8'\n    } else {\n      encoding = length\n      length = undefined\n    }\n  // legacy write(string, encoding, offset, length) - remove in v0.13\n  } else {\n    throw new Error(\n      'Buffer.write(string, encoding, offset[, length]) is no longer supported'\n    )\n  }\n\n  var remaining = this.length - offset\n  if (length === undefined || length > remaining) length = remaining\n\n  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {\n    throw new RangeError('Attempt to write outside buffer bounds')\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  var loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'hex':\n        return hexWrite(this, string, offset, length)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Write(this, string, offset, length)\n\n      case 'ascii':\n        return asciiWrite(this, string, offset, length)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Write(this, string, offset, length)\n\n      case 'base64':\n        // Warning: maxLength not taken into account in base64Write\n        return base64Write(this, string, offset, length)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return ucs2Write(this, string, offset, length)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\nBuffer.prototype.toJSON = function toJSON () {\n  return {\n    type: 'Buffer',\n    data: Array.prototype.slice.call(this._arr || this, 0)\n  }\n}\n\nfunction base64Slice (buf, start, end) {\n  if (start === 0 && end === buf.length) {\n    return base64.fromByteArray(buf)\n  } else {\n    return base64.fromByteArray(buf.slice(start, end))\n  }\n}\n\nfunction utf8Slice (buf, start, end) {\n  end = Math.min(buf.length, end)\n  var res = []\n\n  var i = start\n  while (i < end) {\n    var firstByte = buf[i]\n    var codePoint = null\n    var bytesPerSequence = (firstByte > 0xEF) ? 4\n      : (firstByte > 0xDF) ? 3\n      : (firstByte > 0xBF) ? 2\n      : 1\n\n    if (i + bytesPerSequence <= end) {\n      var secondByte, thirdByte, fourthByte, tempCodePoint\n\n      switch (bytesPerSequence) {\n        case 1:\n          if (firstByte < 0x80) {\n            codePoint = firstByte\n          }\n          break\n        case 2:\n          secondByte = buf[i + 1]\n          if ((secondByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)\n            if (tempCodePoint > 0x7F) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 3:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)\n            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 4:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          fourthByte = buf[i + 3]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)\n            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {\n              codePoint = tempCodePoint\n            }\n          }\n      }\n    }\n\n    if (codePoint === null) {\n      // we did not generate a valid codePoint so insert a\n      // replacement char (U+FFFD) and advance only 1 byte\n      codePoint = 0xFFFD\n      bytesPerSequence = 1\n    } else if (codePoint > 0xFFFF) {\n      // encode to utf16 (surrogate pair dance)\n      codePoint -= 0x10000\n      res.push(codePoint >>> 10 & 0x3FF | 0xD800)\n      codePoint = 0xDC00 | codePoint & 0x3FF\n    }\n\n    res.push(codePoint)\n    i += bytesPerSequence\n  }\n\n  return decodeCodePointsArray(res)\n}\n\n// Based on http://stackoverflow.com/a/22747272/680742, the browser with\n// the lowest limit is Chrome, with 0x10000 args.\n// We go 1 magnitude less, for safety\nvar MAX_ARGUMENTS_LENGTH = 0x1000\n\nfunction decodeCodePointsArray (codePoints) {\n  var len = codePoints.length\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()\n  }\n\n  // Decode in chunks to avoid \"call stack size exceeded\".\n  var res = ''\n  var i = 0\n  while (i < len) {\n    res += String.fromCharCode.apply(\n      String,\n      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)\n    )\n  }\n  return res\n}\n\nfunction asciiSlice (buf, start, end) {\n  var ret = ''\n  end = Math.min(buf.length, end)\n\n  for (var i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i] & 0x7F)\n  }\n  return ret\n}\n\nfunction latin1Slice (buf, start, end) {\n  var ret = ''\n  end = Math.min(buf.length, end)\n\n  for (var i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i])\n  }\n  return ret\n}\n\nfunction hexSlice (buf, start, end) {\n  var len = buf.length\n\n  if (!start || start < 0) start = 0\n  if (!end || end < 0 || end > len) end = len\n\n  var out = ''\n  for (var i = start; i < end; ++i) {\n    out += toHex(buf[i])\n  }\n  return out\n}\n\nfunction utf16leSlice (buf, start, end) {\n  var bytes = buf.slice(start, end)\n  var res = ''\n  for (var i = 0; i < bytes.length; i += 2) {\n    res += String.fromCharCode(bytes[i] + bytes[i + 1] * 256)\n  }\n  return res\n}\n\nBuffer.prototype.slice = function slice (start, end) {\n  var len = this.length\n  start = ~~start\n  end = end === undefined ? len : ~~end\n\n  if (start < 0) {\n    start += len\n    if (start < 0) start = 0\n  } else if (start > len) {\n    start = len\n  }\n\n  if (end < 0) {\n    end += len\n    if (end < 0) end = 0\n  } else if (end > len) {\n    end = len\n  }\n\n  if (end < start) end = start\n\n  var newBuf\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    newBuf = this.subarray(start, end)\n    newBuf.__proto__ = Buffer.prototype\n  } else {\n    var sliceLen = end - start\n    newBuf = new Buffer(sliceLen, undefined)\n    for (var i = 0; i < sliceLen; ++i) {\n      newBuf[i] = this[i + start]\n    }\n  }\n\n  return newBuf\n}\n\n/*\n * Need to make sure that buffer isn't trying to write out of bounds.\n */\nfunction checkOffset (offset, ext, length) {\n  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')\n  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')\n}\n\nBuffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var val = this[offset]\n  var mul = 1\n  var i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    checkOffset(offset, byteLength, this.length)\n  }\n\n  var val = this[offset + --byteLength]\n  var mul = 1\n  while (byteLength > 0 && (mul *= 0x100)) {\n    val += this[offset + --byteLength] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  return this[offset]\n}\n\nBuffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return this[offset] | (this[offset + 1] << 8)\n}\n\nBuffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return (this[offset] << 8) | this[offset + 1]\n}\n\nBuffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return ((this[offset]) |\n      (this[offset + 1] << 8) |\n      (this[offset + 2] << 16)) +\n      (this[offset + 3] * 0x1000000)\n}\n\nBuffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] * 0x1000000) +\n    ((this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    this[offset + 3])\n}\n\nBuffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var val = this[offset]\n  var mul = 1\n  var i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var i = byteLength\n  var mul = 1\n  var val = this[offset + --i]\n  while (i > 0 && (mul *= 0x100)) {\n    val += this[offset + --i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readInt8 = function readInt8 (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  if (!(this[offset] & 0x80)) return (this[offset])\n  return ((0xff - this[offset] + 1) * -1)\n}\n\nBuffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  var val = this[offset] | (this[offset + 1] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  var val = this[offset + 1] | (this[offset] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset]) |\n    (this[offset + 1] << 8) |\n    (this[offset + 2] << 16) |\n    (this[offset + 3] << 24)\n}\n\nBuffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] << 24) |\n    (this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    (this[offset + 3])\n}\n\nBuffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, true, 23, 4)\n}\n\nBuffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, false, 23, 4)\n}\n\nBuffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, true, 52, 8)\n}\n\nBuffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, false, 52, 8)\n}\n\nfunction checkInt (buf, value, offset, ext, max, min) {\n  if (!Buffer.isBuffer(buf)) throw new TypeError('\"buffer\" argument must be a Buffer instance')\n  if (value > max || value < min) throw new RangeError('\"value\" argument is out of bounds')\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n}\n\nBuffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    var maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  var mul = 1\n  var i = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    var maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  var i = byteLength - 1\n  var mul = 1\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nfunction objectWriteUInt16 (buf, value, offset, littleEndian) {\n  if (value < 0) value = 0xffff + value + 1\n  for (var i = 0, j = Math.min(buf.length - offset, 2); i < j; ++i) {\n    buf[offset + i] = (value & (0xff << (8 * (littleEndian ? i : 1 - i)))) >>>\n      (littleEndian ? i : 1 - i) * 8\n  }\n}\n\nBuffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n  } else {\n    objectWriteUInt16(this, value, offset, true)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 8)\n    this[offset + 1] = (value & 0xff)\n  } else {\n    objectWriteUInt16(this, value, offset, false)\n  }\n  return offset + 2\n}\n\nfunction objectWriteUInt32 (buf, value, offset, littleEndian) {\n  if (value < 0) value = 0xffffffff + value + 1\n  for (var i = 0, j = Math.min(buf.length - offset, 4); i < j; ++i) {\n    buf[offset + i] = (value >>> (littleEndian ? i : 3 - i) * 8) & 0xff\n  }\n}\n\nBuffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset + 3] = (value >>> 24)\n    this[offset + 2] = (value >>> 16)\n    this[offset + 1] = (value >>> 8)\n    this[offset] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, true)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 24)\n    this[offset + 1] = (value >>> 16)\n    this[offset + 2] = (value >>> 8)\n    this[offset + 3] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, false)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) {\n    var limit = Math.pow(2, 8 * byteLength - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  var i = 0\n  var mul = 1\n  var sub = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) {\n    var limit = Math.pow(2, 8 * byteLength - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  var i = byteLength - 1\n  var mul = 1\n  var sub = 0\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)\n  if (value < 0) value = 0xff + value + 1\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nBuffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n  } else {\n    objectWriteUInt16(this, value, offset, true)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 8)\n    this[offset + 1] = (value & 0xff)\n  } else {\n    objectWriteUInt16(this, value, offset, false)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n    this[offset + 2] = (value >>> 16)\n    this[offset + 3] = (value >>> 24)\n  } else {\n    objectWriteUInt32(this, value, offset, true)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (value < 0) value = 0xffffffff + value + 1\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 24)\n    this[offset + 1] = (value >>> 16)\n    this[offset + 2] = (value >>> 8)\n    this[offset + 3] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, false)\n  }\n  return offset + 4\n}\n\nfunction checkIEEE754 (buf, value, offset, ext, max, min) {\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n  if (offset < 0) throw new RangeError('Index out of range')\n}\n\nfunction writeFloat (buf, value, offset, littleEndian, noAssert) {\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 23, 4)\n  return offset + 4\n}\n\nBuffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, false, noAssert)\n}\n\nfunction writeDouble (buf, value, offset, littleEndian, noAssert) {\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 52, 8)\n  return offset + 8\n}\n\nBuffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, false, noAssert)\n}\n\n// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)\nBuffer.prototype.copy = function copy (target, targetStart, start, end) {\n  if (!start) start = 0\n  if (!end && end !== 0) end = this.length\n  if (targetStart >= target.length) targetStart = target.length\n  if (!targetStart) targetStart = 0\n  if (end > 0 && end < start) end = start\n\n  // Copy 0 bytes; we're done\n  if (end === start) return 0\n  if (target.length === 0 || this.length === 0) return 0\n\n  // Fatal error conditions\n  if (targetStart < 0) {\n    throw new RangeError('targetStart out of bounds')\n  }\n  if (start < 0 || start >= this.length) throw new RangeError('sourceStart out of bounds')\n  if (end < 0) throw new RangeError('sourceEnd out of bounds')\n\n  // Are we oob?\n  if (end > this.length) end = this.length\n  if (target.length - targetStart < end - start) {\n    end = target.length - targetStart + start\n  }\n\n  var len = end - start\n  var i\n\n  if (this === target && start < targetStart && targetStart < end) {\n    // descending copy from end\n    for (i = len - 1; i >= 0; --i) {\n      target[i + targetStart] = this[i + start]\n    }\n  } else if (len < 1000 || !Buffer.TYPED_ARRAY_SUPPORT) {\n    // ascending copy from start\n    for (i = 0; i < len; ++i) {\n      target[i + targetStart] = this[i + start]\n    }\n  } else {\n    Uint8Array.prototype.set.call(\n      target,\n      this.subarray(start, start + len),\n      targetStart\n    )\n  }\n\n  return len\n}\n\n// Usage:\n//    buffer.fill(number[, offset[, end]])\n//    buffer.fill(buffer[, offset[, end]])\n//    buffer.fill(string[, offset[, end]][, encoding])\nBuffer.prototype.fill = function fill (val, start, end, encoding) {\n  // Handle string cases:\n  if (typeof val === 'string') {\n    if (typeof start === 'string') {\n      encoding = start\n      start = 0\n      end = this.length\n    } else if (typeof end === 'string') {\n      encoding = end\n      end = this.length\n    }\n    if (val.length === 1) {\n      var code = val.charCodeAt(0)\n      if (code < 256) {\n        val = code\n      }\n    }\n    if (encoding !== undefined && typeof encoding !== 'string') {\n      throw new TypeError('encoding must be a string')\n    }\n    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {\n      throw new TypeError('Unknown encoding: ' + encoding)\n    }\n  } else if (typeof val === 'number') {\n    val = val & 255\n  }\n\n  // Invalid ranges are not set to a default, so can range check early.\n  if (start < 0 || this.length < start || this.length < end) {\n    throw new RangeError('Out of range index')\n  }\n\n  if (end <= start) {\n    return this\n  }\n\n  start = start >>> 0\n  end = end === undefined ? this.length : end >>> 0\n\n  if (!val) val = 0\n\n  var i\n  if (typeof val === 'number') {\n    for (i = start; i < end; ++i) {\n      this[i] = val\n    }\n  } else {\n    var bytes = Buffer.isBuffer(val)\n      ? val\n      : utf8ToBytes(new Buffer(val, encoding).toString())\n    var len = bytes.length\n    for (i = 0; i < end - start; ++i) {\n      this[i + start] = bytes[i % len]\n    }\n  }\n\n  return this\n}\n\n// HELPER FUNCTIONS\n// ================\n\nvar INVALID_BASE64_RE = /[^+\\/0-9A-Za-z-_]/g\n\nfunction base64clean (str) {\n  // Node strips out invalid characters like \\n and \\t from the string, base64-js does not\n  str = stringtrim(str).replace(INVALID_BASE64_RE, '')\n  // Node converts strings with length < 2 to ''\n  if (str.length < 2) return ''\n  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not\n  while (str.length % 4 !== 0) {\n    str = str + '='\n  }\n  return str\n}\n\nfunction stringtrim (str) {\n  if (str.trim) return str.trim()\n  return str.replace(/^\\s+|\\s+$/g, '')\n}\n\nfunction toHex (n) {\n  if (n < 16) return '0' + n.toString(16)\n  return n.toString(16)\n}\n\nfunction utf8ToBytes (string, units) {\n  units = units || Infinity\n  var codePoint\n  var length = string.length\n  var leadSurrogate = null\n  var bytes = []\n\n  for (var i = 0; i < length; ++i) {\n    codePoint = string.charCodeAt(i)\n\n    // is surrogate component\n    if (codePoint > 0xD7FF && codePoint < 0xE000) {\n      // last char was a lead\n      if (!leadSurrogate) {\n        // no lead yet\n        if (codePoint > 0xDBFF) {\n          // unexpected trail\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        } else if (i + 1 === length) {\n          // unpaired lead\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        }\n\n        // valid lead\n        leadSurrogate = codePoint\n\n        continue\n      }\n\n      // 2 leads in a row\n      if (codePoint < 0xDC00) {\n        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n        leadSurrogate = codePoint\n        continue\n      }\n\n      // valid surrogate pair\n      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000\n    } else if (leadSurrogate) {\n      // valid bmp char, but last char was a lead\n      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n    }\n\n    leadSurrogate = null\n\n    // encode utf8\n    if (codePoint < 0x80) {\n      if ((units -= 1) < 0) break\n      bytes.push(codePoint)\n    } else if (codePoint < 0x800) {\n      if ((units -= 2) < 0) break\n      bytes.push(\n        codePoint >> 0x6 | 0xC0,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x10000) {\n      if ((units -= 3) < 0) break\n      bytes.push(\n        codePoint >> 0xC | 0xE0,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x110000) {\n      if ((units -= 4) < 0) break\n      bytes.push(\n        codePoint >> 0x12 | 0xF0,\n        codePoint >> 0xC & 0x3F | 0x80,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else {\n      throw new Error('Invalid code point')\n    }\n  }\n\n  return bytes\n}\n\nfunction asciiToBytes (str) {\n  var byteArray = []\n  for (var i = 0; i < str.length; ++i) {\n    // Node's code seems to be doing this and not & 0x7F..\n    byteArray.push(str.charCodeAt(i) & 0xFF)\n  }\n  return byteArray\n}\n\nfunction utf16leToBytes (str, units) {\n  var c, hi, lo\n  var byteArray = []\n  for (var i = 0; i < str.length; ++i) {\n    if ((units -= 2) < 0) break\n\n    c = str.charCodeAt(i)\n    hi = c >> 8\n    lo = c % 256\n    byteArray.push(lo)\n    byteArray.push(hi)\n  }\n\n  return byteArray\n}\n\nfunction base64ToBytes (str) {\n  return base64.toByteArray(base64clean(str))\n}\n\nfunction blitBuffer (src, dst, offset, length) {\n  for (var i = 0; i < length; ++i) {\n    if ((i + offset >= dst.length) || (i >= src.length)) break\n    dst[i + offset] = src[i]\n  }\n  return i\n}\n\nfunction isnan (val) {\n  return val !== val // eslint-disable-line no-self-compare\n}\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12)))\n\n/***/ }),\n/* 25 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(process) {\n\nif (!process.version ||\n    process.version.indexOf('v0.') === 0 ||\n    process.version.indexOf('v1.') === 0 && process.version.indexOf('v1.8.') !== 0) {\n  module.exports = { nextTick: nextTick };\n} else {\n  module.exports = process\n}\n\nfunction nextTick(fn, arg1, arg2, arg3) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('\"callback\" argument must be a function');\n  }\n  var len = arguments.length;\n  var args, i;\n  switch (len) {\n  case 0:\n  case 1:\n    return process.nextTick(fn);\n  case 2:\n    return process.nextTick(function afterTickOne() {\n      fn.call(null, arg1);\n    });\n  case 3:\n    return process.nextTick(function afterTickTwo() {\n      fn.call(null, arg1, arg2);\n    });\n  case 4:\n    return process.nextTick(function afterTickThree() {\n      fn.call(null, arg1, arg2, arg3);\n    });\n  default:\n    args = new Array(len - 1);\n    i = 0;\n    while (i < args.length) {\n      args[i++] = arguments[i];\n    }\n    return process.nextTick(function afterTick() {\n      fn.apply(null, args);\n    });\n  }\n}\n\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8)))\n\n/***/ }),\n/* 26 */\n/***/ (function(module, exports) {\n\nvar core = module.exports = { version: '2.5.7' };\nif (typeof __e == 'number') __e = core; // eslint-disable-line no-undef\n\n\n/***/ }),\n/* 27 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// optional / simple context binding\nvar aFunction = __webpack_require__(15);\nmodule.exports = function (fn, that, length) {\n  aFunction(fn);\n  if (that === undefined) return fn;\n  switch (length) {\n    case 1: return function (a) {\n      return fn.call(that, a);\n    };\n    case 2: return function (a, b) {\n      return fn.call(that, a, b);\n    };\n    case 3: return function (a, b, c) {\n      return fn.call(that, a, b, c);\n    };\n  }\n  return function (/* ...args */) {\n    return fn.apply(that, arguments);\n  };\n};\n\n\n/***/ }),\n/* 28 */\n/***/ (function(module, exports) {\n\nvar toString = {}.toString;\n\nmodule.exports = function (it) {\n  return toString.call(it).slice(8, -1);\n};\n\n\n/***/ }),\n/* 29 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar fails = __webpack_require__(4);\n\nmodule.exports = function (method, arg) {\n  return !!method && fails(function () {\n    // eslint-disable-next-line no-useless-call\n    arg ? method.call(null, function () { /* empty */ }, 1) : method.call(null);\n  });\n};\n\n\n/***/ }),\n/* 30 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 7.1.1 ToPrimitive(input [, PreferredType])\nvar isObject = __webpack_require__(5);\n// instead of the ES6 spec version, we didn't implement @@toPrimitive case\n// and the second argument - flag - preferred type is a string\nmodule.exports = function (it, S) {\n  if (!isObject(it)) return it;\n  var fn, val;\n  if (S && typeof (fn = it.toString) == 'function' && !isObject(val = fn.call(it))) return val;\n  if (typeof (fn = it.valueOf) == 'function' && !isObject(val = fn.call(it))) return val;\n  if (!S && typeof (fn = it.toString) == 'function' && !isObject(val = fn.call(it))) return val;\n  throw TypeError(\"Can't convert object to primitive value\");\n};\n\n\n/***/ }),\n/* 31 */\n/***/ (function(module, exports) {\n\n// 7.2.1 RequireObjectCoercible(argument)\nmodule.exports = function (it) {\n  if (it == undefined) throw TypeError(\"Can't call method on  \" + it);\n  return it;\n};\n\n\n/***/ }),\n/* 32 */\n/***/ (function(module, exports) {\n\n// 7.1.4 ToInteger\nvar ceil = Math.ceil;\nvar floor = Math.floor;\nmodule.exports = function (it) {\n  return isNaN(it = +it) ? 0 : (it > 0 ? floor : ceil)(it);\n};\n\n\n/***/ }),\n/* 33 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// most Object methods by ES6 should accept primitives\nvar $export = __webpack_require__(0);\nvar core = __webpack_require__(26);\nvar fails = __webpack_require__(4);\nmodule.exports = function (KEY, exec) {\n  var fn = (core.Object || {})[KEY] || Object[KEY];\n  var exp = {};\n  exp[KEY] = exec(fn);\n  $export($export.S + $export.F * fails(function () { fn(1); }), 'Object', exp);\n};\n\n\n/***/ }),\n/* 34 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 0 -> Array#forEach\n// 1 -> Array#map\n// 2 -> Array#filter\n// 3 -> Array#some\n// 4 -> Array#every\n// 5 -> Array#find\n// 6 -> Array#findIndex\nvar ctx = __webpack_require__(27);\nvar IObject = __webpack_require__(62);\nvar toObject = __webpack_require__(14);\nvar toLength = __webpack_require__(11);\nvar asc = __webpack_require__(110);\nmodule.exports = function (TYPE, $create) {\n  var IS_MAP = TYPE == 1;\n  var IS_FILTER = TYPE == 2;\n  var IS_SOME = TYPE == 3;\n  var IS_EVERY = TYPE == 4;\n  var IS_FIND_INDEX = TYPE == 6;\n  var NO_HOLES = TYPE == 5 || IS_FIND_INDEX;\n  var create = $create || asc;\n  return function ($this, callbackfn, that) {\n    var O = toObject($this);\n    var self = IObject(O);\n    var f = ctx(callbackfn, that, 3);\n    var length = toLength(self.length);\n    var index = 0;\n    var result = IS_MAP ? create($this, length) : IS_FILTER ? create($this, 0) : undefined;\n    var val, res;\n    for (;length > index; index++) if (NO_HOLES || index in self) {\n      val = self[index];\n      res = f(val, index, O);\n      if (TYPE) {\n        if (IS_MAP) result[index] = res;   // map\n        else if (res) switch (TYPE) {\n          case 3: return true;             // some\n          case 5: return val;              // find\n          case 6: return index;            // findIndex\n          case 2: result.push(val);        // filter\n        } else if (IS_EVERY) return false; // every\n      }\n    }\n    return IS_FIND_INDEX ? -1 : IS_SOME || IS_EVERY ? IS_EVERY : result;\n  };\n};\n\n\n/***/ }),\n/* 35 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* eslint-disable node/no-deprecated-api */\nvar buffer = __webpack_require__(24)\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n\n\n/***/ }),\n/* 36 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nif (__webpack_require__(9)) {\n  var LIBRARY = __webpack_require__(40);\n  var global = __webpack_require__(3);\n  var fails = __webpack_require__(4);\n  var $export = __webpack_require__(0);\n  var $typed = __webpack_require__(81);\n  var $buffer = __webpack_require__(116);\n  var ctx = __webpack_require__(27);\n  var anInstance = __webpack_require__(50);\n  var propertyDesc = __webpack_require__(43);\n  var hide = __webpack_require__(16);\n  var redefineAll = __webpack_require__(52);\n  var toInteger = __webpack_require__(32);\n  var toLength = __webpack_require__(11);\n  var toIndex = __webpack_require__(171);\n  var toAbsoluteIndex = __webpack_require__(46);\n  var toPrimitive = __webpack_require__(30);\n  var has = __webpack_require__(19);\n  var classof = __webpack_require__(64);\n  var isObject = __webpack_require__(5);\n  var toObject = __webpack_require__(14);\n  var isArrayIter = __webpack_require__(107);\n  var create = __webpack_require__(47);\n  var getPrototypeOf = __webpack_require__(22);\n  var gOPN = __webpack_require__(48).f;\n  var getIterFn = __webpack_require__(109);\n  var uid = __webpack_require__(44);\n  var wks = __webpack_require__(7);\n  var createArrayMethod = __webpack_require__(34);\n  var createArrayIncludes = __webpack_require__(71);\n  var speciesConstructor = __webpack_require__(78);\n  var ArrayIterators = __webpack_require__(112);\n  var Iterators = __webpack_require__(58);\n  var $iterDetect = __webpack_require__(75);\n  var setSpecies = __webpack_require__(49);\n  var arrayFill = __webpack_require__(111);\n  var arrayCopyWithin = __webpack_require__(161);\n  var $DP = __webpack_require__(10);\n  var $GOPD = __webpack_require__(21);\n  var dP = $DP.f;\n  var gOPD = $GOPD.f;\n  var RangeError = global.RangeError;\n  var TypeError = global.TypeError;\n  var Uint8Array = global.Uint8Array;\n  var ARRAY_BUFFER = 'ArrayBuffer';\n  var SHARED_BUFFER = 'Shared' + ARRAY_BUFFER;\n  var BYTES_PER_ELEMENT = 'BYTES_PER_ELEMENT';\n  var PROTOTYPE = 'prototype';\n  var ArrayProto = Array[PROTOTYPE];\n  var $ArrayBuffer = $buffer.ArrayBuffer;\n  var $DataView = $buffer.DataView;\n  var arrayForEach = createArrayMethod(0);\n  var arrayFilter = createArrayMethod(2);\n  var arraySome = createArrayMethod(3);\n  var arrayEvery = createArrayMethod(4);\n  var arrayFind = createArrayMethod(5);\n  var arrayFindIndex = createArrayMethod(6);\n  var arrayIncludes = createArrayIncludes(true);\n  var arrayIndexOf = createArrayIncludes(false);\n  var arrayValues = ArrayIterators.values;\n  var arrayKeys = ArrayIterators.keys;\n  var arrayEntries = ArrayIterators.entries;\n  var arrayLastIndexOf = ArrayProto.lastIndexOf;\n  var arrayReduce = ArrayProto.reduce;\n  var arrayReduceRight = ArrayProto.reduceRight;\n  var arrayJoin = ArrayProto.join;\n  var arraySort = ArrayProto.sort;\n  var arraySlice = ArrayProto.slice;\n  var arrayToString = ArrayProto.toString;\n  var arrayToLocaleString = ArrayProto.toLocaleString;\n  var ITERATOR = wks('iterator');\n  var TAG = wks('toStringTag');\n  var TYPED_CONSTRUCTOR = uid('typed_constructor');\n  var DEF_CONSTRUCTOR = uid('def_constructor');\n  var ALL_CONSTRUCTORS = $typed.CONSTR;\n  var TYPED_ARRAY = $typed.TYPED;\n  var VIEW = $typed.VIEW;\n  var WRONG_LENGTH = 'Wrong length!';\n\n  var $map = createArrayMethod(1, function (O, length) {\n    return allocate(speciesConstructor(O, O[DEF_CONSTRUCTOR]), length);\n  });\n\n  var LITTLE_ENDIAN = fails(function () {\n    // eslint-disable-next-line no-undef\n    return new Uint8Array(new Uint16Array([1]).buffer)[0] === 1;\n  });\n\n  var FORCED_SET = !!Uint8Array && !!Uint8Array[PROTOTYPE].set && fails(function () {\n    new Uint8Array(1).set({});\n  });\n\n  var toOffset = function (it, BYTES) {\n    var offset = toInteger(it);\n    if (offset < 0 || offset % BYTES) throw RangeError('Wrong offset!');\n    return offset;\n  };\n\n  var validate = function (it) {\n    if (isObject(it) && TYPED_ARRAY in it) return it;\n    throw TypeError(it + ' is not a typed array!');\n  };\n\n  var allocate = function (C, length) {\n    if (!(isObject(C) && TYPED_CONSTRUCTOR in C)) {\n      throw TypeError('It is not a typed array constructor!');\n    } return new C(length);\n  };\n\n  var speciesFromList = function (O, list) {\n    return fromList(speciesConstructor(O, O[DEF_CONSTRUCTOR]), list);\n  };\n\n  var fromList = function (C, list) {\n    var index = 0;\n    var length = list.length;\n    var result = allocate(C, length);\n    while (length > index) result[index] = list[index++];\n    return result;\n  };\n\n  var addGetter = function (it, key, internal) {\n    dP(it, key, { get: function () { return this._d[internal]; } });\n  };\n\n  var $from = function from(source /* , mapfn, thisArg */) {\n    var O = toObject(source);\n    var aLen = arguments.length;\n    var mapfn = aLen > 1 ? arguments[1] : undefined;\n    var mapping = mapfn !== undefined;\n    var iterFn = getIterFn(O);\n    var i, length, values, result, step, iterator;\n    if (iterFn != undefined && !isArrayIter(iterFn)) {\n      for (iterator = iterFn.call(O), values = [], i = 0; !(step = iterator.next()).done; i++) {\n        values.push(step.value);\n      } O = values;\n    }\n    if (mapping && aLen > 2) mapfn = ctx(mapfn, arguments[2], 2);\n    for (i = 0, length = toLength(O.length), result = allocate(this, length); length > i; i++) {\n      result[i] = mapping ? mapfn(O[i], i) : O[i];\n    }\n    return result;\n  };\n\n  var $of = function of(/* ...items */) {\n    var index = 0;\n    var length = arguments.length;\n    var result = allocate(this, length);\n    while (length > index) result[index] = arguments[index++];\n    return result;\n  };\n\n  // iOS Safari 6.x fails here\n  var TO_LOCALE_BUG = !!Uint8Array && fails(function () { arrayToLocaleString.call(new Uint8Array(1)); });\n\n  var $toLocaleString = function toLocaleString() {\n    return arrayToLocaleString.apply(TO_LOCALE_BUG ? arraySlice.call(validate(this)) : validate(this), arguments);\n  };\n\n  var proto = {\n    copyWithin: function copyWithin(target, start /* , end */) {\n      return arrayCopyWithin.call(validate(this), target, start, arguments.length > 2 ? arguments[2] : undefined);\n    },\n    every: function every(callbackfn /* , thisArg */) {\n      return arrayEvery(validate(this), callbackfn, arguments.length > 1 ? arguments[1] : undefined);\n    },\n    fill: function fill(value /* , start, end */) { // eslint-disable-line no-unused-vars\n      return arrayFill.apply(validate(this), arguments);\n    },\n    filter: function filter(callbackfn /* , thisArg */) {\n      return speciesFromList(this, arrayFilter(validate(this), callbackfn,\n        arguments.length > 1 ? arguments[1] : undefined));\n    },\n    find: function find(predicate /* , thisArg */) {\n      return arrayFind(validate(this), predicate, arguments.length > 1 ? arguments[1] : undefined);\n    },\n    findIndex: function findIndex(predicate /* , thisArg */) {\n      return arrayFindIndex(validate(this), predicate, arguments.length > 1 ? arguments[1] : undefined);\n    },\n    forEach: function forEach(callbackfn /* , thisArg */) {\n      arrayForEach(validate(this), callbackfn, arguments.length > 1 ? arguments[1] : undefined);\n    },\n    indexOf: function indexOf(searchElement /* , fromIndex */) {\n      return arrayIndexOf(validate(this), searchElement, arguments.length > 1 ? arguments[1] : undefined);\n    },\n    includes: function includes(searchElement /* , fromIndex */) {\n      return arrayIncludes(validate(this), searchElement, arguments.length > 1 ? arguments[1] : undefined);\n    },\n    join: function join(separator) { // eslint-disable-line no-unused-vars\n      return arrayJoin.apply(validate(this), arguments);\n    },\n    lastIndexOf: function lastIndexOf(searchElement /* , fromIndex */) { // eslint-disable-line no-unused-vars\n      return arrayLastIndexOf.apply(validate(this), arguments);\n    },\n    map: function map(mapfn /* , thisArg */) {\n      return $map(validate(this), mapfn, arguments.length > 1 ? arguments[1] : undefined);\n    },\n    reduce: function reduce(callbackfn /* , initialValue */) { // eslint-disable-line no-unused-vars\n      return arrayReduce.apply(validate(this), arguments);\n    },\n    reduceRight: function reduceRight(callbackfn /* , initialValue */) { // eslint-disable-line no-unused-vars\n      return arrayReduceRight.apply(validate(this), arguments);\n    },\n    reverse: function reverse() {\n      var that = this;\n      var length = validate(that).length;\n      var middle = Math.floor(length / 2);\n      var index = 0;\n      var value;\n      while (index < middle) {\n        value = that[index];\n        that[index++] = that[--length];\n        that[length] = value;\n      } return that;\n    },\n    some: function some(callbackfn /* , thisArg */) {\n      return arraySome(validate(this), callbackfn, arguments.length > 1 ? arguments[1] : undefined);\n    },\n    sort: function sort(comparefn) {\n      return arraySort.call(validate(this), comparefn);\n    },\n    subarray: function subarray(begin, end) {\n      var O = validate(this);\n      var length = O.length;\n      var $begin = toAbsoluteIndex(begin, length);\n      return new (speciesConstructor(O, O[DEF_CONSTRUCTOR]))(\n        O.buffer,\n        O.byteOffset + $begin * O.BYTES_PER_ELEMENT,\n        toLength((end === undefined ? length : toAbsoluteIndex(end, length)) - $begin)\n      );\n    }\n  };\n\n  var $slice = function slice(start, end) {\n    return speciesFromList(this, arraySlice.call(validate(this), start, end));\n  };\n\n  var $set = function set(arrayLike /* , offset */) {\n    validate(this);\n    var offset = toOffset(arguments[1], 1);\n    var length = this.length;\n    var src = toObject(arrayLike);\n    var len = toLength(src.length);\n    var index = 0;\n    if (len + offset > length) throw RangeError(WRONG_LENGTH);\n    while (index < len) this[offset + index] = src[index++];\n  };\n\n  var $iterators = {\n    entries: function entries() {\n      return arrayEntries.call(validate(this));\n    },\n    keys: function keys() {\n      return arrayKeys.call(validate(this));\n    },\n    values: function values() {\n      return arrayValues.call(validate(this));\n    }\n  };\n\n  var isTAIndex = function (target, key) {\n    return isObject(target)\n      && target[TYPED_ARRAY]\n      && typeof key != 'symbol'\n      && key in target\n      && String(+key) == String(key);\n  };\n  var $getDesc = function getOwnPropertyDescriptor(target, key) {\n    return isTAIndex(target, key = toPrimitive(key, true))\n      ? propertyDesc(2, target[key])\n      : gOPD(target, key);\n  };\n  var $setDesc = function defineProperty(target, key, desc) {\n    if (isTAIndex(target, key = toPrimitive(key, true))\n      && isObject(desc)\n      && has(desc, 'value')\n      && !has(desc, 'get')\n      && !has(desc, 'set')\n      // TODO: add validation descriptor w/o calling accessors\n      && !desc.configurable\n      && (!has(desc, 'writable') || desc.writable)\n      && (!has(desc, 'enumerable') || desc.enumerable)\n    ) {\n      target[key] = desc.value;\n      return target;\n    } return dP(target, key, desc);\n  };\n\n  if (!ALL_CONSTRUCTORS) {\n    $GOPD.f = $getDesc;\n    $DP.f = $setDesc;\n  }\n\n  $export($export.S + $export.F * !ALL_CONSTRUCTORS, 'Object', {\n    getOwnPropertyDescriptor: $getDesc,\n    defineProperty: $setDesc\n  });\n\n  if (fails(function () { arrayToString.call({}); })) {\n    arrayToString = arrayToLocaleString = function toString() {\n      return arrayJoin.call(this);\n    };\n  }\n\n  var $TypedArrayPrototype$ = redefineAll({}, proto);\n  redefineAll($TypedArrayPrototype$, $iterators);\n  hide($TypedArrayPrototype$, ITERATOR, $iterators.values);\n  redefineAll($TypedArrayPrototype$, {\n    slice: $slice,\n    set: $set,\n    constructor: function () { /* noop */ },\n    toString: arrayToString,\n    toLocaleString: $toLocaleString\n  });\n  addGetter($TypedArrayPrototype$, 'buffer', 'b');\n  addGetter($TypedArrayPrototype$, 'byteOffset', 'o');\n  addGetter($TypedArrayPrototype$, 'byteLength', 'l');\n  addGetter($TypedArrayPrototype$, 'length', 'e');\n  dP($TypedArrayPrototype$, TAG, {\n    get: function () { return this[TYPED_ARRAY]; }\n  });\n\n  // eslint-disable-next-line max-statements\n  module.exports = function (KEY, BYTES, wrapper, CLAMPED) {\n    CLAMPED = !!CLAMPED;\n    var NAME = KEY + (CLAMPED ? 'Clamped' : '') + 'Array';\n    var GETTER = 'get' + KEY;\n    var SETTER = 'set' + KEY;\n    var TypedArray = global[NAME];\n    var Base = TypedArray || {};\n    var TAC = TypedArray && getPrototypeOf(TypedArray);\n    var FORCED = !TypedArray || !$typed.ABV;\n    var O = {};\n    var TypedArrayPrototype = TypedArray && TypedArray[PROTOTYPE];\n    var getter = function (that, index) {\n      var data = that._d;\n      return data.v[GETTER](index * BYTES + data.o, LITTLE_ENDIAN);\n    };\n    var setter = function (that, index, value) {\n      var data = that._d;\n      if (CLAMPED) value = (value = Math.round(value)) < 0 ? 0 : value > 0xff ? 0xff : value & 0xff;\n      data.v[SETTER](index * BYTES + data.o, value, LITTLE_ENDIAN);\n    };\n    var addElement = function (that, index) {\n      dP(that, index, {\n        get: function () {\n          return getter(this, index);\n        },\n        set: function (value) {\n          return setter(this, index, value);\n        },\n        enumerable: true\n      });\n    };\n    if (FORCED) {\n      TypedArray = wrapper(function (that, data, $offset, $length) {\n        anInstance(that, TypedArray, NAME, '_d');\n        var index = 0;\n        var offset = 0;\n        var buffer, byteLength, length, klass;\n        if (!isObject(data)) {\n          length = toIndex(data);\n          byteLength = length * BYTES;\n          buffer = new $ArrayBuffer(byteLength);\n        } else if (data instanceof $ArrayBuffer || (klass = classof(data)) == ARRAY_BUFFER || klass == SHARED_BUFFER) {\n          buffer = data;\n          offset = toOffset($offset, BYTES);\n          var $len = data.byteLength;\n          if ($length === undefined) {\n            if ($len % BYTES) throw RangeError(WRONG_LENGTH);\n            byteLength = $len - offset;\n            if (byteLength < 0) throw RangeError(WRONG_LENGTH);\n          } else {\n            byteLength = toLength($length) * BYTES;\n            if (byteLength + offset > $len) throw RangeError(WRONG_LENGTH);\n          }\n          length = byteLength / BYTES;\n        } else if (TYPED_ARRAY in data) {\n          return fromList(TypedArray, data);\n        } else {\n          return $from.call(TypedArray, data);\n        }\n        hide(that, '_d', {\n          b: buffer,\n          o: offset,\n          l: byteLength,\n          e: length,\n          v: new $DataView(buffer)\n        });\n        while (index < length) addElement(that, index++);\n      });\n      TypedArrayPrototype = TypedArray[PROTOTYPE] = create($TypedArrayPrototype$);\n      hide(TypedArrayPrototype, 'constructor', TypedArray);\n    } else if (!fails(function () {\n      TypedArray(1);\n    }) || !fails(function () {\n      new TypedArray(-1); // eslint-disable-line no-new\n    }) || !$iterDetect(function (iter) {\n      new TypedArray(); // eslint-disable-line no-new\n      new TypedArray(null); // eslint-disable-line no-new\n      new TypedArray(1.5); // eslint-disable-line no-new\n      new TypedArray(iter); // eslint-disable-line no-new\n    }, true)) {\n      TypedArray = wrapper(function (that, data, $offset, $length) {\n        anInstance(that, TypedArray, NAME);\n        var klass;\n        // `ws` module bug, temporarily remove validation length for Uint8Array\n        // https://github.com/websockets/ws/pull/645\n        if (!isObject(data)) return new Base(toIndex(data));\n        if (data instanceof $ArrayBuffer || (klass = classof(data)) == ARRAY_BUFFER || klass == SHARED_BUFFER) {\n          return $length !== undefined\n            ? new Base(data, toOffset($offset, BYTES), $length)\n            : $offset !== undefined\n              ? new Base(data, toOffset($offset, BYTES))\n              : new Base(data);\n        }\n        if (TYPED_ARRAY in data) return fromList(TypedArray, data);\n        return $from.call(TypedArray, data);\n      });\n      arrayForEach(TAC !== Function.prototype ? gOPN(Base).concat(gOPN(TAC)) : gOPN(Base), function (key) {\n        if (!(key in TypedArray)) hide(TypedArray, key, Base[key]);\n      });\n      TypedArray[PROTOTYPE] = TypedArrayPrototype;\n      if (!LIBRARY) TypedArrayPrototype.constructor = TypedArray;\n    }\n    var $nativeIterator = TypedArrayPrototype[ITERATOR];\n    var CORRECT_ITER_NAME = !!$nativeIterator\n      && ($nativeIterator.name == 'values' || $nativeIterator.name == undefined);\n    var $iterator = $iterators.values;\n    hide(TypedArray, TYPED_CONSTRUCTOR, true);\n    hide(TypedArrayPrototype, TYPED_ARRAY, NAME);\n    hide(TypedArrayPrototype, VIEW, true);\n    hide(TypedArrayPrototype, DEF_CONSTRUCTOR, TypedArray);\n\n    if (CLAMPED ? new TypedArray(1)[TAG] != NAME : !(TAG in TypedArrayPrototype)) {\n      dP(TypedArrayPrototype, TAG, {\n        get: function () { return NAME; }\n      });\n    }\n\n    O[NAME] = TypedArray;\n\n    $export($export.G + $export.W + $export.F * (TypedArray != Base), O);\n\n    $export($export.S, NAME, {\n      BYTES_PER_ELEMENT: BYTES\n    });\n\n    $export($export.S + $export.F * fails(function () { Base.of.call(TypedArray, 1); }), NAME, {\n      from: $from,\n      of: $of\n    });\n\n    if (!(BYTES_PER_ELEMENT in TypedArrayPrototype)) hide(TypedArrayPrototype, BYTES_PER_ELEMENT, BYTES);\n\n    $export($export.P, NAME, proto);\n\n    setSpecies(NAME);\n\n    $export($export.P + $export.F * FORCED_SET, NAME, { set: $set });\n\n    $export($export.P + $export.F * !CORRECT_ITER_NAME, NAME, $iterators);\n\n    if (!LIBRARY && TypedArrayPrototype.toString != arrayToString) TypedArrayPrototype.toString = arrayToString;\n\n    $export($export.P + $export.F * fails(function () {\n      new TypedArray(1).slice();\n    }), NAME, { slice: $slice });\n\n    $export($export.P + $export.F * (fails(function () {\n      return [1, 2].toLocaleString() != new TypedArray([1, 2]).toLocaleString();\n    }) || !fails(function () {\n      TypedArrayPrototype.toLocaleString.call([1, 2]);\n    })), NAME, { toLocaleString: $toLocaleString });\n\n    Iterators[NAME] = CORRECT_ITER_NAME ? $nativeIterator : $iterator;\n    if (!LIBRARY && !CORRECT_ITER_NAME) hide(TypedArrayPrototype, ITERATOR, $iterator);\n  };\n} else module.exports = function () { /* empty */ };\n\n\n/***/ }),\n/* 37 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar Map = __webpack_require__(166);\nvar $export = __webpack_require__(0);\nvar shared = __webpack_require__(70)('metadata');\nvar store = shared.store || (shared.store = new (__webpack_require__(169))());\n\nvar getOrCreateMetadataMap = function (target, targetKey, create) {\n  var targetMetadata = store.get(target);\n  if (!targetMetadata) {\n    if (!create) return undefined;\n    store.set(target, targetMetadata = new Map());\n  }\n  var keyMetadata = targetMetadata.get(targetKey);\n  if (!keyMetadata) {\n    if (!create) return undefined;\n    targetMetadata.set(targetKey, keyMetadata = new Map());\n  } return keyMetadata;\n};\nvar ordinaryHasOwnMetadata = function (MetadataKey, O, P) {\n  var metadataMap = getOrCreateMetadataMap(O, P, false);\n  return metadataMap === undefined ? false : metadataMap.has(MetadataKey);\n};\nvar ordinaryGetOwnMetadata = function (MetadataKey, O, P) {\n  var metadataMap = getOrCreateMetadataMap(O, P, false);\n  return metadataMap === undefined ? undefined : metadataMap.get(MetadataKey);\n};\nvar ordinaryDefineOwnMetadata = function (MetadataKey, MetadataValue, O, P) {\n  getOrCreateMetadataMap(O, P, true).set(MetadataKey, MetadataValue);\n};\nvar ordinaryOwnMetadataKeys = function (target, targetKey) {\n  var metadataMap = getOrCreateMetadataMap(target, targetKey, false);\n  var keys = [];\n  if (metadataMap) metadataMap.forEach(function (_, key) { keys.push(key); });\n  return keys;\n};\nvar toMetaKey = function (it) {\n  return it === undefined || typeof it == 'symbol' ? it : String(it);\n};\nvar exp = function (O) {\n  $export($export.S, 'Reflect', O);\n};\n\nmodule.exports = {\n  store: store,\n  map: getOrCreateMetadataMap,\n  has: ordinaryHasOwnMetadata,\n  get: ordinaryGetOwnMetadata,\n  set: ordinaryDefineOwnMetadata,\n  keys: ordinaryOwnMetadataKeys,\n  key: toMetaKey,\n  exp: exp\n};\n\n\n/***/ }),\n/* 38 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Constructors cached from literals.\n * @version 1.0.2\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module cached-constructors-x\n */\n\n\n\n/**\n * Constructors cached from literals.\n *\n * @type Object\n * @example\n * var constructors = require('cached-constructors-x');\n */\nmodule.exports = {\n  Array: [].constructor,\n  Boolean: true.constructor,\n  Function: function () {}.constructor,\n  Number: (0).constructor,\n  Object: {}.constructor,\n  RegExp: (/(?:)/).constructor,\n  String: ''.constructor\n};\n\n\n/***/ }),\n/* 39 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar META = __webpack_require__(44)('meta');\nvar isObject = __webpack_require__(5);\nvar has = __webpack_require__(19);\nvar setDesc = __webpack_require__(10).f;\nvar id = 0;\nvar isExtensible = Object.isExtensible || function () {\n  return true;\n};\nvar FREEZE = !__webpack_require__(4)(function () {\n  return isExtensible(Object.preventExtensions({}));\n});\nvar setMeta = function (it) {\n  setDesc(it, META, { value: {\n    i: 'O' + ++id, // object ID\n    w: {}          // weak collections IDs\n  } });\n};\nvar fastKey = function (it, create) {\n  // return primitive with prefix\n  if (!isObject(it)) return typeof it == 'symbol' ? it : (typeof it == 'string' ? 'S' : 'P') + it;\n  if (!has(it, META)) {\n    // can't set metadata to uncaught frozen object\n    if (!isExtensible(it)) return 'F';\n    // not necessary to add metadata\n    if (!create) return 'E';\n    // add missing metadata\n    setMeta(it);\n  // return object ID\n  } return it[META].i;\n};\nvar getWeak = function (it, create) {\n  if (!has(it, META)) {\n    // can't set metadata to uncaught frozen object\n    if (!isExtensible(it)) return true;\n    // not necessary to add metadata\n    if (!create) return false;\n    // add missing metadata\n    setMeta(it);\n  // return hash weak collections IDs\n  } return it[META].w;\n};\n// add metadata on freeze-family methods calling\nvar onFreeze = function (it) {\n  if (FREEZE && meta.NEED && isExtensible(it) && !has(it, META)) setMeta(it);\n  return it;\n};\nvar meta = module.exports = {\n  KEY: META,\n  NEED: false,\n  fastKey: fastKey,\n  getWeak: getWeak,\n  onFreeze: onFreeze\n};\n\n\n/***/ }),\n/* 40 */\n/***/ (function(module, exports) {\n\nmodule.exports = false;\n\n\n/***/ }),\n/* 41 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 22.1.3.31 Array.prototype[@@unscopables]\nvar UNSCOPABLES = __webpack_require__(7)('unscopables');\nvar ArrayProto = Array.prototype;\nif (ArrayProto[UNSCOPABLES] == undefined) __webpack_require__(16)(ArrayProto, UNSCOPABLES, {});\nmodule.exports = function (key) {\n  ArrayProto[UNSCOPABLES][key] = true;\n};\n\n\n/***/ }),\n/* 42 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(35).Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}\n\n/***/ }),\n/* 43 */\n/***/ (function(module, exports) {\n\nmodule.exports = function (bitmap, value) {\n  return {\n    enumerable: !(bitmap & 1),\n    configurable: !(bitmap & 2),\n    writable: !(bitmap & 4),\n    value: value\n  };\n};\n\n\n/***/ }),\n/* 44 */\n/***/ (function(module, exports) {\n\nvar id = 0;\nvar px = Math.random();\nmodule.exports = function (key) {\n  return 'Symbol('.concat(key === undefined ? '' : key, ')_', (++id + px).toString(36));\n};\n\n\n/***/ }),\n/* 45 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.14 / 15.2.3.14 Object.keys(O)\nvar $keys = __webpack_require__(147);\nvar enumBugKeys = __webpack_require__(94);\n\nmodule.exports = Object.keys || function keys(O) {\n  return $keys(O, enumBugKeys);\n};\n\n\n/***/ }),\n/* 46 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar toInteger = __webpack_require__(32);\nvar max = Math.max;\nvar min = Math.min;\nmodule.exports = function (index, length) {\n  index = toInteger(index);\n  return index < 0 ? max(index + length, 0) : min(index, length);\n};\n\n\n/***/ }),\n/* 47 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.2 / 15.2.3.5 Object.create(O [, Properties])\nvar anObject = __webpack_require__(2);\nvar dPs = __webpack_require__(148);\nvar enumBugKeys = __webpack_require__(94);\nvar IE_PROTO = __webpack_require__(93)('IE_PROTO');\nvar Empty = function () { /* empty */ };\nvar PROTOTYPE = 'prototype';\n\n// Create object with fake `null` prototype: use iframe Object with cleared prototype\nvar createDict = function () {\n  // Thrash, waste and sodomy: IE GC bug\n  var iframe = __webpack_require__(91)('iframe');\n  var i = enumBugKeys.length;\n  var lt = '<';\n  var gt = '>';\n  var iframeDocument;\n  iframe.style.display = 'none';\n  __webpack_require__(95).appendChild(iframe);\n  iframe.src = 'javascript:'; // eslint-disable-line no-script-url\n  // createDict = iframe.contentWindow.Object;\n  // html.removeChild(iframe);\n  iframeDocument = iframe.contentWindow.document;\n  iframeDocument.open();\n  iframeDocument.write(lt + 'script' + gt + 'document.F=Object' + lt + '/script' + gt);\n  iframeDocument.close();\n  createDict = iframeDocument.F;\n  while (i--) delete createDict[PROTOTYPE][enumBugKeys[i]];\n  return createDict();\n};\n\nmodule.exports = Object.create || function create(O, Properties) {\n  var result;\n  if (O !== null) {\n    Empty[PROTOTYPE] = anObject(O);\n    result = new Empty();\n    Empty[PROTOTYPE] = null;\n    // add \"__proto__\" for Object.getPrototypeOf polyfill\n    result[IE_PROTO] = O;\n  } else result = createDict();\n  return Properties === undefined ? result : dPs(result, Properties);\n};\n\n\n/***/ }),\n/* 48 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.7 / 15.2.3.4 Object.getOwnPropertyNames(O)\nvar $keys = __webpack_require__(147);\nvar hiddenKeys = __webpack_require__(94).concat('length', 'prototype');\n\nexports.f = Object.getOwnPropertyNames || function getOwnPropertyNames(O) {\n  return $keys(O, hiddenKeys);\n};\n\n\n/***/ }),\n/* 49 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar global = __webpack_require__(3);\nvar dP = __webpack_require__(10);\nvar DESCRIPTORS = __webpack_require__(9);\nvar SPECIES = __webpack_require__(7)('species');\n\nmodule.exports = function (KEY) {\n  var C = global[KEY];\n  if (DESCRIPTORS && C && !C[SPECIES]) dP.f(C, SPECIES, {\n    configurable: true,\n    get: function () { return this; }\n  });\n};\n\n\n/***/ }),\n/* 50 */\n/***/ (function(module, exports) {\n\nmodule.exports = function (it, Constructor, name, forbiddenField) {\n  if (!(it instanceof Constructor) || (forbiddenField !== undefined && forbiddenField in it)) {\n    throw TypeError(name + ': incorrect invocation!');\n  } return it;\n};\n\n\n/***/ }),\n/* 51 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar ctx = __webpack_require__(27);\nvar call = __webpack_require__(159);\nvar isArrayIter = __webpack_require__(107);\nvar anObject = __webpack_require__(2);\nvar toLength = __webpack_require__(11);\nvar getIterFn = __webpack_require__(109);\nvar BREAK = {};\nvar RETURN = {};\nvar exports = module.exports = function (iterable, entries, fn, that, ITERATOR) {\n  var iterFn = ITERATOR ? function () { return iterable; } : getIterFn(iterable);\n  var f = ctx(fn, that, entries ? 2 : 1);\n  var index = 0;\n  var length, step, iterator, result;\n  if (typeof iterFn != 'function') throw TypeError(iterable + ' is not iterable!');\n  // fast case for arrays with default iterator\n  if (isArrayIter(iterFn)) for (length = toLength(iterable.length); length > index; index++) {\n    result = entries ? f(anObject(step = iterable[index])[0], step[1]) : f(iterable[index]);\n    if (result === BREAK || result === RETURN) return result;\n  } else for (iterator = iterFn.call(iterable); !(step = iterator.next()).done;) {\n    result = call(iterator, f, step.value, entries);\n    if (result === BREAK || result === RETURN) return result;\n  }\n};\nexports.BREAK = BREAK;\nexports.RETURN = RETURN;\n\n\n/***/ }),\n/* 52 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar redefine = __webpack_require__(17);\nmodule.exports = function (target, src, safe) {\n  for (var key in src) redefine(target, key, src[key], safe);\n  return target;\n};\n\n\n/***/ }),\n/* 53 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(25);\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nvar Readable = __webpack_require__(199);\nvar Writable = __webpack_require__(128);\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};\n\n/***/ }),\n/* 54 */,\n/* 55 */,\n/* 56 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar def = __webpack_require__(10).f;\nvar has = __webpack_require__(19);\nvar TAG = __webpack_require__(7)('toStringTag');\n\nmodule.exports = function (it, tag, stat) {\n  if (it && !has(it = stat ? it : it.prototype, TAG)) def(it, TAG, { configurable: true, value: tag });\n};\n\n\n/***/ }),\n/* 57 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\nvar defined = __webpack_require__(31);\nvar fails = __webpack_require__(4);\nvar spaces = __webpack_require__(97);\nvar space = '[' + spaces + ']';\nvar non = '\\u200b\\u0085';\nvar ltrim = RegExp('^' + space + space + '*');\nvar rtrim = RegExp(space + space + '*$');\n\nvar exporter = function (KEY, exec, ALIAS) {\n  var exp = {};\n  var FORCE = fails(function () {\n    return !!spaces[KEY]() || non[KEY]() != non;\n  });\n  var fn = exp[KEY] = FORCE ? exec(trim) : spaces[KEY];\n  if (ALIAS) exp[ALIAS] = fn;\n  $export($export.P + $export.F * FORCE, 'String', exp);\n};\n\n// 1 -> String#trimLeft\n// 2 -> String#trimRight\n// 3 -> String#trim\nvar trim = exporter.trim = function (string, TYPE) {\n  string = String(defined(string));\n  if (TYPE & 1) string = string.replace(ltrim, '');\n  if (TYPE & 2) string = string.replace(rtrim, '');\n  return string;\n};\n\nmodule.exports = exporter;\n\n\n/***/ }),\n/* 58 */\n/***/ (function(module, exports) {\n\nmodule.exports = {};\n\n\n/***/ }),\n/* 59 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar isObject = __webpack_require__(5);\nmodule.exports = function (it, TYPE) {\n  if (!isObject(it) || it._t !== TYPE) throw TypeError('Incompatible receiver, ' + TYPE + ' required!');\n  return it;\n};\n\n\n/***/ }),\n/* 60 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(25);\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nvar Readable = __webpack_require__(192);\nvar Writable = __webpack_require__(195);\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};\n\n/***/ }),\n/* 61 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(25);\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nvar Readable = __webpack_require__(206);\nvar Writable = __webpack_require__(209);\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};\n\n/***/ }),\n/* 62 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// fallback for non-array-like ES3 and non-enumerable old V8 strings\nvar cof = __webpack_require__(28);\n// eslint-disable-next-line no-prototype-builtins\nmodule.exports = Object('z').propertyIsEnumerable(0) ? Object : function (it) {\n  return cof(it) == 'String' ? it.split('') : Object(it);\n};\n\n\n/***/ }),\n/* 63 */\n/***/ (function(module, exports) {\n\nexports.f = {}.propertyIsEnumerable;\n\n\n/***/ }),\n/* 64 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// getting tag from 19.1.3.6 Object.prototype.toString()\nvar cof = __webpack_require__(28);\nvar TAG = __webpack_require__(7)('toStringTag');\n// ES3 wrong here\nvar ARG = cof(function () { return arguments; }()) == 'Arguments';\n\n// fallback for IE11 Script Access Denied error\nvar tryGet = function (it, key) {\n  try {\n    return it[key];\n  } catch (e) { /* empty */ }\n};\n\nmodule.exports = function (it) {\n  var O, T, B;\n  return it === undefined ? 'Undefined' : it === null ? 'Null'\n    // @@toStringTag case\n    : typeof (T = tryGet(O = Object(it), TAG)) == 'string' ? T\n    // builtinTag case\n    : ARG ? cof(O)\n    // ES3 arguments fallback\n    : (B = cof(O)) == 'Object' && typeof O.callee == 'function' ? 'Arguments' : B;\n};\n\n\n/***/ }),\n/* 65 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(global, process) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar formatRegExp = /%[sdj%]/g;\nexports.format = function(f) {\n  if (!isString(f)) {\n    var objects = [];\n    for (var i = 0; i < arguments.length; i++) {\n      objects.push(inspect(arguments[i]));\n    }\n    return objects.join(' ');\n  }\n\n  var i = 1;\n  var args = arguments;\n  var len = args.length;\n  var str = String(f).replace(formatRegExp, function(x) {\n    if (x === '%%') return '%';\n    if (i >= len) return x;\n    switch (x) {\n      case '%s': return String(args[i++]);\n      case '%d': return Number(args[i++]);\n      case '%j':\n        try {\n          return JSON.stringify(args[i++]);\n        } catch (_) {\n          return '[Circular]';\n        }\n      default:\n        return x;\n    }\n  });\n  for (var x = args[i]; i < len; x = args[++i]) {\n    if (isNull(x) || !isObject(x)) {\n      str += ' ' + x;\n    } else {\n      str += ' ' + inspect(x);\n    }\n  }\n  return str;\n};\n\n\n// Mark that a method should not be used.\n// Returns a modified function which warns once by default.\n// If --no-deprecation is set, then it is a no-op.\nexports.deprecate = function(fn, msg) {\n  // Allow for deprecating things in the process of starting up.\n  if (isUndefined(global.process)) {\n    return function() {\n      return exports.deprecate(fn, msg).apply(this, arguments);\n    };\n  }\n\n  if (process.noDeprecation === true) {\n    return fn;\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (process.throwDeprecation) {\n        throw new Error(msg);\n      } else if (process.traceDeprecation) {\n        console.trace(msg);\n      } else {\n        console.error(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n};\n\n\nvar debugs = {};\nvar debugEnviron;\nexports.debuglog = function(set) {\n  if (isUndefined(debugEnviron))\n    debugEnviron = process.env.NODE_DEBUG || '';\n  set = set.toUpperCase();\n  if (!debugs[set]) {\n    if (new RegExp('\\\\b' + set + '\\\\b', 'i').test(debugEnviron)) {\n      var pid = process.pid;\n      debugs[set] = function() {\n        var msg = exports.format.apply(exports, arguments);\n        console.error('%s %d: %s', set, pid, msg);\n      };\n    } else {\n      debugs[set] = function() {};\n    }\n  }\n  return debugs[set];\n};\n\n\n/**\n * Echos the value of a value. Trys to print the value out\n * in the best way possible given the different types.\n *\n * @param {Object} obj The object to print out.\n * @param {Object} opts Optional options object that alters the output.\n */\n/* legacy: obj, showHidden, depth, colors*/\nfunction inspect(obj, opts) {\n  // default options\n  var ctx = {\n    seen: [],\n    stylize: stylizeNoColor\n  };\n  // legacy...\n  if (arguments.length >= 3) ctx.depth = arguments[2];\n  if (arguments.length >= 4) ctx.colors = arguments[3];\n  if (isBoolean(opts)) {\n    // legacy...\n    ctx.showHidden = opts;\n  } else if (opts) {\n    // got an \"options\" object\n    exports._extend(ctx, opts);\n  }\n  // set default options\n  if (isUndefined(ctx.showHidden)) ctx.showHidden = false;\n  if (isUndefined(ctx.depth)) ctx.depth = 2;\n  if (isUndefined(ctx.colors)) ctx.colors = false;\n  if (isUndefined(ctx.customInspect)) ctx.customInspect = true;\n  if (ctx.colors) ctx.stylize = stylizeWithColor;\n  return formatValue(ctx, obj, ctx.depth);\n}\nexports.inspect = inspect;\n\n\n// http://en.wikipedia.org/wiki/ANSI_escape_code#graphics\ninspect.colors = {\n  'bold' : [1, 22],\n  'italic' : [3, 23],\n  'underline' : [4, 24],\n  'inverse' : [7, 27],\n  'white' : [37, 39],\n  'grey' : [90, 39],\n  'black' : [30, 39],\n  'blue' : [34, 39],\n  'cyan' : [36, 39],\n  'green' : [32, 39],\n  'magenta' : [35, 39],\n  'red' : [31, 39],\n  'yellow' : [33, 39]\n};\n\n// Don't use 'blue' not visible on cmd.exe\ninspect.styles = {\n  'special': 'cyan',\n  'number': 'yellow',\n  'boolean': 'yellow',\n  'undefined': 'grey',\n  'null': 'bold',\n  'string': 'green',\n  'date': 'magenta',\n  // \"name\": intentionally not styling\n  'regexp': 'red'\n};\n\n\nfunction stylizeWithColor(str, styleType) {\n  var style = inspect.styles[styleType];\n\n  if (style) {\n    return '\\u001b[' + inspect.colors[style][0] + 'm' + str +\n           '\\u001b[' + inspect.colors[style][1] + 'm';\n  } else {\n    return str;\n  }\n}\n\n\nfunction stylizeNoColor(str, styleType) {\n  return str;\n}\n\n\nfunction arrayToHash(array) {\n  var hash = {};\n\n  array.forEach(function(val, idx) {\n    hash[val] = true;\n  });\n\n  return hash;\n}\n\n\nfunction formatValue(ctx, value, recurseTimes) {\n  // Provide a hook for user-specified inspect functions.\n  // Check that value is an object with an inspect function on it\n  if (ctx.customInspect &&\n      value &&\n      isFunction(value.inspect) &&\n      // Filter out the util module, it's inspect function is special\n      value.inspect !== exports.inspect &&\n      // Also filter out any prototype objects using the circular check.\n      !(value.constructor && value.constructor.prototype === value)) {\n    var ret = value.inspect(recurseTimes, ctx);\n    if (!isString(ret)) {\n      ret = formatValue(ctx, ret, recurseTimes);\n    }\n    return ret;\n  }\n\n  // Primitive types cannot have properties\n  var primitive = formatPrimitive(ctx, value);\n  if (primitive) {\n    return primitive;\n  }\n\n  // Look up the keys of the object.\n  var keys = Object.keys(value);\n  var visibleKeys = arrayToHash(keys);\n\n  if (ctx.showHidden) {\n    keys = Object.getOwnPropertyNames(value);\n  }\n\n  // IE doesn't make error fields non-enumerable\n  // http://msdn.microsoft.com/en-us/library/ie/dww52sbt(v=vs.94).aspx\n  if (isError(value)\n      && (keys.indexOf('message') >= 0 || keys.indexOf('description') >= 0)) {\n    return formatError(value);\n  }\n\n  // Some type of object without properties can be shortcutted.\n  if (keys.length === 0) {\n    if (isFunction(value)) {\n      var name = value.name ? ': ' + value.name : '';\n      return ctx.stylize('[Function' + name + ']', 'special');\n    }\n    if (isRegExp(value)) {\n      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');\n    }\n    if (isDate(value)) {\n      return ctx.stylize(Date.prototype.toString.call(value), 'date');\n    }\n    if (isError(value)) {\n      return formatError(value);\n    }\n  }\n\n  var base = '', array = false, braces = ['{', '}'];\n\n  // Make Array say that they are Array\n  if (isArray(value)) {\n    array = true;\n    braces = ['[', ']'];\n  }\n\n  // Make functions say that they are functions\n  if (isFunction(value)) {\n    var n = value.name ? ': ' + value.name : '';\n    base = ' [Function' + n + ']';\n  }\n\n  // Make RegExps say that they are RegExps\n  if (isRegExp(value)) {\n    base = ' ' + RegExp.prototype.toString.call(value);\n  }\n\n  // Make dates with properties first say the date\n  if (isDate(value)) {\n    base = ' ' + Date.prototype.toUTCString.call(value);\n  }\n\n  // Make error with message first say the error\n  if (isError(value)) {\n    base = ' ' + formatError(value);\n  }\n\n  if (keys.length === 0 && (!array || value.length == 0)) {\n    return braces[0] + base + braces[1];\n  }\n\n  if (recurseTimes < 0) {\n    if (isRegExp(value)) {\n      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');\n    } else {\n      return ctx.stylize('[Object]', 'special');\n    }\n  }\n\n  ctx.seen.push(value);\n\n  var output;\n  if (array) {\n    output = formatArray(ctx, value, recurseTimes, visibleKeys, keys);\n  } else {\n    output = keys.map(function(key) {\n      return formatProperty(ctx, value, recurseTimes, visibleKeys, key, array);\n    });\n  }\n\n  ctx.seen.pop();\n\n  return reduceToSingleString(output, base, braces);\n}\n\n\nfunction formatPrimitive(ctx, value) {\n  if (isUndefined(value))\n    return ctx.stylize('undefined', 'undefined');\n  if (isString(value)) {\n    var simple = '\\'' + JSON.stringify(value).replace(/^\"|\"$/g, '')\n                                             .replace(/'/g, \"\\\\'\")\n                                             .replace(/\\\\\"/g, '\"') + '\\'';\n    return ctx.stylize(simple, 'string');\n  }\n  if (isNumber(value))\n    return ctx.stylize('' + value, 'number');\n  if (isBoolean(value))\n    return ctx.stylize('' + value, 'boolean');\n  // For some reason typeof null is \"object\", so special case here.\n  if (isNull(value))\n    return ctx.stylize('null', 'null');\n}\n\n\nfunction formatError(value) {\n  return '[' + Error.prototype.toString.call(value) + ']';\n}\n\n\nfunction formatArray(ctx, value, recurseTimes, visibleKeys, keys) {\n  var output = [];\n  for (var i = 0, l = value.length; i < l; ++i) {\n    if (hasOwnProperty(value, String(i))) {\n      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,\n          String(i), true));\n    } else {\n      output.push('');\n    }\n  }\n  keys.forEach(function(key) {\n    if (!key.match(/^\\d+$/)) {\n      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,\n          key, true));\n    }\n  });\n  return output;\n}\n\n\nfunction formatProperty(ctx, value, recurseTimes, visibleKeys, key, array) {\n  var name, str, desc;\n  desc = Object.getOwnPropertyDescriptor(value, key) || { value: value[key] };\n  if (desc.get) {\n    if (desc.set) {\n      str = ctx.stylize('[Getter/Setter]', 'special');\n    } else {\n      str = ctx.stylize('[Getter]', 'special');\n    }\n  } else {\n    if (desc.set) {\n      str = ctx.stylize('[Setter]', 'special');\n    }\n  }\n  if (!hasOwnProperty(visibleKeys, key)) {\n    name = '[' + key + ']';\n  }\n  if (!str) {\n    if (ctx.seen.indexOf(desc.value) < 0) {\n      if (isNull(recurseTimes)) {\n        str = formatValue(ctx, desc.value, null);\n      } else {\n        str = formatValue(ctx, desc.value, recurseTimes - 1);\n      }\n      if (str.indexOf('\\n') > -1) {\n        if (array) {\n          str = str.split('\\n').map(function(line) {\n            return '  ' + line;\n          }).join('\\n').substr(2);\n        } else {\n          str = '\\n' + str.split('\\n').map(function(line) {\n            return '   ' + line;\n          }).join('\\n');\n        }\n      }\n    } else {\n      str = ctx.stylize('[Circular]', 'special');\n    }\n  }\n  if (isUndefined(name)) {\n    if (array && key.match(/^\\d+$/)) {\n      return str;\n    }\n    name = JSON.stringify('' + key);\n    if (name.match(/^\"([a-zA-Z_][a-zA-Z_0-9]*)\"$/)) {\n      name = name.substr(1, name.length - 2);\n      name = ctx.stylize(name, 'name');\n    } else {\n      name = name.replace(/'/g, \"\\\\'\")\n                 .replace(/\\\\\"/g, '\"')\n                 .replace(/(^\"|\"$)/g, \"'\");\n      name = ctx.stylize(name, 'string');\n    }\n  }\n\n  return name + ': ' + str;\n}\n\n\nfunction reduceToSingleString(output, base, braces) {\n  var numLinesEst = 0;\n  var length = output.reduce(function(prev, cur) {\n    numLinesEst++;\n    if (cur.indexOf('\\n') >= 0) numLinesEst++;\n    return prev + cur.replace(/\\u001b\\[\\d\\d?m/g, '').length + 1;\n  }, 0);\n\n  if (length > 60) {\n    return braces[0] +\n           (base === '' ? '' : base + '\\n ') +\n           ' ' +\n           output.join(',\\n  ') +\n           ' ' +\n           braces[1];\n  }\n\n  return braces[0] + base + ' ' + output.join(', ') + ' ' + braces[1];\n}\n\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\nfunction isArray(ar) {\n  return Array.isArray(ar);\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return isObject(re) && objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return isObject(d) && objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return isObject(e) &&\n      (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = __webpack_require__(576);\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n\n\nfunction pad(n) {\n  return n < 10 ? '0' + n.toString(10) : n.toString(10);\n}\n\n\nvar months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',\n              'Oct', 'Nov', 'Dec'];\n\n// 26 Feb 16:19:34\nfunction timestamp() {\n  var d = new Date();\n  var time = [pad(d.getHours()),\n              pad(d.getMinutes()),\n              pad(d.getSeconds())].join(':');\n  return [d.getDate(), months[d.getMonth()], time].join(' ');\n}\n\n\n// log is just a thin wrapper to console.log that prepends a timestamp\nexports.log = function() {\n  console.log('%s - %s', timestamp(), exports.format.apply(exports, arguments));\n};\n\n\n/**\n * Inherit the prototype methods from one constructor into another.\n *\n * The Function.prototype.inherits from lang.js rewritten as a standalone\n * function (not on Function.prototype). NOTE: If this file is to be loaded\n * during bootstrapping this function needs to be rewritten using some native\n * functions as prototype setup using normal JavaScript does not work as\n * expected during bootstrapping (see mirror.js in r114903).\n *\n * @param {function} ctor Constructor function which needs to inherit the\n *     prototype.\n * @param {function} superCtor Constructor function to inherit prototype from.\n */\nexports.inherits = __webpack_require__(577);\n\nexports._extend = function(origin, add) {\n  // Don't do anything if add isn't an object\n  if (!add || !isObject(add)) return origin;\n\n  var keys = Object.keys(add);\n  var i = keys.length;\n  while (i--) {\n    origin[keys[i]] = add[keys[i]];\n  }\n  return origin;\n};\n\nfunction hasOwnProperty(obj, prop) {\n  return Object.prototype.hasOwnProperty.call(obj, prop);\n}\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12), __webpack_require__(8)))\n\n/***/ }),\n/* 66 */\n/***/ (function(module, exports) {\n\nmodule.exports = extend\n\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\nfunction extend() {\n    var target = {}\n\n    for (var i = 0; i < arguments.length; i++) {\n        var source = arguments[i]\n\n        for (var key in source) {\n            if (hasOwnProperty.call(source, key)) {\n                target[key] = source[key]\n            }\n        }\n    }\n\n    return target\n}\n\n\n/***/ }),\n/* 67 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Tests if ES6 Symbol is supported.\n * @version 1.4.2\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module has-symbol-support-x\n */\n\n\n\n/**\n * Indicates if `Symbol`exists and creates the correct type.\n * `true`, if it exists and creates the correct type, otherwise `false`.\n *\n * @type boolean\n */\nmodule.exports = typeof Symbol === 'function' && typeof Symbol('') === 'symbol';\n\n\n/***/ }),\n/* 68 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file List of ECMAScript white space characters.\n * @version 3.0.1\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module white-space-x\n */\n\n\n\n/**\n * A record of a white space character.\n *\n * @typedef {Object} CharRecord\n * @property {number} code - The character code.\n * @property {string} description - A description of the character.\n * @property {boolean} es5 - Whether the spec lists this as a white space.\n * @property {boolean} es2015 - Whether the spec lists this as a white space.\n * @property {boolean} es2016 - Whether the spec lists this as a white space.\n * @property {boolean} es2017 - Whether the spec lists this as a white space.\n * @property {boolean} es2018 - Whether the spec lists this as a white space.\n * @property {string} string - The character string.\n */\n\n/**\n * An array of the whitespace char codes, string, descriptions and language\n * presence in the specifications.\n *\n * @private\n * @type Array.<CharRecord>\n */\nvar list = [\n  {\n    code: 0x0009,\n    description: 'Tab',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u0009'\n  },\n  {\n    code: 0x000a,\n    description: 'Line Feed',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u000a'\n  },\n  {\n    code: 0x000b,\n    description: 'Vertical Tab',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u000b'\n  },\n  {\n    code: 0x000c,\n    description: 'Form Feed',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u000c'\n  },\n  {\n    code: 0x000d,\n    description: 'Carriage Return',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u000d'\n  },\n  {\n    code: 0x0020,\n    description: 'Space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u0020'\n  },\n  /*\n  {\n    code: 0x0085,\n    description: 'Next line',\n    es5: false,\n    es2015: false,\n    es2016: false,\n    es2017: false,\n    es2018: false,\n    string: '\\u0085'\n  }\n  */\n  {\n    code: 0x00a0,\n    description: 'No-break space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u00a0'\n  },\n  {\n    code: 0x1680,\n    description: 'Ogham space mark',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u1680'\n  },\n  {\n    code: 0x180e,\n    description: 'Mongolian vowel separator',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: false,\n    es2018: false,\n    string: '\\u180e'\n  },\n  {\n    code: 0x2000,\n    description: 'En quad',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u2000'\n  },\n  {\n    code: 0x2001,\n    description: 'Em quad',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u2001'\n  },\n  {\n    code: 0x2002,\n    description: 'En space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u2002'\n  },\n  {\n    code: 0x2003,\n    description: 'Em space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u2003'\n  },\n  {\n    code: 0x2004,\n    description: 'Three-per-em space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u2004'\n  },\n  {\n    code: 0x2005,\n    description: 'Four-per-em space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u2005'\n  },\n  {\n    code: 0x2006,\n    description: 'Six-per-em space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u2006'\n  },\n  {\n    code: 0x2007,\n    description: 'Figure space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u2007'\n  },\n  {\n    code: 0x2008,\n    description: 'Punctuation space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u2008'\n  },\n  {\n    code: 0x2009,\n    description: 'Thin space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u2009'\n  },\n  {\n    code: 0x200a,\n    description: 'Hair space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u200a'\n  },\n  /*\n  {\n    code: 0x200b,\n    description: 'Zero width space',\n    es5: false,\n    es2015: false,\n    es2016: false,\n    es2017: false,\n    es2018: false,\n    string: '\\u200b'\n  },\n  */\n  {\n    code: 0x2028,\n    description: 'Line separator',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u2028'\n  },\n  {\n    code: 0x2029,\n    description: 'Paragraph separator',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u2029'\n  },\n  {\n    code: 0x202f,\n    description: 'Narrow no-break space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u202f'\n  },\n  {\n    code: 0x205f,\n    description: 'Medium mathematical space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u205f'\n  },\n  {\n    code: 0x3000,\n    description: 'Ideographic space',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\u3000'\n  },\n  {\n    code: 0xfeff,\n    description: 'Byte Order Mark',\n    es5: true,\n    es2015: true,\n    es2016: true,\n    es2017: true,\n    es2018: true,\n    string: '\\ufeff'\n  }\n];\n\nvar stringES2016 = '';\nvar stringES2018 = '';\nvar length = list.length;\nfor (var i = 0; i < length; i += 1) {\n  if (list[i].es2016) {\n    stringES2016 += list[i].string;\n  }\n\n  if (list[i].es2018) {\n    stringES2018 += list[i].string;\n  }\n}\n\nmodule.exports = {\n  /**\n   * An array of the whitespace char codes, string, descriptions and language\n   * presence in the specifications.\n   *\n   * @type Array.<CharRecord>\n   * @example\n   * var whiteSpace = require('white-space-x');\n   * whiteSpaces.list.foreach(function (item) {\n   *   console.log(lib.description, item.code, item.string);\n   * });\n   */\n  list: list,\n  /**\n   * A string of the ES2017 to ES2018 whitespace characters.\n   *\n   * @type string\n   */\n  string: stringES2018,\n\n  /**\n   * A string of the ES5 to ES2016 whitespace characters.\n   *\n   * @type string\n   */\n  string5: stringES2016,\n\n  /**\n   * A string of the ES5 to ES2016 whitespace characters.\n   *\n   * @type string\n   */\n  string2015: stringES2016,\n\n  /**\n   * A string of the ES5 to ES2016 whitespace characters.\n   *\n   * @type string\n   * @example\n   * var whiteSpace = require('white-space-x');\n   * var characters = [\n   *   '\\u0009',\n   *   '\\u000a',\n   *   '\\u000b',\n   *   '\\u000c',\n   *   '\\u000d',\n   *   '\\u0020',\n   *   '\\u00a0',\n   *   '\\u1680',\n   *   '\\u180e',\n   *   '\\u2000',\n   *   '\\u2001',\n   *   '\\u2002',\n   *   '\\u2003',\n   *   '\\u2004',\n   *   '\\u2005',\n   *   '\\u2006',\n   *   '\\u2007',\n   *   '\\u2008',\n   *   '\\u2009',\n   *   '\\u200a',\n   *   '\\u2028',\n   *   '\\u2029',\n   *   '\\u202f',\n   *   '\\u205f',\n   *   '\\u3000',\n   *   '\\ufeff'\n   * ];\n   * var ws = characters.join('');\n   * var re1 = new RegExp('^[' + whiteSpace.string2016 + ']+$)');\n   * re1.test(ws); // true\n   */\n  string2016: stringES2016,\n\n  /**\n   * A string of the ES2017 to ES2018 whitespace characters.\n   *\n   * @type string\n   */\n  string2017: stringES2018,\n\n  /**\n   * A string of the ES2017 to ES2018 whitespace characters.\n   *\n   * @type string\n   * @example\n   * var whiteSpace = require('white-space-x');\n   * var characters = [\n   *   '\\u0009',\n   *   '\\u000a',\n   *   '\\u000b',\n   *   '\\u000c',\n   *   '\\u000d',\n   *   '\\u0020',\n   *   '\\u00a0',\n   *   '\\u1680',\n   *   '\\u2000',\n   *   '\\u2001',\n   *   '\\u2002',\n   *   '\\u2003',\n   *   '\\u2004',\n   *   '\\u2005',\n   *   '\\u2006',\n   *   '\\u2007',\n   *   '\\u2008',\n   *   '\\u2009',\n   *   '\\u200a',\n   *   '\\u2028',\n   *   '\\u2029',\n   *   '\\u202f',\n   *   '\\u205f',\n   *   '\\u3000',\n   *   '\\ufeff'\n   * ];\n   * var ws = characters.join('');\n   * var re1 = new RegExp('^[' + whiteSpace.string2018 + ']+$)');\n   * re1.test(ws); // true\n   */\n  string2018: stringES2018\n};\n\n\n/***/ }),\n/* 69 */,\n/* 70 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar core = __webpack_require__(26);\nvar global = __webpack_require__(3);\nvar SHARED = '__core-js_shared__';\nvar store = global[SHARED] || (global[SHARED] = {});\n\n(module.exports = function (key, value) {\n  return store[key] || (store[key] = value !== undefined ? value : {});\n})('versions', []).push({\n  version: core.version,\n  mode: __webpack_require__(40) ? 'pure' : 'global',\n  copyright: ' 2018 Denis Pushkarev (zloirock.ru)'\n});\n\n\n/***/ }),\n/* 71 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// false -> Array#indexOf\n// true  -> Array#includes\nvar toIObject = __webpack_require__(20);\nvar toLength = __webpack_require__(11);\nvar toAbsoluteIndex = __webpack_require__(46);\nmodule.exports = function (IS_INCLUDES) {\n  return function ($this, el, fromIndex) {\n    var O = toIObject($this);\n    var length = toLength(O.length);\n    var index = toAbsoluteIndex(fromIndex, length);\n    var value;\n    // Array#includes uses SameValueZero equality algorithm\n    // eslint-disable-next-line no-self-compare\n    if (IS_INCLUDES && el != el) while (length > index) {\n      value = O[index++];\n      // eslint-disable-next-line no-self-compare\n      if (value != value) return true;\n    // Array#indexOf ignores holes, Array#includes - not\n    } else for (;length > index; index++) if (IS_INCLUDES || index in O) {\n      if (O[index] === el) return IS_INCLUDES || index || 0;\n    } return !IS_INCLUDES && -1;\n  };\n};\n\n\n/***/ }),\n/* 72 */\n/***/ (function(module, exports) {\n\nexports.f = Object.getOwnPropertySymbols;\n\n\n/***/ }),\n/* 73 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 7.2.2 IsArray(argument)\nvar cof = __webpack_require__(28);\nmodule.exports = Array.isArray || function isArray(arg) {\n  return cof(arg) == 'Array';\n};\n\n\n/***/ }),\n/* 74 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 7.2.8 IsRegExp(argument)\nvar isObject = __webpack_require__(5);\nvar cof = __webpack_require__(28);\nvar MATCH = __webpack_require__(7)('match');\nmodule.exports = function (it) {\n  var isRegExp;\n  return isObject(it) && ((isRegExp = it[MATCH]) !== undefined ? !!isRegExp : cof(it) == 'RegExp');\n};\n\n\n/***/ }),\n/* 75 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar ITERATOR = __webpack_require__(7)('iterator');\nvar SAFE_CLOSING = false;\n\ntry {\n  var riter = [7][ITERATOR]();\n  riter['return'] = function () { SAFE_CLOSING = true; };\n  // eslint-disable-next-line no-throw-literal\n  Array.from(riter, function () { throw 2; });\n} catch (e) { /* empty */ }\n\nmodule.exports = function (exec, skipClosing) {\n  if (!skipClosing && !SAFE_CLOSING) return false;\n  var safe = false;\n  try {\n    var arr = [7];\n    var iter = arr[ITERATOR]();\n    iter.next = function () { return { done: safe = true }; };\n    arr[ITERATOR] = function () { return iter; };\n    exec(arr);\n  } catch (e) { /* empty */ }\n  return safe;\n};\n\n\n/***/ }),\n/* 76 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// 21.2.5.3 get RegExp.prototype.flags\nvar anObject = __webpack_require__(2);\nmodule.exports = function () {\n  var that = anObject(this);\n  var result = '';\n  if (that.global) result += 'g';\n  if (that.ignoreCase) result += 'i';\n  if (that.multiline) result += 'm';\n  if (that.unicode) result += 'u';\n  if (that.sticky) result += 'y';\n  return result;\n};\n\n\n/***/ }),\n/* 77 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar hide = __webpack_require__(16);\nvar redefine = __webpack_require__(17);\nvar fails = __webpack_require__(4);\nvar defined = __webpack_require__(31);\nvar wks = __webpack_require__(7);\n\nmodule.exports = function (KEY, length, exec) {\n  var SYMBOL = wks(KEY);\n  var fns = exec(defined, SYMBOL, ''[KEY]);\n  var strfn = fns[0];\n  var rxfn = fns[1];\n  if (fails(function () {\n    var O = {};\n    O[SYMBOL] = function () { return 7; };\n    return ''[KEY](O) != 7;\n  })) {\n    redefine(String.prototype, KEY, strfn);\n    hide(RegExp.prototype, SYMBOL, length == 2\n      // 21.2.5.8 RegExp.prototype[@@replace](string, replaceValue)\n      // 21.2.5.11 RegExp.prototype[@@split](string, limit)\n      ? function (string, arg) { return rxfn.call(string, this, arg); }\n      // 21.2.5.6 RegExp.prototype[@@match](string)\n      // 21.2.5.9 RegExp.prototype[@@search](string)\n      : function (string) { return rxfn.call(string, this); }\n    );\n  }\n};\n\n\n/***/ }),\n/* 78 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 7.3.20 SpeciesConstructor(O, defaultConstructor)\nvar anObject = __webpack_require__(2);\nvar aFunction = __webpack_require__(15);\nvar SPECIES = __webpack_require__(7)('species');\nmodule.exports = function (O, D) {\n  var C = anObject(O).constructor;\n  var S;\n  return C === undefined || (S = anObject(C)[SPECIES]) == undefined ? D : aFunction(S);\n};\n\n\n/***/ }),\n/* 79 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar global = __webpack_require__(3);\nvar navigator = global.navigator;\n\nmodule.exports = navigator && navigator.userAgent || '';\n\n\n/***/ }),\n/* 80 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar global = __webpack_require__(3);\nvar $export = __webpack_require__(0);\nvar redefine = __webpack_require__(17);\nvar redefineAll = __webpack_require__(52);\nvar meta = __webpack_require__(39);\nvar forOf = __webpack_require__(51);\nvar anInstance = __webpack_require__(50);\nvar isObject = __webpack_require__(5);\nvar fails = __webpack_require__(4);\nvar $iterDetect = __webpack_require__(75);\nvar setToStringTag = __webpack_require__(56);\nvar inheritIfRequired = __webpack_require__(98);\n\nmodule.exports = function (NAME, wrapper, methods, common, IS_MAP, IS_WEAK) {\n  var Base = global[NAME];\n  var C = Base;\n  var ADDER = IS_MAP ? 'set' : 'add';\n  var proto = C && C.prototype;\n  var O = {};\n  var fixMethod = function (KEY) {\n    var fn = proto[KEY];\n    redefine(proto, KEY,\n      KEY == 'delete' ? function (a) {\n        return IS_WEAK && !isObject(a) ? false : fn.call(this, a === 0 ? 0 : a);\n      } : KEY == 'has' ? function has(a) {\n        return IS_WEAK && !isObject(a) ? false : fn.call(this, a === 0 ? 0 : a);\n      } : KEY == 'get' ? function get(a) {\n        return IS_WEAK && !isObject(a) ? undefined : fn.call(this, a === 0 ? 0 : a);\n      } : KEY == 'add' ? function add(a) { fn.call(this, a === 0 ? 0 : a); return this; }\n        : function set(a, b) { fn.call(this, a === 0 ? 0 : a, b); return this; }\n    );\n  };\n  if (typeof C != 'function' || !(IS_WEAK || proto.forEach && !fails(function () {\n    new C().entries().next();\n  }))) {\n    // create collection constructor\n    C = common.getConstructor(wrapper, NAME, IS_MAP, ADDER);\n    redefineAll(C.prototype, methods);\n    meta.NEED = true;\n  } else {\n    var instance = new C();\n    // early implementations not supports chaining\n    var HASNT_CHAINING = instance[ADDER](IS_WEAK ? {} : -0, 1) != instance;\n    // V8 ~  Chromium 40- weak-collections throws on primitives, but should return false\n    var THROWS_ON_PRIMITIVES = fails(function () { instance.has(1); });\n    // most early implementations doesn't supports iterables, most modern - not close it correctly\n    var ACCEPT_ITERABLES = $iterDetect(function (iter) { new C(iter); }); // eslint-disable-line no-new\n    // for early implementations -0 and +0 not the same\n    var BUGGY_ZERO = !IS_WEAK && fails(function () {\n      // V8 ~ Chromium 42- fails only with 5+ elements\n      var $instance = new C();\n      var index = 5;\n      while (index--) $instance[ADDER](index, index);\n      return !$instance.has(-0);\n    });\n    if (!ACCEPT_ITERABLES) {\n      C = wrapper(function (target, iterable) {\n        anInstance(target, C, NAME);\n        var that = inheritIfRequired(new Base(), target, C);\n        if (iterable != undefined) forOf(iterable, IS_MAP, that[ADDER], that);\n        return that;\n      });\n      C.prototype = proto;\n      proto.constructor = C;\n    }\n    if (THROWS_ON_PRIMITIVES || BUGGY_ZERO) {\n      fixMethod('delete');\n      fixMethod('has');\n      IS_MAP && fixMethod('get');\n    }\n    if (BUGGY_ZERO || HASNT_CHAINING) fixMethod(ADDER);\n    // weak collections should not contains .clear method\n    if (IS_WEAK && proto.clear) delete proto.clear;\n  }\n\n  setToStringTag(C, NAME);\n\n  O[NAME] = C;\n  $export($export.G + $export.W + $export.F * (C != Base), O);\n\n  if (!IS_WEAK) common.setStrong(C, NAME, IS_MAP);\n\n  return C;\n};\n\n\n/***/ }),\n/* 81 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar global = __webpack_require__(3);\nvar hide = __webpack_require__(16);\nvar uid = __webpack_require__(44);\nvar TYPED = uid('typed_array');\nvar VIEW = uid('view');\nvar ABV = !!(global.ArrayBuffer && global.DataView);\nvar CONSTR = ABV;\nvar i = 0;\nvar l = 9;\nvar Typed;\n\nvar TypedArrayConstructors = (\n  'Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array'\n).split(',');\n\nwhile (i < l) {\n  if (Typed = global[TypedArrayConstructors[i++]]) {\n    hide(Typed.prototype, TYPED, true);\n    hide(Typed.prototype, VIEW, true);\n  } else CONSTR = false;\n}\n\nmodule.exports = {\n  ABV: ABV,\n  CONSTR: CONSTR,\n  TYPED: TYPED,\n  VIEW: VIEW\n};\n\n\n/***/ }),\n/* 82 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// Forced replacement prototype accessors methods\nmodule.exports = __webpack_require__(40) || !__webpack_require__(4)(function () {\n  var K = Math.random();\n  // In FF throws only define methods\n  // eslint-disable-next-line no-undef, no-useless-call\n  __defineSetter__.call(null, K, function () { /* empty */ });\n  delete __webpack_require__(3)[K];\n});\n\n\n/***/ }),\n/* 83 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://tc39.github.io/proposal-setmap-offrom/\nvar $export = __webpack_require__(0);\n\nmodule.exports = function (COLLECTION) {\n  $export($export.S, COLLECTION, { of: function of() {\n    var length = arguments.length;\n    var A = new Array(length);\n    while (length--) A[length] = arguments[length];\n    return new this(A);\n  } });\n};\n\n\n/***/ }),\n/* 84 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://tc39.github.io/proposal-setmap-offrom/\nvar $export = __webpack_require__(0);\nvar aFunction = __webpack_require__(15);\nvar ctx = __webpack_require__(27);\nvar forOf = __webpack_require__(51);\n\nmodule.exports = function (COLLECTION) {\n  $export($export.S, COLLECTION, { from: function from(source /* , mapFn, thisArg */) {\n    var mapFn = arguments[1];\n    var mapping, A, n, cb;\n    aFunction(this);\n    mapping = mapFn !== undefined;\n    if (mapping) aFunction(mapFn);\n    if (source == undefined) return new this();\n    A = [];\n    if (mapping) {\n      n = 0;\n      cb = ctx(mapFn, arguments[2], 2);\n      forOf(source, false, function (nextItem) {\n        A.push(cb(nextItem, n++));\n      });\n    } else {\n      forOf(source, false, A.push, A);\n    }\n    return new this(A);\n  } });\n};\n\n\n/***/ }),\n/* 85 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file ES6-compliant shim for ToString.\n * @see {@link http://www.ecma-international.org/ecma-262/6.0/#sec-tostring|7.1.12 ToString ( argument )}\n * @version 1.4.5\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module to-string-x\n */\n\n\n\nvar castString = __webpack_require__(38).String;\nvar isSymbol = __webpack_require__(136);\n\n/**\n * The abstract operation ToString converts argument to a value of type String.\n *\n * @param {*} value - The value to convert to a string.\n * @throws {TypeError} If `value` is a Symbol.\n * @returns {string} The converted value.\n * @example\n * var $toString = require('to-string-x');\n *\n * $toString(); // 'undefined'\n * $toString(null); // 'null'\n * $toString('abc'); // 'abc'\n * $toString(true); // 'true'\n * $toString(Symbol('foo')); // TypeError\n * $toString(Symbol.iterator); // TypeError\n * $toString(Object(Symbol.iterator)); // TypeError\n * $toString(Object.create(null)); // TypeError\n */\nmodule.exports = function ToString(value) {\n  if (isSymbol(value)) {\n    throw new TypeError('Cannot convert a Symbol value to a string');\n  }\n\n  return castString(value);\n};\n\n\n/***/ }),\n/* 86 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Converts argument to a value of type Number.\n * @version 2.0.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module to-number-x\n */\n\n\n\nvar cachedCtrs = __webpack_require__(38);\nvar castNumber = cachedCtrs.Number;\nvar Rx = cachedCtrs.RegExp;\nvar toPrimitive = __webpack_require__(219);\nvar libTrim = __webpack_require__(217);\nvar trim2016 = libTrim.trim2016;\nvar trim2018 = libTrim.trim2018;\nvar libParseInt = __webpack_require__(636);\nvar $parseInt2016 = libParseInt.parseInt2016;\nvar $parseInt2018 = libParseInt.parseInt2018;\nvar pStrSlice = cachedCtrs.String.prototype.slice;\nvar NAN = __webpack_require__(220);\n\nvar binaryRegex = /^0b[01]+$/i;\n// Note that in IE 8, RegExp.prototype.test doesn't seem to exist: ie, \"test\" is\n// an own property of regexes. wtf.\nvar test = binaryRegex.test;\nvar isBinary = function _isBinary(value) {\n  return test.call(binaryRegex, value);\n};\n\nvar octalRegex = /^0o[0-7]+$/i;\nvar isOctal = function _isOctal(value) {\n  return test.call(octalRegex, value);\n};\n\nvar nonWSregex2016 = new Rx('[\\u0085\\u200b\\ufffe]', 'g');\nvar hasNonWS2016 = function _hasNonWS(value) {\n  return test.call(nonWSregex2016, value);\n};\n\nvar nonWSregex2018 = new Rx('[\\u0085\\u180e\\u200b\\ufffe]', 'g');\nvar hasNonWS2018 = function _hasNonWS(value) {\n  return test.call(nonWSregex2018, value);\n};\n\nvar invalidHexLiteral = /^[-+]0x[0-9a-f]+$/i;\nvar isInvalidHexLiteral = function _isInvalidHexLiteral(value) {\n  return test.call(invalidHexLiteral, value);\n};\n\nvar $toNumber2016 = function toNumber2016(argument) {\n  var value = toPrimitive(argument, Number);\n  if (typeof value === 'symbol') {\n    throw new TypeError('Cannot convert a Symbol value to a number');\n  }\n\n  if (typeof value === 'string') {\n    if (isBinary(value)) {\n      return toNumber2016($parseInt2016(pStrSlice.call(value, 2), 2));\n    }\n\n    if (isOctal(value)) {\n      return toNumber2016($parseInt2016(pStrSlice.call(value, 2), 8));\n    }\n\n    if (hasNonWS2016(value) || isInvalidHexLiteral(value)) {\n      return NAN;\n    }\n\n    var trimmed = trim2016(value);\n    if (trimmed !== value) {\n      return toNumber2016(trimmed);\n    }\n  }\n\n  return castNumber(value);\n};\n\nvar $toNumber2018 = function toNumber2018(argument) {\n  var value = toPrimitive(argument, Number);\n  if (typeof value === 'symbol') {\n    throw new TypeError('Cannot convert a Symbol value to a number');\n  }\n\n  if (typeof value === 'string') {\n    if (isBinary(value)) {\n      return toNumber2018($parseInt2018(pStrSlice.call(value, 2), 2));\n    }\n\n    if (isOctal(value)) {\n      return toNumber2018($parseInt2018(pStrSlice.call(value, 2), 8));\n    }\n\n    if (hasNonWS2018(value) || isInvalidHexLiteral(value)) {\n      return NAN;\n    }\n\n    var trimmed = trim2018(value);\n    if (trimmed !== value) {\n      return toNumber2018(trimmed);\n    }\n  }\n\n  return castNumber(value);\n};\n\nmodule.exports = {\n  /**\n   * reference to toNumber2018.\n   */\n  toNumber: $toNumber2018,\n\n  /**\n   * This method converts argument to a value of type Number. (ES2016)\n\n   * @param {*} argument - The argument to convert to a number.\n   * @throws {TypeError} - If argument is a Symbol or not coercible.\n   * @returns {*} The argument converted to a number.\n   * @example\n   * var toNumber = require('to-number-x').toNumber2016;\n   *\n   * toNumber('1'); // 1\n   * toNumber(null); // 0\n   * toNumber(true); // 1\n   * toNumber('0o10'); // 8\n   * toNumber('0b10'); // 2\n   * toNumber('0xF'); // 16\n   *\n   * toNumber(' 1 '); // 1\n   *\n   * toNumber(Symbol('')) // TypeError\n   * toNumber(Object.create(null)) // TypeError\n   */\n  toNumber2016: $toNumber2016,\n\n  /**\n   * This method converts argument to a value of type Number. (ES2018)\n\n   * @param {*} argument - The argument to convert to a number.\n   * @throws {TypeError} - If argument is a Symbol or not coercible.\n   * @returns {*} The argument converted to a number.\n   * @example\n   * var toNumber = require('to-number-x').toNumber2018;\n   *\n   * toNumber('1'); // 1\n   * toNumber(null); // 0\n   * toNumber(true); // 1\n   * toNumber('0o10'); // 8\n   * toNumber('0b10'); // 2\n   * toNumber('0xF'); // 16\n   *\n   * toNumber(' 1 '); // 1\n   *\n   * toNumber(Symbol('')) // TypeError\n   * toNumber(Object.create(null)) // TypeError\n   */\n  toNumber2018: $toNumber2018\n};\n\n\n/***/ }),\n/* 87 */,\n/* 88 */,\n/* 89 */,\n/* 90 */,\n/* 91 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar isObject = __webpack_require__(5);\nvar document = __webpack_require__(3).document;\n// typeof document.createElement is 'object' in old IE\nvar is = isObject(document) && isObject(document.createElement);\nmodule.exports = function (it) {\n  return is ? document.createElement(it) : {};\n};\n\n\n/***/ }),\n/* 92 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar global = __webpack_require__(3);\nvar core = __webpack_require__(26);\nvar LIBRARY = __webpack_require__(40);\nvar wksExt = __webpack_require__(146);\nvar defineProperty = __webpack_require__(10).f;\nmodule.exports = function (name) {\n  var $Symbol = core.Symbol || (core.Symbol = LIBRARY ? {} : global.Symbol || {});\n  if (name.charAt(0) != '_' && !(name in $Symbol)) defineProperty($Symbol, name, { value: wksExt.f(name) });\n};\n\n\n/***/ }),\n/* 93 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar shared = __webpack_require__(70)('keys');\nvar uid = __webpack_require__(44);\nmodule.exports = function (key) {\n  return shared[key] || (shared[key] = uid(key));\n};\n\n\n/***/ }),\n/* 94 */\n/***/ (function(module, exports) {\n\n// IE 8- don't enum bug keys\nmodule.exports = (\n  'constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf'\n).split(',');\n\n\n/***/ }),\n/* 95 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar document = __webpack_require__(3).document;\nmodule.exports = document && document.documentElement;\n\n\n/***/ }),\n/* 96 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// Works with __proto__ only. Old v8 can't work with null proto objects.\n/* eslint-disable no-proto */\nvar isObject = __webpack_require__(5);\nvar anObject = __webpack_require__(2);\nvar check = function (O, proto) {\n  anObject(O);\n  if (!isObject(proto) && proto !== null) throw TypeError(proto + \": can't set as prototype!\");\n};\nmodule.exports = {\n  set: Object.setPrototypeOf || ('__proto__' in {} ? // eslint-disable-line\n    function (test, buggy, set) {\n      try {\n        set = __webpack_require__(27)(Function.call, __webpack_require__(21).f(Object.prototype, '__proto__').set, 2);\n        set(test, []);\n        buggy = !(test instanceof Array);\n      } catch (e) { buggy = true; }\n      return function setPrototypeOf(O, proto) {\n        check(O, proto);\n        if (buggy) O.__proto__ = proto;\n        else set(O, proto);\n        return O;\n      };\n    }({}, false) : undefined),\n  check: check\n};\n\n\n/***/ }),\n/* 97 */\n/***/ (function(module, exports) {\n\nmodule.exports = '\\x09\\x0A\\x0B\\x0C\\x0D\\x20\\xA0\\u1680\\u180E\\u2000\\u2001\\u2002\\u2003' +\n  '\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200A\\u202F\\u205F\\u3000\\u2028\\u2029\\uFEFF';\n\n\n/***/ }),\n/* 98 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar isObject = __webpack_require__(5);\nvar setPrototypeOf = __webpack_require__(96).set;\nmodule.exports = function (that, target, C) {\n  var S = target.constructor;\n  var P;\n  if (S !== C && typeof S == 'function' && (P = S.prototype) !== C.prototype && isObject(P) && setPrototypeOf) {\n    setPrototypeOf(that, P);\n  } return that;\n};\n\n\n/***/ }),\n/* 99 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar toInteger = __webpack_require__(32);\nvar defined = __webpack_require__(31);\n\nmodule.exports = function repeat(count) {\n  var str = String(defined(this));\n  var res = '';\n  var n = toInteger(count);\n  if (n < 0 || n == Infinity) throw RangeError(\"Count can't be negative\");\n  for (;n > 0; (n >>>= 1) && (str += str)) if (n & 1) res += str;\n  return res;\n};\n\n\n/***/ }),\n/* 100 */\n/***/ (function(module, exports) {\n\n// 20.2.2.28 Math.sign(x)\nmodule.exports = Math.sign || function sign(x) {\n  // eslint-disable-next-line no-self-compare\n  return (x = +x) == 0 || x != x ? x : x < 0 ? -1 : 1;\n};\n\n\n/***/ }),\n/* 101 */\n/***/ (function(module, exports) {\n\n// 20.2.2.14 Math.expm1(x)\nvar $expm1 = Math.expm1;\nmodule.exports = (!$expm1\n  // Old FF bug\n  || $expm1(10) > 22025.465794806719 || $expm1(10) < 22025.4657948067165168\n  // Tor Browser bug\n  || $expm1(-2e-17) != -2e-17\n) ? function expm1(x) {\n  return (x = +x) == 0 ? x : x > -1e-6 && x < 1e-6 ? x + x * x / 2 : Math.exp(x) - 1;\n} : $expm1;\n\n\n/***/ }),\n/* 102 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar toInteger = __webpack_require__(32);\nvar defined = __webpack_require__(31);\n// true  -> String#at\n// false -> String#codePointAt\nmodule.exports = function (TO_STRING) {\n  return function (that, pos) {\n    var s = String(defined(that));\n    var i = toInteger(pos);\n    var l = s.length;\n    var a, b;\n    if (i < 0 || i >= l) return TO_STRING ? '' : undefined;\n    a = s.charCodeAt(i);\n    return a < 0xd800 || a > 0xdbff || i + 1 === l || (b = s.charCodeAt(i + 1)) < 0xdc00 || b > 0xdfff\n      ? TO_STRING ? s.charAt(i) : a\n      : TO_STRING ? s.slice(i, i + 2) : (a - 0xd800 << 10) + (b - 0xdc00) + 0x10000;\n  };\n};\n\n\n/***/ }),\n/* 103 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar LIBRARY = __webpack_require__(40);\nvar $export = __webpack_require__(0);\nvar redefine = __webpack_require__(17);\nvar hide = __webpack_require__(16);\nvar Iterators = __webpack_require__(58);\nvar $iterCreate = __webpack_require__(104);\nvar setToStringTag = __webpack_require__(56);\nvar getPrototypeOf = __webpack_require__(22);\nvar ITERATOR = __webpack_require__(7)('iterator');\nvar BUGGY = !([].keys && 'next' in [].keys()); // Safari has buggy iterators w/o `next`\nvar FF_ITERATOR = '@@iterator';\nvar KEYS = 'keys';\nvar VALUES = 'values';\n\nvar returnThis = function () { return this; };\n\nmodule.exports = function (Base, NAME, Constructor, next, DEFAULT, IS_SET, FORCED) {\n  $iterCreate(Constructor, NAME, next);\n  var getMethod = function (kind) {\n    if (!BUGGY && kind in proto) return proto[kind];\n    switch (kind) {\n      case KEYS: return function keys() { return new Constructor(this, kind); };\n      case VALUES: return function values() { return new Constructor(this, kind); };\n    } return function entries() { return new Constructor(this, kind); };\n  };\n  var TAG = NAME + ' Iterator';\n  var DEF_VALUES = DEFAULT == VALUES;\n  var VALUES_BUG = false;\n  var proto = Base.prototype;\n  var $native = proto[ITERATOR] || proto[FF_ITERATOR] || DEFAULT && proto[DEFAULT];\n  var $default = $native || getMethod(DEFAULT);\n  var $entries = DEFAULT ? !DEF_VALUES ? $default : getMethod('entries') : undefined;\n  var $anyNative = NAME == 'Array' ? proto.entries || $native : $native;\n  var methods, key, IteratorPrototype;\n  // Fix native\n  if ($anyNative) {\n    IteratorPrototype = getPrototypeOf($anyNative.call(new Base()));\n    if (IteratorPrototype !== Object.prototype && IteratorPrototype.next) {\n      // Set @@toStringTag to native iterators\n      setToStringTag(IteratorPrototype, TAG, true);\n      // fix for some old engines\n      if (!LIBRARY && typeof IteratorPrototype[ITERATOR] != 'function') hide(IteratorPrototype, ITERATOR, returnThis);\n    }\n  }\n  // fix Array#{values, @@iterator}.name in V8 / FF\n  if (DEF_VALUES && $native && $native.name !== VALUES) {\n    VALUES_BUG = true;\n    $default = function values() { return $native.call(this); };\n  }\n  // Define iterator\n  if ((!LIBRARY || FORCED) && (BUGGY || VALUES_BUG || !proto[ITERATOR])) {\n    hide(proto, ITERATOR, $default);\n  }\n  // Plug for library\n  Iterators[NAME] = $default;\n  Iterators[TAG] = returnThis;\n  if (DEFAULT) {\n    methods = {\n      values: DEF_VALUES ? $default : getMethod(VALUES),\n      keys: IS_SET ? $default : getMethod(KEYS),\n      entries: $entries\n    };\n    if (FORCED) for (key in methods) {\n      if (!(key in proto)) redefine(proto, key, methods[key]);\n    } else $export($export.P + $export.F * (BUGGY || VALUES_BUG), NAME, methods);\n  }\n  return methods;\n};\n\n\n/***/ }),\n/* 104 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar create = __webpack_require__(47);\nvar descriptor = __webpack_require__(43);\nvar setToStringTag = __webpack_require__(56);\nvar IteratorPrototype = {};\n\n// 25.1.2.1.1 %IteratorPrototype%[@@iterator]()\n__webpack_require__(16)(IteratorPrototype, __webpack_require__(7)('iterator'), function () { return this; });\n\nmodule.exports = function (Constructor, NAME, next) {\n  Constructor.prototype = create(IteratorPrototype, { next: descriptor(1, next) });\n  setToStringTag(Constructor, NAME + ' Iterator');\n};\n\n\n/***/ }),\n/* 105 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// helper for String#{startsWith, endsWith, includes}\nvar isRegExp = __webpack_require__(74);\nvar defined = __webpack_require__(31);\n\nmodule.exports = function (that, searchString, NAME) {\n  if (isRegExp(searchString)) throw TypeError('String#' + NAME + \" doesn't accept regex!\");\n  return String(defined(that));\n};\n\n\n/***/ }),\n/* 106 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar MATCH = __webpack_require__(7)('match');\nmodule.exports = function (KEY) {\n  var re = /./;\n  try {\n    '/./'[KEY](re);\n  } catch (e) {\n    try {\n      re[MATCH] = false;\n      return !'/./'[KEY](re);\n    } catch (f) { /* empty */ }\n  } return true;\n};\n\n\n/***/ }),\n/* 107 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// check on default Array iterator\nvar Iterators = __webpack_require__(58);\nvar ITERATOR = __webpack_require__(7)('iterator');\nvar ArrayProto = Array.prototype;\n\nmodule.exports = function (it) {\n  return it !== undefined && (Iterators.Array === it || ArrayProto[ITERATOR] === it);\n};\n\n\n/***/ }),\n/* 108 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $defineProperty = __webpack_require__(10);\nvar createDesc = __webpack_require__(43);\n\nmodule.exports = function (object, index, value) {\n  if (index in object) $defineProperty.f(object, index, createDesc(0, value));\n  else object[index] = value;\n};\n\n\n/***/ }),\n/* 109 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar classof = __webpack_require__(64);\nvar ITERATOR = __webpack_require__(7)('iterator');\nvar Iterators = __webpack_require__(58);\nmodule.exports = __webpack_require__(26).getIteratorMethod = function (it) {\n  if (it != undefined) return it[ITERATOR]\n    || it['@@iterator']\n    || Iterators[classof(it)];\n};\n\n\n/***/ }),\n/* 110 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 9.4.2.3 ArraySpeciesCreate(originalArray, length)\nvar speciesConstructor = __webpack_require__(455);\n\nmodule.exports = function (original, length) {\n  return new (speciesConstructor(original))(length);\n};\n\n\n/***/ }),\n/* 111 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// 22.1.3.6 Array.prototype.fill(value, start = 0, end = this.length)\n\nvar toObject = __webpack_require__(14);\nvar toAbsoluteIndex = __webpack_require__(46);\nvar toLength = __webpack_require__(11);\nmodule.exports = function fill(value /* , start = 0, end = @length */) {\n  var O = toObject(this);\n  var length = toLength(O.length);\n  var aLen = arguments.length;\n  var index = toAbsoluteIndex(aLen > 1 ? arguments[1] : undefined, length);\n  var end = aLen > 2 ? arguments[2] : undefined;\n  var endPos = end === undefined ? length : toAbsoluteIndex(end, length);\n  while (endPos > index) O[index++] = value;\n  return O;\n};\n\n\n/***/ }),\n/* 112 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar addToUnscopables = __webpack_require__(41);\nvar step = __webpack_require__(162);\nvar Iterators = __webpack_require__(58);\nvar toIObject = __webpack_require__(20);\n\n// 22.1.3.4 Array.prototype.entries()\n// 22.1.3.13 Array.prototype.keys()\n// 22.1.3.29 Array.prototype.values()\n// 22.1.3.30 Array.prototype[@@iterator]()\nmodule.exports = __webpack_require__(103)(Array, 'Array', function (iterated, kind) {\n  this._t = toIObject(iterated); // target\n  this._i = 0;                   // next index\n  this._k = kind;                // kind\n// 22.1.5.2.1 %ArrayIteratorPrototype%.next()\n}, function () {\n  var O = this._t;\n  var kind = this._k;\n  var index = this._i++;\n  if (!O || index >= O.length) {\n    this._t = undefined;\n    return step(1);\n  }\n  if (kind == 'keys') return step(0, index);\n  if (kind == 'values') return step(0, O[index]);\n  return step(0, [index, O[index]]);\n}, 'values');\n\n// argumentsList[@@iterator] is %ArrayProto_values% (9.4.4.6, 9.4.4.7)\nIterators.Arguments = Iterators.Array;\n\naddToUnscopables('keys');\naddToUnscopables('values');\naddToUnscopables('entries');\n\n\n/***/ }),\n/* 113 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar ctx = __webpack_require__(27);\nvar invoke = __webpack_require__(152);\nvar html = __webpack_require__(95);\nvar cel = __webpack_require__(91);\nvar global = __webpack_require__(3);\nvar process = global.process;\nvar setTask = global.setImmediate;\nvar clearTask = global.clearImmediate;\nvar MessageChannel = global.MessageChannel;\nvar Dispatch = global.Dispatch;\nvar counter = 0;\nvar queue = {};\nvar ONREADYSTATECHANGE = 'onreadystatechange';\nvar defer, channel, port;\nvar run = function () {\n  var id = +this;\n  // eslint-disable-next-line no-prototype-builtins\n  if (queue.hasOwnProperty(id)) {\n    var fn = queue[id];\n    delete queue[id];\n    fn();\n  }\n};\nvar listener = function (event) {\n  run.call(event.data);\n};\n// Node.js 0.9+ & IE10+ has setImmediate, otherwise:\nif (!setTask || !clearTask) {\n  setTask = function setImmediate(fn) {\n    var args = [];\n    var i = 1;\n    while (arguments.length > i) args.push(arguments[i++]);\n    queue[++counter] = function () {\n      // eslint-disable-next-line no-new-func\n      invoke(typeof fn == 'function' ? fn : Function(fn), args);\n    };\n    defer(counter);\n    return counter;\n  };\n  clearTask = function clearImmediate(id) {\n    delete queue[id];\n  };\n  // Node.js 0.8-\n  if (__webpack_require__(28)(process) == 'process') {\n    defer = function (id) {\n      process.nextTick(ctx(run, id, 1));\n    };\n  // Sphere (JS game engine) Dispatch API\n  } else if (Dispatch && Dispatch.now) {\n    defer = function (id) {\n      Dispatch.now(ctx(run, id, 1));\n    };\n  // Browsers with MessageChannel, includes WebWorkers\n  } else if (MessageChannel) {\n    channel = new MessageChannel();\n    port = channel.port2;\n    channel.port1.onmessage = listener;\n    defer = ctx(port.postMessage, port, 1);\n  // Browsers with postMessage, skip WebWorkers\n  // IE8 has postMessage, but it's sync & typeof its postMessage is 'object'\n  } else if (global.addEventListener && typeof postMessage == 'function' && !global.importScripts) {\n    defer = function (id) {\n      global.postMessage(id + '', '*');\n    };\n    global.addEventListener('message', listener, false);\n  // IE8-\n  } else if (ONREADYSTATECHANGE in cel('script')) {\n    defer = function (id) {\n      html.appendChild(cel('script'))[ONREADYSTATECHANGE] = function () {\n        html.removeChild(this);\n        run.call(id);\n      };\n    };\n  // Rest old browsers\n  } else {\n    defer = function (id) {\n      setTimeout(ctx(run, id, 1), 0);\n    };\n  }\n}\nmodule.exports = {\n  set: setTask,\n  clear: clearTask\n};\n\n\n/***/ }),\n/* 114 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar global = __webpack_require__(3);\nvar macrotask = __webpack_require__(113).set;\nvar Observer = global.MutationObserver || global.WebKitMutationObserver;\nvar process = global.process;\nvar Promise = global.Promise;\nvar isNode = __webpack_require__(28)(process) == 'process';\n\nmodule.exports = function () {\n  var head, last, notify;\n\n  var flush = function () {\n    var parent, fn;\n    if (isNode && (parent = process.domain)) parent.exit();\n    while (head) {\n      fn = head.fn;\n      head = head.next;\n      try {\n        fn();\n      } catch (e) {\n        if (head) notify();\n        else last = undefined;\n        throw e;\n      }\n    } last = undefined;\n    if (parent) parent.enter();\n  };\n\n  // Node.js\n  if (isNode) {\n    notify = function () {\n      process.nextTick(flush);\n    };\n  // browsers with MutationObserver, except iOS Safari - https://github.com/zloirock/core-js/issues/339\n  } else if (Observer && !(global.navigator && global.navigator.standalone)) {\n    var toggle = true;\n    var node = document.createTextNode('');\n    new Observer(flush).observe(node, { characterData: true }); // eslint-disable-line no-new\n    notify = function () {\n      node.data = toggle = !toggle;\n    };\n  // environments with maybe non-completely correct, but existent Promise\n  } else if (Promise && Promise.resolve) {\n    // Promise.resolve without an argument throws an error in LG WebOS 2\n    var promise = Promise.resolve(undefined);\n    notify = function () {\n      promise.then(flush);\n    };\n  // for other environments - macrotask based on:\n  // - setImmediate\n  // - MessageChannel\n  // - window.postMessag\n  // - onreadystatechange\n  // - setTimeout\n  } else {\n    notify = function () {\n      // strange IE + webpack dev server bug - use .call(global)\n      macrotask.call(global, flush);\n    };\n  }\n\n  return function (fn) {\n    var task = { fn: fn, next: undefined };\n    if (last) last.next = task;\n    if (!head) {\n      head = task;\n      notify();\n    } last = task;\n  };\n};\n\n\n/***/ }),\n/* 115 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// 25.4.1.5 NewPromiseCapability(C)\nvar aFunction = __webpack_require__(15);\n\nfunction PromiseCapability(C) {\n  var resolve, reject;\n  this.promise = new C(function ($$resolve, $$reject) {\n    if (resolve !== undefined || reject !== undefined) throw TypeError('Bad Promise constructor');\n    resolve = $$resolve;\n    reject = $$reject;\n  });\n  this.resolve = aFunction(resolve);\n  this.reject = aFunction(reject);\n}\n\nmodule.exports.f = function (C) {\n  return new PromiseCapability(C);\n};\n\n\n/***/ }),\n/* 116 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar global = __webpack_require__(3);\nvar DESCRIPTORS = __webpack_require__(9);\nvar LIBRARY = __webpack_require__(40);\nvar $typed = __webpack_require__(81);\nvar hide = __webpack_require__(16);\nvar redefineAll = __webpack_require__(52);\nvar fails = __webpack_require__(4);\nvar anInstance = __webpack_require__(50);\nvar toInteger = __webpack_require__(32);\nvar toLength = __webpack_require__(11);\nvar toIndex = __webpack_require__(171);\nvar gOPN = __webpack_require__(48).f;\nvar dP = __webpack_require__(10).f;\nvar arrayFill = __webpack_require__(111);\nvar setToStringTag = __webpack_require__(56);\nvar ARRAY_BUFFER = 'ArrayBuffer';\nvar DATA_VIEW = 'DataView';\nvar PROTOTYPE = 'prototype';\nvar WRONG_LENGTH = 'Wrong length!';\nvar WRONG_INDEX = 'Wrong index!';\nvar $ArrayBuffer = global[ARRAY_BUFFER];\nvar $DataView = global[DATA_VIEW];\nvar Math = global.Math;\nvar RangeError = global.RangeError;\n// eslint-disable-next-line no-shadow-restricted-names\nvar Infinity = global.Infinity;\nvar BaseBuffer = $ArrayBuffer;\nvar abs = Math.abs;\nvar pow = Math.pow;\nvar floor = Math.floor;\nvar log = Math.log;\nvar LN2 = Math.LN2;\nvar BUFFER = 'buffer';\nvar BYTE_LENGTH = 'byteLength';\nvar BYTE_OFFSET = 'byteOffset';\nvar $BUFFER = DESCRIPTORS ? '_b' : BUFFER;\nvar $LENGTH = DESCRIPTORS ? '_l' : BYTE_LENGTH;\nvar $OFFSET = DESCRIPTORS ? '_o' : BYTE_OFFSET;\n\n// IEEE754 conversions based on https://github.com/feross/ieee754\nfunction packIEEE754(value, mLen, nBytes) {\n  var buffer = new Array(nBytes);\n  var eLen = nBytes * 8 - mLen - 1;\n  var eMax = (1 << eLen) - 1;\n  var eBias = eMax >> 1;\n  var rt = mLen === 23 ? pow(2, -24) - pow(2, -77) : 0;\n  var i = 0;\n  var s = value < 0 || value === 0 && 1 / value < 0 ? 1 : 0;\n  var e, m, c;\n  value = abs(value);\n  // eslint-disable-next-line no-self-compare\n  if (value != value || value === Infinity) {\n    // eslint-disable-next-line no-self-compare\n    m = value != value ? 1 : 0;\n    e = eMax;\n  } else {\n    e = floor(log(value) / LN2);\n    if (value * (c = pow(2, -e)) < 1) {\n      e--;\n      c *= 2;\n    }\n    if (e + eBias >= 1) {\n      value += rt / c;\n    } else {\n      value += rt * pow(2, 1 - eBias);\n    }\n    if (value * c >= 2) {\n      e++;\n      c /= 2;\n    }\n    if (e + eBias >= eMax) {\n      m = 0;\n      e = eMax;\n    } else if (e + eBias >= 1) {\n      m = (value * c - 1) * pow(2, mLen);\n      e = e + eBias;\n    } else {\n      m = value * pow(2, eBias - 1) * pow(2, mLen);\n      e = 0;\n    }\n  }\n  for (; mLen >= 8; buffer[i++] = m & 255, m /= 256, mLen -= 8);\n  e = e << mLen | m;\n  eLen += mLen;\n  for (; eLen > 0; buffer[i++] = e & 255, e /= 256, eLen -= 8);\n  buffer[--i] |= s * 128;\n  return buffer;\n}\nfunction unpackIEEE754(buffer, mLen, nBytes) {\n  var eLen = nBytes * 8 - mLen - 1;\n  var eMax = (1 << eLen) - 1;\n  var eBias = eMax >> 1;\n  var nBits = eLen - 7;\n  var i = nBytes - 1;\n  var s = buffer[i--];\n  var e = s & 127;\n  var m;\n  s >>= 7;\n  for (; nBits > 0; e = e * 256 + buffer[i], i--, nBits -= 8);\n  m = e & (1 << -nBits) - 1;\n  e >>= -nBits;\n  nBits += mLen;\n  for (; nBits > 0; m = m * 256 + buffer[i], i--, nBits -= 8);\n  if (e === 0) {\n    e = 1 - eBias;\n  } else if (e === eMax) {\n    return m ? NaN : s ? -Infinity : Infinity;\n  } else {\n    m = m + pow(2, mLen);\n    e = e - eBias;\n  } return (s ? -1 : 1) * m * pow(2, e - mLen);\n}\n\nfunction unpackI32(bytes) {\n  return bytes[3] << 24 | bytes[2] << 16 | bytes[1] << 8 | bytes[0];\n}\nfunction packI8(it) {\n  return [it & 0xff];\n}\nfunction packI16(it) {\n  return [it & 0xff, it >> 8 & 0xff];\n}\nfunction packI32(it) {\n  return [it & 0xff, it >> 8 & 0xff, it >> 16 & 0xff, it >> 24 & 0xff];\n}\nfunction packF64(it) {\n  return packIEEE754(it, 52, 8);\n}\nfunction packF32(it) {\n  return packIEEE754(it, 23, 4);\n}\n\nfunction addGetter(C, key, internal) {\n  dP(C[PROTOTYPE], key, { get: function () { return this[internal]; } });\n}\n\nfunction get(view, bytes, index, isLittleEndian) {\n  var numIndex = +index;\n  var intIndex = toIndex(numIndex);\n  if (intIndex + bytes > view[$LENGTH]) throw RangeError(WRONG_INDEX);\n  var store = view[$BUFFER]._b;\n  var start = intIndex + view[$OFFSET];\n  var pack = store.slice(start, start + bytes);\n  return isLittleEndian ? pack : pack.reverse();\n}\nfunction set(view, bytes, index, conversion, value, isLittleEndian) {\n  var numIndex = +index;\n  var intIndex = toIndex(numIndex);\n  if (intIndex + bytes > view[$LENGTH]) throw RangeError(WRONG_INDEX);\n  var store = view[$BUFFER]._b;\n  var start = intIndex + view[$OFFSET];\n  var pack = conversion(+value);\n  for (var i = 0; i < bytes; i++) store[start + i] = pack[isLittleEndian ? i : bytes - i - 1];\n}\n\nif (!$typed.ABV) {\n  $ArrayBuffer = function ArrayBuffer(length) {\n    anInstance(this, $ArrayBuffer, ARRAY_BUFFER);\n    var byteLength = toIndex(length);\n    this._b = arrayFill.call(new Array(byteLength), 0);\n    this[$LENGTH] = byteLength;\n  };\n\n  $DataView = function DataView(buffer, byteOffset, byteLength) {\n    anInstance(this, $DataView, DATA_VIEW);\n    anInstance(buffer, $ArrayBuffer, DATA_VIEW);\n    var bufferLength = buffer[$LENGTH];\n    var offset = toInteger(byteOffset);\n    if (offset < 0 || offset > bufferLength) throw RangeError('Wrong offset!');\n    byteLength = byteLength === undefined ? bufferLength - offset : toLength(byteLength);\n    if (offset + byteLength > bufferLength) throw RangeError(WRONG_LENGTH);\n    this[$BUFFER] = buffer;\n    this[$OFFSET] = offset;\n    this[$LENGTH] = byteLength;\n  };\n\n  if (DESCRIPTORS) {\n    addGetter($ArrayBuffer, BYTE_LENGTH, '_l');\n    addGetter($DataView, BUFFER, '_b');\n    addGetter($DataView, BYTE_LENGTH, '_l');\n    addGetter($DataView, BYTE_OFFSET, '_o');\n  }\n\n  redefineAll($DataView[PROTOTYPE], {\n    getInt8: function getInt8(byteOffset) {\n      return get(this, 1, byteOffset)[0] << 24 >> 24;\n    },\n    getUint8: function getUint8(byteOffset) {\n      return get(this, 1, byteOffset)[0];\n    },\n    getInt16: function getInt16(byteOffset /* , littleEndian */) {\n      var bytes = get(this, 2, byteOffset, arguments[1]);\n      return (bytes[1] << 8 | bytes[0]) << 16 >> 16;\n    },\n    getUint16: function getUint16(byteOffset /* , littleEndian */) {\n      var bytes = get(this, 2, byteOffset, arguments[1]);\n      return bytes[1] << 8 | bytes[0];\n    },\n    getInt32: function getInt32(byteOffset /* , littleEndian */) {\n      return unpackI32(get(this, 4, byteOffset, arguments[1]));\n    },\n    getUint32: function getUint32(byteOffset /* , littleEndian */) {\n      return unpackI32(get(this, 4, byteOffset, arguments[1])) >>> 0;\n    },\n    getFloat32: function getFloat32(byteOffset /* , littleEndian */) {\n      return unpackIEEE754(get(this, 4, byteOffset, arguments[1]), 23, 4);\n    },\n    getFloat64: function getFloat64(byteOffset /* , littleEndian */) {\n      return unpackIEEE754(get(this, 8, byteOffset, arguments[1]), 52, 8);\n    },\n    setInt8: function setInt8(byteOffset, value) {\n      set(this, 1, byteOffset, packI8, value);\n    },\n    setUint8: function setUint8(byteOffset, value) {\n      set(this, 1, byteOffset, packI8, value);\n    },\n    setInt16: function setInt16(byteOffset, value /* , littleEndian */) {\n      set(this, 2, byteOffset, packI16, value, arguments[2]);\n    },\n    setUint16: function setUint16(byteOffset, value /* , littleEndian */) {\n      set(this, 2, byteOffset, packI16, value, arguments[2]);\n    },\n    setInt32: function setInt32(byteOffset, value /* , littleEndian */) {\n      set(this, 4, byteOffset, packI32, value, arguments[2]);\n    },\n    setUint32: function setUint32(byteOffset, value /* , littleEndian */) {\n      set(this, 4, byteOffset, packI32, value, arguments[2]);\n    },\n    setFloat32: function setFloat32(byteOffset, value /* , littleEndian */) {\n      set(this, 4, byteOffset, packF32, value, arguments[2]);\n    },\n    setFloat64: function setFloat64(byteOffset, value /* , littleEndian */) {\n      set(this, 8, byteOffset, packF64, value, arguments[2]);\n    }\n  });\n} else {\n  if (!fails(function () {\n    $ArrayBuffer(1);\n  }) || !fails(function () {\n    new $ArrayBuffer(-1); // eslint-disable-line no-new\n  }) || fails(function () {\n    new $ArrayBuffer(); // eslint-disable-line no-new\n    new $ArrayBuffer(1.5); // eslint-disable-line no-new\n    new $ArrayBuffer(NaN); // eslint-disable-line no-new\n    return $ArrayBuffer.name != ARRAY_BUFFER;\n  })) {\n    $ArrayBuffer = function ArrayBuffer(length) {\n      anInstance(this, $ArrayBuffer);\n      return new BaseBuffer(toIndex(length));\n    };\n    var ArrayBufferProto = $ArrayBuffer[PROTOTYPE] = BaseBuffer[PROTOTYPE];\n    for (var keys = gOPN(BaseBuffer), j = 0, key; keys.length > j;) {\n      if (!((key = keys[j++]) in $ArrayBuffer)) hide($ArrayBuffer, key, BaseBuffer[key]);\n    }\n    if (!LIBRARY) ArrayBufferProto.constructor = $ArrayBuffer;\n  }\n  // iOS Safari 7.x bug\n  var view = new $DataView(new $ArrayBuffer(2));\n  var $setInt8 = $DataView[PROTOTYPE].setInt8;\n  view.setInt8(0, 2147483648);\n  view.setInt8(1, 2147483649);\n  if (view.getInt8(0) || !view.getInt8(1)) redefineAll($DataView[PROTOTYPE], {\n    setInt8: function setInt8(byteOffset, value) {\n      $setInt8.call(this, byteOffset, value << 24 >> 24);\n    },\n    setUint8: function setUint8(byteOffset, value) {\n      $setInt8.call(this, byteOffset, value << 24 >> 24);\n    }\n  }, true);\n}\nsetToStringTag($ArrayBuffer, ARRAY_BUFFER);\nsetToStringTag($DataView, DATA_VIEW);\nhide($DataView[PROTOTYPE], $typed.VIEW, true);\nexports[ARRAY_BUFFER] = $ArrayBuffer;\nexports[DATA_VIEW] = $DataView;\n\n\n/***/ }),\n/* 117 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global) {\nvar Mutation = global.MutationObserver || global.WebKitMutationObserver;\n\nvar scheduleDrain;\n\n{\n  if (Mutation) {\n    var called = 0;\n    var observer = new Mutation(nextTick);\n    var element = global.document.createTextNode('');\n    observer.observe(element, {\n      characterData: true\n    });\n    scheduleDrain = function () {\n      element.data = (called = ++called % 2);\n    };\n  } else if (!global.setImmediate && typeof global.MessageChannel !== 'undefined') {\n    var channel = new global.MessageChannel();\n    channel.port1.onmessage = nextTick;\n    scheduleDrain = function () {\n      channel.port2.postMessage(0);\n    };\n  } else if ('document' in global && 'onreadystatechange' in global.document.createElement('script')) {\n    scheduleDrain = function () {\n\n      // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n      // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n      var scriptEl = global.document.createElement('script');\n      scriptEl.onreadystatechange = function () {\n        nextTick();\n\n        scriptEl.onreadystatechange = null;\n        scriptEl.parentNode.removeChild(scriptEl);\n        scriptEl = null;\n      };\n      global.document.documentElement.appendChild(scriptEl);\n    };\n  } else {\n    scheduleDrain = function () {\n      setTimeout(nextTick, 0);\n    };\n  }\n}\n\nvar draining;\nvar queue = [];\n//named nextTick for less confusing stack traces\nfunction nextTick() {\n  draining = true;\n  var i, oldQueue;\n  var len = queue.length;\n  while (len) {\n    oldQueue = queue;\n    queue = [];\n    i = -1;\n    while (++i < len) {\n      oldQueue[i]();\n    }\n    len = queue.length;\n  }\n  draining = false;\n}\n\nmodule.exports = immediate;\nfunction immediate(task) {\n  if (queue.push(task) === 1 && !draining) {\n    scheduleDrain();\n  }\n}\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12)))\n\n/***/ }),\n/* 118 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nmodule.exports = argsArray;\n\nfunction argsArray(fun) {\n  return function () {\n    var len = arguments.length;\n    if (len) {\n      var args = [];\n      var i = -1;\n      while (++i < len) {\n        args[i] = arguments[i];\n      }\n      return fun.call(this, args);\n    } else {\n      return fun.call(this, []);\n    }\n  };\n}\n\n/***/ }),\n/* 119 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* unused harmony export adapterFun */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return assign$1; });\n/* unused harmony export bulkGetShim */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"b\", function() { return Changes; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"c\", function() { return clone; });\n/* unused harmony export defaultBackOff */\n/* unused harmony export explainError */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"d\", function() { return filterChange; });\n/* unused harmony export flatten */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"e\", function() { return res$1; });\n/* unused harmony export guardedConsole */\n/* unused harmony export hasLocalStorage */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"f\", function() { return invalidIdError; });\n/* unused harmony export isChromeApp */\n/* unused harmony export isCordova */\n/* unused harmony export isRemote */\n/* unused harmony export listenerCount */\n/* unused harmony export normalizeDdocFunctionName */\n/* unused harmony export once */\n/* unused harmony export parseDdocFunctionName */\n/* unused harmony export parseUri */\n/* unused harmony export pick */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"h\", function() { return rev; });\n/* unused harmony export scopeEval */\n/* unused harmony export toPromise */\n/* unused harmony export upsert */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"i\", function() { return uuid; });\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_argsarray__ = __webpack_require__(118);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_argsarray___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_0_argsarray__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_pouchdb_promise__ = __webpack_require__(120);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2_pouchdb_collections__ = __webpack_require__(121);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_3_immediate__ = __webpack_require__(117);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_3_immediate___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_3_immediate__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_4_events__ = __webpack_require__(23);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_4_events___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_4_events__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_5_inherits__ = __webpack_require__(6);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_5_inherits___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_5_inherits__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_6_pouchdb_errors__ = __webpack_require__(122);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_7_uuid__ = __webpack_require__(571);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_7_uuid___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_7_uuid__);\n/* harmony reexport (default from non-hamory) */ __webpack_require__.d(__webpack_exports__, \"g\", function() { return __WEBPACK_IMPORTED_MODULE_3_immediate___default.a; });\n\n\n\n\n\n\n\n\n\nfunction isBinaryObject(object) {\n  return (typeof ArrayBuffer !== 'undefined' && object instanceof ArrayBuffer) ||\n    (typeof Blob !== 'undefined' && object instanceof Blob);\n}\n\nfunction cloneArrayBuffer(buff) {\n  if (typeof buff.slice === 'function') {\n    return buff.slice(0);\n  }\n  // IE10-11 slice() polyfill\n  var target = new ArrayBuffer(buff.byteLength);\n  var targetArray = new Uint8Array(target);\n  var sourceArray = new Uint8Array(buff);\n  targetArray.set(sourceArray);\n  return target;\n}\n\nfunction cloneBinaryObject(object) {\n  if (object instanceof ArrayBuffer) {\n    return cloneArrayBuffer(object);\n  }\n  var size = object.size;\n  var type = object.type;\n  // Blob\n  if (typeof object.slice === 'function') {\n    return object.slice(0, size, type);\n  }\n  // PhantomJS slice() replacement\n  return object.webkitSlice(0, size, type);\n}\n\n// most of this is borrowed from lodash.isPlainObject:\n// https://github.com/fis-components/lodash.isplainobject/\n// blob/29c358140a74f252aeb08c9eb28bef86f2217d4a/index.js\n\nvar funcToString = Function.prototype.toString;\nvar objectCtorString = funcToString.call(Object);\n\nfunction isPlainObject(value) {\n  var proto = Object.getPrototypeOf(value);\n  /* istanbul ignore if */\n  if (proto === null) { // not sure when this happens, but I guess it can\n    return true;\n  }\n  var Ctor = proto.constructor;\n  return (typeof Ctor == 'function' &&\n    Ctor instanceof Ctor && funcToString.call(Ctor) == objectCtorString);\n}\n\nfunction clone(object) {\n  var newObject;\n  var i;\n  var len;\n\n  if (!object || typeof object !== 'object') {\n    return object;\n  }\n\n  if (Array.isArray(object)) {\n    newObject = [];\n    for (i = 0, len = object.length; i < len; i++) {\n      newObject[i] = clone(object[i]);\n    }\n    return newObject;\n  }\n\n  // special case: to avoid inconsistencies between IndexedDB\n  // and other backends, we automatically stringify Dates\n  if (object instanceof Date) {\n    return object.toISOString();\n  }\n\n  if (isBinaryObject(object)) {\n    return cloneBinaryObject(object);\n  }\n\n  if (!isPlainObject(object)) {\n    return object; // don't clone objects like Workers\n  }\n\n  newObject = {};\n  for (i in object) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(object, i)) {\n      var value = clone(object[i]);\n      if (typeof value !== 'undefined') {\n        newObject[i] = value;\n      }\n    }\n  }\n  return newObject;\n}\n\nfunction once(fun) {\n  var called = false;\n  return __WEBPACK_IMPORTED_MODULE_0_argsarray___default()(function (args) {\n    /* istanbul ignore if */\n    if (called) {\n      // this is a smoke test and should never actually happen\n      throw new Error('once called more than once');\n    } else {\n      called = true;\n      fun.apply(this, args);\n    }\n  });\n}\n\nfunction toPromise(func) {\n  //create the function we will be returning\n  return __WEBPACK_IMPORTED_MODULE_0_argsarray___default()(function (args) {\n    // Clone arguments\n    args = clone(args);\n    var self = this;\n    // if the last argument is a function, assume its a callback\n    var usedCB = (typeof args[args.length - 1] === 'function') ? args.pop() : false;\n    var promise = new __WEBPACK_IMPORTED_MODULE_1_pouchdb_promise__[\"a\" /* default */](function (fulfill, reject) {\n      var resp;\n      try {\n        var callback = once(function (err, mesg) {\n          if (err) {\n            reject(err);\n          } else {\n            fulfill(mesg);\n          }\n        });\n        // create a callback for this invocation\n        // apply the function in the orig context\n        args.push(callback);\n        resp = func.apply(self, args);\n        if (resp && typeof resp.then === 'function') {\n          fulfill(resp);\n        }\n      } catch (e) {\n        reject(e);\n      }\n    });\n    // if there is a callback, call it back\n    if (usedCB) {\n      promise.then(function (result) {\n        usedCB(null, result);\n      }, usedCB);\n    }\n    return promise;\n  });\n}\n\nfunction logApiCall(self, name, args) {\n  /* istanbul ignore if */\n  if (self.constructor.listeners('debug').length) {\n    var logArgs = ['api', self.name, name];\n    for (var i = 0; i < args.length - 1; i++) {\n      logArgs.push(args[i]);\n    }\n    self.constructor.emit('debug', logArgs);\n\n    // override the callback itself to log the response\n    var origCallback = args[args.length - 1];\n    args[args.length - 1] = function (err, res) {\n      var responseArgs = ['api', self.name, name];\n      responseArgs = responseArgs.concat(\n        err ? ['error', err] : ['success', res]\n      );\n      self.constructor.emit('debug', responseArgs);\n      origCallback(err, res);\n    };\n  }\n}\n\nfunction adapterFun(name, callback) {\n  return toPromise(__WEBPACK_IMPORTED_MODULE_0_argsarray___default()(function (args) {\n    if (this._closed) {\n      return __WEBPACK_IMPORTED_MODULE_1_pouchdb_promise__[\"a\" /* default */].reject(new Error('database is closed'));\n    }\n    if (this._destroyed) {\n      return __WEBPACK_IMPORTED_MODULE_1_pouchdb_promise__[\"a\" /* default */].reject(new Error('database is destroyed'));\n    }\n    var self = this;\n    logApiCall(self, name, args);\n    if (!this.taskqueue.isReady) {\n      return new __WEBPACK_IMPORTED_MODULE_1_pouchdb_promise__[\"a\" /* default */](function (fulfill, reject) {\n        self.taskqueue.addTask(function (failed) {\n          if (failed) {\n            reject(failed);\n          } else {\n            fulfill(self[name].apply(self, args));\n          }\n        });\n      });\n    }\n    return callback.apply(this, args);\n  }));\n}\n\n// like underscore/lodash _.pick()\nfunction pick(obj, arr) {\n  var res = {};\n  for (var i = 0, len = arr.length; i < len; i++) {\n    var prop = arr[i];\n    if (prop in obj) {\n      res[prop] = obj[prop];\n    }\n  }\n  return res;\n}\n\n// Most browsers throttle concurrent requests at 6, so it's silly\n// to shim _bulk_get by trying to launch potentially hundreds of requests\n// and then letting the majority time out. We can handle this ourselves.\nvar MAX_NUM_CONCURRENT_REQUESTS = 6;\n\nfunction identityFunction(x) {\n  return x;\n}\n\nfunction formatResultForOpenRevsGet(result) {\n  return [{\n    ok: result\n  }];\n}\n\n// shim for P/CouchDB adapters that don't directly implement _bulk_get\nfunction bulkGet(db, opts, callback) {\n  var requests = opts.docs;\n\n  // consolidate into one request per doc if possible\n  var requestsById = new __WEBPACK_IMPORTED_MODULE_2_pouchdb_collections__[\"a\" /* Map */]();\n  requests.forEach(function (request) {\n    if (requestsById.has(request.id)) {\n      requestsById.get(request.id).push(request);\n    } else {\n      requestsById.set(request.id, [request]);\n    }\n  });\n\n  var numDocs = requestsById.size;\n  var numDone = 0;\n  var perDocResults = new Array(numDocs);\n\n  function collapseResultsAndFinish() {\n    var results = [];\n    perDocResults.forEach(function (res) {\n      res.docs.forEach(function (info) {\n        results.push({\n          id: res.id,\n          docs: [info]\n        });\n      });\n    });\n    callback(null, {results: results});\n  }\n\n  function checkDone() {\n    if (++numDone === numDocs) {\n      collapseResultsAndFinish();\n    }\n  }\n\n  function gotResult(docIndex, id, docs) {\n    perDocResults[docIndex] = {id: id, docs: docs};\n    checkDone();\n  }\n\n  var allRequests = [];\n  requestsById.forEach(function (value, key) {\n    allRequests.push(key);\n  });\n\n  var i = 0;\n\n  function nextBatch() {\n\n    if (i >= allRequests.length) {\n      return;\n    }\n\n    var upTo = Math.min(i + MAX_NUM_CONCURRENT_REQUESTS, allRequests.length);\n    var batch = allRequests.slice(i, upTo);\n    processBatch(batch, i);\n    i += batch.length;\n  }\n\n  function processBatch(batch, offset) {\n    batch.forEach(function (docId, j) {\n      var docIdx = offset + j;\n      var docRequests = requestsById.get(docId);\n\n      // just use the first request as the \"template\"\n      // TODO: The _bulk_get API allows for more subtle use cases than this,\n      // but for now it is unlikely that there will be a mix of different\n      // \"atts_since\" or \"attachments\" in the same request, since it's just\n      // replicate.js that is using this for the moment.\n      // Also, atts_since is aspirational, since we don't support it yet.\n      var docOpts = pick(docRequests[0], ['atts_since', 'attachments']);\n      docOpts.open_revs = docRequests.map(function (request) {\n        // rev is optional, open_revs disallowed\n        return request.rev;\n      });\n\n      // remove falsey / undefined revisions\n      docOpts.open_revs = docOpts.open_revs.filter(identityFunction);\n\n      var formatResult = identityFunction;\n\n      if (docOpts.open_revs.length === 0) {\n        delete docOpts.open_revs;\n\n        // when fetching only the \"winning\" leaf,\n        // transform the result so it looks like an open_revs\n        // request\n        formatResult = formatResultForOpenRevsGet;\n      }\n\n      // globally-supplied options\n      ['revs', 'attachments', 'binary', 'ajax', 'latest'].forEach(function (param) {\n        if (param in opts) {\n          docOpts[param] = opts[param];\n        }\n      });\n      db.get(docId, docOpts, function (err, res) {\n        var result;\n        /* istanbul ignore if */\n        if (err) {\n          result = [{error: err}];\n        } else {\n          result = formatResult(res);\n        }\n        gotResult(docIdx, docId, result);\n        nextBatch();\n      });\n    });\n  }\n\n  nextBatch();\n\n}\n\nfunction isChromeApp() {\n  return (typeof chrome !== \"undefined\" &&\n    typeof chrome.storage !== \"undefined\" &&\n    typeof chrome.storage.local !== \"undefined\");\n}\n\nvar hasLocal;\n\nif (isChromeApp()) {\n  hasLocal = false;\n} else {\n  try {\n    localStorage.setItem('_pouch_check_localstorage', 1);\n    hasLocal = !!localStorage.getItem('_pouch_check_localstorage');\n  } catch (e) {\n    hasLocal = false;\n  }\n}\n\nfunction hasLocalStorage() {\n  return hasLocal;\n}\n\n// Custom nextTick() shim for browsers. In node, this will just be process.nextTick(). We\n// avoid using process.nextTick() directly because the polyfill is very large and we don't\n// need all of it (see: https://github.com/defunctzombie/node-process).\n// \"immediate\" 3.0.8 is used by lie, and it's a smaller version of the latest \"immediate\"\n// package, so it's the one we use.\n// When we use nextTick() in our codebase, we only care about not releasing Zalgo\n// (see: http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony).\n// Microtask vs macrotask doesn't matter to us. So we're free to use the fastest\n// (least latency) option, which is \"immediate\" due to use of microtasks.\n// All of our nextTicks are isolated to this one function so we can easily swap out one\n// implementation for another.\n\n__WEBPACK_IMPORTED_MODULE_5_inherits___default()(Changes, __WEBPACK_IMPORTED_MODULE_4_events__[\"EventEmitter\"]);\n\n/* istanbul ignore next */\nfunction attachBrowserEvents(self) {\n  if (isChromeApp()) {\n    chrome.storage.onChanged.addListener(function (e) {\n      // make sure it's event addressed to us\n      if (e.db_name != null) {\n        //object only has oldValue, newValue members\n        self.emit(e.dbName.newValue);\n      }\n    });\n  } else if (hasLocalStorage()) {\n    if (typeof addEventListener !== 'undefined') {\n      addEventListener(\"storage\", function (e) {\n        self.emit(e.key);\n      });\n    } else { // old IE\n      window.attachEvent(\"storage\", function (e) {\n        self.emit(e.key);\n      });\n    }\n  }\n}\n\nfunction Changes() {\n  __WEBPACK_IMPORTED_MODULE_4_events__[\"EventEmitter\"].call(this);\n  this._listeners = {};\n\n  attachBrowserEvents(this);\n}\nChanges.prototype.addListener = function (dbName, id, db, opts) {\n  /* istanbul ignore if */\n  if (this._listeners[id]) {\n    return;\n  }\n  var self = this;\n  var inprogress = false;\n  function eventFunction() {\n    /* istanbul ignore if */\n    if (!self._listeners[id]) {\n      return;\n    }\n    if (inprogress) {\n      inprogress = 'waiting';\n      return;\n    }\n    inprogress = true;\n    var changesOpts = pick(opts, [\n      'style', 'include_docs', 'attachments', 'conflicts', 'filter',\n      'doc_ids', 'view', 'since', 'query_params', 'binary'\n    ]);\n\n    /* istanbul ignore next */\n    function onError() {\n      inprogress = false;\n    }\n\n    db.changes(changesOpts).on('change', function (c) {\n      if (c.seq > opts.since && !opts.cancelled) {\n        opts.since = c.seq;\n        opts.onChange(c);\n      }\n    }).on('complete', function () {\n      if (inprogress === 'waiting') {\n        __WEBPACK_IMPORTED_MODULE_3_immediate___default()(eventFunction);\n      }\n      inprogress = false;\n    }).on('error', onError);\n  }\n  this._listeners[id] = eventFunction;\n  this.on(dbName, eventFunction);\n};\n\nChanges.prototype.removeListener = function (dbName, id) {\n  /* istanbul ignore if */\n  if (!(id in this._listeners)) {\n    return;\n  }\n  __WEBPACK_IMPORTED_MODULE_4_events__[\"EventEmitter\"].prototype.removeListener.call(this, dbName,\n    this._listeners[id]);\n  delete this._listeners[id];\n};\n\n\n/* istanbul ignore next */\nChanges.prototype.notifyLocalWindows = function (dbName) {\n  //do a useless change on a storage thing\n  //in order to get other windows's listeners to activate\n  if (isChromeApp()) {\n    chrome.storage.local.set({dbName: dbName});\n  } else if (hasLocalStorage()) {\n    localStorage[dbName] = (localStorage[dbName] === \"a\") ? \"b\" : \"a\";\n  }\n};\n\nChanges.prototype.notify = function (dbName) {\n  this.emit(dbName);\n  this.notifyLocalWindows(dbName);\n};\n\nfunction guardedConsole(method) {\n  /* istanbul ignore else */\n  if (typeof console !== 'undefined' && typeof console[method] === 'function') {\n    var args = Array.prototype.slice.call(arguments, 1);\n    console[method].apply(console, args);\n  }\n}\n\nfunction randomNumber(min, max) {\n  var maxTimeout = 600000; // Hard-coded default of 10 minutes\n  min = parseInt(min, 10) || 0;\n  max = parseInt(max, 10);\n  if (max !== max || max <= min) {\n    max = (min || 1) << 1; //doubling\n  } else {\n    max = max + 1;\n  }\n  // In order to not exceed maxTimeout, pick a random value between half of maxTimeout and maxTimeout\n  if (max > maxTimeout) {\n    min = maxTimeout >> 1; // divide by two\n    max = maxTimeout;\n  }\n  var ratio = Math.random();\n  var range = max - min;\n\n  return ~~(range * ratio + min); // ~~ coerces to an int, but fast.\n}\n\nfunction defaultBackOff(min) {\n  var max = 0;\n  if (!min) {\n    max = 2000;\n  }\n  return randomNumber(min, max);\n}\n\n// designed to give info to browser users, who are disturbed\n// when they see http errors in the console\nfunction explainError(status, str) {\n  guardedConsole('info', 'The above ' + status + ' is totally normal. ' + str);\n}\n\nvar assign;\n{\n  if (typeof Object.assign === 'function') {\n    assign = Object.assign;\n  } else {\n    // lite Object.assign polyfill based on\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign\n    assign = function (target) {\n      var to = Object(target);\n\n      for (var index = 1; index < arguments.length; index++) {\n        var nextSource = arguments[index];\n\n        if (nextSource != null) { // Skip over if undefined or null\n          for (var nextKey in nextSource) {\n            // Avoid bugs when hasOwnProperty is shadowed\n            if (Object.prototype.hasOwnProperty.call(nextSource, nextKey)) {\n              to[nextKey] = nextSource[nextKey];\n            }\n          }\n        }\n      }\n      return to;\n    };\n  }\n}\n\nvar assign$1 = assign;\n\nfunction tryFilter(filter, doc, req) {\n  try {\n    return !filter(doc, req);\n  } catch (err) {\n    var msg = 'Filter function threw: ' + err.toString();\n    return Object(__WEBPACK_IMPORTED_MODULE_6_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_6_pouchdb_errors__[\"b\" /* BAD_REQUEST */], msg);\n  }\n}\n\nfunction filterChange(opts) {\n  var req = {};\n  var hasFilter = opts.filter && typeof opts.filter === 'function';\n  req.query = opts.query_params;\n\n  return function filter(change) {\n    if (!change.doc) {\n      // CSG sends events on the changes feed that don't have documents,\n      // this hack makes a whole lot of existing code robust.\n      change.doc = {};\n    }\n\n    var filterReturn = hasFilter && tryFilter(opts.filter, change.doc, req);\n\n    if (typeof filterReturn === 'object') {\n      return filterReturn;\n    }\n\n    if (filterReturn) {\n      return false;\n    }\n\n    if (!opts.include_docs) {\n      delete change.doc;\n    } else if (!opts.attachments) {\n      for (var att in change.doc._attachments) {\n        /* istanbul ignore else */\n        if (change.doc._attachments.hasOwnProperty(att)) {\n          change.doc._attachments[att].stub = true;\n        }\n      }\n    }\n    return true;\n  };\n}\n\nfunction flatten(arrs) {\n  var res = [];\n  for (var i = 0, len = arrs.length; i < len; i++) {\n    res = res.concat(arrs[i]);\n  }\n  return res;\n}\n\n// shim for Function.prototype.name,\n// for browsers that don't support it like IE\n\n/* istanbul ignore next */\nfunction f() {}\n\nvar hasName = f.name;\nvar res;\n\n// We dont run coverage in IE\n/* istanbul ignore else */\nif (hasName) {\n  res = function (fun) {\n    return fun.name;\n  };\n} else {\n  res = function (fun) {\n    return fun.toString().match(/^\\s*function\\s*(\\S*)\\s*\\(/)[1];\n  };\n}\n\nvar res$1 = res;\n\n// Determine id an ID is valid\n//   - invalid IDs begin with an underescore that does not begin '_design' or\n//     '_local'\n//   - any other string value is a valid id\n// Returns the specific error object for each case\nfunction invalidIdError(id) {\n  var err;\n  if (!id) {\n    err = Object(__WEBPACK_IMPORTED_MODULE_6_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_6_pouchdb_errors__[\"g\" /* MISSING_ID */]);\n  } else if (typeof id !== 'string') {\n    err = Object(__WEBPACK_IMPORTED_MODULE_6_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_6_pouchdb_errors__[\"d\" /* INVALID_ID */]);\n  } else if (/^_/.test(id) && !(/^_(design|local)/).test(id)) {\n    err = Object(__WEBPACK_IMPORTED_MODULE_6_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_6_pouchdb_errors__[\"j\" /* RESERVED_ID */]);\n  }\n  if (err) {\n    throw err;\n  }\n}\n\nfunction isCordova() {\n  return (typeof cordova !== \"undefined\" ||\n  typeof PhoneGap !== \"undefined\" ||\n  typeof phonegap !== \"undefined\");\n}\n\n// Checks if a PouchDB object is \"remote\" or not. This is\n// designed to opt-in to certain optimizations, such as\n// avoiding checks for \"dependentDbs\" and other things that\n// we know only apply to local databases. In general, \"remote\"\n// should be true for the http adapter, and for third-party\n// adapters with similar expensive boundaries to cross for\n// every API call, such as socket-pouch and worker-pouch.\n// Previously, this was handled via db.type() === 'http'\n// which is now deprecated.\n\nfunction isRemote(db) {\n  if (typeof db._remote === 'boolean') {\n    return db._remote;\n  }\n  /* istanbul ignore next */\n  if (typeof db.type === 'function') {\n    guardedConsole('warn',\n      'db.type() is deprecated and will be removed in ' +\n      'a future version of PouchDB');\n    return db.type() === 'http';\n  }\n  /* istanbul ignore next */\n  return false;\n}\n\nfunction listenerCount(ee, type) {\n  return 'listenerCount' in ee ? ee.listenerCount(type) :\n                                 __WEBPACK_IMPORTED_MODULE_4_events__[\"EventEmitter\"].listenerCount(ee, type);\n}\n\nfunction parseDesignDocFunctionName(s) {\n  if (!s) {\n    return null;\n  }\n  var parts = s.split('/');\n  if (parts.length === 2) {\n    return parts;\n  }\n  if (parts.length === 1) {\n    return [s, s];\n  }\n  return null;\n}\n\nfunction normalizeDesignDocFunctionName(s) {\n  var normalized = parseDesignDocFunctionName(s);\n  return normalized ? normalized.join('/') : null;\n}\n\n// originally parseUri 1.2.2, now patched by us\n// (c) Steven Levithan <stevenlevithan.com>\n// MIT License\nvar keys = [\"source\", \"protocol\", \"authority\", \"userInfo\", \"user\", \"password\",\n    \"host\", \"port\", \"relative\", \"path\", \"directory\", \"file\", \"query\", \"anchor\"];\nvar qName =\"queryKey\";\nvar qParser = /(?:^|&)([^&=]*)=?([^&]*)/g;\n\n// use the \"loose\" parser\n/* eslint maxlen: 0, no-useless-escape: 0 */\nvar parser = /^(?:(?![^:@]+:[^:@\\/]*@)([^:\\/?#.]+):)?(?:\\/\\/)?((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d*))?)(((\\/(?:[^?#](?![^?#\\/]*\\.[^?#\\/.]+(?:[?#]|$)))*\\/?)?([^?#\\/]*))(?:\\?([^#]*))?(?:#(.*))?)/;\n\nfunction parseUri(str) {\n  var m = parser.exec(str);\n  var uri = {};\n  var i = 14;\n\n  while (i--) {\n    var key = keys[i];\n    var value = m[i] || \"\";\n    var encoded = ['user', 'password'].indexOf(key) !== -1;\n    uri[key] = encoded ? decodeURIComponent(value) : value;\n  }\n\n  uri[qName] = {};\n  uri[keys[12]].replace(qParser, function ($0, $1, $2) {\n    if ($1) {\n      uri[qName][$1] = $2;\n    }\n  });\n\n  return uri;\n}\n\n// Based on https://github.com/alexdavid/scope-eval v0.0.3\n// (source: https://unpkg.com/scope-eval@0.0.3/scope_eval.js)\n// This is basically just a wrapper around new Function()\n\nfunction scopeEval(source, scope) {\n  var keys = [];\n  var values = [];\n  for (var key in scope) {\n    if (scope.hasOwnProperty(key)) {\n      keys.push(key);\n      values.push(scope[key]);\n    }\n  }\n  keys.push(source);\n  return Function.apply(null, keys).apply(null, values);\n}\n\n// this is essentially the \"update sugar\" function from daleharvey/pouchdb#1388\n// the diffFun tells us what delta to apply to the doc.  it either returns\n// the doc, or false if it doesn't need to do an update after all\nfunction upsert(db, docId, diffFun) {\n  return new __WEBPACK_IMPORTED_MODULE_1_pouchdb_promise__[\"a\" /* default */](function (fulfill, reject) {\n    db.get(docId, function (err, doc) {\n      if (err) {\n        /* istanbul ignore next */\n        if (err.status !== 404) {\n          return reject(err);\n        }\n        doc = {};\n      }\n\n      // the user might change the _rev, so save it for posterity\n      var docRev = doc._rev;\n      var newDoc = diffFun(doc);\n\n      if (!newDoc) {\n        // if the diffFun returns falsy, we short-circuit as\n        // an optimization\n        return fulfill({updated: false, rev: docRev});\n      }\n\n      // users aren't allowed to modify these values,\n      // so reset them here\n      newDoc._id = docId;\n      newDoc._rev = docRev;\n      fulfill(tryAndPut(db, newDoc, diffFun));\n    });\n  });\n}\n\nfunction tryAndPut(db, doc, diffFun) {\n  return db.put(doc).then(function (res) {\n    return {\n      updated: true,\n      rev: res.rev\n    };\n  }, function (err) {\n    /* istanbul ignore next */\n    if (err.status !== 409) {\n      throw err;\n    }\n    return upsert(db, doc._id, diffFun);\n  });\n}\n\nfunction rev() {\n  return __WEBPACK_IMPORTED_MODULE_7_uuid___default.a.v4().replace(/-/g, '').toLowerCase();\n}\n\nvar uuid = __WEBPACK_IMPORTED_MODULE_7_uuid___default.a.v4;\n\n\n\n\n/***/ }),\n/* 120 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_lie__ = __webpack_require__(180);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_lie___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_0_lie__);\n\n\n/* istanbul ignore next */\nvar PouchPromise = typeof Promise === 'function' ? Promise : __WEBPACK_IMPORTED_MODULE_0_lie___default.a;\n\n/* harmony default export */ __webpack_exports__[\"a\"] = (PouchPromise);\n\n\n/***/ }),\n/* 121 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"b\", function() { return ExportedSet; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return ExportedMap; });\nfunction mangle(key) {\n  return '$' + key;\n}\nfunction unmangle(key) {\n  return key.substring(1);\n}\nfunction Map$1() {\n  this._store = {};\n}\nMap$1.prototype.get = function (key) {\n  var mangled = mangle(key);\n  return this._store[mangled];\n};\nMap$1.prototype.set = function (key, value) {\n  var mangled = mangle(key);\n  this._store[mangled] = value;\n  return true;\n};\nMap$1.prototype.has = function (key) {\n  var mangled = mangle(key);\n  return mangled in this._store;\n};\nMap$1.prototype.delete = function (key) {\n  var mangled = mangle(key);\n  var res = mangled in this._store;\n  delete this._store[mangled];\n  return res;\n};\nMap$1.prototype.forEach = function (cb) {\n  var keys = Object.keys(this._store);\n  for (var i = 0, len = keys.length; i < len; i++) {\n    var key = keys[i];\n    var value = this._store[key];\n    key = unmangle(key);\n    cb(value, key);\n  }\n};\nObject.defineProperty(Map$1.prototype, 'size', {\n  get: function () {\n    return Object.keys(this._store).length;\n  }\n});\n\nfunction Set$1(array) {\n  this._store = new Map$1();\n\n  // init with an array\n  if (array && Array.isArray(array)) {\n    for (var i = 0, len = array.length; i < len; i++) {\n      this.add(array[i]);\n    }\n  }\n}\nSet$1.prototype.add = function (key) {\n  return this._store.set(key, true);\n};\nSet$1.prototype.has = function (key) {\n  return this._store.has(key);\n};\nSet$1.prototype.forEach = function (cb) {\n  this._store.forEach(function (value, key) {\n    cb(key);\n  });\n};\nObject.defineProperty(Set$1.prototype, 'size', {\n  get: function () {\n    return this._store.size;\n  }\n});\n\n/* global Map,Set,Symbol */\n// Based on https://kangax.github.io/compat-table/es6/ we can sniff out\n// incomplete Map/Set implementations which would otherwise cause our tests to fail.\n// Notably they fail in IE11 and iOS 8.4, which this prevents.\nfunction supportsMapAndSet() {\n  if (typeof Symbol === 'undefined' || typeof Map === 'undefined' || typeof Set === 'undefined') {\n    return false;\n  }\n  var prop = Object.getOwnPropertyDescriptor(Map, Symbol.species);\n  return prop && 'get' in prop && Map[Symbol.species] === Map;\n}\n\n// based on https://github.com/montagejs/collections\n/* global Map,Set */\n\nvar ExportedSet;\nvar ExportedMap;\n\n{\n  if (supportsMapAndSet()) { // prefer built-in Map/Set\n    ExportedSet = Set;\n    ExportedMap = Map;\n  } else { // fall back to our polyfill\n    ExportedSet = Set$1;\n    ExportedMap = Map$1;\n  }\n}\n\n\n\n\n/***/ }),\n/* 122 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* unused harmony export UNAUTHORIZED */\n/* unused harmony export MISSING_BULK_DOCS */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"f\", function() { return MISSING_DOC; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"k\", function() { return REV_CONFLICT; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"d\", function() { return INVALID_ID; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"g\", function() { return MISSING_ID; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"j\", function() { return RESERVED_ID; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"i\", function() { return NOT_OPEN; });\n/* unused harmony export UNKNOWN_ERROR */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return BAD_ARG; });\n/* unused harmony export INVALID_REQUEST */\n/* unused harmony export QUERY_PARSE_ERROR */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"c\", function() { return DOC_VALIDATION; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"b\", function() { return BAD_REQUEST; });\n/* unused harmony export NOT_AN_OBJECT */\n/* unused harmony export DB_MISSING */\n/* unused harmony export WSQ_ERROR */\n/* unused harmony export LDB_ERROR */\n/* unused harmony export FORBIDDEN */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"e\", function() { return INVALID_REV; });\n/* unused harmony export FILE_EXISTS */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"h\", function() { return MISSING_STUB; });\n/* unused harmony export IDB_ERROR */\n/* unused harmony export INVALID_URL */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"l\", function() { return createError; });\n/* unused harmony export generateErrorFromResponse */\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_inherits__ = __webpack_require__(6);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_inherits___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_0_inherits__);\n\n\n__WEBPACK_IMPORTED_MODULE_0_inherits___default()(PouchError, Error);\n\nfunction PouchError(status, error, reason) {\n  Error.call(this, reason);\n  this.status = status;\n  this.name = error;\n  this.message = reason;\n  this.error = true;\n}\n\nPouchError.prototype.toString = function () {\n  return JSON.stringify({\n    status: this.status,\n    name: this.name,\n    message: this.message,\n    reason: this.reason\n  });\n};\n\nvar UNAUTHORIZED = new PouchError(401, 'unauthorized', \"Name or password is incorrect.\");\nvar MISSING_BULK_DOCS = new PouchError(400, 'bad_request', \"Missing JSON list of 'docs'\");\nvar MISSING_DOC = new PouchError(404, 'not_found', 'missing');\nvar REV_CONFLICT = new PouchError(409, 'conflict', 'Document update conflict');\nvar INVALID_ID = new PouchError(400, 'bad_request', '_id field must contain a string');\nvar MISSING_ID = new PouchError(412, 'missing_id', '_id is required for puts');\nvar RESERVED_ID = new PouchError(400, 'bad_request', 'Only reserved document ids may start with underscore.');\nvar NOT_OPEN = new PouchError(412, 'precondition_failed', 'Database not open');\nvar UNKNOWN_ERROR = new PouchError(500, 'unknown_error', 'Database encountered an unknown error');\nvar BAD_ARG = new PouchError(500, 'badarg', 'Some query argument is invalid');\nvar INVALID_REQUEST = new PouchError(400, 'invalid_request', 'Request was invalid');\nvar QUERY_PARSE_ERROR = new PouchError(400, 'query_parse_error', 'Some query parameter is invalid');\nvar DOC_VALIDATION = new PouchError(500, 'doc_validation', 'Bad special document member');\nvar BAD_REQUEST = new PouchError(400, 'bad_request', 'Something wrong with the request');\nvar NOT_AN_OBJECT = new PouchError(400, 'bad_request', 'Document must be a JSON object');\nvar DB_MISSING = new PouchError(404, 'not_found', 'Database not found');\nvar IDB_ERROR = new PouchError(500, 'indexed_db_went_bad', 'unknown');\nvar WSQ_ERROR = new PouchError(500, 'web_sql_went_bad', 'unknown');\nvar LDB_ERROR = new PouchError(500, 'levelDB_went_went_bad', 'unknown');\nvar FORBIDDEN = new PouchError(403, 'forbidden', 'Forbidden by design doc validate_doc_update function');\nvar INVALID_REV = new PouchError(400, 'bad_request', 'Invalid rev format');\nvar FILE_EXISTS = new PouchError(412, 'file_exists', 'The database could not be created, the file already exists.');\nvar MISSING_STUB = new PouchError(412, 'missing_stub', 'A pre-existing attachment stub wasn\\'t found');\nvar INVALID_URL = new PouchError(413, 'invalid_url', 'Provided URL is invalid');\n\nfunction createError(error, reason) {\n  function CustomPouchError(reason) {\n    // inherit error properties from our parent error manually\n    // so as to allow proper JSON parsing.\n    /* jshint ignore:start */\n    for (var p in error) {\n      if (typeof error[p] !== 'function') {\n        this[p] = error[p];\n      }\n    }\n    /* jshint ignore:end */\n    if (reason !== undefined) {\n      this.reason = reason;\n    }\n  }\n  CustomPouchError.prototype = PouchError.prototype;\n  return new CustomPouchError(reason);\n}\n\nfunction generateErrorFromResponse(err) {\n\n  if (typeof err !== 'object') {\n    var data = err;\n    err = UNKNOWN_ERROR;\n    err.data = data;\n  }\n\n  if ('error' in err && err.error === 'conflict') {\n    err.name = 'conflict';\n    err.status = 409;\n  }\n\n  if (!('name' in err)) {\n    err.name = err.error || 'unknown';\n  }\n\n  if (!('status' in err)) {\n    err.status = 500;\n  }\n\n  if (!('message' in err)) {\n    err.message = err.message || err.reason;\n  }\n\n  return err;\n}\n\n\n\n\n/***/ }),\n/* 123 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return thisAtob; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"f\", function() { return thisBtoa; });\n/* unused harmony export base64StringToBlobOrBuffer */\n/* unused harmony export binaryStringToArrayBuffer */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"b\", function() { return binStringToBluffer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"c\", function() { return createBlob; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"d\", function() { return blobToBase64; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"e\", function() { return blobToBinaryString; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"g\", function() { return readAsArrayBuffer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"h\", function() { return readAsBinaryString; });\n/* unused harmony export typedBuffer */\nvar thisAtob = function (str) {\n  return atob(str);\n};\n\nvar thisBtoa = function (str) {\n  return btoa(str);\n};\n\n// Abstracts constructing a Blob object, so it also works in older\n// browsers that don't support the native Blob constructor (e.g.\n// old QtWebKit versions, Android < 4.4).\nfunction createBlob(parts, properties) {\n  /* global BlobBuilder,MSBlobBuilder,MozBlobBuilder,WebKitBlobBuilder */\n  parts = parts || [];\n  properties = properties || {};\n  try {\n    return new Blob(parts, properties);\n  } catch (e) {\n    if (e.name !== \"TypeError\") {\n      throw e;\n    }\n    var Builder = typeof BlobBuilder !== 'undefined' ? BlobBuilder :\n                  typeof MSBlobBuilder !== 'undefined' ? MSBlobBuilder :\n                  typeof MozBlobBuilder !== 'undefined' ? MozBlobBuilder :\n                  WebKitBlobBuilder;\n    var builder = new Builder();\n    for (var i = 0; i < parts.length; i += 1) {\n      builder.append(parts[i]);\n    }\n    return builder.getBlob(properties.type);\n  }\n}\n\n// From http://stackoverflow.com/questions/14967647/ (continues on next line)\n// encode-decode-image-with-base64-breaks-image (2013-04-21)\nfunction binaryStringToArrayBuffer(bin) {\n  var length = bin.length;\n  var buf = new ArrayBuffer(length);\n  var arr = new Uint8Array(buf);\n  for (var i = 0; i < length; i++) {\n    arr[i] = bin.charCodeAt(i);\n  }\n  return buf;\n}\n\nfunction binStringToBluffer(binString, type) {\n  return createBlob([binaryStringToArrayBuffer(binString)], {type: type});\n}\n\nfunction b64ToBluffer(b64, type) {\n  return binStringToBluffer(thisAtob(b64), type);\n}\n\n//Can't find original post, but this is close\n//http://stackoverflow.com/questions/6965107/ (continues on next line)\n//converting-between-strings-and-arraybuffers\nfunction arrayBufferToBinaryString(buffer) {\n  var binary = '';\n  var bytes = new Uint8Array(buffer);\n  var length = bytes.byteLength;\n  for (var i = 0; i < length; i++) {\n    binary += String.fromCharCode(bytes[i]);\n  }\n  return binary;\n}\n\n// shim for browsers that don't support it\nfunction readAsBinaryString(blob, callback) {\n  if (typeof FileReader === 'undefined') {\n    // fix for Firefox in a web worker\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=901097\n    return callback(arrayBufferToBinaryString(\n      new FileReaderSync().readAsArrayBuffer(blob)));\n  }\n\n  var reader = new FileReader();\n  var hasBinaryString = typeof reader.readAsBinaryString === 'function';\n  reader.onloadend = function (e) {\n    var result = e.target.result || '';\n    if (hasBinaryString) {\n      return callback(result);\n    }\n    callback(arrayBufferToBinaryString(result));\n  };\n  if (hasBinaryString) {\n    reader.readAsBinaryString(blob);\n  } else {\n    reader.readAsArrayBuffer(blob);\n  }\n}\n\nfunction blobToBinaryString(blobOrBuffer, callback) {\n  readAsBinaryString(blobOrBuffer, function (bin) {\n    callback(bin);\n  });\n}\n\nfunction blobToBase64(blobOrBuffer, callback) {\n  blobToBinaryString(blobOrBuffer, function (base64) {\n    callback(thisBtoa(base64));\n  });\n}\n\n// simplified API. universal browser support is assumed\nfunction readAsArrayBuffer(blob, callback) {\n  if (typeof FileReader === 'undefined') {\n    // fix for Firefox in a web worker:\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=901097\n    return callback(new FileReaderSync().readAsArrayBuffer(blob));\n  }\n\n  var reader = new FileReader();\n  reader.onloadend = function (e) {\n    var result = e.target.result || new ArrayBuffer(0);\n    callback(result);\n  };\n  reader.readAsArrayBuffer(blob);\n}\n\n// this is not used in the browser\nfunction typedBuffer() {\n}\n\n\n\n\n/***/ }),\n/* 124 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(global) {var scope = (typeof global !== \"undefined\" && global) ||\n            (typeof self !== \"undefined\" && self) ||\n            window;\nvar apply = Function.prototype.apply;\n\n// DOM APIs, for completeness\n\nexports.setTimeout = function() {\n  return new Timeout(apply.call(setTimeout, scope, arguments), clearTimeout);\n};\nexports.setInterval = function() {\n  return new Timeout(apply.call(setInterval, scope, arguments), clearInterval);\n};\nexports.clearTimeout =\nexports.clearInterval = function(timeout) {\n  if (timeout) {\n    timeout.close();\n  }\n};\n\nfunction Timeout(id, clearFn) {\n  this._id = id;\n  this._clearFn = clearFn;\n}\nTimeout.prototype.unref = Timeout.prototype.ref = function() {};\nTimeout.prototype.close = function() {\n  this._clearFn.call(scope, this._id);\n};\n\n// Does not start the time, just sets up the members needed.\nexports.enroll = function(item, msecs) {\n  clearTimeout(item._idleTimeoutId);\n  item._idleTimeout = msecs;\n};\n\nexports.unenroll = function(item) {\n  clearTimeout(item._idleTimeoutId);\n  item._idleTimeout = -1;\n};\n\nexports._unrefActive = exports.active = function(item) {\n  clearTimeout(item._idleTimeoutId);\n\n  var msecs = item._idleTimeout;\n  if (msecs >= 0) {\n    item._idleTimeoutId = setTimeout(function onTimeout() {\n      if (item._onTimeout)\n        item._onTimeout();\n    }, msecs);\n  }\n};\n\n// setimmediate attaches itself to the global object\n__webpack_require__(590);\n// On some exotic environments, it's not clear which object `setimmediate` was\n// able to install onto.  Search each possibility in the same order as the\n// `setimmediate` library.\nexports.setImmediate = (typeof self !== \"undefined\" && self.setImmediate) ||\n                       (typeof global !== \"undefined\" && global.setImmediate) ||\n                       (this && this.setImmediate);\nexports.clearImmediate = (typeof self !== \"undefined\" && self.clearImmediate) ||\n                         (typeof global !== \"undefined\" && global.clearImmediate) ||\n                         (this && this.clearImmediate);\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12)))\n\n/***/ }),\n/* 125 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(global) {\n/**\n * Module exports.\n */\n\nmodule.exports = deprecate;\n\n/**\n * Mark that a method should not be used.\n * Returns a modified function which warns once by default.\n *\n * If `localStorage.noDeprecation = true` is set, then it is a no-op.\n *\n * If `localStorage.throwDeprecation = true` is set, then deprecated functions\n * will throw an Error when invoked.\n *\n * If `localStorage.traceDeprecation = true` is set, then deprecated functions\n * will invoke `console.trace()` instead of `console.error()`.\n *\n * @param {Function} fn - the function to deprecate\n * @param {String} msg - the string to print to the console when `fn` is invoked\n * @returns {Function} a new \"deprecated\" version of `fn`\n * @api public\n */\n\nfunction deprecate (fn, msg) {\n  if (config('noDeprecation')) {\n    return fn;\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (config('throwDeprecation')) {\n        throw new Error(msg);\n      } else if (config('traceDeprecation')) {\n        console.trace(msg);\n      } else {\n        console.warn(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n}\n\n/**\n * Checks `localStorage` for boolean values for the given `name`.\n *\n * @param {String} name\n * @returns {Boolean}\n * @api private\n */\n\nfunction config (name) {\n  // accessing global.localStorage can trigger a DOMException in sandboxed iframes\n  try {\n    if (!global.localStorage) return false;\n  } catch (_) {\n    return false;\n  }\n  var val = global.localStorage[name];\n  if (null == val) return false;\n  return String(val).toLowerCase() === 'true';\n}\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12)))\n\n/***/ }),\n/* 126 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nmodule.exports = Stream;\n\nvar EE = __webpack_require__(23).EventEmitter;\nvar inherits = __webpack_require__(6);\n\ninherits(Stream, EE);\nStream.Readable = __webpack_require__(127);\nStream.Writable = __webpack_require__(605);\nStream.Duplex = __webpack_require__(606);\nStream.Transform = __webpack_require__(607);\nStream.PassThrough = __webpack_require__(608);\n\n// Backwards-compat with node 0.4.x\nStream.Stream = Stream;\n\n\n\n// old-style streams.  Note that the pipe method (the only relevant\n// part of this class) is overridden in the Readable class.\n\nfunction Stream() {\n  EE.call(this);\n}\n\nStream.prototype.pipe = function(dest, options) {\n  var source = this;\n\n  function ondata(chunk) {\n    if (dest.writable) {\n      if (false === dest.write(chunk) && source.pause) {\n        source.pause();\n      }\n    }\n  }\n\n  source.on('data', ondata);\n\n  function ondrain() {\n    if (source.readable && source.resume) {\n      source.resume();\n    }\n  }\n\n  dest.on('drain', ondrain);\n\n  // If the 'end' option is not supplied, dest.end() will be called when\n  // source gets the 'end' or 'close' events.  Only dest.end() once.\n  if (!dest._isStdio && (!options || options.end !== false)) {\n    source.on('end', onend);\n    source.on('close', onclose);\n  }\n\n  var didOnEnd = false;\n  function onend() {\n    if (didOnEnd) return;\n    didOnEnd = true;\n\n    dest.end();\n  }\n\n\n  function onclose() {\n    if (didOnEnd) return;\n    didOnEnd = true;\n\n    if (typeof dest.destroy === 'function') dest.destroy();\n  }\n\n  // don't leave dangling pipes when there are errors.\n  function onerror(er) {\n    cleanup();\n    if (EE.listenerCount(this, 'error') === 0) {\n      throw er; // Unhandled stream error in pipe.\n    }\n  }\n\n  source.on('error', onerror);\n  dest.on('error', onerror);\n\n  // remove all the event listeners that were added.\n  function cleanup() {\n    source.removeListener('data', ondata);\n    dest.removeListener('drain', ondrain);\n\n    source.removeListener('end', onend);\n    source.removeListener('close', onclose);\n\n    source.removeListener('error', onerror);\n    dest.removeListener('error', onerror);\n\n    source.removeListener('end', cleanup);\n    source.removeListener('close', cleanup);\n\n    dest.removeListener('close', cleanup);\n  }\n\n  source.on('end', cleanup);\n  source.on('close', cleanup);\n\n  dest.on('close', cleanup);\n\n  dest.emit('pipe', source);\n\n  // Allow for unix-like usage: A.pipe(B).pipe(C)\n  return dest;\n};\n\n\n/***/ }),\n/* 127 */\n/***/ (function(module, exports, __webpack_require__) {\n\nexports = module.exports = __webpack_require__(199);\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = __webpack_require__(128);\nexports.Duplex = __webpack_require__(53);\nexports.Transform = __webpack_require__(202);\nexports.PassThrough = __webpack_require__(604);\n\n\n/***/ }),\n/* 128 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(process, setImmediate, global) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(25);\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: __webpack_require__(125)\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(200);\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(35).Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = __webpack_require__(201);\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || __webpack_require__(53);\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || __webpack_require__(53);\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8), __webpack_require__(124).setImmediate, __webpack_require__(12)))\n\n/***/ }),\n/* 129 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) keys.push(key);\n  return keys;\n}\n/*</replacement>*/\n\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nvar Readable = __webpack_require__(203);\nvar Writable = __webpack_require__(204);\n\nutil.inherits(Duplex, Readable);\n\nforEach(objectKeys(Writable.prototype), function(method) {\n  if (!Duplex.prototype[method])\n    Duplex.prototype[method] = Writable.prototype[method];\n});\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex))\n    return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false)\n    this.readable = false;\n\n  if (options && options.writable === false)\n    this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false)\n    this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended)\n    return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  process.nextTick(this.end.bind(this));\n}\n\nfunction forEach (xs, f) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    f(xs[i], i);\n  }\n}\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8)))\n\n/***/ }),\n/* 130 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Invokes function, returning an object of the results.\n * @version 1.1.3\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module attempt-x\n */\n\n\n\nvar getArgs = function _getArgs(args) {\n  var length = args.length >>> 0;\n  var array = [];\n  var argLength = length - 1;\n  if (argLength < 1) {\n    return array;\n  }\n\n  array.length = argLength;\n  for (var index = 1; index < length; index += 1) {\n    array[index - 1] = args[index];\n  }\n\n  return array;\n};\n\n/**\n * This method attempts to invoke the function, returning either the result or\n * the caught error object. Any additional arguments are provided to the\n * function when it's invoked.\n *\n * @param {Function} fn - The function to attempt.\n * @param {...*} [args] - The arguments to invoke the function with.\n * @returns {Object} Returns an object of the result.\n * @example\n * var attempt = require('attempt-x');\n *\n * function thrower() {\n *   throw new Error('Threw');\n * }\n *\n * attempt(thrower, 1, 2);\n * // {\n * //   threw: true,\n * //   value: // Error('Threw') object\n * // }\n *\n * function sumArgs(a, b) {\n *   return a + b;\n * }\n *\n * attempt(sumArgs, 1, 2);\n * // {\n * //   threw: false,\n * //   value: 3\n * // }\n *\n * var thisArg = [];\n * function pusher(a, b) {\n *   return this.push(a, b);\n * }\n *\n * attempt.call(thisArg, pusher, 1, 2);\n * // {\n * //   threw: false,\n * //   value: 2\n * // }\n * // thisArg => [1, 2];\n */\nmodule.exports = function attempt(fn) {\n  try {\n    return {\n      threw: false,\n      value: fn.apply(this, getArgs(arguments))\n    };\n  } catch (e) {\n    return {\n      threw: true,\n      value: e\n    };\n  }\n};\n\n\n/***/ }),\n/* 131 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n*\n*\tVALIDATE: undefined\n*\n*\n*\tDESCRIPTION:\n*\t\t- Validates if a value is undefined.\n*\n*\n*\tNOTES:\n*\t\t[1]\n*\n*\n*\tTODO:\n*\t\t[1]\n*\n*\n*\tLICENSE:\n*\t\tMIT\n*\n*\tCopyright (c) 2014. Athan Reines.\n*\n*\n*\tAUTHOR:\n*\t\tAthan Reines. kgryte@gmail.com. 2014.\n*\n*/\n\n\n\n/**\n* FUNCTION: isUndefined( value )\n*\tValidates if a value is undefined.\n*\n* @param {*} value - value to be validated\n* @returns {Boolean} boolean indicating whether value is undefined\n*/\nfunction isUndefined( value ) {\n\treturn value === void 0;\n} // end FUNCTION isUndefined()\n\n\n// EXPORTS //\n\nmodule.exports = isUndefined;\n\n\n/***/ }),\n/* 132 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/*!\n * is-primitive <https://github.com/jonschlinkert/is-primitive>\n *\n * Copyright (c) 2014-2015, Jon Schlinkert.\n * Licensed under the MIT License.\n */\n\n\n\n// see http://jsperf.com/testing-value-is-primitive/7\nmodule.exports = function isPrimitive(value) {\n  return value == null || (typeof value !== 'function' && typeof value !== 'object');\n};\n\n\n/***/ }),\n/* 133 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file This method removes whitespace from the left end of a string.\n * @version 3.0.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module trim-left-x\n */\n\n\n\nvar requireCoercibleToString = __webpack_require__(134);\nvar Rx = __webpack_require__(38).RegExp;\nvar reLeft2016 = new Rx('^[' + __webpack_require__(68).string2016 + ']+');\nvar reLeft2018 = new Rx('^[' + __webpack_require__(68).string2018 + ']+');\nvar replace = ''.replace;\n\nvar $trimLeft2016 = function trimLeft2016(string) {\n  return replace.call(requireCoercibleToString(string), reLeft2016, '');\n};\n\nvar $trimLeft2018 = function trimLeft2018(string) {\n  return replace.call(requireCoercibleToString(string), reLeft2018, '');\n};\n\nmodule.exports = {\n  /**\n   * A reference to leftTrim2018.\n   */\n  trimLeft: $trimLeft2018,\n\n  /**\n   * This method removes whitespace from the left end of a string. (ES2016)\n   *\n   * @param {string} string - The string to trim the left end whitespace from.\n   * @throws {TypeError} If string is null or undefined or not coercible.\n   * @returns {string} The left trimmed string.\n   * @example\n   * var trimLeft = require('trim-left-x').trimLeft2016;\n   *\n   * trimLeft(' \\t\\na \\t\\n') === 'a \\t\\n'; // true\n   */\n  trimLeft2016: $trimLeft2016,\n\n  /**\n   * This method removes whitespace from the left end of a string. (ES2018)\n   *\n   * @param {string} string - The string to trim the left end whitespace from.\n   * @throws {TypeError} If string is null or undefined or not coercible.\n   * @returns {string} The left trimmed string.\n   * @example\n   * var trimLeft = require('trim-left-x').trimLeft2018;\n   *\n   * trimLeft(' \\t\\na \\t\\n') === 'a \\t\\n'; // true\n   */\n  trimLeft2018: $trimLeft2018\n};\n\n\n/***/ }),\n/* 134 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Requires an argument is corecible then converts using ToString.\n * @version 1.0.2\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module require-coercible-to-string-x\n */\n\n\n\nvar requireObjectCoercible = __webpack_require__(135);\nvar toStr = __webpack_require__(85);\n\n/**\n * This method requires an argument is corecible then converts using ToString.\n *\n * @param {*} value - The value to converted to a string.\n * @throws {TypeError} If value is null or undefined.\n * @returns {string} The value as a string.\n * @example\n * var requireCoercibleToString = require('require-coercible-to-string-x');\n *\n * requireCoercibleToString(); // TypeError\n * requireCoercibleToString(null); // TypeError\n * requireCoercibleToString(Symbol('')); // TypeError\n * requireCoercibleToString(Object.create(null)); // TypeError\n * requireCoercibleToString(1); // '1'\n * requireCoercibleToString(true); // 'true'\n */\nmodule.exports = function requireCoercibleToString(value) {\n  return toStr(requireObjectCoercible(value));\n};\n\n\n/***/ }),\n/* 135 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file ES6-compliant shim for RequireObjectCoercible.\n * @see {@link http://www.ecma-international.org/ecma-262/6.0/#sec-requireobjectcoercible|7.2.1 RequireObjectCoercible ( argument )}\n * @version 1.4.3\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module require-object-coercible-x\n */\n\n\n\nvar isNil = __webpack_require__(218);\n\n/**\n * The abstract operation RequireObjectCoercible throws an error if argument\n * is a value that cannot be converted to an Object using ToObject.\n *\n * @param {*} value - The `value` to check.\n * @throws {TypeError} If `value` is a `null` or `undefined`.\n * @returns {string} The `value`.\n * @example\n * var RequireObjectCoercible = require('require-object-coercible-x');\n *\n * RequireObjectCoercible(); // TypeError\n * RequireObjectCoercible(null); // TypeError\n * RequireObjectCoercible('abc'); // 'abc'\n * RequireObjectCoercible(true); // true\n * RequireObjectCoercible(Symbol('foo')); // Symbol('foo')\n */\nmodule.exports = function RequireObjectCoercible(value) {\n  if (isNil(value)) {\n    throw new TypeError('Cannot call method on ' + value);\n  }\n\n  return value;\n};\n\n\n/***/ }),\n/* 136 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nvar toStr = Object.prototype.toString;\nvar hasSymbols = typeof Symbol === 'function' && typeof Symbol() === 'symbol';\n\nif (hasSymbols) {\n\tvar symToStr = Symbol.prototype.toString;\n\tvar symStringRegex = /^Symbol\\(.*\\)$/;\n\tvar isSymbolObject = function isSymbolObject(value) {\n\t\tif (typeof value.valueOf() !== 'symbol') { return false; }\n\t\treturn symStringRegex.test(symToStr.call(value));\n\t};\n\tmodule.exports = function isSymbol(value) {\n\t\tif (typeof value === 'symbol') { return true; }\n\t\tif (toStr.call(value) !== '[object Symbol]') { return false; }\n\t\ttry {\n\t\t\treturn isSymbolObject(value);\n\t\t} catch (e) {\n\t\t\treturn false;\n\t\t}\n\t};\n} else {\n\tmodule.exports = function isSymbol(value) {\n\t\t// this environment does not support Symbols.\n\t\treturn false;\n\t};\n}\n\n\n/***/ }),\n/* 137 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file ES6-compliant shim for ToObject.\n * @see {@link http://www.ecma-international.org/ecma-262/6.0/#sec-toobject|7.1.13 ToObject ( argument )}\n * @version 1.5.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module to-object-x\n */\n\n\n\nvar requireObjectCoercible = __webpack_require__(135);\nvar castObject = __webpack_require__(38).Object;\n\n/**\n * The abstract operation ToObject converts argument to a value of\n * type Object.\n *\n * @param {*} value - The `value` to convert.\n * @throws {TypeError} If `value` is a `null` or `undefined`.\n * @returns {!Object} The `value` converted to an object.\n * @example\n * var ToObject = require('to-object-x');\n *\n * ToObject(); // TypeError\n * ToObject(null); // TypeError\n * ToObject('abc'); // Object('abc')\n * ToObject(true); // Object(true)\n * ToObject(Symbol('foo')); // Object(Symbol('foo'))\n */\nmodule.exports = function toObject(value) {\n  return castObject(requireObjectCoercible(value));\n};\n\n\n/***/ }),\n/* 138 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Converts argument to a value that can be used as a property key.\n * @version 2.0.2\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module to-property-key-x\n */\n\n\n\nvar hasSymbols = __webpack_require__(67);\nvar toPrimitive = __webpack_require__(219);\nvar toStr = __webpack_require__(85);\n\n/**\n * This method Converts argument to a value that can be used as a property key.\n *\n * @param {*} argument - The argument to onvert to a property key.\n * @throws {TypeError} If argument is not a symbol and is not coercible to a string.\n * @returns {string|symbol} The converted argument.\n * @example\n * var toPropertyKey = require('to-property-key-x');\n *\n * toPropertyKey(); // 'undefined'\n * toPropertyKey(1); // '1'\n * toPropertyKey(true); // 'true'\n *\n * var symbol = Symbol('a');\n * toPropertyKey(symbol); // symbol\n *\n * toPropertyKey(Object.create(null)); // TypeError\n */\nmodule.exports = function toPropertyKey(argument) {\n  var key = toPrimitive(argument, String);\n  return hasSymbols && typeof key === 'symbol' ? key : toStr(key);\n};\n\n\n/***/ }),\n/* 139 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file ES6-compliant shim for Number.isNaN - the global isNaN returns false positives.\n * @version 1.0.3\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module is-nan-x\n */\n\n\n\n/**\n * This method determines whether the passed value is NaN and its type is\n * `Number`. It is a more robust version of the original, global isNaN().\n *\n * @param {*} value - The value to be tested for NaN.\n * @returns {boolean} `true` if the given value is NaN and its type is Number;\n *  otherwise, `false`.\n * @example\n * var numberIsNaN = require('is-nan-x');\n *\n * numberIsNaN(NaN);        // true\n * numberIsNaN(Number.NaN); // true\n * numberIsNaN(0 / 0);      // true\n *\n * // e.g. these would have been true with global isNaN()\n * numberIsNaN('NaN');      // false\n * numberIsNaN(undefined);  // false\n * numberIsNaN({});         // false\n * numberIsNaN('blabla');   // false\n *\n * // These all return false\n * numberIsNaN(true);\n * numberIsNaN(null);\n * numberIsNaN(37);\n * numberIsNaN('37');\n * numberIsNaN('37.37');\n * numberIsNaN('');\n * numberIsNaN(' ');\n */\nmodule.exports = function isNaN(value) {\n  return value !== value;\n};\n\n\n/***/ }),\n/* 140 */,\n/* 141 */,\n/* 142 */,\n/* 143 */,\n/* 144 */,\n/* 145 */\n/***/ (function(module, exports, __webpack_require__) {\n\nmodule.exports = !__webpack_require__(9) && !__webpack_require__(4)(function () {\n  return Object.defineProperty(__webpack_require__(91)('div'), 'a', { get: function () { return 7; } }).a != 7;\n});\n\n\n/***/ }),\n/* 146 */\n/***/ (function(module, exports, __webpack_require__) {\n\nexports.f = __webpack_require__(7);\n\n\n/***/ }),\n/* 147 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar has = __webpack_require__(19);\nvar toIObject = __webpack_require__(20);\nvar arrayIndexOf = __webpack_require__(71)(false);\nvar IE_PROTO = __webpack_require__(93)('IE_PROTO');\n\nmodule.exports = function (object, names) {\n  var O = toIObject(object);\n  var i = 0;\n  var result = [];\n  var key;\n  for (key in O) if (key != IE_PROTO) has(O, key) && result.push(key);\n  // Don't enum bug & hidden keys\n  while (names.length > i) if (has(O, key = names[i++])) {\n    ~arrayIndexOf(result, key) || result.push(key);\n  }\n  return result;\n};\n\n\n/***/ }),\n/* 148 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar dP = __webpack_require__(10);\nvar anObject = __webpack_require__(2);\nvar getKeys = __webpack_require__(45);\n\nmodule.exports = __webpack_require__(9) ? Object.defineProperties : function defineProperties(O, Properties) {\n  anObject(O);\n  var keys = getKeys(Properties);\n  var length = keys.length;\n  var i = 0;\n  var P;\n  while (length > i) dP.f(O, P = keys[i++], Properties[P]);\n  return O;\n};\n\n\n/***/ }),\n/* 149 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// fallback for IE11 buggy Object.getOwnPropertyNames with iframe and window\nvar toIObject = __webpack_require__(20);\nvar gOPN = __webpack_require__(48).f;\nvar toString = {}.toString;\n\nvar windowNames = typeof window == 'object' && window && Object.getOwnPropertyNames\n  ? Object.getOwnPropertyNames(window) : [];\n\nvar getWindowNames = function (it) {\n  try {\n    return gOPN(it);\n  } catch (e) {\n    return windowNames.slice();\n  }\n};\n\nmodule.exports.f = function getOwnPropertyNames(it) {\n  return windowNames && toString.call(it) == '[object Window]' ? getWindowNames(it) : gOPN(toIObject(it));\n};\n\n\n/***/ }),\n/* 150 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// 19.1.2.1 Object.assign(target, source, ...)\nvar getKeys = __webpack_require__(45);\nvar gOPS = __webpack_require__(72);\nvar pIE = __webpack_require__(63);\nvar toObject = __webpack_require__(14);\nvar IObject = __webpack_require__(62);\nvar $assign = Object.assign;\n\n// should work with symbols and should have deterministic property order (V8 bug)\nmodule.exports = !$assign || __webpack_require__(4)(function () {\n  var A = {};\n  var B = {};\n  // eslint-disable-next-line no-undef\n  var S = Symbol();\n  var K = 'abcdefghijklmnopqrst';\n  A[S] = 7;\n  K.split('').forEach(function (k) { B[k] = k; });\n  return $assign({}, A)[S] != 7 || Object.keys($assign({}, B)).join('') != K;\n}) ? function assign(target, source) { // eslint-disable-line no-unused-vars\n  var T = toObject(target);\n  var aLen = arguments.length;\n  var index = 1;\n  var getSymbols = gOPS.f;\n  var isEnum = pIE.f;\n  while (aLen > index) {\n    var S = IObject(arguments[index++]);\n    var keys = getSymbols ? getKeys(S).concat(getSymbols(S)) : getKeys(S);\n    var length = keys.length;\n    var j = 0;\n    var key;\n    while (length > j) if (isEnum.call(S, key = keys[j++])) T[key] = S[key];\n  } return T;\n} : $assign;\n\n\n/***/ }),\n/* 151 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar aFunction = __webpack_require__(15);\nvar isObject = __webpack_require__(5);\nvar invoke = __webpack_require__(152);\nvar arraySlice = [].slice;\nvar factories = {};\n\nvar construct = function (F, len, args) {\n  if (!(len in factories)) {\n    for (var n = [], i = 0; i < len; i++) n[i] = 'a[' + i + ']';\n    // eslint-disable-next-line no-new-func\n    factories[len] = Function('F,a', 'return new F(' + n.join(',') + ')');\n  } return factories[len](F, args);\n};\n\nmodule.exports = Function.bind || function bind(that /* , ...args */) {\n  var fn = aFunction(this);\n  var partArgs = arraySlice.call(arguments, 1);\n  var bound = function (/* args... */) {\n    var args = partArgs.concat(arraySlice.call(arguments));\n    return this instanceof bound ? construct(fn, args.length, args) : invoke(fn, args, that);\n  };\n  if (isObject(fn.prototype)) bound.prototype = fn.prototype;\n  return bound;\n};\n\n\n/***/ }),\n/* 152 */\n/***/ (function(module, exports) {\n\n// fast apply, http://jsperf.lnkit.com/fast-apply/5\nmodule.exports = function (fn, args, that) {\n  var un = that === undefined;\n  switch (args.length) {\n    case 0: return un ? fn()\n                      : fn.call(that);\n    case 1: return un ? fn(args[0])\n                      : fn.call(that, args[0]);\n    case 2: return un ? fn(args[0], args[1])\n                      : fn.call(that, args[0], args[1]);\n    case 3: return un ? fn(args[0], args[1], args[2])\n                      : fn.call(that, args[0], args[1], args[2]);\n    case 4: return un ? fn(args[0], args[1], args[2], args[3])\n                      : fn.call(that, args[0], args[1], args[2], args[3]);\n  } return fn.apply(that, args);\n};\n\n\n/***/ }),\n/* 153 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $parseInt = __webpack_require__(3).parseInt;\nvar $trim = __webpack_require__(57).trim;\nvar ws = __webpack_require__(97);\nvar hex = /^[-+]?0[xX]/;\n\nmodule.exports = $parseInt(ws + '08') !== 8 || $parseInt(ws + '0x16') !== 22 ? function parseInt(str, radix) {\n  var string = $trim(String(str), 3);\n  return $parseInt(string, (radix >>> 0) || (hex.test(string) ? 16 : 10));\n} : $parseInt;\n\n\n/***/ }),\n/* 154 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $parseFloat = __webpack_require__(3).parseFloat;\nvar $trim = __webpack_require__(57).trim;\n\nmodule.exports = 1 / $parseFloat(__webpack_require__(97) + '-0') !== -Infinity ? function parseFloat(str) {\n  var string = $trim(String(str), 3);\n  var result = $parseFloat(string);\n  return result === 0 && string.charAt(0) == '-' ? -0 : result;\n} : $parseFloat;\n\n\n/***/ }),\n/* 155 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar cof = __webpack_require__(28);\nmodule.exports = function (it, msg) {\n  if (typeof it != 'number' && cof(it) != 'Number') throw TypeError(msg);\n  return +it;\n};\n\n\n/***/ }),\n/* 156 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.1.2.3 Number.isInteger(number)\nvar isObject = __webpack_require__(5);\nvar floor = Math.floor;\nmodule.exports = function isInteger(it) {\n  return !isObject(it) && isFinite(it) && floor(it) === it;\n};\n\n\n/***/ }),\n/* 157 */\n/***/ (function(module, exports) {\n\n// 20.2.2.20 Math.log1p(x)\nmodule.exports = Math.log1p || function log1p(x) {\n  return (x = +x) > -1e-8 && x < 1e-8 ? x - x * x / 2 : Math.log(1 + x);\n};\n\n\n/***/ }),\n/* 158 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.16 Math.fround(x)\nvar sign = __webpack_require__(100);\nvar pow = Math.pow;\nvar EPSILON = pow(2, -52);\nvar EPSILON32 = pow(2, -23);\nvar MAX32 = pow(2, 127) * (2 - EPSILON32);\nvar MIN32 = pow(2, -126);\n\nvar roundTiesToEven = function (n) {\n  return n + 1 / EPSILON - 1 / EPSILON;\n};\n\nmodule.exports = Math.fround || function fround(x) {\n  var $abs = Math.abs(x);\n  var $sign = sign(x);\n  var a, result;\n  if ($abs < MIN32) return $sign * roundTiesToEven($abs / MIN32 / EPSILON32) * MIN32 * EPSILON32;\n  a = (1 + EPSILON32 / EPSILON) * $abs;\n  result = a - (a - $abs);\n  // eslint-disable-next-line no-self-compare\n  if (result > MAX32 || result != result) return $sign * Infinity;\n  return $sign * result;\n};\n\n\n/***/ }),\n/* 159 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// call something on iterator step with safe closing on error\nvar anObject = __webpack_require__(2);\nmodule.exports = function (iterator, fn, value, entries) {\n  try {\n    return entries ? fn(anObject(value)[0], value[1]) : fn(value);\n  // 7.4.6 IteratorClose(iterator, completion)\n  } catch (e) {\n    var ret = iterator['return'];\n    if (ret !== undefined) anObject(ret.call(iterator));\n    throw e;\n  }\n};\n\n\n/***/ }),\n/* 160 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar aFunction = __webpack_require__(15);\nvar toObject = __webpack_require__(14);\nvar IObject = __webpack_require__(62);\nvar toLength = __webpack_require__(11);\n\nmodule.exports = function (that, callbackfn, aLen, memo, isRight) {\n  aFunction(callbackfn);\n  var O = toObject(that);\n  var self = IObject(O);\n  var length = toLength(O.length);\n  var index = isRight ? length - 1 : 0;\n  var i = isRight ? -1 : 1;\n  if (aLen < 2) for (;;) {\n    if (index in self) {\n      memo = self[index];\n      index += i;\n      break;\n    }\n    index += i;\n    if (isRight ? index < 0 : length <= index) {\n      throw TypeError('Reduce of empty array with no initial value');\n    }\n  }\n  for (;isRight ? index >= 0 : length > index; index += i) if (index in self) {\n    memo = callbackfn(memo, self[index], index, O);\n  }\n  return memo;\n};\n\n\n/***/ }),\n/* 161 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// 22.1.3.3 Array.prototype.copyWithin(target, start, end = this.length)\n\nvar toObject = __webpack_require__(14);\nvar toAbsoluteIndex = __webpack_require__(46);\nvar toLength = __webpack_require__(11);\n\nmodule.exports = [].copyWithin || function copyWithin(target /* = 0 */, start /* = 0, end = @length */) {\n  var O = toObject(this);\n  var len = toLength(O.length);\n  var to = toAbsoluteIndex(target, len);\n  var from = toAbsoluteIndex(start, len);\n  var end = arguments.length > 2 ? arguments[2] : undefined;\n  var count = Math.min((end === undefined ? len : toAbsoluteIndex(end, len)) - from, len - to);\n  var inc = 1;\n  if (from < to && to < from + count) {\n    inc = -1;\n    from += count - 1;\n    to += count - 1;\n  }\n  while (count-- > 0) {\n    if (from in O) O[to] = O[from];\n    else delete O[to];\n    to += inc;\n    from += inc;\n  } return O;\n};\n\n\n/***/ }),\n/* 162 */\n/***/ (function(module, exports) {\n\nmodule.exports = function (done, value) {\n  return { value: value, done: !!done };\n};\n\n\n/***/ }),\n/* 163 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 21.2.5.3 get RegExp.prototype.flags()\nif (__webpack_require__(9) && /./g.flags != 'g') __webpack_require__(10).f(RegExp.prototype, 'flags', {\n  configurable: true,\n  get: __webpack_require__(76)\n});\n\n\n/***/ }),\n/* 164 */\n/***/ (function(module, exports) {\n\nmodule.exports = function (exec) {\n  try {\n    return { e: false, v: exec() };\n  } catch (e) {\n    return { e: true, v: e };\n  }\n};\n\n\n/***/ }),\n/* 165 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar anObject = __webpack_require__(2);\nvar isObject = __webpack_require__(5);\nvar newPromiseCapability = __webpack_require__(115);\n\nmodule.exports = function (C, x) {\n  anObject(C);\n  if (isObject(x) && x.constructor === C) return x;\n  var promiseCapability = newPromiseCapability.f(C);\n  var resolve = promiseCapability.resolve;\n  resolve(x);\n  return promiseCapability.promise;\n};\n\n\n/***/ }),\n/* 166 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar strong = __webpack_require__(167);\nvar validate = __webpack_require__(59);\nvar MAP = 'Map';\n\n// 23.1 Map Objects\nmodule.exports = __webpack_require__(80)(MAP, function (get) {\n  return function Map() { return get(this, arguments.length > 0 ? arguments[0] : undefined); };\n}, {\n  // 23.1.3.6 Map.prototype.get(key)\n  get: function get(key) {\n    var entry = strong.getEntry(validate(this, MAP), key);\n    return entry && entry.v;\n  },\n  // 23.1.3.9 Map.prototype.set(key, value)\n  set: function set(key, value) {\n    return strong.def(validate(this, MAP), key === 0 ? 0 : key, value);\n  }\n}, strong, true);\n\n\n/***/ }),\n/* 167 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar dP = __webpack_require__(10).f;\nvar create = __webpack_require__(47);\nvar redefineAll = __webpack_require__(52);\nvar ctx = __webpack_require__(27);\nvar anInstance = __webpack_require__(50);\nvar forOf = __webpack_require__(51);\nvar $iterDefine = __webpack_require__(103);\nvar step = __webpack_require__(162);\nvar setSpecies = __webpack_require__(49);\nvar DESCRIPTORS = __webpack_require__(9);\nvar fastKey = __webpack_require__(39).fastKey;\nvar validate = __webpack_require__(59);\nvar SIZE = DESCRIPTORS ? '_s' : 'size';\n\nvar getEntry = function (that, key) {\n  // fast case\n  var index = fastKey(key);\n  var entry;\n  if (index !== 'F') return that._i[index];\n  // frozen object case\n  for (entry = that._f; entry; entry = entry.n) {\n    if (entry.k == key) return entry;\n  }\n};\n\nmodule.exports = {\n  getConstructor: function (wrapper, NAME, IS_MAP, ADDER) {\n    var C = wrapper(function (that, iterable) {\n      anInstance(that, C, NAME, '_i');\n      that._t = NAME;         // collection type\n      that._i = create(null); // index\n      that._f = undefined;    // first entry\n      that._l = undefined;    // last entry\n      that[SIZE] = 0;         // size\n      if (iterable != undefined) forOf(iterable, IS_MAP, that[ADDER], that);\n    });\n    redefineAll(C.prototype, {\n      // 23.1.3.1 Map.prototype.clear()\n      // 23.2.3.2 Set.prototype.clear()\n      clear: function clear() {\n        for (var that = validate(this, NAME), data = that._i, entry = that._f; entry; entry = entry.n) {\n          entry.r = true;\n          if (entry.p) entry.p = entry.p.n = undefined;\n          delete data[entry.i];\n        }\n        that._f = that._l = undefined;\n        that[SIZE] = 0;\n      },\n      // 23.1.3.3 Map.prototype.delete(key)\n      // 23.2.3.4 Set.prototype.delete(value)\n      'delete': function (key) {\n        var that = validate(this, NAME);\n        var entry = getEntry(that, key);\n        if (entry) {\n          var next = entry.n;\n          var prev = entry.p;\n          delete that._i[entry.i];\n          entry.r = true;\n          if (prev) prev.n = next;\n          if (next) next.p = prev;\n          if (that._f == entry) that._f = next;\n          if (that._l == entry) that._l = prev;\n          that[SIZE]--;\n        } return !!entry;\n      },\n      // 23.2.3.6 Set.prototype.forEach(callbackfn, thisArg = undefined)\n      // 23.1.3.5 Map.prototype.forEach(callbackfn, thisArg = undefined)\n      forEach: function forEach(callbackfn /* , that = undefined */) {\n        validate(this, NAME);\n        var f = ctx(callbackfn, arguments.length > 1 ? arguments[1] : undefined, 3);\n        var entry;\n        while (entry = entry ? entry.n : this._f) {\n          f(entry.v, entry.k, this);\n          // revert to the last existing entry\n          while (entry && entry.r) entry = entry.p;\n        }\n      },\n      // 23.1.3.7 Map.prototype.has(key)\n      // 23.2.3.7 Set.prototype.has(value)\n      has: function has(key) {\n        return !!getEntry(validate(this, NAME), key);\n      }\n    });\n    if (DESCRIPTORS) dP(C.prototype, 'size', {\n      get: function () {\n        return validate(this, NAME)[SIZE];\n      }\n    });\n    return C;\n  },\n  def: function (that, key, value) {\n    var entry = getEntry(that, key);\n    var prev, index;\n    // change existing entry\n    if (entry) {\n      entry.v = value;\n    // create new entry\n    } else {\n      that._l = entry = {\n        i: index = fastKey(key, true), // <- index\n        k: key,                        // <- key\n        v: value,                      // <- value\n        p: prev = that._l,             // <- previous entry\n        n: undefined,                  // <- next entry\n        r: false                       // <- removed\n      };\n      if (!that._f) that._f = entry;\n      if (prev) prev.n = entry;\n      that[SIZE]++;\n      // add to index\n      if (index !== 'F') that._i[index] = entry;\n    } return that;\n  },\n  getEntry: getEntry,\n  setStrong: function (C, NAME, IS_MAP) {\n    // add .keys, .values, .entries, [@@iterator]\n    // 23.1.3.4, 23.1.3.8, 23.1.3.11, 23.1.3.12, 23.2.3.5, 23.2.3.8, 23.2.3.10, 23.2.3.11\n    $iterDefine(C, NAME, function (iterated, kind) {\n      this._t = validate(iterated, NAME); // target\n      this._k = kind;                     // kind\n      this._l = undefined;                // previous\n    }, function () {\n      var that = this;\n      var kind = that._k;\n      var entry = that._l;\n      // revert to the last existing entry\n      while (entry && entry.r) entry = entry.p;\n      // get next entry\n      if (!that._t || !(that._l = entry = entry ? entry.n : that._t._f)) {\n        // or finish the iteration\n        that._t = undefined;\n        return step(1);\n      }\n      // return step by kind\n      if (kind == 'keys') return step(0, entry.k);\n      if (kind == 'values') return step(0, entry.v);\n      return step(0, [entry.k, entry.v]);\n    }, IS_MAP ? 'entries' : 'values', !IS_MAP, true);\n\n    // add [@@species], 23.1.2.2, 23.2.2.2\n    setSpecies(NAME);\n  }\n};\n\n\n/***/ }),\n/* 168 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar strong = __webpack_require__(167);\nvar validate = __webpack_require__(59);\nvar SET = 'Set';\n\n// 23.2 Set Objects\nmodule.exports = __webpack_require__(80)(SET, function (get) {\n  return function Set() { return get(this, arguments.length > 0 ? arguments[0] : undefined); };\n}, {\n  // 23.2.3.1 Set.prototype.add(value)\n  add: function add(value) {\n    return strong.def(validate(this, SET), value = value === 0 ? 0 : value, value);\n  }\n}, strong);\n\n\n/***/ }),\n/* 169 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar each = __webpack_require__(34)(0);\nvar redefine = __webpack_require__(17);\nvar meta = __webpack_require__(39);\nvar assign = __webpack_require__(150);\nvar weak = __webpack_require__(170);\nvar isObject = __webpack_require__(5);\nvar fails = __webpack_require__(4);\nvar validate = __webpack_require__(59);\nvar WEAK_MAP = 'WeakMap';\nvar getWeak = meta.getWeak;\nvar isExtensible = Object.isExtensible;\nvar uncaughtFrozenStore = weak.ufstore;\nvar tmp = {};\nvar InternalMap;\n\nvar wrapper = function (get) {\n  return function WeakMap() {\n    return get(this, arguments.length > 0 ? arguments[0] : undefined);\n  };\n};\n\nvar methods = {\n  // 23.3.3.3 WeakMap.prototype.get(key)\n  get: function get(key) {\n    if (isObject(key)) {\n      var data = getWeak(key);\n      if (data === true) return uncaughtFrozenStore(validate(this, WEAK_MAP)).get(key);\n      return data ? data[this._i] : undefined;\n    }\n  },\n  // 23.3.3.5 WeakMap.prototype.set(key, value)\n  set: function set(key, value) {\n    return weak.def(validate(this, WEAK_MAP), key, value);\n  }\n};\n\n// 23.3 WeakMap Objects\nvar $WeakMap = module.exports = __webpack_require__(80)(WEAK_MAP, wrapper, methods, weak, true, true);\n\n// IE11 WeakMap frozen keys fix\nif (fails(function () { return new $WeakMap().set((Object.freeze || Object)(tmp), 7).get(tmp) != 7; })) {\n  InternalMap = weak.getConstructor(wrapper, WEAK_MAP);\n  assign(InternalMap.prototype, methods);\n  meta.NEED = true;\n  each(['delete', 'has', 'get', 'set'], function (key) {\n    var proto = $WeakMap.prototype;\n    var method = proto[key];\n    redefine(proto, key, function (a, b) {\n      // store frozen objects on internal weakmap shim\n      if (isObject(a) && !isExtensible(a)) {\n        if (!this._f) this._f = new InternalMap();\n        var result = this._f[key](a, b);\n        return key == 'set' ? this : result;\n      // store all the rest on native weakmap\n      } return method.call(this, a, b);\n    });\n  });\n}\n\n\n/***/ }),\n/* 170 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar redefineAll = __webpack_require__(52);\nvar getWeak = __webpack_require__(39).getWeak;\nvar anObject = __webpack_require__(2);\nvar isObject = __webpack_require__(5);\nvar anInstance = __webpack_require__(50);\nvar forOf = __webpack_require__(51);\nvar createArrayMethod = __webpack_require__(34);\nvar $has = __webpack_require__(19);\nvar validate = __webpack_require__(59);\nvar arrayFind = createArrayMethod(5);\nvar arrayFindIndex = createArrayMethod(6);\nvar id = 0;\n\n// fallback for uncaught frozen keys\nvar uncaughtFrozenStore = function (that) {\n  return that._l || (that._l = new UncaughtFrozenStore());\n};\nvar UncaughtFrozenStore = function () {\n  this.a = [];\n};\nvar findUncaughtFrozen = function (store, key) {\n  return arrayFind(store.a, function (it) {\n    return it[0] === key;\n  });\n};\nUncaughtFrozenStore.prototype = {\n  get: function (key) {\n    var entry = findUncaughtFrozen(this, key);\n    if (entry) return entry[1];\n  },\n  has: function (key) {\n    return !!findUncaughtFrozen(this, key);\n  },\n  set: function (key, value) {\n    var entry = findUncaughtFrozen(this, key);\n    if (entry) entry[1] = value;\n    else this.a.push([key, value]);\n  },\n  'delete': function (key) {\n    var index = arrayFindIndex(this.a, function (it) {\n      return it[0] === key;\n    });\n    if (~index) this.a.splice(index, 1);\n    return !!~index;\n  }\n};\n\nmodule.exports = {\n  getConstructor: function (wrapper, NAME, IS_MAP, ADDER) {\n    var C = wrapper(function (that, iterable) {\n      anInstance(that, C, NAME, '_i');\n      that._t = NAME;      // collection type\n      that._i = id++;      // collection id\n      that._l = undefined; // leak store for uncaught frozen objects\n      if (iterable != undefined) forOf(iterable, IS_MAP, that[ADDER], that);\n    });\n    redefineAll(C.prototype, {\n      // 23.3.3.2 WeakMap.prototype.delete(key)\n      // 23.4.3.3 WeakSet.prototype.delete(value)\n      'delete': function (key) {\n        if (!isObject(key)) return false;\n        var data = getWeak(key);\n        if (data === true) return uncaughtFrozenStore(validate(this, NAME))['delete'](key);\n        return data && $has(data, this._i) && delete data[this._i];\n      },\n      // 23.3.3.4 WeakMap.prototype.has(key)\n      // 23.4.3.4 WeakSet.prototype.has(value)\n      has: function has(key) {\n        if (!isObject(key)) return false;\n        var data = getWeak(key);\n        if (data === true) return uncaughtFrozenStore(validate(this, NAME)).has(key);\n        return data && $has(data, this._i);\n      }\n    });\n    return C;\n  },\n  def: function (that, key, value) {\n    var data = getWeak(anObject(key), true);\n    if (data === true) uncaughtFrozenStore(that).set(key, value);\n    else data[that._i] = value;\n    return that;\n  },\n  ufstore: uncaughtFrozenStore\n};\n\n\n/***/ }),\n/* 171 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://tc39.github.io/ecma262/#sec-toindex\nvar toInteger = __webpack_require__(32);\nvar toLength = __webpack_require__(11);\nmodule.exports = function (it) {\n  if (it === undefined) return 0;\n  var number = toInteger(it);\n  var length = toLength(number);\n  if (number !== length) throw RangeError('Wrong length!');\n  return length;\n};\n\n\n/***/ }),\n/* 172 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// all object keys, includes non-enumerable and symbols\nvar gOPN = __webpack_require__(48);\nvar gOPS = __webpack_require__(72);\nvar anObject = __webpack_require__(2);\nvar Reflect = __webpack_require__(3).Reflect;\nmodule.exports = Reflect && Reflect.ownKeys || function ownKeys(it) {\n  var keys = gOPN.f(anObject(it));\n  var getSymbols = gOPS.f;\n  return getSymbols ? keys.concat(getSymbols(it)) : keys;\n};\n\n\n/***/ }),\n/* 173 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://tc39.github.io/proposal-flatMap/#sec-FlattenIntoArray\nvar isArray = __webpack_require__(73);\nvar isObject = __webpack_require__(5);\nvar toLength = __webpack_require__(11);\nvar ctx = __webpack_require__(27);\nvar IS_CONCAT_SPREADABLE = __webpack_require__(7)('isConcatSpreadable');\n\nfunction flattenIntoArray(target, original, source, sourceLen, start, depth, mapper, thisArg) {\n  var targetIndex = start;\n  var sourceIndex = 0;\n  var mapFn = mapper ? ctx(mapper, thisArg, 3) : false;\n  var element, spreadable;\n\n  while (sourceIndex < sourceLen) {\n    if (sourceIndex in source) {\n      element = mapFn ? mapFn(source[sourceIndex], sourceIndex, original) : source[sourceIndex];\n\n      spreadable = false;\n      if (isObject(element)) {\n        spreadable = element[IS_CONCAT_SPREADABLE];\n        spreadable = spreadable !== undefined ? !!spreadable : isArray(element);\n      }\n\n      if (spreadable && depth > 0) {\n        targetIndex = flattenIntoArray(target, original, element, toLength(element.length), targetIndex, depth - 1) - 1;\n      } else {\n        if (targetIndex >= 0x1fffffffffffff) throw TypeError();\n        target[targetIndex] = element;\n      }\n\n      targetIndex++;\n    }\n    sourceIndex++;\n  }\n  return targetIndex;\n}\n\nmodule.exports = flattenIntoArray;\n\n\n/***/ }),\n/* 174 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://github.com/tc39/proposal-string-pad-start-end\nvar toLength = __webpack_require__(11);\nvar repeat = __webpack_require__(99);\nvar defined = __webpack_require__(31);\n\nmodule.exports = function (that, maxLength, fillString, left) {\n  var S = String(defined(that));\n  var stringLength = S.length;\n  var fillStr = fillString === undefined ? ' ' : String(fillString);\n  var intMaxLength = toLength(maxLength);\n  if (intMaxLength <= stringLength || fillStr == '') return S;\n  var fillLen = intMaxLength - stringLength;\n  var stringFiller = repeat.call(fillStr, Math.ceil(fillLen / fillStr.length));\n  if (stringFiller.length > fillLen) stringFiller = stringFiller.slice(0, fillLen);\n  return left ? stringFiller + S : S + stringFiller;\n};\n\n\n/***/ }),\n/* 175 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar getKeys = __webpack_require__(45);\nvar toIObject = __webpack_require__(20);\nvar isEnum = __webpack_require__(63).f;\nmodule.exports = function (isEntries) {\n  return function (it) {\n    var O = toIObject(it);\n    var keys = getKeys(O);\n    var length = keys.length;\n    var i = 0;\n    var result = [];\n    var key;\n    while (length > i) if (isEnum.call(O, key = keys[i++])) {\n      result.push(isEntries ? [key, O[key]] : O[key]);\n    } return result;\n  };\n};\n\n\n/***/ }),\n/* 176 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://github.com/DavidBruant/Map-Set.prototype.toJSON\nvar classof = __webpack_require__(64);\nvar from = __webpack_require__(177);\nmodule.exports = function (NAME) {\n  return function toJSON() {\n    if (classof(this) != NAME) throw TypeError(NAME + \"#toJSON isn't generic\");\n    return from(this);\n  };\n};\n\n\n/***/ }),\n/* 177 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar forOf = __webpack_require__(51);\n\nmodule.exports = function (iter, ITERATOR) {\n  var result = [];\n  forOf(iter, false, result.push, result, ITERATOR);\n  return result;\n};\n\n\n/***/ }),\n/* 178 */\n/***/ (function(module, exports) {\n\n// https://rwaldron.github.io/proposal-math-extensions/\nmodule.exports = Math.scale || function scale(x, inLow, inHigh, outLow, outHigh) {\n  if (\n    arguments.length === 0\n      // eslint-disable-next-line no-self-compare\n      || x != x\n      // eslint-disable-next-line no-self-compare\n      || inLow != inLow\n      // eslint-disable-next-line no-self-compare\n      || inHigh != inHigh\n      // eslint-disable-next-line no-self-compare\n      || outLow != outLow\n      // eslint-disable-next-line no-self-compare\n      || outHigh != outHigh\n  ) return NaN;\n  if (x === Infinity || x === -Infinity) return x;\n  return (x - inLow) * (outHigh - outLow) / (inHigh - inLow) + outLow;\n};\n\n\n/***/ }),\n/* 179 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\nObject.defineProperty(__webpack_exports__, \"__esModule\", { value: true });\n/* WEBPACK VAR INJECTION */(function(global) {/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_lie__ = __webpack_require__(180);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_lie___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_0_lie__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_argsarray__ = __webpack_require__(118);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_argsarray___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_1_argsarray__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2_immediate__ = __webpack_require__(117);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2_immediate___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_2_immediate__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_3_events__ = __webpack_require__(23);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_3_events___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_3_events__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_4_inherits__ = __webpack_require__(6);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_4_inherits___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_4_inherits__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_5_uuid__ = __webpack_require__(565);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_5_uuid___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_5_uuid__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_6_debug__ = __webpack_require__(568);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_6_debug___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_6_debug__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_7_spark_md5__ = __webpack_require__(183);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_7_spark_md5___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_7_spark_md5__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_8_vuvuzela__ = __webpack_require__(184);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_8_vuvuzela___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_8_vuvuzela__);\n\n\n\n\n\n\n\n\n\n\n/* istanbul ignore next */\nvar PouchPromise = typeof Promise === 'function' ? Promise : __WEBPACK_IMPORTED_MODULE_0_lie___default.a;\n\nfunction isBinaryObject(object) {\n  return (typeof ArrayBuffer !== 'undefined' && object instanceof ArrayBuffer) ||\n    (typeof Blob !== 'undefined' && object instanceof Blob);\n}\n\nfunction cloneArrayBuffer(buff) {\n  if (typeof buff.slice === 'function') {\n    return buff.slice(0);\n  }\n  // IE10-11 slice() polyfill\n  var target = new ArrayBuffer(buff.byteLength);\n  var targetArray = new Uint8Array(target);\n  var sourceArray = new Uint8Array(buff);\n  targetArray.set(sourceArray);\n  return target;\n}\n\nfunction cloneBinaryObject(object) {\n  if (object instanceof ArrayBuffer) {\n    return cloneArrayBuffer(object);\n  }\n  var size = object.size;\n  var type = object.type;\n  // Blob\n  if (typeof object.slice === 'function') {\n    return object.slice(0, size, type);\n  }\n  // PhantomJS slice() replacement\n  return object.webkitSlice(0, size, type);\n}\n\n// most of this is borrowed from lodash.isPlainObject:\n// https://github.com/fis-components/lodash.isplainobject/\n// blob/29c358140a74f252aeb08c9eb28bef86f2217d4a/index.js\n\nvar funcToString = Function.prototype.toString;\nvar objectCtorString = funcToString.call(Object);\n\nfunction isPlainObject(value) {\n  var proto = Object.getPrototypeOf(value);\n  /* istanbul ignore if */\n  if (proto === null) { // not sure when this happens, but I guess it can\n    return true;\n  }\n  var Ctor = proto.constructor;\n  return (typeof Ctor == 'function' &&\n    Ctor instanceof Ctor && funcToString.call(Ctor) == objectCtorString);\n}\n\nfunction clone(object) {\n  var newObject;\n  var i;\n  var len;\n\n  if (!object || typeof object !== 'object') {\n    return object;\n  }\n\n  if (Array.isArray(object)) {\n    newObject = [];\n    for (i = 0, len = object.length; i < len; i++) {\n      newObject[i] = clone(object[i]);\n    }\n    return newObject;\n  }\n\n  // special case: to avoid inconsistencies between IndexedDB\n  // and other backends, we automatically stringify Dates\n  if (object instanceof Date) {\n    return object.toISOString();\n  }\n\n  if (isBinaryObject(object)) {\n    return cloneBinaryObject(object);\n  }\n\n  if (!isPlainObject(object)) {\n    return object; // don't clone objects like Workers\n  }\n\n  newObject = {};\n  for (i in object) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(object, i)) {\n      var value = clone(object[i]);\n      if (typeof value !== 'undefined') {\n        newObject[i] = value;\n      }\n    }\n  }\n  return newObject;\n}\n\nfunction once(fun) {\n  var called = false;\n  return __WEBPACK_IMPORTED_MODULE_1_argsarray___default()(function (args) {\n    /* istanbul ignore if */\n    if (called) {\n      // this is a smoke test and should never actually happen\n      throw new Error('once called more than once');\n    } else {\n      called = true;\n      fun.apply(this, args);\n    }\n  });\n}\n\nfunction toPromise(func) {\n  //create the function we will be returning\n  return __WEBPACK_IMPORTED_MODULE_1_argsarray___default()(function (args) {\n    // Clone arguments\n    args = clone(args);\n    var self = this;\n    // if the last argument is a function, assume its a callback\n    var usedCB = (typeof args[args.length - 1] === 'function') ? args.pop() : false;\n    var promise = new PouchPromise(function (fulfill, reject) {\n      var resp;\n      try {\n        var callback = once(function (err, mesg) {\n          if (err) {\n            reject(err);\n          } else {\n            fulfill(mesg);\n          }\n        });\n        // create a callback for this invocation\n        // apply the function in the orig context\n        args.push(callback);\n        resp = func.apply(self, args);\n        if (resp && typeof resp.then === 'function') {\n          fulfill(resp);\n        }\n      } catch (e) {\n        reject(e);\n      }\n    });\n    // if there is a callback, call it back\n    if (usedCB) {\n      promise.then(function (result) {\n        usedCB(null, result);\n      }, usedCB);\n    }\n    return promise;\n  });\n}\n\nfunction logApiCall(self, name, args) {\n  /* istanbul ignore if */\n  if (self.constructor.listeners('debug').length) {\n    var logArgs = ['api', self.name, name];\n    for (var i = 0; i < args.length - 1; i++) {\n      logArgs.push(args[i]);\n    }\n    self.constructor.emit('debug', logArgs);\n\n    // override the callback itself to log the response\n    var origCallback = args[args.length - 1];\n    args[args.length - 1] = function (err, res) {\n      var responseArgs = ['api', self.name, name];\n      responseArgs = responseArgs.concat(\n        err ? ['error', err] : ['success', res]\n      );\n      self.constructor.emit('debug', responseArgs);\n      origCallback(err, res);\n    };\n  }\n}\n\nfunction adapterFun(name, callback) {\n  return toPromise(__WEBPACK_IMPORTED_MODULE_1_argsarray___default()(function (args) {\n    if (this._closed) {\n      return PouchPromise.reject(new Error('database is closed'));\n    }\n    if (this._destroyed) {\n      return PouchPromise.reject(new Error('database is destroyed'));\n    }\n    var self = this;\n    logApiCall(self, name, args);\n    if (!this.taskqueue.isReady) {\n      return new PouchPromise(function (fulfill, reject) {\n        self.taskqueue.addTask(function (failed) {\n          if (failed) {\n            reject(failed);\n          } else {\n            fulfill(self[name].apply(self, args));\n          }\n        });\n      });\n    }\n    return callback.apply(this, args);\n  }));\n}\n\nfunction mangle(key) {\n  return '$' + key;\n}\nfunction unmangle(key) {\n  return key.substring(1);\n}\nfunction Map$1() {\n  this._store = {};\n}\nMap$1.prototype.get = function (key) {\n  var mangled = mangle(key);\n  return this._store[mangled];\n};\nMap$1.prototype.set = function (key, value) {\n  var mangled = mangle(key);\n  this._store[mangled] = value;\n  return true;\n};\nMap$1.prototype.has = function (key) {\n  var mangled = mangle(key);\n  return mangled in this._store;\n};\nMap$1.prototype.delete = function (key) {\n  var mangled = mangle(key);\n  var res = mangled in this._store;\n  delete this._store[mangled];\n  return res;\n};\nMap$1.prototype.forEach = function (cb) {\n  var keys = Object.keys(this._store);\n  for (var i = 0, len = keys.length; i < len; i++) {\n    var key = keys[i];\n    var value = this._store[key];\n    key = unmangle(key);\n    cb(value, key);\n  }\n};\nObject.defineProperty(Map$1.prototype, 'size', {\n  get: function () {\n    return Object.keys(this._store).length;\n  }\n});\n\nfunction Set$1(array) {\n  this._store = new Map$1();\n\n  // init with an array\n  if (array && Array.isArray(array)) {\n    for (var i = 0, len = array.length; i < len; i++) {\n      this.add(array[i]);\n    }\n  }\n}\nSet$1.prototype.add = function (key) {\n  return this._store.set(key, true);\n};\nSet$1.prototype.has = function (key) {\n  return this._store.has(key);\n};\nSet$1.prototype.forEach = function (cb) {\n  this._store.forEach(function (value, key) {\n    cb(key);\n  });\n};\nObject.defineProperty(Set$1.prototype, 'size', {\n  get: function () {\n    return this._store.size;\n  }\n});\n\n/* global Map,Set,Symbol */\n// Based on https://kangax.github.io/compat-table/es6/ we can sniff out\n// incomplete Map/Set implementations which would otherwise cause our tests to fail.\n// Notably they fail in IE11 and iOS 8.4, which this prevents.\nfunction supportsMapAndSet() {\n  if (typeof Symbol === 'undefined' || typeof Map === 'undefined' || typeof Set === 'undefined') {\n    return false;\n  }\n  var prop = Object.getOwnPropertyDescriptor(Map, Symbol.species);\n  return prop && 'get' in prop && Map[Symbol.species] === Map;\n}\n\n// based on https://github.com/montagejs/collections\n/* global Map,Set */\n\nvar ExportedSet;\nvar ExportedMap;\n\n{\n  if (supportsMapAndSet()) { // prefer built-in Map/Set\n    ExportedSet = Set;\n    ExportedMap = Map;\n  } else { // fall back to our polyfill\n    ExportedSet = Set$1;\n    ExportedMap = Map$1;\n  }\n}\n\n// like underscore/lodash _.pick()\nfunction pick(obj, arr) {\n  var res = {};\n  for (var i = 0, len = arr.length; i < len; i++) {\n    var prop = arr[i];\n    if (prop in obj) {\n      res[prop] = obj[prop];\n    }\n  }\n  return res;\n}\n\n// Most browsers throttle concurrent requests at 6, so it's silly\n// to shim _bulk_get by trying to launch potentially hundreds of requests\n// and then letting the majority time out. We can handle this ourselves.\nvar MAX_NUM_CONCURRENT_REQUESTS = 6;\n\nfunction identityFunction(x) {\n  return x;\n}\n\nfunction formatResultForOpenRevsGet(result) {\n  return [{\n    ok: result\n  }];\n}\n\n// shim for P/CouchDB adapters that don't directly implement _bulk_get\nfunction bulkGet(db, opts, callback) {\n  var requests = opts.docs;\n\n  // consolidate into one request per doc if possible\n  var requestsById = new ExportedMap();\n  requests.forEach(function (request) {\n    if (requestsById.has(request.id)) {\n      requestsById.get(request.id).push(request);\n    } else {\n      requestsById.set(request.id, [request]);\n    }\n  });\n\n  var numDocs = requestsById.size;\n  var numDone = 0;\n  var perDocResults = new Array(numDocs);\n\n  function collapseResultsAndFinish() {\n    var results = [];\n    perDocResults.forEach(function (res) {\n      res.docs.forEach(function (info) {\n        results.push({\n          id: res.id,\n          docs: [info]\n        });\n      });\n    });\n    callback(null, {results: results});\n  }\n\n  function checkDone() {\n    if (++numDone === numDocs) {\n      collapseResultsAndFinish();\n    }\n  }\n\n  function gotResult(docIndex, id, docs) {\n    perDocResults[docIndex] = {id: id, docs: docs};\n    checkDone();\n  }\n\n  var allRequests = [];\n  requestsById.forEach(function (value, key) {\n    allRequests.push(key);\n  });\n\n  var i = 0;\n\n  function nextBatch() {\n\n    if (i >= allRequests.length) {\n      return;\n    }\n\n    var upTo = Math.min(i + MAX_NUM_CONCURRENT_REQUESTS, allRequests.length);\n    var batch = allRequests.slice(i, upTo);\n    processBatch(batch, i);\n    i += batch.length;\n  }\n\n  function processBatch(batch, offset) {\n    batch.forEach(function (docId, j) {\n      var docIdx = offset + j;\n      var docRequests = requestsById.get(docId);\n\n      // just use the first request as the \"template\"\n      // TODO: The _bulk_get API allows for more subtle use cases than this,\n      // but for now it is unlikely that there will be a mix of different\n      // \"atts_since\" or \"attachments\" in the same request, since it's just\n      // replicate.js that is using this for the moment.\n      // Also, atts_since is aspirational, since we don't support it yet.\n      var docOpts = pick(docRequests[0], ['atts_since', 'attachments']);\n      docOpts.open_revs = docRequests.map(function (request) {\n        // rev is optional, open_revs disallowed\n        return request.rev;\n      });\n\n      // remove falsey / undefined revisions\n      docOpts.open_revs = docOpts.open_revs.filter(identityFunction);\n\n      var formatResult = identityFunction;\n\n      if (docOpts.open_revs.length === 0) {\n        delete docOpts.open_revs;\n\n        // when fetching only the \"winning\" leaf,\n        // transform the result so it looks like an open_revs\n        // request\n        formatResult = formatResultForOpenRevsGet;\n      }\n\n      // globally-supplied options\n      ['revs', 'attachments', 'binary', 'ajax', 'latest'].forEach(function (param) {\n        if (param in opts) {\n          docOpts[param] = opts[param];\n        }\n      });\n      db.get(docId, docOpts, function (err, res) {\n        var result;\n        /* istanbul ignore if */\n        if (err) {\n          result = [{error: err}];\n        } else {\n          result = formatResult(res);\n        }\n        gotResult(docIdx, docId, result);\n        nextBatch();\n      });\n    });\n  }\n\n  nextBatch();\n\n}\n\nfunction isChromeApp() {\n  return (typeof chrome !== \"undefined\" &&\n    typeof chrome.storage !== \"undefined\" &&\n    typeof chrome.storage.local !== \"undefined\");\n}\n\nvar hasLocal;\n\nif (isChromeApp()) {\n  hasLocal = false;\n} else {\n  try {\n    localStorage.setItem('_pouch_check_localstorage', 1);\n    hasLocal = !!localStorage.getItem('_pouch_check_localstorage');\n  } catch (e) {\n    hasLocal = false;\n  }\n}\n\nfunction hasLocalStorage() {\n  return hasLocal;\n}\n\n// Custom nextTick() shim for browsers. In node, this will just be process.nextTick(). We\n// avoid using process.nextTick() directly because the polyfill is very large and we don't\n// need all of it (see: https://github.com/defunctzombie/node-process).\n// \"immediate\" 3.0.8 is used by lie, and it's a smaller version of the latest \"immediate\"\n// package, so it's the one we use.\n// When we use nextTick() in our codebase, we only care about not releasing Zalgo\n// (see: http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony).\n// Microtask vs macrotask doesn't matter to us. So we're free to use the fastest\n// (least latency) option, which is \"immediate\" due to use of microtasks.\n// All of our nextTicks are isolated to this one function so we can easily swap out one\n// implementation for another.\n\n__WEBPACK_IMPORTED_MODULE_4_inherits___default()(Changes, __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"]);\n\n/* istanbul ignore next */\nfunction attachBrowserEvents(self) {\n  if (isChromeApp()) {\n    chrome.storage.onChanged.addListener(function (e) {\n      // make sure it's event addressed to us\n      if (e.db_name != null) {\n        //object only has oldValue, newValue members\n        self.emit(e.dbName.newValue);\n      }\n    });\n  } else if (hasLocalStorage()) {\n    if (typeof addEventListener !== 'undefined') {\n      addEventListener(\"storage\", function (e) {\n        self.emit(e.key);\n      });\n    } else { // old IE\n      window.attachEvent(\"storage\", function (e) {\n        self.emit(e.key);\n      });\n    }\n  }\n}\n\nfunction Changes() {\n  __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"].call(this);\n  this._listeners = {};\n\n  attachBrowserEvents(this);\n}\nChanges.prototype.addListener = function (dbName, id, db, opts) {\n  /* istanbul ignore if */\n  if (this._listeners[id]) {\n    return;\n  }\n  var self = this;\n  var inprogress = false;\n  function eventFunction() {\n    /* istanbul ignore if */\n    if (!self._listeners[id]) {\n      return;\n    }\n    if (inprogress) {\n      inprogress = 'waiting';\n      return;\n    }\n    inprogress = true;\n    var changesOpts = pick(opts, [\n      'style', 'include_docs', 'attachments', 'conflicts', 'filter',\n      'doc_ids', 'view', 'since', 'query_params', 'binary'\n    ]);\n\n    /* istanbul ignore next */\n    function onError() {\n      inprogress = false;\n    }\n\n    db.changes(changesOpts).on('change', function (c) {\n      if (c.seq > opts.since && !opts.cancelled) {\n        opts.since = c.seq;\n        opts.onChange(c);\n      }\n    }).on('complete', function () {\n      if (inprogress === 'waiting') {\n        __WEBPACK_IMPORTED_MODULE_2_immediate___default()(eventFunction);\n      }\n      inprogress = false;\n    }).on('error', onError);\n  }\n  this._listeners[id] = eventFunction;\n  this.on(dbName, eventFunction);\n};\n\nChanges.prototype.removeListener = function (dbName, id) {\n  /* istanbul ignore if */\n  if (!(id in this._listeners)) {\n    return;\n  }\n  __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"].prototype.removeListener.call(this, dbName,\n    this._listeners[id]);\n  delete this._listeners[id];\n};\n\n\n/* istanbul ignore next */\nChanges.prototype.notifyLocalWindows = function (dbName) {\n  //do a useless change on a storage thing\n  //in order to get other windows's listeners to activate\n  if (isChromeApp()) {\n    chrome.storage.local.set({dbName: dbName});\n  } else if (hasLocalStorage()) {\n    localStorage[dbName] = (localStorage[dbName] === \"a\") ? \"b\" : \"a\";\n  }\n};\n\nChanges.prototype.notify = function (dbName) {\n  this.emit(dbName);\n  this.notifyLocalWindows(dbName);\n};\n\nfunction guardedConsole(method) {\n  /* istanbul ignore else */\n  if (typeof console !== 'undefined' && typeof console[method] === 'function') {\n    var args = Array.prototype.slice.call(arguments, 1);\n    console[method].apply(console, args);\n  }\n}\n\nfunction randomNumber(min, max) {\n  var maxTimeout = 600000; // Hard-coded default of 10 minutes\n  min = parseInt(min, 10) || 0;\n  max = parseInt(max, 10);\n  if (max !== max || max <= min) {\n    max = (min || 1) << 1; //doubling\n  } else {\n    max = max + 1;\n  }\n  // In order to not exceed maxTimeout, pick a random value between half of maxTimeout and maxTimeout\n  if (max > maxTimeout) {\n    min = maxTimeout >> 1; // divide by two\n    max = maxTimeout;\n  }\n  var ratio = Math.random();\n  var range = max - min;\n\n  return ~~(range * ratio + min); // ~~ coerces to an int, but fast.\n}\n\nfunction defaultBackOff(min) {\n  var max = 0;\n  if (!min) {\n    max = 2000;\n  }\n  return randomNumber(min, max);\n}\n\n// designed to give info to browser users, who are disturbed\n// when they see http errors in the console\nfunction explainError(status, str) {\n  guardedConsole('info', 'The above ' + status + ' is totally normal. ' + str);\n}\n\nvar assign;\n{\n  if (typeof Object.assign === 'function') {\n    assign = Object.assign;\n  } else {\n    // lite Object.assign polyfill based on\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign\n    assign = function (target) {\n      var to = Object(target);\n\n      for (var index = 1; index < arguments.length; index++) {\n        var nextSource = arguments[index];\n\n        if (nextSource != null) { // Skip over if undefined or null\n          for (var nextKey in nextSource) {\n            // Avoid bugs when hasOwnProperty is shadowed\n            if (Object.prototype.hasOwnProperty.call(nextSource, nextKey)) {\n              to[nextKey] = nextSource[nextKey];\n            }\n          }\n        }\n      }\n      return to;\n    };\n  }\n}\n\nvar $inject_Object_assign = assign;\n\n__WEBPACK_IMPORTED_MODULE_4_inherits___default()(PouchError, Error);\n\nfunction PouchError(status, error, reason) {\n  Error.call(this, reason);\n  this.status = status;\n  this.name = error;\n  this.message = reason;\n  this.error = true;\n}\n\nPouchError.prototype.toString = function () {\n  return JSON.stringify({\n    status: this.status,\n    name: this.name,\n    message: this.message,\n    reason: this.reason\n  });\n};\n\nvar UNAUTHORIZED = new PouchError(401, 'unauthorized', \"Name or password is incorrect.\");\nvar MISSING_BULK_DOCS = new PouchError(400, 'bad_request', \"Missing JSON list of 'docs'\");\nvar MISSING_DOC = new PouchError(404, 'not_found', 'missing');\nvar REV_CONFLICT = new PouchError(409, 'conflict', 'Document update conflict');\nvar INVALID_ID = new PouchError(400, 'bad_request', '_id field must contain a string');\nvar MISSING_ID = new PouchError(412, 'missing_id', '_id is required for puts');\nvar RESERVED_ID = new PouchError(400, 'bad_request', 'Only reserved document ids may start with underscore.');\nvar NOT_OPEN = new PouchError(412, 'precondition_failed', 'Database not open');\nvar UNKNOWN_ERROR = new PouchError(500, 'unknown_error', 'Database encountered an unknown error');\nvar BAD_ARG = new PouchError(500, 'badarg', 'Some query argument is invalid');\nvar INVALID_REQUEST = new PouchError(400, 'invalid_request', 'Request was invalid');\nvar QUERY_PARSE_ERROR = new PouchError(400, 'query_parse_error', 'Some query parameter is invalid');\nvar DOC_VALIDATION = new PouchError(500, 'doc_validation', 'Bad special document member');\nvar BAD_REQUEST = new PouchError(400, 'bad_request', 'Something wrong with the request');\nvar NOT_AN_OBJECT = new PouchError(400, 'bad_request', 'Document must be a JSON object');\nvar DB_MISSING = new PouchError(404, 'not_found', 'Database not found');\nvar IDB_ERROR = new PouchError(500, 'indexed_db_went_bad', 'unknown');\nvar WSQ_ERROR = new PouchError(500, 'web_sql_went_bad', 'unknown');\nvar LDB_ERROR = new PouchError(500, 'levelDB_went_went_bad', 'unknown');\nvar FORBIDDEN = new PouchError(403, 'forbidden', 'Forbidden by design doc validate_doc_update function');\nvar INVALID_REV = new PouchError(400, 'bad_request', 'Invalid rev format');\nvar FILE_EXISTS = new PouchError(412, 'file_exists', 'The database could not be created, the file already exists.');\nvar MISSING_STUB = new PouchError(412, 'missing_stub', 'A pre-existing attachment stub wasn\\'t found');\nvar INVALID_URL = new PouchError(413, 'invalid_url', 'Provided URL is invalid');\n\nfunction createError(error, reason) {\n  function CustomPouchError(reason) {\n    // inherit error properties from our parent error manually\n    // so as to allow proper JSON parsing.\n    /* jshint ignore:start */\n    for (var p in error) {\n      if (typeof error[p] !== 'function') {\n        this[p] = error[p];\n      }\n    }\n    /* jshint ignore:end */\n    if (reason !== undefined) {\n      this.reason = reason;\n    }\n  }\n  CustomPouchError.prototype = PouchError.prototype;\n  return new CustomPouchError(reason);\n}\n\nfunction generateErrorFromResponse(err) {\n\n  if (typeof err !== 'object') {\n    var data = err;\n    err = UNKNOWN_ERROR;\n    err.data = data;\n  }\n\n  if ('error' in err && err.error === 'conflict') {\n    err.name = 'conflict';\n    err.status = 409;\n  }\n\n  if (!('name' in err)) {\n    err.name = err.error || 'unknown';\n  }\n\n  if (!('status' in err)) {\n    err.status = 500;\n  }\n\n  if (!('message' in err)) {\n    err.message = err.message || err.reason;\n  }\n\n  return err;\n}\n\nfunction tryFilter(filter, doc, req) {\n  try {\n    return !filter(doc, req);\n  } catch (err) {\n    var msg = 'Filter function threw: ' + err.toString();\n    return createError(BAD_REQUEST, msg);\n  }\n}\n\nfunction filterChange(opts) {\n  var req = {};\n  var hasFilter = opts.filter && typeof opts.filter === 'function';\n  req.query = opts.query_params;\n\n  return function filter(change) {\n    if (!change.doc) {\n      // CSG sends events on the changes feed that don't have documents,\n      // this hack makes a whole lot of existing code robust.\n      change.doc = {};\n    }\n\n    var filterReturn = hasFilter && tryFilter(opts.filter, change.doc, req);\n\n    if (typeof filterReturn === 'object') {\n      return filterReturn;\n    }\n\n    if (filterReturn) {\n      return false;\n    }\n\n    if (!opts.include_docs) {\n      delete change.doc;\n    } else if (!opts.attachments) {\n      for (var att in change.doc._attachments) {\n        /* istanbul ignore else */\n        if (change.doc._attachments.hasOwnProperty(att)) {\n          change.doc._attachments[att].stub = true;\n        }\n      }\n    }\n    return true;\n  };\n}\n\nfunction flatten(arrs) {\n  var res = [];\n  for (var i = 0, len = arrs.length; i < len; i++) {\n    res = res.concat(arrs[i]);\n  }\n  return res;\n}\n\n// shim for Function.prototype.name,\n// for browsers that don't support it like IE\n\n/* istanbul ignore next */\n\n// Determine id an ID is valid\n//   - invalid IDs begin with an underescore that does not begin '_design' or\n//     '_local'\n//   - any other string value is a valid id\n// Returns the specific error object for each case\nfunction invalidIdError(id) {\n  var err;\n  if (!id) {\n    err = createError(MISSING_ID);\n  } else if (typeof id !== 'string') {\n    err = createError(INVALID_ID);\n  } else if (/^_/.test(id) && !(/^_(design|local)/).test(id)) {\n    err = createError(RESERVED_ID);\n  }\n  if (err) {\n    throw err;\n  }\n}\n\n// Checks if a PouchDB object is \"remote\" or not. This is\n// designed to opt-in to certain optimizations, such as\n// avoiding checks for \"dependentDbs\" and other things that\n// we know only apply to local databases. In general, \"remote\"\n// should be true for the http adapter, and for third-party\n// adapters with similar expensive boundaries to cross for\n// every API call, such as socket-pouch and worker-pouch.\n// Previously, this was handled via db.type() === 'http'\n// which is now deprecated.\n\nfunction isRemote(db) {\n  if (typeof db._remote === 'boolean') {\n    return db._remote;\n  }\n  /* istanbul ignore next */\n  if (typeof db.type === 'function') {\n    guardedConsole('warn',\n      'db.type() is deprecated and will be removed in ' +\n      'a future version of PouchDB');\n    return db.type() === 'http';\n  }\n  /* istanbul ignore next */\n  return false;\n}\n\nfunction listenerCount(ee, type) {\n  return 'listenerCount' in ee ? ee.listenerCount(type) :\n                                 __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"].listenerCount(ee, type);\n}\n\nfunction parseDesignDocFunctionName(s) {\n  if (!s) {\n    return null;\n  }\n  var parts = s.split('/');\n  if (parts.length === 2) {\n    return parts;\n  }\n  if (parts.length === 1) {\n    return [s, s];\n  }\n  return null;\n}\n\nfunction normalizeDesignDocFunctionName(s) {\n  var normalized = parseDesignDocFunctionName(s);\n  return normalized ? normalized.join('/') : null;\n}\n\n// originally parseUri 1.2.2, now patched by us\n// (c) Steven Levithan <stevenlevithan.com>\n// MIT License\nvar keys = [\"source\", \"protocol\", \"authority\", \"userInfo\", \"user\", \"password\",\n    \"host\", \"port\", \"relative\", \"path\", \"directory\", \"file\", \"query\", \"anchor\"];\nvar qName =\"queryKey\";\nvar qParser = /(?:^|&)([^&=]*)=?([^&]*)/g;\n\n// use the \"loose\" parser\n/* eslint maxlen: 0, no-useless-escape: 0 */\nvar parser = /^(?:(?![^:@]+:[^:@\\/]*@)([^:\\/?#.]+):)?(?:\\/\\/)?((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d*))?)(((\\/(?:[^?#](?![^?#\\/]*\\.[^?#\\/.]+(?:[?#]|$)))*\\/?)?([^?#\\/]*))(?:\\?([^#]*))?(?:#(.*))?)/;\n\nfunction parseUri(str) {\n  var m = parser.exec(str);\n  var uri = {};\n  var i = 14;\n\n  while (i--) {\n    var key = keys[i];\n    var value = m[i] || \"\";\n    var encoded = ['user', 'password'].indexOf(key) !== -1;\n    uri[key] = encoded ? decodeURIComponent(value) : value;\n  }\n\n  uri[qName] = {};\n  uri[keys[12]].replace(qParser, function ($0, $1, $2) {\n    if ($1) {\n      uri[qName][$1] = $2;\n    }\n  });\n\n  return uri;\n}\n\n// Based on https://github.com/alexdavid/scope-eval v0.0.3\n// (source: https://unpkg.com/scope-eval@0.0.3/scope_eval.js)\n// This is basically just a wrapper around new Function()\n\nfunction scopeEval(source, scope) {\n  var keys = [];\n  var values = [];\n  for (var key in scope) {\n    if (scope.hasOwnProperty(key)) {\n      keys.push(key);\n      values.push(scope[key]);\n    }\n  }\n  keys.push(source);\n  return Function.apply(null, keys).apply(null, values);\n}\n\n// this is essentially the \"update sugar\" function from daleharvey/pouchdb#1388\n// the diffFun tells us what delta to apply to the doc.  it either returns\n// the doc, or false if it doesn't need to do an update after all\nfunction upsert(db, docId, diffFun) {\n  return new PouchPromise(function (fulfill, reject) {\n    db.get(docId, function (err, doc) {\n      if (err) {\n        /* istanbul ignore next */\n        if (err.status !== 404) {\n          return reject(err);\n        }\n        doc = {};\n      }\n\n      // the user might change the _rev, so save it for posterity\n      var docRev = doc._rev;\n      var newDoc = diffFun(doc);\n\n      if (!newDoc) {\n        // if the diffFun returns falsy, we short-circuit as\n        // an optimization\n        return fulfill({updated: false, rev: docRev});\n      }\n\n      // users aren't allowed to modify these values,\n      // so reset them here\n      newDoc._id = docId;\n      newDoc._rev = docRev;\n      fulfill(tryAndPut(db, newDoc, diffFun));\n    });\n  });\n}\n\nfunction tryAndPut(db, doc, diffFun) {\n  return db.put(doc).then(function (res) {\n    return {\n      updated: true,\n      rev: res.rev\n    };\n  }, function (err) {\n    /* istanbul ignore next */\n    if (err.status !== 409) {\n      throw err;\n    }\n    return upsert(db, doc._id, diffFun);\n  });\n}\n\nfunction rev() {\n  return __WEBPACK_IMPORTED_MODULE_5_uuid___default.a.v4().replace(/-/g, '').toLowerCase();\n}\n\nvar uuid = __WEBPACK_IMPORTED_MODULE_5_uuid___default.a.v4;\n\n// We fetch all leafs of the revision tree, and sort them based on tree length\n// and whether they were deleted, undeleted documents with the longest revision\n// tree (most edits) win\n// The final sort algorithm is slightly documented in a sidebar here:\n// http://guide.couchdb.org/draft/conflicts.html\nfunction winningRev(metadata) {\n  var winningId;\n  var winningPos;\n  var winningDeleted;\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var tree = node.ids;\n    var branches = tree[2];\n    var pos = node.pos;\n    if (branches.length) { // non-leaf\n      for (var i = 0, len = branches.length; i < len; i++) {\n        toVisit.push({pos: pos + 1, ids: branches[i]});\n      }\n      continue;\n    }\n    var deleted = !!tree[1].deleted;\n    var id = tree[0];\n    // sort by deleted, then pos, then id\n    if (!winningId || (winningDeleted !== deleted ? winningDeleted :\n        winningPos !== pos ? winningPos < pos : winningId < id)) {\n      winningId = id;\n      winningPos = pos;\n      winningDeleted = deleted;\n    }\n  }\n\n  return winningPos + '-' + winningId;\n}\n\n// Pretty much all below can be combined into a higher order function to\n// traverse revisions\n// The return value from the callback will be passed as context to all\n// children of that node\nfunction traverseRevTree(revs, callback) {\n  var toVisit = revs.slice();\n\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var branches = tree[2];\n    var newCtx =\n      callback(branches.length === 0, pos, tree[0], node.ctx, tree[1]);\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], ctx: newCtx});\n    }\n  }\n}\n\nfunction sortByPos(a, b) {\n  return a.pos - b.pos;\n}\n\nfunction collectLeaves(revs) {\n  var leaves = [];\n  traverseRevTree(revs, function (isLeaf, pos, id, acc, opts) {\n    if (isLeaf) {\n      leaves.push({rev: pos + \"-\" + id, pos: pos, opts: opts});\n    }\n  });\n  leaves.sort(sortByPos).reverse();\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    delete leaves[i].pos;\n  }\n  return leaves;\n}\n\n// returns revs of all conflicts that is leaves such that\n// 1. are not deleted and\n// 2. are different than winning revision\nfunction collectConflicts(metadata) {\n  var win = winningRev(metadata);\n  var leaves = collectLeaves(metadata.rev_tree);\n  var conflicts = [];\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    var leaf = leaves[i];\n    if (leaf.rev !== win && !leaf.opts.deleted) {\n      conflicts.push(leaf.rev);\n    }\n  }\n  return conflicts;\n}\n\n// compact a tree by marking its non-leafs as missing,\n// and return a list of revs to delete\nfunction compactTree(metadata) {\n  var revs = [];\n  traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                               revHash, ctx, opts) {\n    if (opts.status === 'available' && !isLeaf) {\n      revs.push(pos + '-' + revHash);\n      opts.status = 'missing';\n    }\n  });\n  return revs;\n}\n\n// build up a list of all the paths to the leafs in this revision tree\nfunction rootToLeaf(revs) {\n  var paths = [];\n  var toVisit = revs.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, opts: opts});\n    if (isLeaf) {\n      paths.push({pos: (pos + 1 - history.length), ids: history});\n    }\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], history: history});\n    }\n  }\n  return paths.reverse();\n}\n\n// for a better overview of what this is doing, read:\n// https://github.com/apache/couchdb-couch/blob/master/src/couch_key_tree.erl\n//\n// But for a quick intro, CouchDB uses a revision tree to store a documents\n// history, A -> B -> C, when a document has conflicts, that is a branch in the\n// tree, A -> (B1 | B2 -> C), We store these as a nested array in the format\n//\n// KeyTree = [Path ... ]\n// Path = {pos: position_from_root, ids: Tree}\n// Tree = [Key, Opts, [Tree, ...]], in particular single node: [Key, []]\n\nfunction sortByPos$1(a, b) {\n  return a.pos - b.pos;\n}\n\n// classic binary search\nfunction binarySearch(arr, item, comparator) {\n  var low = 0;\n  var high = arr.length;\n  var mid;\n  while (low < high) {\n    mid = (low + high) >>> 1;\n    if (comparator(arr[mid], item) < 0) {\n      low = mid + 1;\n    } else {\n      high = mid;\n    }\n  }\n  return low;\n}\n\n// assuming the arr is sorted, insert the item in the proper place\nfunction insertSorted(arr, item, comparator) {\n  var idx = binarySearch(arr, item, comparator);\n  arr.splice(idx, 0, item);\n}\n\n// Turn a path as a flat array into a tree with a single branch.\n// If any should be stemmed from the beginning of the array, that's passed\n// in as the second argument\nfunction pathToTree(path, numStemmed) {\n  var root;\n  var leaf;\n  for (var i = numStemmed, len = path.length; i < len; i++) {\n    var node = path[i];\n    var currentLeaf = [node.id, node.opts, []];\n    if (leaf) {\n      leaf[2].push(currentLeaf);\n      leaf = currentLeaf;\n    } else {\n      root = leaf = currentLeaf;\n    }\n  }\n  return root;\n}\n\n// compare the IDs of two trees\nfunction compareTree(a, b) {\n  return a[0] < b[0] ? -1 : 1;\n}\n\n// Merge two trees together\n// The roots of tree1 and tree2 must be the same revision\nfunction mergeTree(in_tree1, in_tree2) {\n  var queue = [{tree1: in_tree1, tree2: in_tree2}];\n  var conflicts = false;\n  while (queue.length > 0) {\n    var item = queue.pop();\n    var tree1 = item.tree1;\n    var tree2 = item.tree2;\n\n    if (tree1[1].status || tree2[1].status) {\n      tree1[1].status =\n        (tree1[1].status ===  'available' ||\n        tree2[1].status === 'available') ? 'available' : 'missing';\n    }\n\n    for (var i = 0; i < tree2[2].length; i++) {\n      if (!tree1[2][0]) {\n        conflicts = 'new_leaf';\n        tree1[2][0] = tree2[2][i];\n        continue;\n      }\n\n      var merged = false;\n      for (var j = 0; j < tree1[2].length; j++) {\n        if (tree1[2][j][0] === tree2[2][i][0]) {\n          queue.push({tree1: tree1[2][j], tree2: tree2[2][i]});\n          merged = true;\n        }\n      }\n      if (!merged) {\n        conflicts = 'new_branch';\n        insertSorted(tree1[2], tree2[2][i], compareTree);\n      }\n    }\n  }\n  return {conflicts: conflicts, tree: in_tree1};\n}\n\nfunction doMerge(tree, path, dontExpand) {\n  var restree = [];\n  var conflicts = false;\n  var merged = false;\n  var res;\n\n  if (!tree.length) {\n    return {tree: [path], conflicts: 'new_leaf'};\n  }\n\n  for (var i = 0, len = tree.length; i < len; i++) {\n    var branch = tree[i];\n    if (branch.pos === path.pos && branch.ids[0] === path.ids[0]) {\n      // Paths start at the same position and have the same root, so they need\n      // merged\n      res = mergeTree(branch.ids, path.ids);\n      restree.push({pos: branch.pos, ids: res.tree});\n      conflicts = conflicts || res.conflicts;\n      merged = true;\n    } else if (dontExpand !== true) {\n      // The paths start at a different position, take the earliest path and\n      // traverse up until it as at the same point from root as the path we\n      // want to merge.  If the keys match we return the longer path with the\n      // other merged After stemming we dont want to expand the trees\n\n      var t1 = branch.pos < path.pos ? branch : path;\n      var t2 = branch.pos < path.pos ? path : branch;\n      var diff = t2.pos - t1.pos;\n\n      var candidateParents = [];\n\n      var trees = [];\n      trees.push({ids: t1.ids, diff: diff, parent: null, parentIdx: null});\n      while (trees.length > 0) {\n        var item = trees.pop();\n        if (item.diff === 0) {\n          if (item.ids[0] === t2.ids[0]) {\n            candidateParents.push(item);\n          }\n          continue;\n        }\n        var elements = item.ids[2];\n        for (var j = 0, elementsLen = elements.length; j < elementsLen; j++) {\n          trees.push({\n            ids: elements[j],\n            diff: item.diff - 1,\n            parent: item.ids,\n            parentIdx: j\n          });\n        }\n      }\n\n      var el = candidateParents[0];\n\n      if (!el) {\n        restree.push(branch);\n      } else {\n        res = mergeTree(el.ids, t2.ids);\n        el.parent[2][el.parentIdx] = res.tree;\n        restree.push({pos: t1.pos, ids: t1.ids});\n        conflicts = conflicts || res.conflicts;\n        merged = true;\n      }\n    } else {\n      restree.push(branch);\n    }\n  }\n\n  // We didnt find\n  if (!merged) {\n    restree.push(path);\n  }\n\n  restree.sort(sortByPos$1);\n\n  return {\n    tree: restree,\n    conflicts: conflicts || 'internal_node'\n  };\n}\n\n// To ensure we dont grow the revision tree infinitely, we stem old revisions\nfunction stem(tree, depth) {\n  // First we break out the tree into a complete list of root to leaf paths\n  var paths = rootToLeaf(tree);\n  var stemmedRevs;\n\n  var result;\n  for (var i = 0, len = paths.length; i < len; i++) {\n    // Then for each path, we cut off the start of the path based on the\n    // `depth` to stem to, and generate a new set of flat trees\n    var path = paths[i];\n    var stemmed = path.ids;\n    var node;\n    if (stemmed.length > depth) {\n      // only do the stemming work if we actually need to stem\n      if (!stemmedRevs) {\n        stemmedRevs = {}; // avoid allocating this object unnecessarily\n      }\n      var numStemmed = stemmed.length - depth;\n      node = {\n        pos: path.pos + numStemmed,\n        ids: pathToTree(stemmed, numStemmed)\n      };\n\n      for (var s = 0; s < numStemmed; s++) {\n        var rev = (path.pos + s) + '-' + stemmed[s].id;\n        stemmedRevs[rev] = true;\n      }\n    } else { // no need to actually stem\n      node = {\n        pos: path.pos,\n        ids: pathToTree(stemmed, 0)\n      };\n    }\n\n    // Then we remerge all those flat trees together, ensuring that we dont\n    // connect trees that would go beyond the depth limit\n    if (result) {\n      result = doMerge(result, node, true).tree;\n    } else {\n      result = [node];\n    }\n  }\n\n  // this is memory-heavy per Chrome profiler, avoid unless we actually stemmed\n  if (stemmedRevs) {\n    traverseRevTree(result, function (isLeaf, pos, revHash) {\n      // some revisions may have been removed in a branch but not in another\n      delete stemmedRevs[pos + '-' + revHash];\n    });\n  }\n\n  return {\n    tree: result,\n    revs: stemmedRevs ? Object.keys(stemmedRevs) : []\n  };\n}\n\nfunction merge(tree, path, depth) {\n  var newTree = doMerge(tree, path);\n  var stemmed = stem(newTree.tree, depth);\n  return {\n    tree: stemmed.tree,\n    stemmedRevs: stemmed.revs,\n    conflicts: newTree.conflicts\n  };\n}\n\n// return true if a rev exists in the rev tree, false otherwise\nfunction revExists(revs, rev) {\n  var toVisit = revs.slice();\n  var splitRev = rev.split('-');\n  var targetPos = parseInt(splitRev[0], 10);\n  var targetId = splitRev[1];\n\n  var node;\n  while ((node = toVisit.pop())) {\n    if (node.pos === targetPos && node.ids[0] === targetId) {\n      return true;\n    }\n    var branches = node.ids[2];\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: node.pos + 1, ids: branches[i]});\n    }\n  }\n  return false;\n}\n\nfunction getTrees(node) {\n  return node.ids;\n}\n\n// check if a specific revision of a doc has been deleted\n//  - metadata: the metadata object from the doc store\n//  - rev: (optional) the revision to check. defaults to winning revision\nfunction isDeleted(metadata, rev) {\n  if (!rev) {\n    rev = winningRev(metadata);\n  }\n  var id = rev.substring(rev.indexOf('-') + 1);\n  var toVisit = metadata.rev_tree.map(getTrees);\n\n  var tree;\n  while ((tree = toVisit.pop())) {\n    if (tree[0] === id) {\n      return !!tree[1].deleted;\n    }\n    toVisit = toVisit.concat(tree[2]);\n  }\n}\n\nfunction isLocalId(id) {\n  return (/^_local/).test(id);\n}\n\n// returns the current leaf node for a given revision\nfunction latest(rev, metadata) {\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, pos: pos, opts: opts});\n\n    if (isLeaf) {\n      for (var i = 0, len = history.length; i < len; i++) {\n        var historyNode = history[i];\n        var historyRev = historyNode.pos + '-' + historyNode.id;\n\n        if (historyRev === rev) {\n          // return the rev of this leaf\n          return pos + '-' + id;\n        }\n      }\n    }\n\n    for (var j = 0, l = branches.length; j < l; j++) {\n      toVisit.push({pos: pos + 1, ids: branches[j], history: history});\n    }\n  }\n\n  /* istanbul ignore next */\n  throw new Error('Unable to resolve latest revision for id ' + metadata.id + ', rev ' + rev);\n}\n\n__WEBPACK_IMPORTED_MODULE_4_inherits___default()(Changes$2, __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"]);\n\nfunction tryCatchInChangeListener(self, change, pending, lastSeq) {\n  // isolate try/catches to avoid V8 deoptimizations\n  try {\n    self.emit('change', change, pending, lastSeq);\n  } catch (e) {\n    guardedConsole('error', 'Error in .on(\"change\", function):', e);\n  }\n}\n\nfunction Changes$2(db, opts, callback) {\n  __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"].call(this);\n  var self = this;\n  this.db = db;\n  opts = opts ? clone(opts) : {};\n  var complete = opts.complete = once(function (err, resp) {\n    if (err) {\n      if (listenerCount(self, 'error') > 0) {\n        self.emit('error', err);\n      }\n    } else {\n      self.emit('complete', resp);\n    }\n    self.removeAllListeners();\n    db.removeListener('destroyed', onDestroy);\n  });\n  if (callback) {\n    self.on('complete', function (resp) {\n      callback(null, resp);\n    });\n    self.on('error', callback);\n  }\n  function onDestroy() {\n    self.cancel();\n  }\n  db.once('destroyed', onDestroy);\n\n  opts.onChange = function (change, pending, lastSeq) {\n    /* istanbul ignore if */\n    if (self.isCancelled) {\n      return;\n    }\n    tryCatchInChangeListener(self, change, pending, lastSeq);\n  };\n\n  var promise = new PouchPromise(function (fulfill, reject) {\n    opts.complete = function (err, res) {\n      if (err) {\n        reject(err);\n      } else {\n        fulfill(res);\n      }\n    };\n  });\n  self.once('cancel', function () {\n    db.removeListener('destroyed', onDestroy);\n    opts.complete(null, {status: 'cancelled'});\n  });\n  this.then = promise.then.bind(promise);\n  this['catch'] = promise['catch'].bind(promise);\n  this.then(function (result) {\n    complete(null, result);\n  }, complete);\n\n\n\n  if (!db.taskqueue.isReady) {\n    db.taskqueue.addTask(function (failed) {\n      if (failed) {\n        opts.complete(failed);\n      } else if (self.isCancelled) {\n        self.emit('cancel');\n      } else {\n        self.validateChanges(opts);\n      }\n    });\n  } else {\n    self.validateChanges(opts);\n  }\n}\nChanges$2.prototype.cancel = function () {\n  this.isCancelled = true;\n  if (this.db.taskqueue.isReady) {\n    this.emit('cancel');\n  }\n};\nfunction processChange(doc, metadata, opts) {\n  var changeList = [{rev: doc._rev}];\n  if (opts.style === 'all_docs') {\n    changeList = collectLeaves(metadata.rev_tree)\n    .map(function (x) { return {rev: x.rev}; });\n  }\n  var change = {\n    id: metadata.id,\n    changes: changeList,\n    doc: doc\n  };\n\n  if (isDeleted(metadata, doc._rev)) {\n    change.deleted = true;\n  }\n  if (opts.conflicts) {\n    change.doc._conflicts = collectConflicts(metadata);\n    if (!change.doc._conflicts.length) {\n      delete change.doc._conflicts;\n    }\n  }\n  return change;\n}\n\nChanges$2.prototype.validateChanges = function (opts) {\n  var callback = opts.complete;\n  var self = this;\n\n  /* istanbul ignore else */\n  if (PouchDB._changesFilterPlugin) {\n    PouchDB._changesFilterPlugin.validate(opts, function (err) {\n      if (err) {\n        return callback(err);\n      }\n      self.doChanges(opts);\n    });\n  } else {\n    self.doChanges(opts);\n  }\n};\n\nChanges$2.prototype.doChanges = function (opts) {\n  var self = this;\n  var callback = opts.complete;\n\n  opts = clone(opts);\n  if ('live' in opts && !('continuous' in opts)) {\n    opts.continuous = opts.live;\n  }\n  opts.processChange = processChange;\n\n  if (opts.since === 'latest') {\n    opts.since = 'now';\n  }\n  if (!opts.since) {\n    opts.since = 0;\n  }\n  if (opts.since === 'now') {\n    this.db.info().then(function (info) {\n      /* istanbul ignore if */\n      if (self.isCancelled) {\n        callback(null, {status: 'cancelled'});\n        return;\n      }\n      opts.since = info.update_seq;\n      self.doChanges(opts);\n    }, callback);\n    return;\n  }\n\n  /* istanbul ignore else */\n  if (PouchDB._changesFilterPlugin) {\n    PouchDB._changesFilterPlugin.normalize(opts);\n    if (PouchDB._changesFilterPlugin.shouldFilter(this, opts)) {\n      return PouchDB._changesFilterPlugin.filter(this, opts);\n    }\n  } else {\n    ['doc_ids', 'filter', 'selector', 'view'].forEach(function (key) {\n      if (key in opts) {\n        guardedConsole('warn',\n          'The \"' + key + '\" option was passed in to changes/replicate, ' +\n          'but pouchdb-changes-filter plugin is not installed, so it ' +\n          'was ignored. Please install the plugin to enable filtering.'\n        );\n      }\n    });\n  }\n\n  if (!('descending' in opts)) {\n    opts.descending = false;\n  }\n\n  // 0 and 1 should return 1 document\n  opts.limit = opts.limit === 0 ? 1 : opts.limit;\n  opts.complete = callback;\n  var newPromise = this.db._changes(opts);\n  /* istanbul ignore else */\n  if (newPromise && typeof newPromise.cancel === 'function') {\n    var cancel = self.cancel;\n    self.cancel = __WEBPACK_IMPORTED_MODULE_1_argsarray___default()(function (args) {\n      newPromise.cancel();\n      cancel.apply(this, args);\n    });\n  }\n};\n\n/*\n * A generic pouch adapter\n */\n\nfunction compare(left, right) {\n  return left < right ? -1 : left > right ? 1 : 0;\n}\n\n// Wrapper for functions that call the bulkdocs api with a single doc,\n// if the first result is an error, return an error\nfunction yankError(callback, docId) {\n  return function (err, results) {\n    if (err || (results[0] && results[0].error)) {\n      err = err || results[0];\n      err.docId = docId;\n      callback(err);\n    } else {\n      callback(null, results.length ? results[0]  : results);\n    }\n  };\n}\n\n// clean docs given to us by the user\nfunction cleanDocs(docs) {\n  for (var i = 0; i < docs.length; i++) {\n    var doc = docs[i];\n    if (doc._deleted) {\n      delete doc._attachments; // ignore atts for deleted docs\n    } else if (doc._attachments) {\n      // filter out extraneous keys from _attachments\n      var atts = Object.keys(doc._attachments);\n      for (var j = 0; j < atts.length; j++) {\n        var att = atts[j];\n        doc._attachments[att] = pick(doc._attachments[att],\n          ['data', 'digest', 'content_type', 'length', 'revpos', 'stub']);\n      }\n    }\n  }\n}\n\n// compare two docs, first by _id then by _rev\nfunction compareByIdThenRev(a, b) {\n  var idCompare = compare(a._id, b._id);\n  if (idCompare !== 0) {\n    return idCompare;\n  }\n  var aStart = a._revisions ? a._revisions.start : 0;\n  var bStart = b._revisions ? b._revisions.start : 0;\n  return compare(aStart, bStart);\n}\n\n// for every node in a revision tree computes its distance from the closest\n// leaf\nfunction computeHeight(revs) {\n  var height = {};\n  var edges = [];\n  traverseRevTree(revs, function (isLeaf, pos, id, prnt) {\n    var rev$$1 = pos + \"-\" + id;\n    if (isLeaf) {\n      height[rev$$1] = 0;\n    }\n    if (prnt !== undefined) {\n      edges.push({from: prnt, to: rev$$1});\n    }\n    return rev$$1;\n  });\n\n  edges.reverse();\n  edges.forEach(function (edge) {\n    if (height[edge.from] === undefined) {\n      height[edge.from] = 1 + height[edge.to];\n    } else {\n      height[edge.from] = Math.min(height[edge.from], 1 + height[edge.to]);\n    }\n  });\n  return height;\n}\n\nfunction allDocsKeysParse(opts) {\n  var keys =  ('limit' in opts) ?\n    opts.keys.slice(opts.skip, opts.limit + opts.skip) :\n    (opts.skip > 0) ? opts.keys.slice(opts.skip) : opts.keys;\n  opts.keys = keys;\n  opts.skip = 0;\n  delete opts.limit;\n  if (opts.descending) {\n    keys.reverse();\n    opts.descending = false;\n  }\n}\n\n// all compaction is done in a queue, to avoid attaching\n// too many listeners at once\nfunction doNextCompaction(self) {\n  var task = self._compactionQueue[0];\n  var opts = task.opts;\n  var callback = task.callback;\n  self.get('_local/compaction').catch(function () {\n    return false;\n  }).then(function (doc) {\n    if (doc && doc.last_seq) {\n      opts.last_seq = doc.last_seq;\n    }\n    self._compact(opts, function (err, res) {\n      /* istanbul ignore if */\n      if (err) {\n        callback(err);\n      } else {\n        callback(null, res);\n      }\n      __WEBPACK_IMPORTED_MODULE_2_immediate___default()(function () {\n        self._compactionQueue.shift();\n        if (self._compactionQueue.length) {\n          doNextCompaction(self);\n        }\n      });\n    });\n  });\n}\n\nfunction attachmentNameError(name) {\n  if (name.charAt(0) === '_') {\n    return name + ' is not a valid attachment name, attachment ' +\n      'names cannot start with \\'_\\'';\n  }\n  return false;\n}\n\n__WEBPACK_IMPORTED_MODULE_4_inherits___default()(AbstractPouchDB, __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"]);\n\nfunction AbstractPouchDB() {\n  __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"].call(this);\n}\n\nAbstractPouchDB.prototype.post =\n  adapterFun('post', function (doc, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof doc !== 'object' || Array.isArray(doc)) {\n    return callback(createError(NOT_AN_OBJECT));\n  }\n  this.bulkDocs({docs: [doc]}, opts, yankError(callback, doc._id));\n});\n\nAbstractPouchDB.prototype.put = adapterFun('put', function (doc, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n  if (typeof doc !== 'object' || Array.isArray(doc)) {\n    return cb(createError(NOT_AN_OBJECT));\n  }\n  invalidIdError(doc._id);\n  if (isLocalId(doc._id) && typeof this._putLocal === 'function') {\n    if (doc._deleted) {\n      return this._removeLocal(doc, cb);\n    } else {\n      return this._putLocal(doc, cb);\n    }\n  }\n  var self = this;\n  if (opts.force && doc._rev) {\n    transformForceOptionToNewEditsOption();\n    putDoc(function (err) {\n      var result = err ? null : {ok: true, id: doc._id, rev: doc._rev};\n      cb(err, result);\n    });\n  } else {\n    putDoc(cb);\n  }\n\n  function transformForceOptionToNewEditsOption() {\n    var parts = doc._rev.split('-');\n    var oldRevId = parts[1];\n    var oldRevNum = parseInt(parts[0], 10);\n\n    var newRevNum = oldRevNum + 1;\n    var newRevId = rev();\n\n    doc._revisions = {\n      start: newRevNum,\n      ids: [newRevId, oldRevId]\n    };\n    doc._rev = newRevNum + '-' + newRevId;\n    opts.new_edits = false;\n  }\n  function putDoc(next) {\n    if (typeof self._put === 'function' && opts.new_edits !== false) {\n      self._put(doc, opts, next);\n    } else {\n      self.bulkDocs({docs: [doc]}, opts, yankError(next, doc._id));\n    }\n  }\n});\n\nAbstractPouchDB.prototype.putAttachment =\n  adapterFun('putAttachment', function (docId, attachmentId, rev$$1,\n                                              blob, type) {\n  var api = this;\n  if (typeof type === 'function') {\n    type = blob;\n    blob = rev$$1;\n    rev$$1 = null;\n  }\n  // Lets fix in https://github.com/pouchdb/pouchdb/issues/3267\n  /* istanbul ignore if */\n  if (typeof type === 'undefined') {\n    type = blob;\n    blob = rev$$1;\n    rev$$1 = null;\n  }\n  if (!type) {\n    guardedConsole('warn', 'Attachment', attachmentId, 'on document', docId, 'is missing content_type');\n  }\n\n  function createAttachment(doc) {\n    var prevrevpos = '_rev' in doc ? parseInt(doc._rev, 10) : 0;\n    doc._attachments = doc._attachments || {};\n    doc._attachments[attachmentId] = {\n      content_type: type,\n      data: blob,\n      revpos: ++prevrevpos\n    };\n    return api.put(doc);\n  }\n\n  return api.get(docId).then(function (doc) {\n    if (doc._rev !== rev$$1) {\n      throw createError(REV_CONFLICT);\n    }\n\n    return createAttachment(doc);\n  }, function (err) {\n     // create new doc\n    /* istanbul ignore else */\n    if (err.reason === MISSING_DOC.message) {\n      return createAttachment({_id: docId});\n    } else {\n      throw err;\n    }\n  });\n});\n\nAbstractPouchDB.prototype.removeAttachment =\n  adapterFun('removeAttachment', function (docId, attachmentId, rev$$1,\n                                                 callback) {\n  var self = this;\n  self.get(docId, function (err, obj) {\n    /* istanbul ignore if */\n    if (err) {\n      callback(err);\n      return;\n    }\n    if (obj._rev !== rev$$1) {\n      callback(createError(REV_CONFLICT));\n      return;\n    }\n    /* istanbul ignore if */\n    if (!obj._attachments) {\n      return callback();\n    }\n    delete obj._attachments[attachmentId];\n    if (Object.keys(obj._attachments).length === 0) {\n      delete obj._attachments;\n    }\n    self.put(obj, callback);\n  });\n});\n\nAbstractPouchDB.prototype.remove =\n  adapterFun('remove', function (docOrId, optsOrRev, opts, callback) {\n  var doc;\n  if (typeof optsOrRev === 'string') {\n    // id, rev, opts, callback style\n    doc = {\n      _id: docOrId,\n      _rev: optsOrRev\n    };\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n  } else {\n    // doc, opts, callback style\n    doc = docOrId;\n    if (typeof optsOrRev === 'function') {\n      callback = optsOrRev;\n      opts = {};\n    } else {\n      callback = opts;\n      opts = optsOrRev;\n    }\n  }\n  opts = opts || {};\n  opts.was_delete = true;\n  var newDoc = {_id: doc._id, _rev: (doc._rev || opts.rev)};\n  newDoc._deleted = true;\n  if (isLocalId(newDoc._id) && typeof this._removeLocal === 'function') {\n    return this._removeLocal(doc, callback);\n  }\n  this.bulkDocs({docs: [newDoc]}, opts, yankError(callback, newDoc._id));\n});\n\nAbstractPouchDB.prototype.revsDiff =\n  adapterFun('revsDiff', function (req, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  var ids = Object.keys(req);\n\n  if (!ids.length) {\n    return callback(null, {});\n  }\n\n  var count = 0;\n  var missing = new ExportedMap();\n\n  function addToMissing(id, revId) {\n    if (!missing.has(id)) {\n      missing.set(id, {missing: []});\n    }\n    missing.get(id).missing.push(revId);\n  }\n\n  function processDoc(id, rev_tree) {\n    // Is this fast enough? Maybe we should switch to a set simulated by a map\n    var missingForId = req[id].slice(0);\n    traverseRevTree(rev_tree, function (isLeaf, pos, revHash, ctx,\n      opts) {\n        var rev$$1 = pos + '-' + revHash;\n        var idx = missingForId.indexOf(rev$$1);\n        if (idx === -1) {\n          return;\n        }\n\n        missingForId.splice(idx, 1);\n        /* istanbul ignore if */\n        if (opts.status !== 'available') {\n          addToMissing(id, rev$$1);\n        }\n      });\n\n    // Traversing the tree is synchronous, so now `missingForId` contains\n    // revisions that were not found in the tree\n    missingForId.forEach(function (rev$$1) {\n      addToMissing(id, rev$$1);\n    });\n  }\n\n  ids.map(function (id) {\n    this._getRevisionTree(id, function (err, rev_tree) {\n      if (err && err.status === 404 && err.message === 'missing') {\n        missing.set(id, {missing: req[id]});\n      } else if (err) {\n        /* istanbul ignore next */\n        return callback(err);\n      } else {\n        processDoc(id, rev_tree);\n      }\n\n      if (++count === ids.length) {\n        // convert LazyMap to object\n        var missingObj = {};\n        missing.forEach(function (value, key) {\n          missingObj[key] = value;\n        });\n        return callback(null, missingObj);\n      }\n    });\n  }, this);\n});\n\n// _bulk_get API for faster replication, as described in\n// https://github.com/apache/couchdb-chttpd/pull/33\n// At the \"abstract\" level, it will just run multiple get()s in\n// parallel, because this isn't much of a performance cost\n// for local databases (except the cost of multiple transactions, which is\n// small). The http adapter overrides this in order\n// to do a more efficient single HTTP request.\nAbstractPouchDB.prototype.bulkGet =\n  adapterFun('bulkGet', function (opts, callback) {\n  bulkGet(this, opts, callback);\n});\n\n// compact one document and fire callback\n// by compacting we mean removing all revisions which\n// are further from the leaf in revision tree than max_height\nAbstractPouchDB.prototype.compactDocument =\n  adapterFun('compactDocument', function (docId, maxHeight, callback) {\n  var self = this;\n  this._getRevisionTree(docId, function (err, revTree) {\n    /* istanbul ignore if */\n    if (err) {\n      return callback(err);\n    }\n    var height = computeHeight(revTree);\n    var candidates = [];\n    var revs = [];\n    Object.keys(height).forEach(function (rev$$1) {\n      if (height[rev$$1] > maxHeight) {\n        candidates.push(rev$$1);\n      }\n    });\n\n    traverseRevTree(revTree, function (isLeaf, pos, revHash, ctx, opts) {\n      var rev$$1 = pos + '-' + revHash;\n      if (opts.status === 'available' && candidates.indexOf(rev$$1) !== -1) {\n        revs.push(rev$$1);\n      }\n    });\n    self._doCompaction(docId, revs, callback);\n  });\n});\n\n// compact the whole database using single document\n// compaction\nAbstractPouchDB.prototype.compact =\n  adapterFun('compact', function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  var self = this;\n  opts = opts || {};\n\n  self._compactionQueue = self._compactionQueue || [];\n  self._compactionQueue.push({opts: opts, callback: callback});\n  if (self._compactionQueue.length === 1) {\n    doNextCompaction(self);\n  }\n});\nAbstractPouchDB.prototype._compact = function (opts, callback) {\n  var self = this;\n  var changesOpts = {\n    return_docs: false,\n    last_seq: opts.last_seq || 0\n  };\n  var promises = [];\n\n  function onChange(row) {\n    promises.push(self.compactDocument(row.id, 0));\n  }\n  function onComplete(resp) {\n    var lastSeq = resp.last_seq;\n    PouchPromise.all(promises).then(function () {\n      return upsert(self, '_local/compaction', function deltaFunc(doc) {\n        if (!doc.last_seq || doc.last_seq < lastSeq) {\n          doc.last_seq = lastSeq;\n          return doc;\n        }\n        return false; // somebody else got here first, don't update\n      });\n    }).then(function () {\n      callback(null, {ok: true});\n    }).catch(callback);\n  }\n  self.changes(changesOpts)\n    .on('change', onChange)\n    .on('complete', onComplete)\n    .on('error', callback);\n};\n\n/* Begin api wrappers. Specific functionality to storage belongs in the\n   _[method] */\nAbstractPouchDB.prototype.get = adapterFun('get', function (id, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n  if (typeof id !== 'string') {\n    return cb(createError(INVALID_ID));\n  }\n  if (isLocalId(id) && typeof this._getLocal === 'function') {\n    return this._getLocal(id, cb);\n  }\n  var leaves = [], self = this;\n\n  function finishOpenRevs() {\n    var result = [];\n    var count = leaves.length;\n    /* istanbul ignore if */\n    if (!count) {\n      return cb(null, result);\n    }\n\n    // order with open_revs is unspecified\n    leaves.forEach(function (leaf) {\n      self.get(id, {\n        rev: leaf,\n        revs: opts.revs,\n        latest: opts.latest,\n        attachments: opts.attachments,\n        binary: opts.binary\n      }, function (err, doc) {\n        if (!err) {\n          // using latest=true can produce duplicates\n          var existing;\n          for (var i = 0, l = result.length; i < l; i++) {\n            if (result[i].ok && result[i].ok._rev === doc._rev) {\n              existing = true;\n              break;\n            }\n          }\n          if (!existing) {\n            result.push({ok: doc});\n          }\n        } else {\n          result.push({missing: leaf});\n        }\n        count--;\n        if (!count) {\n          cb(null, result);\n        }\n      });\n    });\n  }\n\n  if (opts.open_revs) {\n    if (opts.open_revs === \"all\") {\n      this._getRevisionTree(id, function (err, rev_tree) {\n        if (err) {\n          return cb(err);\n        }\n        leaves = collectLeaves(rev_tree).map(function (leaf) {\n          return leaf.rev;\n        });\n        finishOpenRevs();\n      });\n    } else {\n      if (Array.isArray(opts.open_revs)) {\n        leaves = opts.open_revs;\n        for (var i = 0; i < leaves.length; i++) {\n          var l = leaves[i];\n          // looks like it's the only thing couchdb checks\n          if (!(typeof (l) === \"string\" && /^\\d+-/.test(l))) {\n            return cb(createError(INVALID_REV));\n          }\n        }\n        finishOpenRevs();\n      } else {\n        return cb(createError(UNKNOWN_ERROR, 'function_clause'));\n      }\n    }\n    return; // open_revs does not like other options\n  }\n\n  return this._get(id, opts, function (err, result) {\n    if (err) {\n      err.docId = id;\n      return cb(err);\n    }\n\n    var doc = result.doc;\n    var metadata = result.metadata;\n    var ctx = result.ctx;\n\n    if (opts.conflicts) {\n      var conflicts = collectConflicts(metadata);\n      if (conflicts.length) {\n        doc._conflicts = conflicts;\n      }\n    }\n\n    if (isDeleted(metadata, doc._rev)) {\n      doc._deleted = true;\n    }\n\n    if (opts.revs || opts.revs_info) {\n      var splittedRev = doc._rev.split('-');\n      var revNo       = parseInt(splittedRev[0], 10);\n      var revHash     = splittedRev[1];\n\n      var paths = rootToLeaf(metadata.rev_tree);\n      var path = null;\n\n      for (var i = 0; i < paths.length; i++) {\n        var currentPath = paths[i];\n        var hashIndex = currentPath.ids.map(function (x) { return x.id; })\n          .indexOf(revHash);\n        var hashFoundAtRevPos = hashIndex === (revNo - 1);\n\n        if (hashFoundAtRevPos || (!path && hashIndex !== -1)) {\n          path = currentPath;\n        }\n      }\n\n      var indexOfRev = path.ids.map(function (x) { return x.id; })\n        .indexOf(doc._rev.split('-')[1]) + 1;\n      var howMany = path.ids.length - indexOfRev;\n      path.ids.splice(indexOfRev, howMany);\n      path.ids.reverse();\n\n      if (opts.revs) {\n        doc._revisions = {\n          start: (path.pos + path.ids.length) - 1,\n          ids: path.ids.map(function (rev$$1) {\n            return rev$$1.id;\n          })\n        };\n      }\n      if (opts.revs_info) {\n        var pos =  path.pos + path.ids.length;\n        doc._revs_info = path.ids.map(function (rev$$1) {\n          pos--;\n          return {\n            rev: pos + '-' + rev$$1.id,\n            status: rev$$1.opts.status\n          };\n        });\n      }\n    }\n\n    if (opts.attachments && doc._attachments) {\n      var attachments = doc._attachments;\n      var count = Object.keys(attachments).length;\n      if (count === 0) {\n        return cb(null, doc);\n      }\n      Object.keys(attachments).forEach(function (key) {\n        this._getAttachment(doc._id, key, attachments[key], {\n          // Previously the revision handling was done in adapter.js\n          // getAttachment, however since idb-next doesnt we need to\n          // pass the rev through\n          rev: doc._rev,\n          binary: opts.binary,\n          ctx: ctx\n        }, function (err, data) {\n          var att = doc._attachments[key];\n          att.data = data;\n          delete att.stub;\n          delete att.length;\n          if (!--count) {\n            cb(null, doc);\n          }\n        });\n      }, self);\n    } else {\n      if (doc._attachments) {\n        for (var key in doc._attachments) {\n          /* istanbul ignore else */\n          if (doc._attachments.hasOwnProperty(key)) {\n            doc._attachments[key].stub = true;\n          }\n        }\n      }\n      cb(null, doc);\n    }\n  });\n});\n\n// TODO: I dont like this, it forces an extra read for every\n// attachment read and enforces a confusing api between\n// adapter.js and the adapter implementation\nAbstractPouchDB.prototype.getAttachment =\n  adapterFun('getAttachment', function (docId, attachmentId, opts, callback) {\n  var self = this;\n  if (opts instanceof Function) {\n    callback = opts;\n    opts = {};\n  }\n  this._get(docId, opts, function (err, res) {\n    if (err) {\n      return callback(err);\n    }\n    if (res.doc._attachments && res.doc._attachments[attachmentId]) {\n      opts.ctx = res.ctx;\n      opts.binary = true;\n      self._getAttachment(docId, attachmentId,\n                          res.doc._attachments[attachmentId], opts, callback);\n    } else {\n      return callback(createError(MISSING_DOC));\n    }\n  });\n});\n\nAbstractPouchDB.prototype.allDocs =\n  adapterFun('allDocs', function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  opts.skip = typeof opts.skip !== 'undefined' ? opts.skip : 0;\n  if (opts.start_key) {\n    opts.startkey = opts.start_key;\n  }\n  if (opts.end_key) {\n    opts.endkey = opts.end_key;\n  }\n  if ('keys' in opts) {\n    if (!Array.isArray(opts.keys)) {\n      return callback(new TypeError('options.keys must be an array'));\n    }\n    var incompatibleOpt =\n      ['startkey', 'endkey', 'key'].filter(function (incompatibleOpt) {\n      return incompatibleOpt in opts;\n    })[0];\n    if (incompatibleOpt) {\n      callback(createError(QUERY_PARSE_ERROR,\n        'Query parameter `' + incompatibleOpt +\n        '` is not compatible with multi-get'\n      ));\n      return;\n    }\n    if (!isRemote(this)) {\n      allDocsKeysParse(opts);\n      if (opts.keys.length === 0) {\n        return this._allDocs({limit: 0}, callback);\n      }\n    }\n  }\n\n  return this._allDocs(opts, callback);\n});\n\nAbstractPouchDB.prototype.changes = function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  return new Changes$2(this, opts, callback);\n};\n\nAbstractPouchDB.prototype.close = adapterFun('close', function (callback) {\n  this._closed = true;\n  this.emit('closed');\n  return this._close(callback);\n});\n\nAbstractPouchDB.prototype.info = adapterFun('info', function (callback) {\n  var self = this;\n  this._info(function (err, info) {\n    if (err) {\n      return callback(err);\n    }\n    // assume we know better than the adapter, unless it informs us\n    info.db_name = info.db_name || self.name;\n    info.auto_compaction = !!(self.auto_compaction && !isRemote(self));\n    info.adapter = self.adapter;\n    callback(null, info);\n  });\n});\n\nAbstractPouchDB.prototype.id = adapterFun('id', function (callback) {\n  return this._id(callback);\n});\n\n/* istanbul ignore next */\nAbstractPouchDB.prototype.type = function () {\n  return (typeof this._type === 'function') ? this._type() : this.adapter;\n};\n\nAbstractPouchDB.prototype.bulkDocs =\n  adapterFun('bulkDocs', function (req, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  opts = opts || {};\n\n  if (Array.isArray(req)) {\n    req = {\n      docs: req\n    };\n  }\n\n  if (!req || !req.docs || !Array.isArray(req.docs)) {\n    return callback(createError(MISSING_BULK_DOCS));\n  }\n\n  for (var i = 0; i < req.docs.length; ++i) {\n    if (typeof req.docs[i] !== 'object' || Array.isArray(req.docs[i])) {\n      return callback(createError(NOT_AN_OBJECT));\n    }\n  }\n\n  var attachmentError;\n  req.docs.forEach(function (doc) {\n    if (doc._attachments) {\n      Object.keys(doc._attachments).forEach(function (name) {\n        attachmentError = attachmentError || attachmentNameError(name);\n        if (!doc._attachments[name].content_type) {\n          guardedConsole('warn', 'Attachment', name, 'on document', doc._id, 'is missing content_type');\n        }\n      });\n    }\n  });\n\n  if (attachmentError) {\n    return callback(createError(BAD_REQUEST, attachmentError));\n  }\n\n  if (!('new_edits' in opts)) {\n    if ('new_edits' in req) {\n      opts.new_edits = req.new_edits;\n    } else {\n      opts.new_edits = true;\n    }\n  }\n\n  var adapter = this;\n  if (!opts.new_edits && !isRemote(adapter)) {\n    // ensure revisions of the same doc are sorted, so that\n    // the local adapter processes them correctly (#2935)\n    req.docs.sort(compareByIdThenRev);\n  }\n\n  cleanDocs(req.docs);\n\n  // in the case of conflicts, we want to return the _ids to the user\n  // however, the underlying adapter may destroy the docs array, so\n  // create a copy here\n  var ids = req.docs.map(function (doc) {\n    return doc._id;\n  });\n\n  return this._bulkDocs(req, opts, function (err, res) {\n    if (err) {\n      return callback(err);\n    }\n    if (!opts.new_edits) {\n      // this is what couch does when new_edits is false\n      res = res.filter(function (x) {\n        return x.error;\n      });\n    }\n    // add ids for error/conflict responses (not required for CouchDB)\n    if (!isRemote(adapter)) {\n      for (var i = 0, l = res.length; i < l; i++) {\n        res[i].id = res[i].id || ids[i];\n      }\n    }\n\n    callback(null, res);\n  });\n});\n\nAbstractPouchDB.prototype.registerDependentDatabase =\n  adapterFun('registerDependentDatabase', function (dependentDb,\n                                                          callback) {\n  var depDB = new this.constructor(dependentDb, this.__opts);\n\n  function diffFun(doc) {\n    doc.dependentDbs = doc.dependentDbs || {};\n    if (doc.dependentDbs[dependentDb]) {\n      return false; // no update required\n    }\n    doc.dependentDbs[dependentDb] = true;\n    return doc;\n  }\n  upsert(this, '_local/_pouch_dependentDbs', diffFun)\n    .then(function () {\n      callback(null, {db: depDB});\n    }).catch(callback);\n});\n\nAbstractPouchDB.prototype.destroy =\n  adapterFun('destroy', function (opts, callback) {\n\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  var self = this;\n  var usePrefix = 'use_prefix' in self ? self.use_prefix : true;\n\n  function destroyDb() {\n    // call destroy method of the particular adaptor\n    self._destroy(opts, function (err, resp) {\n      if (err) {\n        return callback(err);\n      }\n      self._destroyed = true;\n      self.emit('destroyed');\n      callback(null, resp || { 'ok': true });\n    });\n  }\n\n  if (isRemote(self)) {\n    // no need to check for dependent DBs if it's a remote DB\n    return destroyDb();\n  }\n\n  self.get('_local/_pouch_dependentDbs', function (err, localDoc) {\n    if (err) {\n      /* istanbul ignore if */\n      if (err.status !== 404) {\n        return callback(err);\n      } else { // no dependencies\n        return destroyDb();\n      }\n    }\n    var dependentDbs = localDoc.dependentDbs;\n    var PouchDB = self.constructor;\n    var deletedMap = Object.keys(dependentDbs).map(function (name) {\n      // use_prefix is only false in the browser\n      /* istanbul ignore next */\n      var trueName = usePrefix ?\n        name.replace(new RegExp('^' + PouchDB.prefix), '') : name;\n      return new PouchDB(trueName, self.__opts).destroy();\n    });\n    PouchPromise.all(deletedMap).then(destroyDb, callback);\n  });\n});\n\nfunction TaskQueue$1() {\n  this.isReady = false;\n  this.failed = false;\n  this.queue = [];\n}\n\nTaskQueue$1.prototype.execute = function () {\n  var fun;\n  if (this.failed) {\n    while ((fun = this.queue.shift())) {\n      fun(this.failed);\n    }\n  } else {\n    while ((fun = this.queue.shift())) {\n      fun();\n    }\n  }\n};\n\nTaskQueue$1.prototype.fail = function (err) {\n  this.failed = err;\n  this.execute();\n};\n\nTaskQueue$1.prototype.ready = function (db) {\n  this.isReady = true;\n  this.db = db;\n  this.execute();\n};\n\nTaskQueue$1.prototype.addTask = function (fun) {\n  this.queue.push(fun);\n  if (this.failed) {\n    this.execute();\n  }\n};\n\nfunction parseAdapter(name, opts) {\n  var match = name.match(/([a-z-]*):\\/\\/(.*)/);\n  if (match) {\n    // the http adapter expects the fully qualified name\n    return {\n      name: /https?/.test(match[1]) ? match[1] + '://' + match[2] : match[2],\n      adapter: match[1]\n    };\n  }\n\n  var adapters = PouchDB.adapters;\n  var preferredAdapters = PouchDB.preferredAdapters;\n  var prefix = PouchDB.prefix;\n  var adapterName = opts.adapter;\n\n  if (!adapterName) { // automatically determine adapter\n    for (var i = 0; i < preferredAdapters.length; ++i) {\n      adapterName = preferredAdapters[i];\n      // check for browsers that have been upgraded from websql-only to websql+idb\n      /* istanbul ignore if */\n      if (adapterName === 'idb' && 'websql' in adapters &&\n          hasLocalStorage() && localStorage['_pouch__websqldb_' + prefix + name]) {\n        // log it, because this can be confusing during development\n        guardedConsole('log', 'PouchDB is downgrading \"' + name + '\" to WebSQL to' +\n          ' avoid data loss, because it was already opened with WebSQL.');\n        continue; // keep using websql to avoid user data loss\n      }\n      break;\n    }\n  }\n\n  var adapter = adapters[adapterName];\n\n  // if adapter is invalid, then an error will be thrown later\n  var usePrefix = (adapter && 'use_prefix' in adapter) ?\n    adapter.use_prefix : true;\n\n  return {\n    name: usePrefix ? (prefix + name) : name,\n    adapter: adapterName\n  };\n}\n\n// OK, so here's the deal. Consider this code:\n//     var db1 = new PouchDB('foo');\n//     var db2 = new PouchDB('foo');\n//     db1.destroy();\n// ^ these two both need to emit 'destroyed' events,\n// as well as the PouchDB constructor itself.\n// So we have one db object (whichever one got destroy() called on it)\n// responsible for emitting the initial event, which then gets emitted\n// by the constructor, which then broadcasts it to any other dbs\n// that may have been created with the same name.\nfunction prepareForDestruction(self) {\n\n  function onDestroyed(from_constructor) {\n    self.removeListener('closed', onClosed);\n    if (!from_constructor) {\n      self.constructor.emit('destroyed', self.name);\n    }\n  }\n\n  function onClosed() {\n    self.removeListener('destroyed', onDestroyed);\n    self.constructor.emit('unref', self);\n  }\n\n  self.once('destroyed', onDestroyed);\n  self.once('closed', onClosed);\n  self.constructor.emit('ref', self);\n}\n\n__WEBPACK_IMPORTED_MODULE_4_inherits___default()(PouchDB, AbstractPouchDB);\nfunction PouchDB(name, opts) {\n  // In Node our test suite only tests this for PouchAlt unfortunately\n  /* istanbul ignore if */\n  if (!(this instanceof PouchDB)) {\n    return new PouchDB(name, opts);\n  }\n\n  var self = this;\n  opts = opts || {};\n\n  if (name && typeof name === 'object') {\n    opts = name;\n    name = opts.name;\n    delete opts.name;\n  }\n\n  this.__opts = opts = clone(opts);\n\n  self.auto_compaction = opts.auto_compaction;\n  self.prefix = PouchDB.prefix;\n\n  if (typeof name !== 'string') {\n    throw new Error('Missing/invalid DB name');\n  }\n\n  var prefixedName = (opts.prefix || '') + name;\n  var backend = parseAdapter(prefixedName, opts);\n\n  opts.name = backend.name;\n  opts.adapter = opts.adapter || backend.adapter;\n\n  self.name = name;\n  self._adapter = opts.adapter;\n  PouchDB.emit('debug', ['adapter', 'Picked adapter: ', opts.adapter]);\n\n  if (!PouchDB.adapters[opts.adapter] ||\n      !PouchDB.adapters[opts.adapter].valid()) {\n    throw new Error('Invalid Adapter: ' + opts.adapter);\n  }\n\n  AbstractPouchDB.call(self);\n  self.taskqueue = new TaskQueue$1();\n\n  self.adapter = opts.adapter;\n\n  PouchDB.adapters[opts.adapter].call(self, opts, function (err) {\n    if (err) {\n      return self.taskqueue.fail(err);\n    }\n    prepareForDestruction(self);\n\n    self.emit('created', self);\n    PouchDB.emit('created', self.name);\n    self.taskqueue.ready(self);\n  });\n\n}\n\nPouchDB.adapters = {};\nPouchDB.preferredAdapters = [];\n\nPouchDB.prefix = '_pouch_';\n\nvar eventEmitter = new __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"]();\n\nfunction setUpEventEmitter(Pouch) {\n  Object.keys(__WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"].prototype).forEach(function (key) {\n    if (typeof __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"].prototype[key] === 'function') {\n      Pouch[key] = eventEmitter[key].bind(eventEmitter);\n    }\n  });\n\n  // these are created in constructor.js, and allow us to notify each DB with\n  // the same name that it was destroyed, via the constructor object\n  var destructListeners = Pouch._destructionListeners = new ExportedMap();\n\n  Pouch.on('ref', function onConstructorRef(db) {\n    if (!destructListeners.has(db.name)) {\n      destructListeners.set(db.name, []);\n    }\n    destructListeners.get(db.name).push(db);\n  });\n\n  Pouch.on('unref', function onConstructorUnref(db) {\n    if (!destructListeners.has(db.name)) {\n      return;\n    }\n    var dbList = destructListeners.get(db.name);\n    var pos = dbList.indexOf(db);\n    if (pos < 0) {\n      /* istanbul ignore next */\n      return;\n    }\n    dbList.splice(pos, 1);\n    if (dbList.length > 1) {\n      /* istanbul ignore next */\n      destructListeners.set(db.name, dbList);\n    } else {\n      destructListeners.delete(db.name);\n    }\n  });\n\n  Pouch.on('destroyed', function onConstructorDestroyed(name) {\n    if (!destructListeners.has(name)) {\n      return;\n    }\n    var dbList = destructListeners.get(name);\n    destructListeners.delete(name);\n    dbList.forEach(function (db) {\n      db.emit('destroyed',true);\n    });\n  });\n}\n\nsetUpEventEmitter(PouchDB);\n\nPouchDB.adapter = function (id, obj, addToPreferredAdapters) {\n  /* istanbul ignore else */\n  if (obj.valid()) {\n    PouchDB.adapters[id] = obj;\n    if (addToPreferredAdapters) {\n      PouchDB.preferredAdapters.push(id);\n    }\n  }\n};\n\nPouchDB.plugin = function (obj) {\n  if (typeof obj === 'function') { // function style for plugins\n    obj(PouchDB);\n  } else if (typeof obj !== 'object' || Object.keys(obj).length === 0) {\n    throw new Error('Invalid plugin: got \"' + obj + '\", expected an object or a function');\n  } else {\n    Object.keys(obj).forEach(function (id) { // object style for plugins\n      PouchDB.prototype[id] = obj[id];\n    });\n  }\n  if (this.__defaults) {\n    PouchDB.__defaults = $inject_Object_assign({}, this.__defaults);\n  }\n  return PouchDB;\n};\n\nPouchDB.defaults = function (defaultOpts) {\n  function PouchAlt(name, opts) {\n    if (!(this instanceof PouchAlt)) {\n      return new PouchAlt(name, opts);\n    }\n\n    opts = opts || {};\n\n    if (name && typeof name === 'object') {\n      opts = name;\n      name = opts.name;\n      delete opts.name;\n    }\n\n    opts = $inject_Object_assign({}, PouchAlt.__defaults, opts);\n    PouchDB.call(this, name, opts);\n  }\n\n  __WEBPACK_IMPORTED_MODULE_4_inherits___default()(PouchAlt, PouchDB);\n\n  PouchAlt.preferredAdapters = PouchDB.preferredAdapters.slice();\n  Object.keys(PouchDB).forEach(function (key) {\n    if (!(key in PouchAlt)) {\n      PouchAlt[key] = PouchDB[key];\n    }\n  });\n\n  // make default options transitive\n  // https://github.com/pouchdb/pouchdb/issues/5922\n  PouchAlt.__defaults = $inject_Object_assign({}, this.__defaults, defaultOpts);\n\n  return PouchAlt;\n};\n\n// managed automatically by set-version.js\nvar version = \"6.4.3\";\n\nfunction debugPouch(PouchDB) {\n  PouchDB.debug = __WEBPACK_IMPORTED_MODULE_6_debug___default.a;\n  var logs = {};\n  /* istanbul ignore next */\n  PouchDB.on('debug', function (args) {\n    // first argument is log identifier\n    var logId = args[0];\n    // rest should be passed verbatim to debug module\n    var logArgs = args.slice(1);\n    if (!logs[logId]) {\n      logs[logId] = __WEBPACK_IMPORTED_MODULE_6_debug___default()('pouchdb:' + logId);\n    }\n    logs[logId].apply(null, logArgs);\n  });\n}\n\n// this would just be \"return doc[field]\", but fields\n// can be \"deep\" due to dot notation\nfunction getFieldFromDoc(doc, parsedField) {\n  var value = doc;\n  for (var i = 0, len = parsedField.length; i < len; i++) {\n    var key = parsedField[i];\n    value = value[key];\n    if (!value) {\n      break;\n    }\n  }\n  return value;\n}\n\nfunction compare$1(left, right) {\n  return left < right ? -1 : left > right ? 1 : 0;\n}\n\n// Converts a string in dot notation to an array of its components, with backslash escaping\nfunction parseField(fieldName) {\n  // fields may be deep (e.g. \"foo.bar.baz\"), so parse\n  var fields = [];\n  var current = '';\n  for (var i = 0, len = fieldName.length; i < len; i++) {\n    var ch = fieldName[i];\n    if (ch === '.') {\n      if (i > 0 && fieldName[i - 1] === '\\\\') { // escaped delimiter\n        current = current.substring(0, current.length - 1) + '.';\n      } else { // not escaped, so delimiter\n        fields.push(current);\n        current = '';\n      }\n    } else { // normal character\n      current += ch;\n    }\n  }\n  fields.push(current);\n  return fields;\n}\n\nvar combinationFields = ['$or', '$nor', '$not'];\nfunction isCombinationalField(field) {\n  return combinationFields.indexOf(field) > -1;\n}\n\nfunction getKey(obj) {\n  return Object.keys(obj)[0];\n}\n\nfunction getValue(obj) {\n  return obj[getKey(obj)];\n}\n\n\n// flatten an array of selectors joined by an $and operator\nfunction mergeAndedSelectors(selectors) {\n\n  // sort to ensure that e.g. if the user specified\n  // $and: [{$gt: 'a'}, {$gt: 'b'}], then it's collapsed into\n  // just {$gt: 'b'}\n  var res = {};\n\n  selectors.forEach(function (selector) {\n    Object.keys(selector).forEach(function (field) {\n      var matcher = selector[field];\n      if (typeof matcher !== 'object') {\n        matcher = {$eq: matcher};\n      }\n\n      if (isCombinationalField(field)) {\n        if (matcher instanceof Array) {\n          res[field] = matcher.map(function (m) {\n            return mergeAndedSelectors([m]);\n          });\n        } else {\n          res[field] = mergeAndedSelectors([matcher]);\n        }\n      } else {\n        var fieldMatchers = res[field] = res[field] || {};\n        Object.keys(matcher).forEach(function (operator) {\n          var value = matcher[operator];\n\n          if (operator === '$gt' || operator === '$gte') {\n            return mergeGtGte(operator, value, fieldMatchers);\n          } else if (operator === '$lt' || operator === '$lte') {\n            return mergeLtLte(operator, value, fieldMatchers);\n          } else if (operator === '$ne') {\n            return mergeNe(value, fieldMatchers);\n          } else if (operator === '$eq') {\n            return mergeEq(value, fieldMatchers);\n          }\n          fieldMatchers[operator] = value;\n        });\n      }\n    });\n  });\n\n  return res;\n}\n\n\n\n// collapse logically equivalent gt/gte values\nfunction mergeGtGte(operator, value, fieldMatchers) {\n  if (typeof fieldMatchers.$eq !== 'undefined') {\n    return; // do nothing\n  }\n  if (typeof fieldMatchers.$gte !== 'undefined') {\n    if (operator === '$gte') {\n      if (value > fieldMatchers.$gte) { // more specificity\n        fieldMatchers.$gte = value;\n      }\n    } else { // operator === '$gt'\n      if (value >= fieldMatchers.$gte) { // more specificity\n        delete fieldMatchers.$gte;\n        fieldMatchers.$gt = value;\n      }\n    }\n  } else if (typeof fieldMatchers.$gt !== 'undefined') {\n    if (operator === '$gte') {\n      if (value > fieldMatchers.$gt) { // more specificity\n        delete fieldMatchers.$gt;\n        fieldMatchers.$gte = value;\n      }\n    } else { // operator === '$gt'\n      if (value > fieldMatchers.$gt) { // more specificity\n        fieldMatchers.$gt = value;\n      }\n    }\n  } else {\n    fieldMatchers[operator] = value;\n  }\n}\n\n// collapse logically equivalent lt/lte values\nfunction mergeLtLte(operator, value, fieldMatchers) {\n  if (typeof fieldMatchers.$eq !== 'undefined') {\n    return; // do nothing\n  }\n  if (typeof fieldMatchers.$lte !== 'undefined') {\n    if (operator === '$lte') {\n      if (value < fieldMatchers.$lte) { // more specificity\n        fieldMatchers.$lte = value;\n      }\n    } else { // operator === '$gt'\n      if (value <= fieldMatchers.$lte) { // more specificity\n        delete fieldMatchers.$lte;\n        fieldMatchers.$lt = value;\n      }\n    }\n  } else if (typeof fieldMatchers.$lt !== 'undefined') {\n    if (operator === '$lte') {\n      if (value < fieldMatchers.$lt) { // more specificity\n        delete fieldMatchers.$lt;\n        fieldMatchers.$lte = value;\n      }\n    } else { // operator === '$gt'\n      if (value < fieldMatchers.$lt) { // more specificity\n        fieldMatchers.$lt = value;\n      }\n    }\n  } else {\n    fieldMatchers[operator] = value;\n  }\n}\n\n// combine $ne values into one array\nfunction mergeNe(value, fieldMatchers) {\n  if ('$ne' in fieldMatchers) {\n    // there are many things this could \"not\" be\n    fieldMatchers.$ne.push(value);\n  } else { // doesn't exist yet\n    fieldMatchers.$ne = [value];\n  }\n}\n\n// add $eq into the mix\nfunction mergeEq(value, fieldMatchers) {\n  // these all have less specificity than the $eq\n  // TODO: check for user errors here\n  delete fieldMatchers.$gt;\n  delete fieldMatchers.$gte;\n  delete fieldMatchers.$lt;\n  delete fieldMatchers.$lte;\n  delete fieldMatchers.$ne;\n  fieldMatchers.$eq = value;\n}\n\n\n//\n// normalize the selector\n//\nfunction massageSelector(input) {\n  var result = clone(input);\n  var wasAnded = false;\n  if ('$and' in result) {\n    result = mergeAndedSelectors(result['$and']);\n    wasAnded = true;\n  }\n\n  ['$or', '$nor'].forEach(function (orOrNor) {\n    if (orOrNor in result) {\n      // message each individual selector\n      // e.g. {foo: 'bar'} becomes {foo: {$eq: 'bar'}}\n      result[orOrNor].forEach(function (subSelector) {\n        var fields = Object.keys(subSelector);\n        for (var i = 0; i < fields.length; i++) {\n          var field = fields[i];\n          var matcher = subSelector[field];\n          if (typeof matcher !== 'object' || matcher === null) {\n            subSelector[field] = {$eq: matcher};\n          }\n        }\n      });\n    }\n  });\n\n  if ('$not' in result) {\n    //This feels a little like forcing, but it will work for now,\n    //I would like to come back to this and make the merging of selectors a little more generic\n    result['$not'] = mergeAndedSelectors([result['$not']]);\n  }\n\n  var fields = Object.keys(result);\n\n  for (var i = 0; i < fields.length; i++) {\n    var field = fields[i];\n    var matcher = result[field];\n\n    if (typeof matcher !== 'object' || matcher === null) {\n      matcher = {$eq: matcher};\n    } else if ('$ne' in matcher && !wasAnded) {\n      // I put these in an array, since there may be more than one\n      // but in the \"mergeAnded\" operation, I already take care of that\n      matcher.$ne = [matcher.$ne];\n    }\n    result[field] = matcher;\n  }\n\n  return result;\n}\n\nfunction pad(str, padWith, upToLength) {\n  var padding = '';\n  var targetLength = upToLength - str.length;\n  /* istanbul ignore next */\n  while (padding.length < targetLength) {\n    padding += padWith;\n  }\n  return padding;\n}\n\nfunction padLeft(str, padWith, upToLength) {\n  var padding = pad(str, padWith, upToLength);\n  return padding + str;\n}\n\nvar MIN_MAGNITUDE = -324; // verified by -Number.MIN_VALUE\nvar MAGNITUDE_DIGITS = 3; // ditto\nvar SEP = ''; // set to '_' for easier debugging \n\nfunction collate(a, b) {\n\n  if (a === b) {\n    return 0;\n  }\n\n  a = normalizeKey(a);\n  b = normalizeKey(b);\n\n  var ai = collationIndex(a);\n  var bi = collationIndex(b);\n  if ((ai - bi) !== 0) {\n    return ai - bi;\n  }\n  switch (typeof a) {\n    case 'number':\n      return a - b;\n    case 'boolean':\n      return a < b ? -1 : 1;\n    case 'string':\n      return stringCollate(a, b);\n  }\n  return Array.isArray(a) ? arrayCollate(a, b) : objectCollate(a, b);\n}\n\n// couch considers null/NaN/Infinity/-Infinity === undefined,\n// for the purposes of mapreduce indexes. also, dates get stringified.\nfunction normalizeKey(key) {\n  switch (typeof key) {\n    case 'undefined':\n      return null;\n    case 'number':\n      if (key === Infinity || key === -Infinity || isNaN(key)) {\n        return null;\n      }\n      return key;\n    case 'object':\n      var origKey = key;\n      if (Array.isArray(key)) {\n        var len = key.length;\n        key = new Array(len);\n        for (var i = 0; i < len; i++) {\n          key[i] = normalizeKey(origKey[i]);\n        }\n      /* istanbul ignore next */\n      } else if (key instanceof Date) {\n        return key.toJSON();\n      } else if (key !== null) { // generic object\n        key = {};\n        for (var k in origKey) {\n          if (origKey.hasOwnProperty(k)) {\n            var val = origKey[k];\n            if (typeof val !== 'undefined') {\n              key[k] = normalizeKey(val);\n            }\n          }\n        }\n      }\n  }\n  return key;\n}\n\nfunction indexify(key) {\n  if (key !== null) {\n    switch (typeof key) {\n      case 'boolean':\n        return key ? 1 : 0;\n      case 'number':\n        return numToIndexableString(key);\n      case 'string':\n        // We've to be sure that key does not contain \\u0000\n        // Do order-preserving replacements:\n        // 0 -> 1, 1\n        // 1 -> 1, 2\n        // 2 -> 2, 2\n        return key\n          .replace(/\\u0002/g, '\\u0002\\u0002')\n          .replace(/\\u0001/g, '\\u0001\\u0002')\n          .replace(/\\u0000/g, '\\u0001\\u0001');\n      case 'object':\n        var isArray = Array.isArray(key);\n        var arr = isArray ? key : Object.keys(key);\n        var i = -1;\n        var len = arr.length;\n        var result = '';\n        if (isArray) {\n          while (++i < len) {\n            result += toIndexableString(arr[i]);\n          }\n        } else {\n          while (++i < len) {\n            var objKey = arr[i];\n            result += toIndexableString(objKey) +\n                toIndexableString(key[objKey]);\n          }\n        }\n        return result;\n    }\n  }\n  return '';\n}\n\n// convert the given key to a string that would be appropriate\n// for lexical sorting, e.g. within a database, where the\n// sorting is the same given by the collate() function.\nfunction toIndexableString(key) {\n  var zero = '\\u0000';\n  key = normalizeKey(key);\n  return collationIndex(key) + SEP + indexify(key) + zero;\n}\n\nfunction parseNumber(str, i) {\n  var originalIdx = i;\n  var num;\n  var zero = str[i] === '1';\n  if (zero) {\n    num = 0;\n    i++;\n  } else {\n    var neg = str[i] === '0';\n    i++;\n    var numAsString = '';\n    var magAsString = str.substring(i, i + MAGNITUDE_DIGITS);\n    var magnitude = parseInt(magAsString, 10) + MIN_MAGNITUDE;\n    /* istanbul ignore next */\n    if (neg) {\n      magnitude = -magnitude;\n    }\n    i += MAGNITUDE_DIGITS;\n    while (true) {\n      var ch = str[i];\n      if (ch === '\\u0000') {\n        break;\n      } else {\n        numAsString += ch;\n      }\n      i++;\n    }\n    numAsString = numAsString.split('.');\n    if (numAsString.length === 1) {\n      num = parseInt(numAsString, 10);\n    } else {\n      /* istanbul ignore next */\n      num = parseFloat(numAsString[0] + '.' + numAsString[1]);\n    }\n    /* istanbul ignore next */\n    if (neg) {\n      num = num - 10;\n    }\n    /* istanbul ignore next */\n    if (magnitude !== 0) {\n      // parseFloat is more reliable than pow due to rounding errors\n      // e.g. Number.MAX_VALUE would return Infinity if we did\n      // num * Math.pow(10, magnitude);\n      num = parseFloat(num + 'e' + magnitude);\n    }\n  }\n  return {num: num, length : i - originalIdx};\n}\n\n// move up the stack while parsing\n// this function moved outside of parseIndexableString for performance\nfunction pop(stack, metaStack) {\n  var obj = stack.pop();\n\n  if (metaStack.length) {\n    var lastMetaElement = metaStack[metaStack.length - 1];\n    if (obj === lastMetaElement.element) {\n      // popping a meta-element, e.g. an object whose value is another object\n      metaStack.pop();\n      lastMetaElement = metaStack[metaStack.length - 1];\n    }\n    var element = lastMetaElement.element;\n    var lastElementIndex = lastMetaElement.index;\n    if (Array.isArray(element)) {\n      element.push(obj);\n    } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n      var key = stack.pop();\n      element[key] = obj;\n    } else {\n      stack.push(obj); // obj with key only\n    }\n  }\n}\n\nfunction parseIndexableString(str) {\n  var stack = [];\n  var metaStack = []; // stack for arrays and objects\n  var i = 0;\n\n  /*eslint no-constant-condition: [\"error\", { \"checkLoops\": false }]*/\n  while (true) {\n    var collationIndex = str[i++];\n    if (collationIndex === '\\u0000') {\n      if (stack.length === 1) {\n        return stack.pop();\n      } else {\n        pop(stack, metaStack);\n        continue;\n      }\n    }\n    switch (collationIndex) {\n      case '1':\n        stack.push(null);\n        break;\n      case '2':\n        stack.push(str[i] === '1');\n        i++;\n        break;\n      case '3':\n        var parsedNum = parseNumber(str, i);\n        stack.push(parsedNum.num);\n        i += parsedNum.length;\n        break;\n      case '4':\n        var parsedStr = '';\n        /*eslint no-constant-condition: [\"error\", { \"checkLoops\": false }]*/\n        while (true) {\n          var ch = str[i];\n          if (ch === '\\u0000') {\n            break;\n          }\n          parsedStr += ch;\n          i++;\n        }\n        // perform the reverse of the order-preserving replacement\n        // algorithm (see above)\n        parsedStr = parsedStr.replace(/\\u0001\\u0001/g, '\\u0000')\n          .replace(/\\u0001\\u0002/g, '\\u0001')\n          .replace(/\\u0002\\u0002/g, '\\u0002');\n        stack.push(parsedStr);\n        break;\n      case '5':\n        var arrayElement = { element: [], index: stack.length };\n        stack.push(arrayElement.element);\n        metaStack.push(arrayElement);\n        break;\n      case '6':\n        var objElement = { element: {}, index: stack.length };\n        stack.push(objElement.element);\n        metaStack.push(objElement);\n        break;\n      /* istanbul ignore next */\n      default:\n        throw new Error(\n          'bad collationIndex or unexpectedly reached end of input: ' +\n            collationIndex);\n    }\n  }\n}\n\nfunction arrayCollate(a, b) {\n  var len = Math.min(a.length, b.length);\n  for (var i = 0; i < len; i++) {\n    var sort = collate(a[i], b[i]);\n    if (sort !== 0) {\n      return sort;\n    }\n  }\n  return (a.length === b.length) ? 0 :\n    (a.length > b.length) ? 1 : -1;\n}\nfunction stringCollate(a, b) {\n  // See: https://github.com/daleharvey/pouchdb/issues/40\n  // This is incompatible with the CouchDB implementation, but its the\n  // best we can do for now\n  return (a === b) ? 0 : ((a > b) ? 1 : -1);\n}\nfunction objectCollate(a, b) {\n  var ak = Object.keys(a), bk = Object.keys(b);\n  var len = Math.min(ak.length, bk.length);\n  for (var i = 0; i < len; i++) {\n    // First sort the keys\n    var sort = collate(ak[i], bk[i]);\n    if (sort !== 0) {\n      return sort;\n    }\n    // if the keys are equal sort the values\n    sort = collate(a[ak[i]], b[bk[i]]);\n    if (sort !== 0) {\n      return sort;\n    }\n\n  }\n  return (ak.length === bk.length) ? 0 :\n    (ak.length > bk.length) ? 1 : -1;\n}\n// The collation is defined by erlangs ordered terms\n// the atoms null, true, false come first, then numbers, strings,\n// arrays, then objects\n// null/undefined/NaN/Infinity/-Infinity are all considered null\nfunction collationIndex(x) {\n  var id = ['boolean', 'number', 'string', 'object'];\n  var idx = id.indexOf(typeof x);\n  //false if -1 otherwise true, but fast!!!!1\n  if (~idx) {\n    if (x === null) {\n      return 1;\n    }\n    if (Array.isArray(x)) {\n      return 5;\n    }\n    return idx < 3 ? (idx + 2) : (idx + 3);\n  }\n  /* istanbul ignore next */\n  if (Array.isArray(x)) {\n    return 5;\n  }\n}\n\n// conversion:\n// x yyy zz...zz\n// x = 0 for negative, 1 for 0, 2 for positive\n// y = exponent (for negative numbers negated) moved so that it's >= 0\n// z = mantisse\nfunction numToIndexableString(num) {\n\n  if (num === 0) {\n    return '1';\n  }\n\n  // convert number to exponential format for easier and\n  // more succinct string sorting\n  var expFormat = num.toExponential().split(/e\\+?/);\n  var magnitude = parseInt(expFormat[1], 10);\n\n  var neg = num < 0;\n\n  var result = neg ? '0' : '2';\n\n  // first sort by magnitude\n  // it's easier if all magnitudes are positive\n  var magForComparison = ((neg ? -magnitude : magnitude) - MIN_MAGNITUDE);\n  var magString = padLeft((magForComparison).toString(), '0', MAGNITUDE_DIGITS);\n\n  result += SEP + magString;\n\n  // then sort by the factor\n  var factor = Math.abs(parseFloat(expFormat[0])); // [1..10)\n  /* istanbul ignore next */\n  if (neg) { // for negative reverse ordering\n    factor = 10 - factor;\n  }\n\n  var factorStr = factor.toFixed(20);\n\n  // strip zeros from the end\n  factorStr = factorStr.replace(/\\.?0+$/, '');\n\n  result += SEP + factorStr;\n\n  return result;\n}\n\n// create a comparator based on the sort object\nfunction createFieldSorter(sort) {\n\n  function getFieldValuesAsArray(doc) {\n    return sort.map(function (sorting) {\n      var fieldName = getKey(sorting);\n      var parsedField = parseField(fieldName);\n      var docFieldValue = getFieldFromDoc(doc, parsedField);\n      return docFieldValue;\n    });\n  }\n\n  return function (aRow, bRow) {\n    var aFieldValues = getFieldValuesAsArray(aRow.doc);\n    var bFieldValues = getFieldValuesAsArray(bRow.doc);\n    var collation = collate(aFieldValues, bFieldValues);\n    if (collation !== 0) {\n      return collation;\n    }\n    // this is what mango seems to do\n    return compare$1(aRow.doc._id, bRow.doc._id);\n  };\n}\n\nfunction filterInMemoryFields(rows, requestDef, inMemoryFields) {\n  rows = rows.filter(function (row) {\n    return rowFilter(row.doc, requestDef.selector, inMemoryFields);\n  });\n\n  if (requestDef.sort) {\n    // in-memory sort\n    var fieldSorter = createFieldSorter(requestDef.sort);\n    rows = rows.sort(fieldSorter);\n    if (typeof requestDef.sort[0] !== 'string' &&\n        getValue(requestDef.sort[0]) === 'desc') {\n      rows = rows.reverse();\n    }\n  }\n\n  if ('limit' in requestDef || 'skip' in requestDef) {\n    // have to do the limit in-memory\n    var skip = requestDef.skip || 0;\n    var limit = ('limit' in requestDef ? requestDef.limit : rows.length) + skip;\n    rows = rows.slice(skip, limit);\n  }\n  return rows;\n}\n\nfunction rowFilter(doc, selector, inMemoryFields) {\n  return inMemoryFields.every(function (field) {\n    var matcher = selector[field];\n    var parsedField = parseField(field);\n    var docFieldValue = getFieldFromDoc(doc, parsedField);\n    if (isCombinationalField(field)) {\n      return matchCominationalSelector(field, matcher, doc);\n    }\n\n    return matchSelector(matcher, doc, parsedField, docFieldValue);\n  });\n}\n\nfunction matchSelector(matcher, doc, parsedField, docFieldValue) {\n  if (!matcher) {\n    // no filtering necessary; this field is just needed for sorting\n    return true;\n  }\n\n  return Object.keys(matcher).every(function (userOperator) {\n    var userValue = matcher[userOperator];\n    return match(userOperator, doc, userValue, parsedField, docFieldValue);\n  });\n}\n\nfunction matchCominationalSelector(field, matcher, doc) {\n\n  if (field === '$or') {\n    return matcher.some(function (orMatchers) {\n      return rowFilter(doc, orMatchers, Object.keys(orMatchers));\n    });\n  }\n\n  if (field === '$not') {\n    return !rowFilter(doc, matcher, Object.keys(matcher));\n  }\n\n  //`$nor`\n  return !matcher.find(function (orMatchers) {\n    return rowFilter(doc, orMatchers, Object.keys(orMatchers));\n  });\n\n}\n\nfunction match(userOperator, doc, userValue, parsedField, docFieldValue) {\n  if (!matchers[userOperator]) {\n    throw new Error('unknown operator \"' + userOperator +\n      '\" - should be one of $eq, $lte, $lt, $gt, $gte, $exists, $ne, $in, ' +\n      '$nin, $size, $mod, $regex, $elemMatch, $type, $allMatch or $all');\n  }\n  return matchers[userOperator](doc, userValue, parsedField, docFieldValue);\n}\n\nfunction fieldExists(docFieldValue) {\n  return typeof docFieldValue !== 'undefined' && docFieldValue !== null;\n}\n\nfunction fieldIsNotUndefined(docFieldValue) {\n  return typeof docFieldValue !== 'undefined';\n}\n\nfunction modField(docFieldValue, userValue) {\n  var divisor = userValue[0];\n  var mod = userValue[1];\n  if (divisor === 0) {\n    throw new Error('Bad divisor, cannot divide by zero');\n  }\n\n  if (parseInt(divisor, 10) !== divisor ) {\n    throw new Error('Divisor is not an integer');\n  }\n\n  if (parseInt(mod, 10) !== mod ) {\n    throw new Error('Modulus is not an integer');\n  }\n\n  if (parseInt(docFieldValue, 10) !== docFieldValue) {\n    return false;\n  }\n\n  return docFieldValue % divisor === mod;\n}\n\nfunction arrayContainsValue(docFieldValue, userValue) {\n  return userValue.some(function (val) {\n    if (docFieldValue instanceof Array) {\n      return docFieldValue.indexOf(val) > -1;\n    }\n\n    return docFieldValue === val;\n  });\n}\n\nfunction arrayContainsAllValues(docFieldValue, userValue) {\n  return userValue.every(function (val) {\n    return docFieldValue.indexOf(val) > -1;\n  });\n}\n\nfunction arraySize(docFieldValue, userValue) {\n  return docFieldValue.length === userValue;\n}\n\nfunction regexMatch(docFieldValue, userValue) {\n  var re = new RegExp(userValue);\n\n  return re.test(docFieldValue);\n}\n\nfunction typeMatch(docFieldValue, userValue) {\n\n  switch (userValue) {\n    case 'null':\n      return docFieldValue === null;\n    case 'boolean':\n      return typeof (docFieldValue) === 'boolean';\n    case 'number':\n      return typeof (docFieldValue) === 'number';\n    case 'string':\n      return typeof (docFieldValue) === 'string';\n    case 'array':\n      return docFieldValue instanceof Array;\n    case 'object':\n      return ({}).toString.call(docFieldValue) === '[object Object]';\n  }\n\n  throw new Error(userValue + ' not supported as a type.' +\n                  'Please use one of object, string, array, number, boolean or null.');\n\n}\n\nvar matchers = {\n\n  '$elemMatch': function (doc, userValue, parsedField, docFieldValue) {\n    if (!Array.isArray(docFieldValue)) {\n      return false;\n    }\n\n    if (docFieldValue.length === 0) {\n      return false;\n    }\n\n    if (typeof docFieldValue[0] === 'object') {\n      return docFieldValue.some(function (val) {\n        return rowFilter(val, userValue, Object.keys(userValue));\n      });\n    }\n\n    return docFieldValue.some(function (val) {\n      return matchSelector(userValue, doc, parsedField, val);\n    });\n  },\n\n  '$allMatch': function (doc, userValue, parsedField, docFieldValue) {\n    if (!Array.isArray(docFieldValue)) {\n      return false;\n    }\n\n    /* istanbul ignore next */\n    if (docFieldValue.length === 0) {\n      return false;\n    }\n\n    if (typeof docFieldValue[0] === 'object') {\n      return docFieldValue.every(function (val) {\n        return rowFilter(val, userValue, Object.keys(userValue));\n      });\n    }\n\n    return docFieldValue.every(function (val) {\n      return matchSelector(userValue, doc, parsedField, val);\n    });\n  },\n\n  '$eq': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) === 0;\n  },\n\n  '$gte': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) >= 0;\n  },\n\n  '$gt': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) > 0;\n  },\n\n  '$lte': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) <= 0;\n  },\n\n  '$lt': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldIsNotUndefined(docFieldValue) && collate(docFieldValue, userValue) < 0;\n  },\n\n  '$exists': function (doc, userValue, parsedField, docFieldValue) {\n    //a field that is null is still considered to exist\n    if (userValue) {\n      return fieldIsNotUndefined(docFieldValue);\n    }\n\n    return !fieldIsNotUndefined(docFieldValue);\n  },\n\n  '$mod': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && modField(docFieldValue, userValue);\n  },\n\n  '$ne': function (doc, userValue, parsedField, docFieldValue) {\n    return userValue.every(function (neValue) {\n      return collate(docFieldValue, neValue) !== 0;\n    });\n  },\n  '$in': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && arrayContainsValue(docFieldValue, userValue);\n  },\n\n  '$nin': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && !arrayContainsValue(docFieldValue, userValue);\n  },\n\n  '$size': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && arraySize(docFieldValue, userValue);\n  },\n\n  '$all': function (doc, userValue, parsedField, docFieldValue) {\n    return Array.isArray(docFieldValue) && arrayContainsAllValues(docFieldValue, userValue);\n  },\n\n  '$regex': function (doc, userValue, parsedField, docFieldValue) {\n    return fieldExists(docFieldValue) && regexMatch(docFieldValue, userValue);\n  },\n\n  '$type': function (doc, userValue, parsedField, docFieldValue) {\n    return typeMatch(docFieldValue, userValue);\n  }\n};\n\n// return true if the given doc matches the supplied selector\nfunction matchesSelector(doc, selector) {\n  /* istanbul ignore if */\n  if (typeof selector !== 'object') {\n    // match the CouchDB error message\n    throw new Error('Selector error: expected a JSON object');\n  }\n\n  selector = massageSelector(selector);\n  var row = {\n    'doc': doc\n  };\n\n  var rowsMatched = filterInMemoryFields([row], { 'selector': selector }, Object.keys(selector));\n  return rowsMatched && rowsMatched.length === 1;\n}\n\nfunction evalFilter(input) {\n  return scopeEval('\"use strict\";\\nreturn ' + input + ';', {});\n}\n\nfunction evalView(input) {\n  var code = [\n    'return function(doc) {',\n    '  \"use strict\";',\n    '  var emitted = false;',\n    '  var emit = function (a, b) {',\n    '    emitted = true;',\n    '  };',\n    '  var view = ' + input + ';',\n    '  view(doc);',\n    '  if (emitted) {',\n    '    return true;',\n    '  }',\n    '};'\n  ].join('\\n');\n\n  return scopeEval(code, {});\n}\n\nfunction validate(opts, callback) {\n  if (opts.selector) {\n    if (opts.filter && opts.filter !== '_selector') {\n      var filterName = typeof opts.filter === 'string' ?\n        opts.filter : 'function';\n      return callback(new Error('selector invalid for filter \"' + filterName + '\"'));\n    }\n  }\n  callback();\n}\n\nfunction normalize(opts) {\n  if (opts.view && !opts.filter) {\n    opts.filter = '_view';\n  }\n\n  if (opts.selector && !opts.filter) {\n    opts.filter = '_selector';\n  }\n\n  if (opts.filter && typeof opts.filter === 'string') {\n    if (opts.filter === '_view') {\n      opts.view = normalizeDesignDocFunctionName(opts.view);\n    } else {\n      opts.filter = normalizeDesignDocFunctionName(opts.filter);\n    }\n  }\n}\n\nfunction shouldFilter(changesHandler, opts) {\n  return opts.filter && typeof opts.filter === 'string' &&\n    !opts.doc_ids && !isRemote(changesHandler.db);\n}\n\nfunction filter(changesHandler, opts) {\n  var callback = opts.complete;\n  if (opts.filter === '_view') {\n    if (!opts.view || typeof opts.view !== 'string') {\n      var err = createError(BAD_REQUEST,\n        '`view` filter parameter not found or invalid.');\n      return callback(err);\n    }\n    // fetch a view from a design doc, make it behave like a filter\n    var viewName = parseDesignDocFunctionName(opts.view);\n    changesHandler.db.get('_design/' + viewName[0], function (err, ddoc) {\n      /* istanbul ignore if */\n      if (changesHandler.isCancelled) {\n        return callback(null, {status: 'cancelled'});\n      }\n      /* istanbul ignore next */\n      if (err) {\n        return callback(generateErrorFromResponse(err));\n      }\n      var mapFun = ddoc && ddoc.views && ddoc.views[viewName[1]] &&\n        ddoc.views[viewName[1]].map;\n      if (!mapFun) {\n        return callback(createError(MISSING_DOC,\n          (ddoc.views ? 'missing json key: ' + viewName[1] :\n            'missing json key: views')));\n      }\n      opts.filter = evalView(mapFun);\n      changesHandler.doChanges(opts);\n    });\n  } else if (opts.selector) {\n    opts.filter = function (doc) {\n      return matchesSelector(doc, opts.selector);\n    };\n    changesHandler.doChanges(opts);\n  } else {\n    // fetch a filter from a design doc\n    var filterName = parseDesignDocFunctionName(opts.filter);\n    changesHandler.db.get('_design/' + filterName[0], function (err, ddoc) {\n      /* istanbul ignore if */\n      if (changesHandler.isCancelled) {\n        return callback(null, {status: 'cancelled'});\n      }\n      /* istanbul ignore next */\n      if (err) {\n        return callback(generateErrorFromResponse(err));\n      }\n      var filterFun = ddoc && ddoc.filters && ddoc.filters[filterName[1]];\n      if (!filterFun) {\n        return callback(createError(MISSING_DOC,\n          ((ddoc && ddoc.filters) ? 'missing json key: ' + filterName[1]\n            : 'missing json key: filters')));\n      }\n      opts.filter = evalFilter(filterFun);\n      changesHandler.doChanges(opts);\n    });\n  }\n}\n\nfunction applyChangesFilterPlugin(PouchDB) {\n  PouchDB._changesFilterPlugin = {\n    validate: validate,\n    normalize: normalize,\n    shouldFilter: shouldFilter,\n    filter: filter\n  };\n}\n\n// TODO: remove from pouchdb-core (breaking)\nPouchDB.plugin(debugPouch);\n\n// TODO: remove from pouchdb-core (breaking)\nPouchDB.plugin(applyChangesFilterPlugin);\n\nPouchDB.version = version;\n\nfunction toObject(array) {\n  return array.reduce(function (obj, item) {\n    obj[item] = true;\n    return obj;\n  }, {});\n}\n// List of top level reserved words for doc\nvar reservedWords = toObject([\n  '_id',\n  '_rev',\n  '_attachments',\n  '_deleted',\n  '_revisions',\n  '_revs_info',\n  '_conflicts',\n  '_deleted_conflicts',\n  '_local_seq',\n  '_rev_tree',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats',\n  // Specific to Couchbase Sync Gateway\n  '_removed'\n]);\n\n// List of reserved words that should end up the document\nvar dataWords = toObject([\n  '_attachments',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats'\n]);\n\nfunction parseRevisionInfo(rev$$1) {\n  if (!/^\\d+-./.test(rev$$1)) {\n    return createError(INVALID_REV);\n  }\n  var idx = rev$$1.indexOf('-');\n  var left = rev$$1.substring(0, idx);\n  var right = rev$$1.substring(idx + 1);\n  return {\n    prefix: parseInt(left, 10),\n    id: right\n  };\n}\n\nfunction makeRevTreeFromRevisions(revisions, opts) {\n  var pos = revisions.start - revisions.ids.length + 1;\n\n  var revisionIds = revisions.ids;\n  var ids = [revisionIds[0], opts, []];\n\n  for (var i = 1, len = revisionIds.length; i < len; i++) {\n    ids = [revisionIds[i], {status: 'missing'}, [ids]];\n  }\n\n  return [{\n    pos: pos,\n    ids: ids\n  }];\n}\n\n// Preprocess documents, parse their revisions, assign an id and a\n// revision for new writes that are missing them, etc\nfunction parseDoc(doc, newEdits) {\n\n  var nRevNum;\n  var newRevId;\n  var revInfo;\n  var opts = {status: 'available'};\n  if (doc._deleted) {\n    opts.deleted = true;\n  }\n\n  if (newEdits) {\n    if (!doc._id) {\n      doc._id = uuid();\n    }\n    newRevId = rev();\n    if (doc._rev) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      doc._rev_tree = [{\n        pos: revInfo.prefix,\n        ids: [revInfo.id, {status: 'missing'}, [[newRevId, opts, []]]]\n      }];\n      nRevNum = revInfo.prefix + 1;\n    } else {\n      doc._rev_tree = [{\n        pos: 1,\n        ids : [newRevId, opts, []]\n      }];\n      nRevNum = 1;\n    }\n  } else {\n    if (doc._revisions) {\n      doc._rev_tree = makeRevTreeFromRevisions(doc._revisions, opts);\n      nRevNum = doc._revisions.start;\n      newRevId = doc._revisions.ids[0];\n    }\n    if (!doc._rev_tree) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      nRevNum = revInfo.prefix;\n      newRevId = revInfo.id;\n      doc._rev_tree = [{\n        pos: nRevNum,\n        ids: [newRevId, opts, []]\n      }];\n    }\n  }\n\n  invalidIdError(doc._id);\n\n  doc._rev = nRevNum + '-' + newRevId;\n\n  var result = {metadata : {}, data : {}};\n  for (var key in doc) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(doc, key)) {\n      var specialKey = key[0] === '_';\n      if (specialKey && !reservedWords[key]) {\n        var error = createError(DOC_VALIDATION, key);\n        error.message = DOC_VALIDATION.message + ': ' + key;\n        throw error;\n      } else if (specialKey && !dataWords[key]) {\n        result.metadata[key.slice(1)] = doc[key];\n      } else {\n        result.data[key] = doc[key];\n      }\n    }\n  }\n  return result;\n}\n\nvar thisAtob = function (str) {\n  return atob(str);\n};\n\nvar thisBtoa = function (str) {\n  return btoa(str);\n};\n\n// Abstracts constructing a Blob object, so it also works in older\n// browsers that don't support the native Blob constructor (e.g.\n// old QtWebKit versions, Android < 4.4).\nfunction createBlob(parts, properties) {\n  /* global BlobBuilder,MSBlobBuilder,MozBlobBuilder,WebKitBlobBuilder */\n  parts = parts || [];\n  properties = properties || {};\n  try {\n    return new Blob(parts, properties);\n  } catch (e) {\n    if (e.name !== \"TypeError\") {\n      throw e;\n    }\n    var Builder = typeof BlobBuilder !== 'undefined' ? BlobBuilder :\n                  typeof MSBlobBuilder !== 'undefined' ? MSBlobBuilder :\n                  typeof MozBlobBuilder !== 'undefined' ? MozBlobBuilder :\n                  WebKitBlobBuilder;\n    var builder = new Builder();\n    for (var i = 0; i < parts.length; i += 1) {\n      builder.append(parts[i]);\n    }\n    return builder.getBlob(properties.type);\n  }\n}\n\n// From http://stackoverflow.com/questions/14967647/ (continues on next line)\n// encode-decode-image-with-base64-breaks-image (2013-04-21)\nfunction binaryStringToArrayBuffer(bin) {\n  var length = bin.length;\n  var buf = new ArrayBuffer(length);\n  var arr = new Uint8Array(buf);\n  for (var i = 0; i < length; i++) {\n    arr[i] = bin.charCodeAt(i);\n  }\n  return buf;\n}\n\nfunction binStringToBluffer(binString, type) {\n  return createBlob([binaryStringToArrayBuffer(binString)], {type: type});\n}\n\nfunction b64ToBluffer(b64, type) {\n  return binStringToBluffer(thisAtob(b64), type);\n}\n\n//Can't find original post, but this is close\n//http://stackoverflow.com/questions/6965107/ (continues on next line)\n//converting-between-strings-and-arraybuffers\nfunction arrayBufferToBinaryString(buffer) {\n  var binary = '';\n  var bytes = new Uint8Array(buffer);\n  var length = bytes.byteLength;\n  for (var i = 0; i < length; i++) {\n    binary += String.fromCharCode(bytes[i]);\n  }\n  return binary;\n}\n\n// shim for browsers that don't support it\nfunction readAsBinaryString(blob, callback) {\n  if (typeof FileReader === 'undefined') {\n    // fix for Firefox in a web worker\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=901097\n    return callback(arrayBufferToBinaryString(\n      new FileReaderSync().readAsArrayBuffer(blob)));\n  }\n\n  var reader = new FileReader();\n  var hasBinaryString = typeof reader.readAsBinaryString === 'function';\n  reader.onloadend = function (e) {\n    var result = e.target.result || '';\n    if (hasBinaryString) {\n      return callback(result);\n    }\n    callback(arrayBufferToBinaryString(result));\n  };\n  if (hasBinaryString) {\n    reader.readAsBinaryString(blob);\n  } else {\n    reader.readAsArrayBuffer(blob);\n  }\n}\n\nfunction blobToBinaryString(blobOrBuffer, callback) {\n  readAsBinaryString(blobOrBuffer, function (bin) {\n    callback(bin);\n  });\n}\n\nfunction blobToBase64(blobOrBuffer, callback) {\n  blobToBinaryString(blobOrBuffer, function (base64) {\n    callback(thisBtoa(base64));\n  });\n}\n\n// simplified API. universal browser support is assumed\nfunction readAsArrayBuffer(blob, callback) {\n  if (typeof FileReader === 'undefined') {\n    // fix for Firefox in a web worker:\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=901097\n    return callback(new FileReaderSync().readAsArrayBuffer(blob));\n  }\n\n  var reader = new FileReader();\n  reader.onloadend = function (e) {\n    var result = e.target.result || new ArrayBuffer(0);\n    callback(result);\n  };\n  reader.readAsArrayBuffer(blob);\n}\n\n// this is not used in the browser\n\nvar setImmediateShim = global.setImmediate || global.setTimeout;\nvar MD5_CHUNK_SIZE = 32768;\n\nfunction rawToBase64(raw) {\n  return thisBtoa(raw);\n}\n\nfunction sliceBlob(blob, start, end) {\n  if (blob.webkitSlice) {\n    return blob.webkitSlice(start, end);\n  }\n  return blob.slice(start, end);\n}\n\nfunction appendBlob(buffer, blob, start, end, callback) {\n  if (start > 0 || end < blob.size) {\n    // only slice blob if we really need to\n    blob = sliceBlob(blob, start, end);\n  }\n  readAsArrayBuffer(blob, function (arrayBuffer) {\n    buffer.append(arrayBuffer);\n    callback();\n  });\n}\n\nfunction appendString(buffer, string, start, end, callback) {\n  if (start > 0 || end < string.length) {\n    // only create a substring if we really need to\n    string = string.substring(start, end);\n  }\n  buffer.appendBinary(string);\n  callback();\n}\n\nfunction binaryMd5(data, callback) {\n  var inputIsString = typeof data === 'string';\n  var len = inputIsString ? data.length : data.size;\n  var chunkSize = Math.min(MD5_CHUNK_SIZE, len);\n  var chunks = Math.ceil(len / chunkSize);\n  var currentChunk = 0;\n  var buffer = inputIsString ? new __WEBPACK_IMPORTED_MODULE_7_spark_md5___default.a() : new __WEBPACK_IMPORTED_MODULE_7_spark_md5___default.a.ArrayBuffer();\n\n  var append = inputIsString ? appendString : appendBlob;\n\n  function next() {\n    setImmediateShim(loadNextChunk);\n  }\n\n  function done() {\n    var raw = buffer.end(true);\n    var base64 = rawToBase64(raw);\n    callback(base64);\n    buffer.destroy();\n  }\n\n  function loadNextChunk() {\n    var start = currentChunk * chunkSize;\n    var end = start + chunkSize;\n    currentChunk++;\n    if (currentChunk < chunks) {\n      append(buffer, data, start, end, next);\n    } else {\n      append(buffer, data, start, end, done);\n    }\n  }\n  loadNextChunk();\n}\n\nfunction stringMd5(string) {\n  return __WEBPACK_IMPORTED_MODULE_7_spark_md5___default.a.hash(string);\n}\n\nfunction parseBase64(data) {\n  try {\n    return thisAtob(data);\n  } catch (e) {\n    var err = createError(BAD_ARG,\n      'Attachment is not a valid base64 string');\n    return {error: err};\n  }\n}\n\nfunction preprocessString(att, blobType, callback) {\n  var asBinary = parseBase64(att.data);\n  if (asBinary.error) {\n    return callback(asBinary.error);\n  }\n\n  att.length = asBinary.length;\n  if (blobType === 'blob') {\n    att.data = binStringToBluffer(asBinary, att.content_type);\n  } else if (blobType === 'base64') {\n    att.data = thisBtoa(asBinary);\n  } else { // binary\n    att.data = asBinary;\n  }\n  binaryMd5(asBinary, function (result) {\n    att.digest = 'md5-' + result;\n    callback();\n  });\n}\n\nfunction preprocessBlob(att, blobType, callback) {\n  binaryMd5(att.data, function (md5) {\n    att.digest = 'md5-' + md5;\n    // size is for blobs (browser), length is for buffers (node)\n    att.length = att.data.size || att.data.length || 0;\n    if (blobType === 'binary') {\n      blobToBinaryString(att.data, function (binString) {\n        att.data = binString;\n        callback();\n      });\n    } else if (blobType === 'base64') {\n      blobToBase64(att.data, function (b64) {\n        att.data = b64;\n        callback();\n      });\n    } else {\n      callback();\n    }\n  });\n}\n\nfunction preprocessAttachment(att, blobType, callback) {\n  if (att.stub) {\n    return callback();\n  }\n  if (typeof att.data === 'string') { // input is a base64 string\n    preprocessString(att, blobType, callback);\n  } else { // input is a blob\n    preprocessBlob(att, blobType, callback);\n  }\n}\n\nfunction preprocessAttachments(docInfos, blobType, callback) {\n\n  if (!docInfos.length) {\n    return callback();\n  }\n\n  var docv = 0;\n  var overallErr;\n\n  docInfos.forEach(function (docInfo) {\n    var attachments = docInfo.data && docInfo.data._attachments ?\n      Object.keys(docInfo.data._attachments) : [];\n    var recv = 0;\n\n    if (!attachments.length) {\n      return done();\n    }\n\n    function processedAttachment(err) {\n      overallErr = err;\n      recv++;\n      if (recv === attachments.length) {\n        done();\n      }\n    }\n\n    for (var key in docInfo.data._attachments) {\n      if (docInfo.data._attachments.hasOwnProperty(key)) {\n        preprocessAttachment(docInfo.data._attachments[key],\n          blobType, processedAttachment);\n      }\n    }\n  });\n\n  function done() {\n    docv++;\n    if (docInfos.length === docv) {\n      if (overallErr) {\n        callback(overallErr);\n      } else {\n        callback();\n      }\n    }\n  }\n}\n\nfunction updateDoc(revLimit, prev, docInfo, results,\n                   i, cb, writeDoc, newEdits) {\n\n  if (revExists(prev.rev_tree, docInfo.metadata.rev)) {\n    results[i] = docInfo;\n    return cb();\n  }\n\n  // sometimes this is pre-calculated. historically not always\n  var previousWinningRev = prev.winningRev || winningRev(prev);\n  var previouslyDeleted = 'deleted' in prev ? prev.deleted :\n    isDeleted(prev, previousWinningRev);\n  var deleted = 'deleted' in docInfo.metadata ? docInfo.metadata.deleted :\n    isDeleted(docInfo.metadata);\n  var isRoot = /^1-/.test(docInfo.metadata.rev);\n\n  if (previouslyDeleted && !deleted && newEdits && isRoot) {\n    var newDoc = docInfo.data;\n    newDoc._rev = previousWinningRev;\n    newDoc._id = docInfo.metadata.id;\n    docInfo = parseDoc(newDoc, newEdits);\n  }\n\n  var merged = merge(prev.rev_tree, docInfo.metadata.rev_tree[0], revLimit);\n\n  var inConflict = newEdits && ((\n    (previouslyDeleted && deleted && merged.conflicts !== 'new_leaf') ||\n    (!previouslyDeleted && merged.conflicts !== 'new_leaf') ||\n    (previouslyDeleted && !deleted && merged.conflicts === 'new_branch')));\n\n  if (inConflict) {\n    var err = createError(REV_CONFLICT);\n    results[i] = err;\n    return cb();\n  }\n\n  var newRev = docInfo.metadata.rev;\n  docInfo.metadata.rev_tree = merged.tree;\n  docInfo.stemmedRevs = merged.stemmedRevs || [];\n  /* istanbul ignore else */\n  if (prev.rev_map) {\n    docInfo.metadata.rev_map = prev.rev_map; // used only by leveldb\n  }\n\n  // recalculate\n  var winningRev$$1 = winningRev(docInfo.metadata);\n  var winningRevIsDeleted = isDeleted(docInfo.metadata, winningRev$$1);\n\n  // calculate the total number of documents that were added/removed,\n  // from the perspective of total_rows/doc_count\n  var delta = (previouslyDeleted === winningRevIsDeleted) ? 0 :\n    previouslyDeleted < winningRevIsDeleted ? -1 : 1;\n\n  var newRevIsDeleted;\n  if (newRev === winningRev$$1) {\n    // if the new rev is the same as the winning rev, we can reuse that value\n    newRevIsDeleted = winningRevIsDeleted;\n  } else {\n    // if they're not the same, then we need to recalculate\n    newRevIsDeleted = isDeleted(docInfo.metadata, newRev);\n  }\n\n  writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n    true, delta, i, cb);\n}\n\nfunction rootIsMissing(docInfo) {\n  return docInfo.metadata.rev_tree[0].ids[1].status === 'missing';\n}\n\nfunction processDocs(revLimit, docInfos, api, fetchedDocs, tx, results,\n                     writeDoc, opts, overallCallback) {\n\n  // Default to 1000 locally\n  revLimit = revLimit || 1000;\n\n  function insertDoc(docInfo, resultsIdx, callback) {\n    // Cant insert new deleted documents\n    var winningRev$$1 = winningRev(docInfo.metadata);\n    var deleted = isDeleted(docInfo.metadata, winningRev$$1);\n    if ('was_delete' in opts && deleted) {\n      results[resultsIdx] = createError(MISSING_DOC, 'deleted');\n      return callback();\n    }\n\n    // 4712 - detect whether a new document was inserted with a _rev\n    var inConflict = newEdits && rootIsMissing(docInfo);\n\n    if (inConflict) {\n      var err = createError(REV_CONFLICT);\n      results[resultsIdx] = err;\n      return callback();\n    }\n\n    var delta = deleted ? 0 : 1;\n\n    writeDoc(docInfo, winningRev$$1, deleted, deleted, false,\n      delta, resultsIdx, callback);\n  }\n\n  var newEdits = opts.new_edits;\n  var idsToDocs = new ExportedMap();\n\n  var docsDone = 0;\n  var docsToDo = docInfos.length;\n\n  function checkAllDocsDone() {\n    if (++docsDone === docsToDo && overallCallback) {\n      overallCallback();\n    }\n  }\n\n  docInfos.forEach(function (currentDoc, resultsIdx) {\n\n    if (currentDoc._id && isLocalId(currentDoc._id)) {\n      var fun = currentDoc._deleted ? '_removeLocal' : '_putLocal';\n      api[fun](currentDoc, {ctx: tx}, function (err, res) {\n        results[resultsIdx] = err || res;\n        checkAllDocsDone();\n      });\n      return;\n    }\n\n    var id = currentDoc.metadata.id;\n    if (idsToDocs.has(id)) {\n      docsToDo--; // duplicate\n      idsToDocs.get(id).push([currentDoc, resultsIdx]);\n    } else {\n      idsToDocs.set(id, [[currentDoc, resultsIdx]]);\n    }\n  });\n\n  // in the case of new_edits, the user can provide multiple docs\n  // with the same id. these need to be processed sequentially\n  idsToDocs.forEach(function (docs, id) {\n    var numDone = 0;\n\n    function docWritten() {\n      if (++numDone < docs.length) {\n        nextDoc();\n      } else {\n        checkAllDocsDone();\n      }\n    }\n    function nextDoc() {\n      var value = docs[numDone];\n      var currentDoc = value[0];\n      var resultsIdx = value[1];\n\n      if (fetchedDocs.has(id)) {\n        updateDoc(revLimit, fetchedDocs.get(id), currentDoc, results,\n          resultsIdx, docWritten, writeDoc, newEdits);\n      } else {\n        // Ensure stemming applies to new writes as well\n        var merged = merge([], currentDoc.metadata.rev_tree[0], revLimit);\n        currentDoc.metadata.rev_tree = merged.tree;\n        currentDoc.stemmedRevs = merged.stemmedRevs || [];\n        insertDoc(currentDoc, resultsIdx, docWritten);\n      }\n    }\n    nextDoc();\n  });\n}\n\n// IndexedDB requires a versioned database structure, so we use the\n// version here to manage migrations.\nvar ADAPTER_VERSION = 5;\n\n// The object stores created for each database\n// DOC_STORE stores the document meta data, its revision history and state\n// Keyed by document id\nvar DOC_STORE = 'document-store';\n// BY_SEQ_STORE stores a particular version of a document, keyed by its\n// sequence id\nvar BY_SEQ_STORE = 'by-sequence';\n// Where we store attachments\nvar ATTACH_STORE = 'attach-store';\n// Where we store many-to-many relations\n// between attachment digests and seqs\nvar ATTACH_AND_SEQ_STORE = 'attach-seq-store';\n\n// Where we store database-wide meta data in a single record\n// keyed by id: META_STORE\nvar META_STORE = 'meta-store';\n// Where we store local documents\nvar LOCAL_STORE = 'local-store';\n// Where we detect blob support\nvar DETECT_BLOB_SUPPORT_STORE = 'detect-blob-support';\n\nfunction safeJsonParse(str) {\n  // This try/catch guards against stack overflow errors.\n  // JSON.parse() is faster than vuvuzela.parse() but vuvuzela\n  // cannot overflow.\n  try {\n    return JSON.parse(str);\n  } catch (e) {\n    /* istanbul ignore next */\n    return __WEBPACK_IMPORTED_MODULE_8_vuvuzela___default.a.parse(str);\n  }\n}\n\nfunction safeJsonStringify(json) {\n  try {\n    return JSON.stringify(json);\n  } catch (e) {\n    /* istanbul ignore next */\n    return __WEBPACK_IMPORTED_MODULE_8_vuvuzela___default.a.stringify(json);\n  }\n}\n\nfunction idbError(callback) {\n  return function (evt) {\n    var message = 'unknown_error';\n    if (evt.target && evt.target.error) {\n      message = evt.target.error.name || evt.target.error.message;\n    }\n    callback(createError(IDB_ERROR, message, evt.type));\n  };\n}\n\n// Unfortunately, the metadata has to be stringified\n// when it is put into the database, because otherwise\n// IndexedDB can throw errors for deeply-nested objects.\n// Originally we just used JSON.parse/JSON.stringify; now\n// we use this custom vuvuzela library that avoids recursion.\n// If we could do it all over again, we'd probably use a\n// format for the revision trees other than JSON.\nfunction encodeMetadata(metadata, winningRev, deleted) {\n  return {\n    data: safeJsonStringify(metadata),\n    winningRev: winningRev,\n    deletedOrLocal: deleted ? '1' : '0',\n    seq: metadata.seq, // highest seq for this doc\n    id: metadata.id\n  };\n}\n\nfunction decodeMetadata(storedObject) {\n  if (!storedObject) {\n    return null;\n  }\n  var metadata = safeJsonParse(storedObject.data);\n  metadata.winningRev = storedObject.winningRev;\n  metadata.deleted = storedObject.deletedOrLocal === '1';\n  metadata.seq = storedObject.seq;\n  return metadata;\n}\n\n// read the doc back out from the database. we don't store the\n// _id or _rev because we already have _doc_id_rev.\nfunction decodeDoc(doc) {\n  if (!doc) {\n    return doc;\n  }\n  var idx = doc._doc_id_rev.lastIndexOf(':');\n  doc._id = doc._doc_id_rev.substring(0, idx - 1);\n  doc._rev = doc._doc_id_rev.substring(idx + 1);\n  delete doc._doc_id_rev;\n  return doc;\n}\n\n// Read a blob from the database, encoding as necessary\n// and translating from base64 if the IDB doesn't support\n// native Blobs\nfunction readBlobData(body, type, asBlob, callback) {\n  if (asBlob) {\n    if (!body) {\n      callback(createBlob([''], {type: type}));\n    } else if (typeof body !== 'string') { // we have blob support\n      callback(body);\n    } else { // no blob support\n      callback(b64ToBluffer(body, type));\n    }\n  } else { // as base64 string\n    if (!body) {\n      callback('');\n    } else if (typeof body !== 'string') { // we have blob support\n      readAsBinaryString(body, function (binary) {\n        callback(thisBtoa(binary));\n      });\n    } else { // no blob support\n      callback(body);\n    }\n  }\n}\n\nfunction fetchAttachmentsIfNecessary(doc, opts, txn, cb) {\n  var attachments = Object.keys(doc._attachments || {});\n  if (!attachments.length) {\n    return cb && cb();\n  }\n  var numDone = 0;\n\n  function checkDone() {\n    if (++numDone === attachments.length && cb) {\n      cb();\n    }\n  }\n\n  function fetchAttachment(doc, att) {\n    var attObj = doc._attachments[att];\n    var digest = attObj.digest;\n    var req = txn.objectStore(ATTACH_STORE).get(digest);\n    req.onsuccess = function (e) {\n      attObj.body = e.target.result.body;\n      checkDone();\n    };\n  }\n\n  attachments.forEach(function (att) {\n    if (opts.attachments && opts.include_docs) {\n      fetchAttachment(doc, att);\n    } else {\n      doc._attachments[att].stub = true;\n      checkDone();\n    }\n  });\n}\n\n// IDB-specific postprocessing necessary because\n// we don't know whether we stored a true Blob or\n// a base64-encoded string, and if it's a Blob it\n// needs to be read outside of the transaction context\nfunction postProcessAttachments(results, asBlob) {\n  return PouchPromise.all(results.map(function (row) {\n    if (row.doc && row.doc._attachments) {\n      var attNames = Object.keys(row.doc._attachments);\n      return PouchPromise.all(attNames.map(function (att) {\n        var attObj = row.doc._attachments[att];\n        if (!('body' in attObj)) { // already processed\n          return;\n        }\n        var body = attObj.body;\n        var type = attObj.content_type;\n        return new PouchPromise(function (resolve) {\n          readBlobData(body, type, asBlob, function (data) {\n            row.doc._attachments[att] = $inject_Object_assign(\n              pick(attObj, ['digest', 'content_type']),\n              {data: data}\n            );\n            resolve();\n          });\n        });\n      }));\n    }\n  }));\n}\n\nfunction compactRevs(revs, docId, txn) {\n\n  var possiblyOrphanedDigests = [];\n  var seqStore = txn.objectStore(BY_SEQ_STORE);\n  var attStore = txn.objectStore(ATTACH_STORE);\n  var attAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n  var count = revs.length;\n\n  function checkDone() {\n    count--;\n    if (!count) { // done processing all revs\n      deleteOrphanedAttachments();\n    }\n  }\n\n  function deleteOrphanedAttachments() {\n    if (!possiblyOrphanedDigests.length) {\n      return;\n    }\n    possiblyOrphanedDigests.forEach(function (digest) {\n      var countReq = attAndSeqStore.index('digestSeq').count(\n        IDBKeyRange.bound(\n          digest + '::', digest + '::\\uffff', false, false));\n      countReq.onsuccess = function (e) {\n        var count = e.target.result;\n        if (!count) {\n          // orphaned\n          attStore.delete(digest);\n        }\n      };\n    });\n  }\n\n  revs.forEach(function (rev$$1) {\n    var index = seqStore.index('_doc_id_rev');\n    var key = docId + \"::\" + rev$$1;\n    index.getKey(key).onsuccess = function (e) {\n      var seq = e.target.result;\n      if (typeof seq !== 'number') {\n        return checkDone();\n      }\n      seqStore.delete(seq);\n\n      var cursor = attAndSeqStore.index('seq')\n        .openCursor(IDBKeyRange.only(seq));\n\n      cursor.onsuccess = function (event) {\n        var cursor = event.target.result;\n        if (cursor) {\n          var digest = cursor.value.digestSeq.split('::')[0];\n          possiblyOrphanedDigests.push(digest);\n          attAndSeqStore.delete(cursor.primaryKey);\n          cursor.continue();\n        } else { // done\n          checkDone();\n        }\n      };\n    };\n  });\n}\n\nfunction openTransactionSafely(idb, stores, mode) {\n  try {\n    return {\n      txn: idb.transaction(stores, mode)\n    };\n  } catch (err) {\n    return {\n      error: err\n    };\n  }\n}\n\nvar changesHandler$$1 = new Changes();\n\nfunction idbBulkDocs(dbOpts, req, opts, api, idb, callback) {\n  var docInfos = req.docs;\n  var txn;\n  var docStore;\n  var bySeqStore;\n  var attachStore;\n  var attachAndSeqStore;\n  var metaStore;\n  var docInfoError;\n  var metaDoc;\n\n  for (var i = 0, len = docInfos.length; i < len; i++) {\n    var doc = docInfos[i];\n    if (doc._id && isLocalId(doc._id)) {\n      continue;\n    }\n    doc = docInfos[i] = parseDoc(doc, opts.new_edits);\n    if (doc.error && !docInfoError) {\n      docInfoError = doc;\n    }\n  }\n\n  if (docInfoError) {\n    return callback(docInfoError);\n  }\n\n  var allDocsProcessed = false;\n  var docCountDelta = 0;\n  var results = new Array(docInfos.length);\n  var fetchedDocs = new ExportedMap();\n  var preconditionErrored = false;\n  var blobType = api._meta.blobSupport ? 'blob' : 'base64';\n\n  preprocessAttachments(docInfos, blobType, function (err) {\n    if (err) {\n      return callback(err);\n    }\n    startTransaction();\n  });\n\n  function startTransaction() {\n\n    var stores = [\n      DOC_STORE, BY_SEQ_STORE,\n      ATTACH_STORE,\n      LOCAL_STORE, ATTACH_AND_SEQ_STORE,\n      META_STORE\n    ];\n    var txnResult = openTransactionSafely(idb, stores, 'readwrite');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    txn = txnResult.txn;\n    txn.onabort = idbError(callback);\n    txn.ontimeout = idbError(callback);\n    txn.oncomplete = complete;\n    docStore = txn.objectStore(DOC_STORE);\n    bySeqStore = txn.objectStore(BY_SEQ_STORE);\n    attachStore = txn.objectStore(ATTACH_STORE);\n    attachAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n    metaStore = txn.objectStore(META_STORE);\n\n    metaStore.get(META_STORE).onsuccess = function (e) {\n      metaDoc = e.target.result;\n      updateDocCountIfReady();\n    };\n\n    verifyAttachments(function (err) {\n      if (err) {\n        preconditionErrored = true;\n        return callback(err);\n      }\n      fetchExistingDocs();\n    });\n  }\n\n  function onAllDocsProcessed() {\n    allDocsProcessed = true;\n    updateDocCountIfReady();\n  }\n\n  function idbProcessDocs() {\n    processDocs(dbOpts.revs_limit, docInfos, api, fetchedDocs,\n                txn, results, writeDoc, opts, onAllDocsProcessed);\n  }\n\n  function updateDocCountIfReady() {\n    if (!metaDoc || !allDocsProcessed) {\n      return;\n    }\n    // caching the docCount saves a lot of time in allDocs() and\n    // info(), which is why we go to all the trouble of doing this\n    metaDoc.docCount += docCountDelta;\n    metaStore.put(metaDoc);\n  }\n\n  function fetchExistingDocs() {\n\n    if (!docInfos.length) {\n      return;\n    }\n\n    var numFetched = 0;\n\n    function checkDone() {\n      if (++numFetched === docInfos.length) {\n        idbProcessDocs();\n      }\n    }\n\n    function readMetadata(event) {\n      var metadata = decodeMetadata(event.target.result);\n\n      if (metadata) {\n        fetchedDocs.set(metadata.id, metadata);\n      }\n      checkDone();\n    }\n\n    for (var i = 0, len = docInfos.length; i < len; i++) {\n      var docInfo = docInfos[i];\n      if (docInfo._id && isLocalId(docInfo._id)) {\n        checkDone(); // skip local docs\n        continue;\n      }\n      var req = docStore.get(docInfo.metadata.id);\n      req.onsuccess = readMetadata;\n    }\n  }\n\n  function complete() {\n    if (preconditionErrored) {\n      return;\n    }\n\n    changesHandler$$1.notify(api._meta.name);\n    callback(null, results);\n  }\n\n  function verifyAttachment(digest, callback) {\n\n    var req = attachStore.get(digest);\n    req.onsuccess = function (e) {\n      if (!e.target.result) {\n        var err = createError(MISSING_STUB,\n          'unknown stub attachment with digest ' +\n          digest);\n        err.status = 412;\n        callback(err);\n      } else {\n        callback();\n      }\n    };\n  }\n\n  function verifyAttachments(finish) {\n\n\n    var digests = [];\n    docInfos.forEach(function (docInfo) {\n      if (docInfo.data && docInfo.data._attachments) {\n        Object.keys(docInfo.data._attachments).forEach(function (filename) {\n          var att = docInfo.data._attachments[filename];\n          if (att.stub) {\n            digests.push(att.digest);\n          }\n        });\n      }\n    });\n    if (!digests.length) {\n      return finish();\n    }\n    var numDone = 0;\n    var err;\n\n    function checkDone() {\n      if (++numDone === digests.length) {\n        finish(err);\n      }\n    }\n    digests.forEach(function (digest) {\n      verifyAttachment(digest, function (attErr) {\n        if (attErr && !err) {\n          err = attErr;\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n                    isUpdate, delta, resultsIdx, callback) {\n\n    docInfo.metadata.winningRev = winningRev$$1;\n    docInfo.metadata.deleted = winningRevIsDeleted;\n\n    var doc = docInfo.data;\n    doc._id = docInfo.metadata.id;\n    doc._rev = docInfo.metadata.rev;\n\n    if (newRevIsDeleted) {\n      doc._deleted = true;\n    }\n\n    var hasAttachments = doc._attachments &&\n      Object.keys(doc._attachments).length;\n    if (hasAttachments) {\n      return writeAttachments(docInfo, winningRev$$1, winningRevIsDeleted,\n        isUpdate, resultsIdx, callback);\n    }\n\n    docCountDelta += delta;\n    updateDocCountIfReady();\n\n    finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n      isUpdate, resultsIdx, callback);\n  }\n\n  function finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n                     isUpdate, resultsIdx, callback) {\n\n    var doc = docInfo.data;\n    var metadata = docInfo.metadata;\n\n    doc._doc_id_rev = metadata.id + '::' + metadata.rev;\n    delete doc._id;\n    delete doc._rev;\n\n    function afterPutDoc(e) {\n      var revsToDelete = docInfo.stemmedRevs || [];\n\n      if (isUpdate && api.auto_compaction) {\n        revsToDelete = revsToDelete.concat(compactTree(docInfo.metadata));\n      }\n\n      if (revsToDelete && revsToDelete.length) {\n        compactRevs(revsToDelete, docInfo.metadata.id, txn);\n      }\n\n      metadata.seq = e.target.result;\n      // Current _rev is calculated from _rev_tree on read\n      // delete metadata.rev;\n      var metadataToStore = encodeMetadata(metadata, winningRev$$1,\n        winningRevIsDeleted);\n      var metaDataReq = docStore.put(metadataToStore);\n      metaDataReq.onsuccess = afterPutMetadata;\n    }\n\n    function afterPutDocError(e) {\n      // ConstraintError, need to update, not put (see #1638 for details)\n      e.preventDefault(); // avoid transaction abort\n      e.stopPropagation(); // avoid transaction onerror\n      var index = bySeqStore.index('_doc_id_rev');\n      var getKeyReq = index.getKey(doc._doc_id_rev);\n      getKeyReq.onsuccess = function (e) {\n        var putReq = bySeqStore.put(doc, e.target.result);\n        putReq.onsuccess = afterPutDoc;\n      };\n    }\n\n    function afterPutMetadata() {\n      results[resultsIdx] = {\n        ok: true,\n        id: metadata.id,\n        rev: metadata.rev\n      };\n      fetchedDocs.set(docInfo.metadata.id, docInfo.metadata);\n      insertAttachmentMappings(docInfo, metadata.seq, callback);\n    }\n\n    var putReq = bySeqStore.put(doc);\n\n    putReq.onsuccess = afterPutDoc;\n    putReq.onerror = afterPutDocError;\n  }\n\n  function writeAttachments(docInfo, winningRev$$1, winningRevIsDeleted,\n                            isUpdate, resultsIdx, callback) {\n\n\n    var doc = docInfo.data;\n\n    var numDone = 0;\n    var attachments = Object.keys(doc._attachments);\n\n    function collectResults() {\n      if (numDone === attachments.length) {\n        finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n          isUpdate, resultsIdx, callback);\n      }\n    }\n\n    function attachmentSaved() {\n      numDone++;\n      collectResults();\n    }\n\n    attachments.forEach(function (key) {\n      var att = docInfo.data._attachments[key];\n      if (!att.stub) {\n        var data = att.data;\n        delete att.data;\n        att.revpos = parseInt(winningRev$$1, 10);\n        var digest = att.digest;\n        saveAttachment(digest, data, attachmentSaved);\n      } else {\n        numDone++;\n        collectResults();\n      }\n    });\n  }\n\n  // map seqs to attachment digests, which\n  // we will need later during compaction\n  function insertAttachmentMappings(docInfo, seq, callback) {\n\n    var attsAdded = 0;\n    var attsToAdd = Object.keys(docInfo.data._attachments || {});\n\n    if (!attsToAdd.length) {\n      return callback();\n    }\n\n    function checkDone() {\n      if (++attsAdded === attsToAdd.length) {\n        callback();\n      }\n    }\n\n    function add(att) {\n      var digest = docInfo.data._attachments[att].digest;\n      var req = attachAndSeqStore.put({\n        seq: seq,\n        digestSeq: digest + '::' + seq\n      });\n\n      req.onsuccess = checkDone;\n      req.onerror = function (e) {\n        // this callback is for a constaint error, which we ignore\n        // because this docid/rev has already been associated with\n        // the digest (e.g. when new_edits == false)\n        e.preventDefault(); // avoid transaction abort\n        e.stopPropagation(); // avoid transaction onerror\n        checkDone();\n      };\n    }\n    for (var i = 0; i < attsToAdd.length; i++) {\n      add(attsToAdd[i]); // do in parallel\n    }\n  }\n\n  function saveAttachment(digest, data, callback) {\n\n\n    var getKeyReq = attachStore.count(digest);\n    getKeyReq.onsuccess = function (e) {\n      var count = e.target.result;\n      if (count) {\n        return callback(); // already exists\n      }\n      var newAtt = {\n        digest: digest,\n        body: data\n      };\n      var putReq = attachStore.put(newAtt);\n      putReq.onsuccess = callback;\n    };\n  }\n}\n\n// Abstraction over IDBCursor and getAll()/getAllKeys() that allows us to batch our operations\n// while falling back to a normal IDBCursor operation on browsers that don't support getAll() or\n// getAllKeys(). This allows for a much faster implementation than just straight-up cursors, because\n// we're not processing each document one-at-a-time.\nfunction runBatchedCursor(objectStore, keyRange, descending, batchSize, onBatch) {\n\n  // Bail out of getAll()/getAllKeys() in the following cases:\n  // 1) either method is unsupported - we need both\n  // 2) batchSize is 1 (might as well use IDBCursor), or batchSize is -1 (i.e. batchSize unlimited,\n  //    not really clear the user wants a batched approach where the entire DB is read into memory,\n  //    perhaps they are filtering on a per-doc basis)\n  // 3) descending  no real way to do this via getAll()/getAllKeys()\n\n  var useGetAll = typeof objectStore.getAll === 'function' &&\n    typeof objectStore.getAllKeys === 'function' &&\n    batchSize > 1 && !descending;\n\n  var keysBatch;\n  var valuesBatch;\n  var pseudoCursor;\n\n  function onGetAll(e) {\n    valuesBatch = e.target.result;\n    if (keysBatch) {\n      onBatch(keysBatch, valuesBatch, pseudoCursor);\n    }\n  }\n\n  function onGetAllKeys(e) {\n    keysBatch = e.target.result;\n    if (valuesBatch) {\n      onBatch(keysBatch, valuesBatch, pseudoCursor);\n    }\n  }\n\n  function continuePseudoCursor() {\n    if (!keysBatch.length) { // no more results\n      return onBatch();\n    }\n    // fetch next batch, exclusive start\n    var lastKey = keysBatch[keysBatch.length - 1];\n    var newKeyRange;\n    if (keyRange && keyRange.upper) {\n      try {\n        newKeyRange = IDBKeyRange.bound(lastKey, keyRange.upper,\n          true, keyRange.upperOpen);\n      } catch (e) {\n        if (e.name === \"DataError\" && e.code === 0) {\n          return onBatch(); // we're done, startkey and endkey are equal\n        }\n      }\n    } else {\n      newKeyRange = IDBKeyRange.lowerBound(lastKey, true);\n    }\n    keyRange = newKeyRange;\n    keysBatch = null;\n    valuesBatch = null;\n    objectStore.getAll(keyRange, batchSize).onsuccess = onGetAll;\n    objectStore.getAllKeys(keyRange, batchSize).onsuccess = onGetAllKeys;\n  }\n\n  function onCursor(e) {\n    var cursor = e.target.result;\n    if (!cursor) { // done\n      return onBatch();\n    }\n    // regular IDBCursor acts like a batch where batch size is always 1\n    onBatch([cursor.key], [cursor.value], cursor);\n  }\n\n  if (useGetAll) {\n    pseudoCursor = {\"continue\": continuePseudoCursor};\n    objectStore.getAll(keyRange, batchSize).onsuccess = onGetAll;\n    objectStore.getAllKeys(keyRange, batchSize).onsuccess = onGetAllKeys;\n  } else if (descending) {\n    objectStore.openCursor(keyRange, 'prev').onsuccess = onCursor;\n  } else {\n    objectStore.openCursor(keyRange).onsuccess = onCursor;\n  }\n}\n\n// simple shim for objectStore.getAll(), falling back to IDBCursor\nfunction getAll(objectStore, keyRange, onSuccess) {\n  if (typeof objectStore.getAll === 'function') {\n    // use native getAll\n    objectStore.getAll(keyRange).onsuccess = onSuccess;\n    return;\n  }\n  // fall back to cursors\n  var values = [];\n\n  function onCursor(e) {\n    var cursor = e.target.result;\n    if (cursor) {\n      values.push(cursor.value);\n      cursor.continue();\n    } else {\n      onSuccess({\n        target: {\n          result: values\n        }\n      });\n    }\n  }\n\n  objectStore.openCursor(keyRange).onsuccess = onCursor;\n}\n\nfunction allDocsKeys(keys, docStore, onBatch) {\n  // It's not guaranted to be returned in right order  \n  var valuesBatch = [];\n  var count = 0;\n  keys.forEach(function (key, index) {\n    docStore.get(key).onsuccess = function (event) {\n      if (event.target.result) {\n        valuesBatch[index] = event.target.result;\n      } else {\n        valuesBatch[index] = {key: key, error: 'not_found'};\n      }\n      count++;\n      if (count === keys.length) {\n        onBatch(keys, valuesBatch, {});\n      }\n    };\n  });\n}\n\nfunction createKeyRange(start, end, inclusiveEnd, key, descending) {\n  try {\n    if (start && end) {\n      if (descending) {\n        return IDBKeyRange.bound(end, start, !inclusiveEnd, false);\n      } else {\n        return IDBKeyRange.bound(start, end, false, !inclusiveEnd);\n      }\n    } else if (start) {\n      if (descending) {\n        return IDBKeyRange.upperBound(start);\n      } else {\n        return IDBKeyRange.lowerBound(start);\n      }\n    } else if (end) {\n      if (descending) {\n        return IDBKeyRange.lowerBound(end, !inclusiveEnd);\n      } else {\n        return IDBKeyRange.upperBound(end, !inclusiveEnd);\n      }\n    } else if (key) {\n      return IDBKeyRange.only(key);\n    }\n  } catch (e) {\n    return {error: e};\n  }\n  return null;\n}\n\nfunction idbAllDocs(opts, idb, callback) {\n  var start = 'startkey' in opts ? opts.startkey : false;\n  var end = 'endkey' in opts ? opts.endkey : false;\n  var key = 'key' in opts ? opts.key : false;\n  var keys = 'keys' in opts ? opts.keys : false; \n  var skip = opts.skip || 0;\n  var limit = typeof opts.limit === 'number' ? opts.limit : -1;\n  var inclusiveEnd = opts.inclusive_end !== false;\n\n  var keyRange; \n  var keyRangeError;\n  if (!keys) {\n    keyRange = createKeyRange(start, end, inclusiveEnd, key, opts.descending);\n    keyRangeError = keyRange && keyRange.error;\n    if (keyRangeError && \n      !(keyRangeError.name === \"DataError\" && keyRangeError.code === 0)) {\n      // DataError with error code 0 indicates start is less than end, so\n      // can just do an empty query. Else need to throw\n      return callback(createError(IDB_ERROR,\n        keyRangeError.name, keyRangeError.message));\n    }\n  }\n\n  var stores = [DOC_STORE, BY_SEQ_STORE, META_STORE];\n\n  if (opts.attachments) {\n    stores.push(ATTACH_STORE);\n  }\n  var txnResult = openTransactionSafely(idb, stores, 'readonly');\n  if (txnResult.error) {\n    return callback(txnResult.error);\n  }\n  var txn = txnResult.txn;\n  txn.oncomplete = onTxnComplete;\n  txn.onabort = idbError(callback);\n  var docStore = txn.objectStore(DOC_STORE);\n  var seqStore = txn.objectStore(BY_SEQ_STORE);\n  var metaStore = txn.objectStore(META_STORE);\n  var docIdRevIndex = seqStore.index('_doc_id_rev');\n  var results = [];\n  var docCount;\n  var updateSeq;\n\n  metaStore.get(META_STORE).onsuccess = function (e) {\n    docCount = e.target.result.docCount;\n  };\n\n  /* istanbul ignore if */\n  if (opts.update_seq) {\n    getMaxUpdateSeq(seqStore, function (e) { \n      if (e.target.result && e.target.result.length > 0) {\n        updateSeq = e.target.result[0];\n      }\n    });\n  }\n\n  function getMaxUpdateSeq(objectStore, onSuccess) {\n    function onCursor(e) {\n      var cursor = e.target.result;\n      var maxKey = undefined;\n      if (cursor && cursor.key) {\n        maxKey = cursor.key;\n      } \n      return onSuccess({\n        target: {\n          result: [maxKey]\n        }\n      });\n    }\n    objectStore.openCursor(null, 'prev').onsuccess = onCursor;\n  }\n\n  // if the user specifies include_docs=true, then we don't\n  // want to block the main cursor while we're fetching the doc\n  function fetchDocAsynchronously(metadata, row, winningRev$$1) {\n    var key = metadata.id + \"::\" + winningRev$$1;\n    docIdRevIndex.get(key).onsuccess =  function onGetDoc(e) {\n      row.doc = decodeDoc(e.target.result);\n      if (opts.conflicts) {\n        var conflicts = collectConflicts(metadata);\n        if (conflicts.length) {\n          row.doc._conflicts = conflicts;\n        }\n      }\n      fetchAttachmentsIfNecessary(row.doc, opts, txn);\n    };\n  }\n\n  function allDocsInner(winningRev$$1, metadata) {\n    var row = {\n      id: metadata.id,\n      key: metadata.id,\n      value: {\n        rev: winningRev$$1\n      }\n    };\n    var deleted = metadata.deleted;\n    if (deleted) {\n      if (keys) {\n        results.push(row);\n        // deleted docs are okay with \"keys\" requests\n        row.value.deleted = true;\n        row.doc = null;\n      }\n    } else if (skip-- <= 0) {\n      results.push(row);\n      if (opts.include_docs) {\n        fetchDocAsynchronously(metadata, row, winningRev$$1);\n      }\n    }\n  }\n\n  function processBatch(batchValues) {\n    for (var i = 0, len = batchValues.length; i < len; i++) {\n      if (results.length === limit) {\n        break;\n      }\n      var batchValue = batchValues[i];\n      if (batchValue.error && keys) {\n        // key was not found with \"keys\" requests\n        results.push(batchValue);\n        continue;\n      }\n      var metadata = decodeMetadata(batchValue);\n      var winningRev$$1 = metadata.winningRev;\n      allDocsInner(winningRev$$1, metadata);\n    }\n  }\n\n  function onBatch(batchKeys, batchValues, cursor) {\n    if (!cursor) {\n      return;\n    }\n    processBatch(batchValues);\n    if (results.length < limit) {\n      cursor.continue();\n    }\n  }\n\n  function onGetAll(e) {\n    var values = e.target.result;\n    if (opts.descending) {\n      values = values.reverse();\n    }\n    processBatch(values);\n  }\n\n  function onResultsReady() {\n    var returnVal = {\n      total_rows: docCount,\n      offset: opts.skip,\n      rows: results\n    };\n    \n    /* istanbul ignore if */\n    if (opts.update_seq && updateSeq !== undefined) {\n      returnVal.update_seq = updateSeq;\n    }\n    callback(null, returnVal);\n  }\n\n  function onTxnComplete() {\n    if (opts.attachments) {\n      postProcessAttachments(results, opts.binary).then(onResultsReady);\n    } else {\n      onResultsReady();\n    }\n  }\n\n  // don't bother doing any requests if start > end or limit === 0\n  if (keyRangeError || limit === 0) {\n    return;\n  }\n  if (keys) {\n    return allDocsKeys(opts.keys, docStore, onBatch);\n  }\n  if (limit === -1) { // just fetch everything\n    return getAll(docStore, keyRange, onGetAll);\n  }\n  // else do a cursor\n  // choose a batch size based on the skip, since we'll need to skip that many\n  runBatchedCursor(docStore, keyRange, opts.descending, limit + skip, onBatch);\n}\n\n//\n// Blobs are not supported in all versions of IndexedDB, notably\n// Chrome <37 and Android <5. In those versions, storing a blob will throw.\n//\n// Various other blob bugs exist in Chrome v37-42 (inclusive).\n// Detecting them is expensive and confusing to users, and Chrome 37-42\n// is at very low usage worldwide, so we do a hacky userAgent check instead.\n//\n// content-type bug: https://code.google.com/p/chromium/issues/detail?id=408120\n// 404 bug: https://code.google.com/p/chromium/issues/detail?id=447916\n// FileReader bug: https://code.google.com/p/chromium/issues/detail?id=447836\n//\nfunction checkBlobSupport(txn) {\n  return new PouchPromise(function (resolve) {\n    var blob$$1 = createBlob(['']);\n    var req = txn.objectStore(DETECT_BLOB_SUPPORT_STORE).put(blob$$1, 'key');\n\n    req.onsuccess = function () {\n      var matchedChrome = navigator.userAgent.match(/Chrome\\/(\\d+)/);\n      var matchedEdge = navigator.userAgent.match(/Edge\\//);\n      // MS Edge pretends to be Chrome 42:\n      // https://msdn.microsoft.com/en-us/library/hh869301%28v=vs.85%29.aspx\n      resolve(matchedEdge || !matchedChrome ||\n        parseInt(matchedChrome[1], 10) >= 43);\n    };\n\n    txn.onabort = function (e) {\n      // If the transaction aborts now its due to not being able to\n      // write to the database, likely due to the disk being full\n      e.preventDefault();\n      e.stopPropagation();\n      resolve(false);\n    };\n  }).catch(function () {\n    return false; // error, so assume unsupported\n  });\n}\n\nfunction countDocs(txn, cb) {\n  var index = txn.objectStore(DOC_STORE).index('deletedOrLocal');\n  index.count(IDBKeyRange.only('0')).onsuccess = function (e) {\n    cb(e.target.result);\n  };\n}\n\n// This task queue ensures that IDB open calls are done in their own tick\n// and sequentially - i.e. we wait for the async IDB open to *fully* complete\n// before calling the next one. This works around IE/Edge race conditions in IDB.\n\nvar running = false;\nvar queue = [];\n\nfunction tryCode(fun, err, res, PouchDB) {\n  try {\n    fun(err, res);\n  } catch (err) {\n    // Shouldn't happen, but in some odd cases\n    // IndexedDB implementations might throw a sync\n    // error, in which case this will at least log it.\n    PouchDB.emit('error', err);\n  }\n}\n\nfunction applyNext() {\n  if (running || !queue.length) {\n    return;\n  }\n  running = true;\n  queue.shift()();\n}\n\nfunction enqueueTask(action, callback, PouchDB) {\n  queue.push(function runAction() {\n    action(function runCallback(err, res) {\n      tryCode(callback, err, res, PouchDB);\n      running = false;\n      __WEBPACK_IMPORTED_MODULE_2_immediate___default()(function runNext() {\n        applyNext(PouchDB);\n      });\n    });\n  });\n  applyNext();\n}\n\nfunction changes(opts, api, dbName, idb) {\n  opts = clone(opts);\n\n  if (opts.continuous) {\n    var id = dbName + ':' + uuid();\n    changesHandler$$1.addListener(dbName, id, api, opts);\n    changesHandler$$1.notify(dbName);\n    return {\n      cancel: function () {\n        changesHandler$$1.removeListener(dbName, id);\n      }\n    };\n  }\n\n  var docIds = opts.doc_ids && new ExportedSet(opts.doc_ids);\n\n  opts.since = opts.since || 0;\n  var lastSeq = opts.since;\n\n  var limit = 'limit' in opts ? opts.limit : -1;\n  if (limit === 0) {\n    limit = 1; // per CouchDB _changes spec\n  }\n  var returnDocs;\n  if ('return_docs' in opts) {\n    returnDocs = opts.return_docs;\n  } else if ('returnDocs' in opts) {\n    // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n    returnDocs = opts.returnDocs;\n  } else {\n    returnDocs = true;\n  }\n\n  var results = [];\n  var numResults = 0;\n  var filter = filterChange(opts);\n  var docIdsToMetadata = new ExportedMap();\n\n  var txn;\n  var bySeqStore;\n  var docStore;\n  var docIdRevIndex;\n\n  function onBatch(batchKeys, batchValues, cursor) {\n    if (!cursor || !batchKeys.length) { // done\n      return;\n    }\n\n    var winningDocs = new Array(batchKeys.length);\n    var metadatas = new Array(batchKeys.length);\n\n    function processMetadataAndWinningDoc(metadata, winningDoc) {\n      var change = opts.processChange(winningDoc, metadata, opts);\n      lastSeq = change.seq = metadata.seq;\n\n      var filtered = filter(change);\n      if (typeof filtered === 'object') { // anything but true/false indicates error\n        return opts.complete(filtered);\n      }\n\n      if (filtered) {\n        numResults++;\n        if (returnDocs) {\n          results.push(change);\n        }\n        // process the attachment immediately\n        // for the benefit of live listeners\n        if (opts.attachments && opts.include_docs) {\n          fetchAttachmentsIfNecessary(winningDoc, opts, txn, function () {\n            postProcessAttachments([change], opts.binary).then(function () {\n              opts.onChange(change);\n            });\n          });\n        } else {\n          opts.onChange(change);\n        }\n      }\n    }\n\n    function onBatchDone() {\n      for (var i = 0, len = winningDocs.length; i < len; i++) {\n        if (numResults === limit) {\n          break;\n        }\n        var winningDoc = winningDocs[i];\n        if (!winningDoc) {\n          continue;\n        }\n        var metadata = metadatas[i];\n        processMetadataAndWinningDoc(metadata, winningDoc);\n      }\n\n      if (numResults !== limit) {\n        cursor.continue();\n      }\n    }\n\n    // Fetch all metadatas/winningdocs from this batch in parallel, then process\n    // them all only once all data has been collected. This is done in parallel\n    // because it's faster than doing it one-at-a-time.\n    var numDone = 0;\n    batchValues.forEach(function (value, i) {\n      var doc = decodeDoc(value);\n      var seq = batchKeys[i];\n      fetchWinningDocAndMetadata(doc, seq, function (metadata, winningDoc) {\n        metadatas[i] = metadata;\n        winningDocs[i] = winningDoc;\n        if (++numDone === batchKeys.length) {\n          onBatchDone();\n        }\n      });\n    });\n  }\n\n  function onGetMetadata(doc, seq, metadata, cb) {\n    if (metadata.seq !== seq) {\n      // some other seq is later\n      return cb();\n    }\n\n    if (metadata.winningRev === doc._rev) {\n      // this is the winning doc\n      return cb(metadata, doc);\n    }\n\n    // fetch winning doc in separate request\n    var docIdRev = doc._id + '::' + metadata.winningRev;\n    var req = docIdRevIndex.get(docIdRev);\n    req.onsuccess = function (e) {\n      cb(metadata, decodeDoc(e.target.result));\n    };\n  }\n\n  function fetchWinningDocAndMetadata(doc, seq, cb) {\n    if (docIds && !docIds.has(doc._id)) {\n      return cb();\n    }\n\n    var metadata = docIdsToMetadata.get(doc._id);\n    if (metadata) { // cached\n      return onGetMetadata(doc, seq, metadata, cb);\n    }\n    // metadata not cached, have to go fetch it\n    docStore.get(doc._id).onsuccess = function (e) {\n      metadata = decodeMetadata(e.target.result);\n      docIdsToMetadata.set(doc._id, metadata);\n      onGetMetadata(doc, seq, metadata, cb);\n    };\n  }\n\n  function finish() {\n    opts.complete(null, {\n      results: results,\n      last_seq: lastSeq\n    });\n  }\n\n  function onTxnComplete() {\n    if (!opts.continuous && opts.attachments) {\n      // cannot guarantee that postProcessing was already done,\n      // so do it again\n      postProcessAttachments(results).then(finish);\n    } else {\n      finish();\n    }\n  }\n\n  var objectStores = [DOC_STORE, BY_SEQ_STORE];\n  if (opts.attachments) {\n    objectStores.push(ATTACH_STORE);\n  }\n  var txnResult = openTransactionSafely(idb, objectStores, 'readonly');\n  if (txnResult.error) {\n    return opts.complete(txnResult.error);\n  }\n  txn = txnResult.txn;\n  txn.onabort = idbError(opts.complete);\n  txn.oncomplete = onTxnComplete;\n\n  bySeqStore = txn.objectStore(BY_SEQ_STORE);\n  docStore = txn.objectStore(DOC_STORE);\n  docIdRevIndex = bySeqStore.index('_doc_id_rev');\n\n  var keyRange = (opts.since && !opts.descending) ?\n    IDBKeyRange.lowerBound(opts.since, true) : null;\n\n  runBatchedCursor(bySeqStore, keyRange, opts.descending, limit, onBatch);\n}\n\nvar cachedDBs = new ExportedMap();\nvar blobSupportPromise;\nvar openReqList = new ExportedMap();\n\nfunction IdbPouch(opts, callback) {\n  var api = this;\n\n  enqueueTask(function (thisCallback) {\n    init(api, opts, thisCallback);\n  }, callback, api.constructor);\n}\n\nfunction init(api, opts, callback) {\n\n  var dbName = opts.name;\n\n  var idb = null;\n  api._meta = null;\n\n  // called when creating a fresh new database\n  function createSchema(db) {\n    var docStore = db.createObjectStore(DOC_STORE, {keyPath : 'id'});\n    db.createObjectStore(BY_SEQ_STORE, {autoIncrement: true})\n      .createIndex('_doc_id_rev', '_doc_id_rev', {unique: true});\n    db.createObjectStore(ATTACH_STORE, {keyPath: 'digest'});\n    db.createObjectStore(META_STORE, {keyPath: 'id', autoIncrement: false});\n    db.createObjectStore(DETECT_BLOB_SUPPORT_STORE);\n\n    // added in v2\n    docStore.createIndex('deletedOrLocal', 'deletedOrLocal', {unique : false});\n\n    // added in v3\n    db.createObjectStore(LOCAL_STORE, {keyPath: '_id'});\n\n    // added in v4\n    var attAndSeqStore = db.createObjectStore(ATTACH_AND_SEQ_STORE,\n      {autoIncrement: true});\n    attAndSeqStore.createIndex('seq', 'seq');\n    attAndSeqStore.createIndex('digestSeq', 'digestSeq', {unique: true});\n  }\n\n  // migration to version 2\n  // unfortunately \"deletedOrLocal\" is a misnomer now that we no longer\n  // store local docs in the main doc-store, but whaddyagonnado\n  function addDeletedOrLocalIndex(txn, callback) {\n    var docStore = txn.objectStore(DOC_STORE);\n    docStore.createIndex('deletedOrLocal', 'deletedOrLocal', {unique : false});\n\n    docStore.openCursor().onsuccess = function (event) {\n      var cursor = event.target.result;\n      if (cursor) {\n        var metadata = cursor.value;\n        var deleted = isDeleted(metadata);\n        metadata.deletedOrLocal = deleted ? \"1\" : \"0\";\n        docStore.put(metadata);\n        cursor.continue();\n      } else {\n        callback();\n      }\n    };\n  }\n\n  // migration to version 3 (part 1)\n  function createLocalStoreSchema(db) {\n    db.createObjectStore(LOCAL_STORE, {keyPath: '_id'})\n      .createIndex('_doc_id_rev', '_doc_id_rev', {unique: true});\n  }\n\n  // migration to version 3 (part 2)\n  function migrateLocalStore(txn, cb) {\n    var localStore = txn.objectStore(LOCAL_STORE);\n    var docStore = txn.objectStore(DOC_STORE);\n    var seqStore = txn.objectStore(BY_SEQ_STORE);\n\n    var cursor = docStore.openCursor();\n    cursor.onsuccess = function (event) {\n      var cursor = event.target.result;\n      if (cursor) {\n        var metadata = cursor.value;\n        var docId = metadata.id;\n        var local = isLocalId(docId);\n        var rev$$1 = winningRev(metadata);\n        if (local) {\n          var docIdRev = docId + \"::\" + rev$$1;\n          // remove all seq entries\n          // associated with this docId\n          var start = docId + \"::\";\n          var end = docId + \"::~\";\n          var index = seqStore.index('_doc_id_rev');\n          var range = IDBKeyRange.bound(start, end, false, false);\n          var seqCursor = index.openCursor(range);\n          seqCursor.onsuccess = function (e) {\n            seqCursor = e.target.result;\n            if (!seqCursor) {\n              // done\n              docStore.delete(cursor.primaryKey);\n              cursor.continue();\n            } else {\n              var data = seqCursor.value;\n              if (data._doc_id_rev === docIdRev) {\n                localStore.put(data);\n              }\n              seqStore.delete(seqCursor.primaryKey);\n              seqCursor.continue();\n            }\n          };\n        } else {\n          cursor.continue();\n        }\n      } else if (cb) {\n        cb();\n      }\n    };\n  }\n\n  // migration to version 4 (part 1)\n  function addAttachAndSeqStore(db) {\n    var attAndSeqStore = db.createObjectStore(ATTACH_AND_SEQ_STORE,\n      {autoIncrement: true});\n    attAndSeqStore.createIndex('seq', 'seq');\n    attAndSeqStore.createIndex('digestSeq', 'digestSeq', {unique: true});\n  }\n\n  // migration to version 4 (part 2)\n  function migrateAttsAndSeqs(txn, callback) {\n    var seqStore = txn.objectStore(BY_SEQ_STORE);\n    var attStore = txn.objectStore(ATTACH_STORE);\n    var attAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n\n    // need to actually populate the table. this is the expensive part,\n    // so as an optimization, check first that this database even\n    // contains attachments\n    var req = attStore.count();\n    req.onsuccess = function (e) {\n      var count = e.target.result;\n      if (!count) {\n        return callback(); // done\n      }\n\n      seqStore.openCursor().onsuccess = function (e) {\n        var cursor = e.target.result;\n        if (!cursor) {\n          return callback(); // done\n        }\n        var doc = cursor.value;\n        var seq = cursor.primaryKey;\n        var atts = Object.keys(doc._attachments || {});\n        var digestMap = {};\n        for (var j = 0; j < atts.length; j++) {\n          var att = doc._attachments[atts[j]];\n          digestMap[att.digest] = true; // uniq digests, just in case\n        }\n        var digests = Object.keys(digestMap);\n        for (j = 0; j < digests.length; j++) {\n          var digest = digests[j];\n          attAndSeqStore.put({\n            seq: seq,\n            digestSeq: digest + '::' + seq\n          });\n        }\n        cursor.continue();\n      };\n    };\n  }\n\n  // migration to version 5\n  // Instead of relying on on-the-fly migration of metadata,\n  // this brings the doc-store to its modern form:\n  // - metadata.winningrev\n  // - metadata.seq\n  // - stringify the metadata when storing it\n  function migrateMetadata(txn) {\n\n    function decodeMetadataCompat(storedObject) {\n      if (!storedObject.data) {\n        // old format, when we didn't store it stringified\n        storedObject.deleted = storedObject.deletedOrLocal === '1';\n        return storedObject;\n      }\n      return decodeMetadata(storedObject);\n    }\n\n    // ensure that every metadata has a winningRev and seq,\n    // which was previously created on-the-fly but better to migrate\n    var bySeqStore = txn.objectStore(BY_SEQ_STORE);\n    var docStore = txn.objectStore(DOC_STORE);\n    var cursor = docStore.openCursor();\n    cursor.onsuccess = function (e) {\n      var cursor = e.target.result;\n      if (!cursor) {\n        return; // done\n      }\n      var metadata = decodeMetadataCompat(cursor.value);\n\n      metadata.winningRev = metadata.winningRev ||\n        winningRev(metadata);\n\n      function fetchMetadataSeq() {\n        // metadata.seq was added post-3.2.0, so if it's missing,\n        // we need to fetch it manually\n        var start = metadata.id + '::';\n        var end = metadata.id + '::\\uffff';\n        var req = bySeqStore.index('_doc_id_rev').openCursor(\n          IDBKeyRange.bound(start, end));\n\n        var metadataSeq = 0;\n        req.onsuccess = function (e) {\n          var cursor = e.target.result;\n          if (!cursor) {\n            metadata.seq = metadataSeq;\n            return onGetMetadataSeq();\n          }\n          var seq = cursor.primaryKey;\n          if (seq > metadataSeq) {\n            metadataSeq = seq;\n          }\n          cursor.continue();\n        };\n      }\n\n      function onGetMetadataSeq() {\n        var metadataToStore = encodeMetadata(metadata,\n          metadata.winningRev, metadata.deleted);\n\n        var req = docStore.put(metadataToStore);\n        req.onsuccess = function () {\n          cursor.continue();\n        };\n      }\n\n      if (metadata.seq) {\n        return onGetMetadataSeq();\n      }\n\n      fetchMetadataSeq();\n    };\n\n  }\n\n  api._remote = false;\n  api.type = function () {\n    return 'idb';\n  };\n\n  api._id = toPromise(function (callback) {\n    callback(null, api._meta.instanceId);\n  });\n\n  api._bulkDocs = function idb_bulkDocs(req, reqOpts, callback) {\n    idbBulkDocs(opts, req, reqOpts, api, idb, callback);\n  };\n\n  // First we look up the metadata in the ids database, then we fetch the\n  // current revision(s) from the by sequence store\n  api._get = function idb_get(id, opts, callback) {\n    var doc;\n    var metadata;\n    var err;\n    var txn = opts.ctx;\n    if (!txn) {\n      var txnResult = openTransactionSafely(idb,\n        [DOC_STORE, BY_SEQ_STORE, ATTACH_STORE], 'readonly');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      txn = txnResult.txn;\n    }\n\n    function finish() {\n      callback(err, {doc: doc, metadata: metadata, ctx: txn});\n    }\n\n    txn.objectStore(DOC_STORE).get(id).onsuccess = function (e) {\n      metadata = decodeMetadata(e.target.result);\n      // we can determine the result here if:\n      // 1. there is no such document\n      // 2. the document is deleted and we don't ask about specific rev\n      // When we ask with opts.rev we expect the answer to be either\n      // doc (possibly with _deleted=true) or missing error\n      if (!metadata) {\n        err = createError(MISSING_DOC, 'missing');\n        return finish();\n      }\n\n      var rev$$1;\n      if (!opts.rev) {\n        rev$$1 = metadata.winningRev;\n        var deleted = isDeleted(metadata);\n        if (deleted) {\n          err = createError(MISSING_DOC, \"deleted\");\n          return finish();\n        }\n      } else {\n        rev$$1 = opts.latest ? latest(opts.rev, metadata) : opts.rev;\n      }\n\n      var objectStore = txn.objectStore(BY_SEQ_STORE);\n      var key = metadata.id + '::' + rev$$1;\n\n      objectStore.index('_doc_id_rev').get(key).onsuccess = function (e) {\n        doc = e.target.result;\n        if (doc) {\n          doc = decodeDoc(doc);\n        }\n        if (!doc) {\n          err = createError(MISSING_DOC, 'missing');\n          return finish();\n        }\n        finish();\n      };\n    };\n  };\n\n  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n    var txn;\n    if (opts.ctx) {\n      txn = opts.ctx;\n    } else {\n      var txnResult = openTransactionSafely(idb,\n        [DOC_STORE, BY_SEQ_STORE, ATTACH_STORE], 'readonly');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      txn = txnResult.txn;\n    }\n    var digest = attachment.digest;\n    var type = attachment.content_type;\n\n    txn.objectStore(ATTACH_STORE).get(digest).onsuccess = function (e) {\n      var body = e.target.result.body;\n      readBlobData(body, type, opts.binary, function (blobData) {\n        callback(null, blobData);\n      });\n    };\n  };\n\n  api._info = function idb_info(callback) {\n    var updateSeq;\n    var docCount;\n\n    var txnResult = openTransactionSafely(idb, [META_STORE, BY_SEQ_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n    txn.objectStore(META_STORE).get(META_STORE).onsuccess = function (e) {\n      docCount = e.target.result.docCount;\n    };\n    txn.objectStore(BY_SEQ_STORE).openCursor(null, 'prev').onsuccess = function (e) {\n      var cursor = e.target.result;\n      updateSeq = cursor ? cursor.key : 0;\n    };\n\n    txn.oncomplete = function () {\n      callback(null, {\n        doc_count: docCount,\n        update_seq: updateSeq,\n        // for debugging\n        idb_attachment_format: (api._meta.blobSupport ? 'binary' : 'base64')\n      });\n    };\n  };\n\n  api._allDocs = function idb_allDocs(opts, callback) {\n    idbAllDocs(opts, idb, callback);\n  };\n\n  api._changes = function idbChanges(opts) {\n    return changes(opts, api, dbName, idb);\n  };\n\n  api._close = function (callback) {\n    // https://developer.mozilla.org/en-US/docs/IndexedDB/IDBDatabase#close\n    // \"Returns immediately and closes the connection in a separate thread...\"\n    idb.close();\n    cachedDBs.delete(dbName);\n    callback();\n  };\n\n  api._getRevisionTree = function (docId, callback) {\n    var txnResult = openTransactionSafely(idb, [DOC_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n    var req = txn.objectStore(DOC_STORE).get(docId);\n    req.onsuccess = function (event) {\n      var doc = decodeMetadata(event.target.result);\n      if (!doc) {\n        callback(createError(MISSING_DOC));\n      } else {\n        callback(null, doc.rev_tree);\n      }\n    };\n  };\n\n  // This function removes revisions of document docId\n  // which are listed in revs and sets this document\n  // revision to to rev_tree\n  api._doCompaction = function (docId, revs, callback) {\n    var stores = [\n      DOC_STORE,\n      BY_SEQ_STORE,\n      ATTACH_STORE,\n      ATTACH_AND_SEQ_STORE\n    ];\n    var txnResult = openTransactionSafely(idb, stores, 'readwrite');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n\n    var docStore = txn.objectStore(DOC_STORE);\n\n    docStore.get(docId).onsuccess = function (event) {\n      var metadata = decodeMetadata(event.target.result);\n      traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                                         revHash, ctx, opts) {\n        var rev$$1 = pos + '-' + revHash;\n        if (revs.indexOf(rev$$1) !== -1) {\n          opts.status = 'missing';\n        }\n      });\n      compactRevs(revs, docId, txn);\n      var winningRev$$1 = metadata.winningRev;\n      var deleted = metadata.deleted;\n      txn.objectStore(DOC_STORE).put(\n        encodeMetadata(metadata, winningRev$$1, deleted));\n    };\n    txn.onabort = idbError(callback);\n    txn.oncomplete = function () {\n      callback();\n    };\n  };\n\n\n  api._getLocal = function (id, callback) {\n    var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var tx = txnResult.txn;\n    var req = tx.objectStore(LOCAL_STORE).get(id);\n\n    req.onerror = idbError(callback);\n    req.onsuccess = function (e) {\n      var doc = e.target.result;\n      if (!doc) {\n        callback(createError(MISSING_DOC));\n      } else {\n        delete doc['_doc_id_rev']; // for backwards compat\n        callback(null, doc);\n      }\n    };\n  };\n\n  api._putLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    delete doc._revisions; // ignore this, trust the rev\n    var oldRev = doc._rev;\n    var id = doc._id;\n    if (!oldRev) {\n      doc._rev = '0-1';\n    } else {\n      doc._rev = '0-' + (parseInt(oldRev.split('-')[1], 10) + 1);\n    }\n\n    var tx = opts.ctx;\n    var ret;\n    if (!tx) {\n      var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readwrite');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      tx = txnResult.txn;\n      tx.onerror = idbError(callback);\n      tx.oncomplete = function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      };\n    }\n\n    var oStore = tx.objectStore(LOCAL_STORE);\n    var req;\n    if (oldRev) {\n      req = oStore.get(id);\n      req.onsuccess = function (e) {\n        var oldDoc = e.target.result;\n        if (!oldDoc || oldDoc._rev !== oldRev) {\n          callback(createError(REV_CONFLICT));\n        } else { // update\n          var req = oStore.put(doc);\n          req.onsuccess = function () {\n            ret = {ok: true, id: doc._id, rev: doc._rev};\n            if (opts.ctx) { // return immediately\n              callback(null, ret);\n            }\n          };\n        }\n      };\n    } else { // new doc\n      req = oStore.add(doc);\n      req.onerror = function (e) {\n        // constraint error, already exists\n        callback(createError(REV_CONFLICT));\n        e.preventDefault(); // avoid transaction abort\n        e.stopPropagation(); // avoid transaction onerror\n      };\n      req.onsuccess = function () {\n        ret = {ok: true, id: doc._id, rev: doc._rev};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      };\n    }\n  };\n\n  api._removeLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var tx = opts.ctx;\n    if (!tx) {\n      var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readwrite');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      tx = txnResult.txn;\n      tx.oncomplete = function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      };\n    }\n    var ret;\n    var id = doc._id;\n    var oStore = tx.objectStore(LOCAL_STORE);\n    var req = oStore.get(id);\n\n    req.onerror = idbError(callback);\n    req.onsuccess = function (e) {\n      var oldDoc = e.target.result;\n      if (!oldDoc || oldDoc._rev !== doc._rev) {\n        callback(createError(MISSING_DOC));\n      } else {\n        oStore.delete(id);\n        ret = {ok: true, id: id, rev: '0-0'};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      }\n    };\n  };\n\n  api._destroy = function (opts, callback) {\n    changesHandler$$1.removeAllListeners(dbName);\n\n    //Close open request for \"dbName\" database to fix ie delay.\n    var openReq = openReqList.get(dbName);\n    if (openReq && openReq.result) {\n      openReq.result.close();\n      cachedDBs.delete(dbName);\n    }\n    var req = indexedDB.deleteDatabase(dbName);\n\n    req.onsuccess = function () {\n      //Remove open request from the list.\n      openReqList.delete(dbName);\n      if (hasLocalStorage() && (dbName in localStorage)) {\n        delete localStorage[dbName];\n      }\n      callback(null, { 'ok': true });\n    };\n\n    req.onerror = idbError(callback);\n  };\n\n  var cached = cachedDBs.get(dbName);\n\n  if (cached) {\n    idb = cached.idb;\n    api._meta = cached.global;\n    return __WEBPACK_IMPORTED_MODULE_2_immediate___default()(function () {\n      callback(null, api);\n    });\n  }\n\n  var req;\n  if (opts.storage) {\n    req = tryStorageOption(dbName, opts.storage);\n  } else {\n    req = indexedDB.open(dbName, ADAPTER_VERSION);\n  }\n\n  openReqList.set(dbName, req);\n\n  req.onupgradeneeded = function (e) {\n    var db = e.target.result;\n    if (e.oldVersion < 1) {\n      return createSchema(db); // new db, initial schema\n    }\n    // do migrations\n\n    var txn = e.currentTarget.transaction;\n    // these migrations have to be done in this function, before\n    // control is returned to the event loop, because IndexedDB\n\n    if (e.oldVersion < 3) {\n      createLocalStoreSchema(db); // v2 -> v3\n    }\n    if (e.oldVersion < 4) {\n      addAttachAndSeqStore(db); // v3 -> v4\n    }\n\n    var migrations = [\n      addDeletedOrLocalIndex, // v1 -> v2\n      migrateLocalStore,      // v2 -> v3\n      migrateAttsAndSeqs,     // v3 -> v4\n      migrateMetadata         // v4 -> v5\n    ];\n\n    var i = e.oldVersion;\n\n    function next() {\n      var migration = migrations[i - 1];\n      i++;\n      if (migration) {\n        migration(txn, next);\n      }\n    }\n\n    next();\n  };\n\n  req.onsuccess = function (e) {\n\n    idb = e.target.result;\n\n    idb.onversionchange = function () {\n      idb.close();\n      cachedDBs.delete(dbName);\n    };\n\n    idb.onabort = function (e) {\n      guardedConsole('error', 'Database has a global failure', e.target.error);\n      idb.close();\n      cachedDBs.delete(dbName);\n    };\n\n    // Do a few setup operations (in parallel as much as possible):\n    // 1. Fetch meta doc\n    // 2. Check blob support\n    // 3. Calculate docCount\n    // 4. Generate an instanceId if necessary\n    // 5. Store docCount and instanceId on meta doc\n\n    var txn = idb.transaction([\n      META_STORE,\n      DETECT_BLOB_SUPPORT_STORE,\n      DOC_STORE\n    ], 'readwrite');\n\n    var storedMetaDoc = false;\n    var metaDoc;\n    var docCount;\n    var blobSupport;\n    var instanceId;\n\n    function completeSetup() {\n      if (typeof blobSupport === 'undefined' || !storedMetaDoc) {\n        return;\n      }\n      api._meta = {\n        name: dbName,\n        instanceId: instanceId,\n        blobSupport: blobSupport\n      };\n\n      cachedDBs.set(dbName, {\n        idb: idb,\n        global: api._meta\n      });\n      callback(null, api);\n    }\n\n    function storeMetaDocIfReady() {\n      if (typeof docCount === 'undefined' || typeof metaDoc === 'undefined') {\n        return;\n      }\n      var instanceKey = dbName + '_id';\n      if (instanceKey in metaDoc) {\n        instanceId = metaDoc[instanceKey];\n      } else {\n        metaDoc[instanceKey] = instanceId = uuid();\n      }\n      metaDoc.docCount = docCount;\n      txn.objectStore(META_STORE).put(metaDoc);\n    }\n\n    //\n    // fetch or generate the instanceId\n    //\n    txn.objectStore(META_STORE).get(META_STORE).onsuccess = function (e) {\n      metaDoc = e.target.result || { id: META_STORE };\n      storeMetaDocIfReady();\n    };\n\n    //\n    // countDocs\n    //\n    countDocs(txn, function (count) {\n      docCount = count;\n      storeMetaDocIfReady();\n    });\n\n    //\n    // check blob support\n    //\n    if (!blobSupportPromise) {\n      // make sure blob support is only checked once\n      blobSupportPromise = checkBlobSupport(txn);\n    }\n\n    blobSupportPromise.then(function (val) {\n      blobSupport = val;\n      completeSetup();\n    });\n\n    // only when the metadata put transaction has completed,\n    // consider the setup done\n    txn.oncomplete = function () {\n      storedMetaDoc = true;\n      completeSetup();\n    };\n    txn.onabort = idbError(callback);\n  };\n\n  req.onerror = function () {\n    var msg = 'Failed to open indexedDB, are you in private browsing mode?';\n    guardedConsole('error', msg);\n    callback(createError(IDB_ERROR, msg));\n  };\n}\n\nIdbPouch.valid = function () {\n  // Issue #2533, we finally gave up on doing bug\n  // detection instead of browser sniffing. Safari brought us\n  // to our knees.\n  var isSafari = typeof openDatabase !== 'undefined' &&\n    /(Safari|iPhone|iPad|iPod)/.test(navigator.userAgent) &&\n    !/Chrome/.test(navigator.userAgent) &&\n    !/BlackBerry/.test(navigator.platform);\n\n  // Safari <10.1 does not meet our requirements for IDB support (#5572)\n  // since Safari 10.1 shipped with fetch, we can use that to detect it\n  var hasFetch = typeof fetch === 'function' &&\n    fetch.toString().indexOf('[native code') !== -1;\n\n  // On Firefox SecurityError is thrown while referencing indexedDB if cookies\n  // are not allowed. `typeof indexedDB` also triggers the error.\n  try {\n    // some outdated implementations of IDB that appear on Samsung\n    // and HTC Android devices <4.4 are missing IDBKeyRange\n    return (!isSafari || hasFetch) && typeof indexedDB !== 'undefined' &&\n      typeof IDBKeyRange !== 'undefined';\n  } catch (e) {\n    return false;\n  }\n};\n\nfunction tryStorageOption(dbName, storage) {\n  try { // option only available in Firefox 26+\n    return indexedDB.open(dbName, {\n      version: ADAPTER_VERSION,\n      storage: storage\n    });\n  } catch (err) {\n      return indexedDB.open(dbName, ADAPTER_VERSION);\n  }\n}\n\nfunction IDBPouch (PouchDB) {\n  PouchDB.adapter('idb', IdbPouch, true);\n}\n\n//\n// Parsing hex strings. Yeah.\n//\n// So basically we need this because of a bug in WebSQL:\n// https://code.google.com/p/chromium/issues/detail?id=422690\n// https://bugs.webkit.org/show_bug.cgi?id=137637\n//\n// UTF-8 and UTF-16 are provided as separate functions\n// for meager performance improvements\n//\n\nfunction decodeUtf8(str) {\n  return decodeURIComponent(escape(str));\n}\n\nfunction hexToInt(charCode) {\n  // '0'-'9' is 48-57\n  // 'A'-'F' is 65-70\n  // SQLite will only give us uppercase hex\n  return charCode < 65 ? (charCode - 48) : (charCode - 55);\n}\n\n\n// Example:\n// pragma encoding=utf8;\n// select hex('A');\n// returns '41'\nfunction parseHexUtf8(str, start, end) {\n  var result = '';\n  while (start < end) {\n    result += String.fromCharCode(\n      (hexToInt(str.charCodeAt(start++)) << 4) |\n        hexToInt(str.charCodeAt(start++)));\n  }\n  return result;\n}\n\n// Example:\n// pragma encoding=utf16;\n// select hex('A');\n// returns '4100'\n// notice that the 00 comes after the 41 (i.e. it's swizzled)\nfunction parseHexUtf16(str, start, end) {\n  var result = '';\n  while (start < end) {\n    // UTF-16, so swizzle the bytes\n    result += String.fromCharCode(\n      (hexToInt(str.charCodeAt(start + 2)) << 12) |\n        (hexToInt(str.charCodeAt(start + 3)) << 8) |\n        (hexToInt(str.charCodeAt(start)) << 4) |\n        hexToInt(str.charCodeAt(start + 1)));\n    start += 4;\n  }\n  return result;\n}\n\nfunction parseHexString(str, encoding) {\n  if (encoding === 'UTF-8') {\n    return decodeUtf8(parseHexUtf8(str, 0, str.length));\n  } else {\n    return parseHexUtf16(str, 0, str.length);\n  }\n}\n\nfunction quote(str) {\n  return \"'\" + str + \"'\";\n}\n\nvar ADAPTER_VERSION$1 = 7; // used to manage migrations\n\n// The object stores created for each database\n// DOC_STORE stores the document meta data, its revision history and state\nvar DOC_STORE$1 = quote('document-store');\n// BY_SEQ_STORE stores a particular version of a document, keyed by its\n// sequence id\nvar BY_SEQ_STORE$1 = quote('by-sequence');\n// Where we store attachments\nvar ATTACH_STORE$1 = quote('attach-store');\nvar LOCAL_STORE$1 = quote('local-store');\nvar META_STORE$1 = quote('metadata-store');\n// where we store many-to-many relations between attachment\n// digests and seqs\nvar ATTACH_AND_SEQ_STORE$1 = quote('attach-seq-store');\n\n// escapeBlob and unescapeBlob are workarounds for a websql bug:\n// https://code.google.com/p/chromium/issues/detail?id=422690\n// https://bugs.webkit.org/show_bug.cgi?id=137637\n// The goal is to never actually insert the \\u0000 character\n// in the database.\nfunction escapeBlob(str) {\n  return str\n    .replace(/\\u0002/g, '\\u0002\\u0002')\n    .replace(/\\u0001/g, '\\u0001\\u0002')\n    .replace(/\\u0000/g, '\\u0001\\u0001');\n}\n\nfunction unescapeBlob(str) {\n  return str\n    .replace(/\\u0001\\u0001/g, '\\u0000')\n    .replace(/\\u0001\\u0002/g, '\\u0001')\n    .replace(/\\u0002\\u0002/g, '\\u0002');\n}\n\nfunction stringifyDoc(doc) {\n  // don't bother storing the id/rev. it uses lots of space,\n  // in persistent map/reduce especially\n  delete doc._id;\n  delete doc._rev;\n  return JSON.stringify(doc);\n}\n\nfunction unstringifyDoc(doc, id, rev$$1) {\n  doc = JSON.parse(doc);\n  doc._id = id;\n  doc._rev = rev$$1;\n  return doc;\n}\n\n// question mark groups IN queries, e.g. 3 -> '(?,?,?)'\nfunction qMarks(num) {\n  var s = '(';\n  while (num--) {\n    s += '?';\n    if (num) {\n      s += ',';\n    }\n  }\n  return s + ')';\n}\n\nfunction select(selector, table, joiner, where, orderBy) {\n  return 'SELECT ' + selector + ' FROM ' +\n    (typeof table === 'string' ? table : table.join(' JOIN ')) +\n    (joiner ? (' ON ' + joiner) : '') +\n    (where ? (' WHERE ' +\n    (typeof where === 'string' ? where : where.join(' AND '))) : '') +\n    (orderBy ? (' ORDER BY ' + orderBy) : '');\n}\n\nfunction compactRevs$1(revs, docId, tx) {\n\n  if (!revs.length) {\n    return;\n  }\n\n  var numDone = 0;\n  var seqs = [];\n\n  function checkDone() {\n    if (++numDone === revs.length) { // done\n      deleteOrphans();\n    }\n  }\n\n  function deleteOrphans() {\n    // find orphaned attachment digests\n\n    if (!seqs.length) {\n      return;\n    }\n\n    var sql = 'SELECT DISTINCT digest AS digest FROM ' +\n      ATTACH_AND_SEQ_STORE$1 + ' WHERE seq IN ' + qMarks(seqs.length);\n\n    tx.executeSql(sql, seqs, function (tx, res) {\n\n      var digestsToCheck = [];\n      for (var i = 0; i < res.rows.length; i++) {\n        digestsToCheck.push(res.rows.item(i).digest);\n      }\n      if (!digestsToCheck.length) {\n        return;\n      }\n\n      var sql = 'DELETE FROM ' + ATTACH_AND_SEQ_STORE$1 +\n        ' WHERE seq IN (' +\n        seqs.map(function () { return '?'; }).join(',') +\n        ')';\n      tx.executeSql(sql, seqs, function (tx) {\n\n        var sql = 'SELECT digest FROM ' + ATTACH_AND_SEQ_STORE$1 +\n          ' WHERE digest IN (' +\n          digestsToCheck.map(function () { return '?'; }).join(',') +\n          ')';\n        tx.executeSql(sql, digestsToCheck, function (tx, res) {\n          var nonOrphanedDigests = new ExportedSet();\n          for (var i = 0; i < res.rows.length; i++) {\n            nonOrphanedDigests.add(res.rows.item(i).digest);\n          }\n          digestsToCheck.forEach(function (digest) {\n            if (nonOrphanedDigests.has(digest)) {\n              return;\n            }\n            tx.executeSql(\n              'DELETE FROM ' + ATTACH_AND_SEQ_STORE$1 + ' WHERE digest=?',\n              [digest]);\n            tx.executeSql(\n              'DELETE FROM ' + ATTACH_STORE$1 + ' WHERE digest=?', [digest]);\n          });\n        });\n      });\n    });\n  }\n\n  // update by-seq and attach stores in parallel\n  revs.forEach(function (rev$$1) {\n    var sql = 'SELECT seq FROM ' + BY_SEQ_STORE$1 +\n      ' WHERE doc_id=? AND rev=?';\n\n    tx.executeSql(sql, [docId, rev$$1], function (tx, res) {\n      if (!res.rows.length) { // already deleted\n        return checkDone();\n      }\n      var seq = res.rows.item(0).seq;\n      seqs.push(seq);\n\n      tx.executeSql(\n        'DELETE FROM ' + BY_SEQ_STORE$1 + ' WHERE seq=?', [seq], checkDone);\n    });\n  });\n}\n\nfunction websqlError(callback) {\n  return function (event) {\n    guardedConsole('error', 'WebSQL threw an error', event);\n    // event may actually be a SQLError object, so report is as such\n    var errorNameMatch = event && event.constructor.toString()\n        .match(/function ([^(]+)/);\n    var errorName = (errorNameMatch && errorNameMatch[1]) || event.type;\n    var errorReason = event.target || event.message;\n    callback(createError(WSQ_ERROR, errorReason, errorName));\n  };\n}\n\nfunction getSize(opts) {\n  if ('size' in opts) {\n    // triggers immediate popup in iOS, fixes #2347\n    // e.g. 5000001 asks for 5 MB, 10000001 asks for 10 MB,\n    return opts.size * 1000000;\n  }\n  // In iOS, doesn't matter as long as it's <= 5000000.\n  // Except that if you request too much, our tests fail\n  // because of the native \"do you accept?\" popup.\n  // In Android <=4.3, this value is actually used as an\n  // honest-to-god ceiling for data, so we need to\n  // set it to a decently high number.\n  var isAndroid = typeof navigator !== 'undefined' &&\n    /Android/.test(navigator.userAgent);\n  return isAndroid ? 5000000 : 1; // in PhantomJS, if you use 0 it will crash\n}\n\nfunction websqlBulkDocs(dbOpts, req, opts, api, db, websqlChanges, callback) {\n  var newEdits = opts.new_edits;\n  var userDocs = req.docs;\n\n  // Parse the docs, give them a sequence number for the result\n  var docInfos = userDocs.map(function (doc) {\n    if (doc._id && isLocalId(doc._id)) {\n      return doc;\n    }\n    var newDoc = parseDoc(doc, newEdits);\n    return newDoc;\n  });\n\n  var docInfoErrors = docInfos.filter(function (docInfo) {\n    return docInfo.error;\n  });\n  if (docInfoErrors.length) {\n    return callback(docInfoErrors[0]);\n  }\n\n  var tx;\n  var results = new Array(docInfos.length);\n  var fetchedDocs = new ExportedMap();\n\n  var preconditionErrored;\n  function complete() {\n    if (preconditionErrored) {\n      return callback(preconditionErrored);\n    }\n    websqlChanges.notify(api._name);\n    callback(null, results);\n  }\n\n  function verifyAttachment(digest, callback) {\n    var sql = 'SELECT count(*) as cnt FROM ' + ATTACH_STORE$1 +\n      ' WHERE digest=?';\n    tx.executeSql(sql, [digest], function (tx, result) {\n      if (result.rows.item(0).cnt === 0) {\n        var err = createError(MISSING_STUB,\n          'unknown stub attachment with digest ' +\n          digest);\n        callback(err);\n      } else {\n        callback();\n      }\n    });\n  }\n\n  function verifyAttachments(finish) {\n    var digests = [];\n    docInfos.forEach(function (docInfo) {\n      if (docInfo.data && docInfo.data._attachments) {\n        Object.keys(docInfo.data._attachments).forEach(function (filename) {\n          var att = docInfo.data._attachments[filename];\n          if (att.stub) {\n            digests.push(att.digest);\n          }\n        });\n      }\n    });\n    if (!digests.length) {\n      return finish();\n    }\n    var numDone = 0;\n    var err;\n\n    function checkDone() {\n      if (++numDone === digests.length) {\n        finish(err);\n      }\n    }\n    digests.forEach(function (digest) {\n      verifyAttachment(digest, function (attErr) {\n        if (attErr && !err) {\n          err = attErr;\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n                    isUpdate, delta, resultsIdx, callback) {\n\n    function finish() {\n      var data = docInfo.data;\n      var deletedInt = newRevIsDeleted ? 1 : 0;\n\n      var id = data._id;\n      var rev = data._rev;\n      var json = stringifyDoc(data);\n      var sql = 'INSERT INTO ' + BY_SEQ_STORE$1 +\n        ' (doc_id, rev, json, deleted) VALUES (?, ?, ?, ?);';\n      var sqlArgs = [id, rev, json, deletedInt];\n\n      // map seqs to attachment digests, which\n      // we will need later during compaction\n      function insertAttachmentMappings(seq, callback) {\n        var attsAdded = 0;\n        var attsToAdd = Object.keys(data._attachments || {});\n\n        if (!attsToAdd.length) {\n          return callback();\n        }\n        function checkDone() {\n          if (++attsAdded === attsToAdd.length) {\n            callback();\n          }\n          return false; // ack handling a constraint error\n        }\n        function add(att) {\n          var sql = 'INSERT INTO ' + ATTACH_AND_SEQ_STORE$1 +\n            ' (digest, seq) VALUES (?,?)';\n          var sqlArgs = [data._attachments[att].digest, seq];\n          tx.executeSql(sql, sqlArgs, checkDone, checkDone);\n          // second callback is for a constaint error, which we ignore\n          // because this docid/rev has already been associated with\n          // the digest (e.g. when new_edits == false)\n        }\n        for (var i = 0; i < attsToAdd.length; i++) {\n          add(attsToAdd[i]); // do in parallel\n        }\n      }\n\n      tx.executeSql(sql, sqlArgs, function (tx, result) {\n        var seq = result.insertId;\n        insertAttachmentMappings(seq, function () {\n          dataWritten(tx, seq);\n        });\n      }, function () {\n        // constraint error, recover by updating instead (see #1638)\n        var fetchSql = select('seq', BY_SEQ_STORE$1, null,\n          'doc_id=? AND rev=?');\n        tx.executeSql(fetchSql, [id, rev], function (tx, res) {\n          var seq = res.rows.item(0).seq;\n          var sql = 'UPDATE ' + BY_SEQ_STORE$1 +\n            ' SET json=?, deleted=? WHERE doc_id=? AND rev=?;';\n          var sqlArgs = [json, deletedInt, id, rev];\n          tx.executeSql(sql, sqlArgs, function (tx) {\n            insertAttachmentMappings(seq, function () {\n              dataWritten(tx, seq);\n            });\n          });\n        });\n        return false; // ack that we've handled the error\n      });\n    }\n\n    function collectResults(attachmentErr) {\n      if (!err) {\n        if (attachmentErr) {\n          err = attachmentErr;\n          callback(err);\n        } else if (recv === attachments.length) {\n          finish();\n        }\n      }\n    }\n\n    var err = null;\n    var recv = 0;\n\n    docInfo.data._id = docInfo.metadata.id;\n    docInfo.data._rev = docInfo.metadata.rev;\n    var attachments = Object.keys(docInfo.data._attachments || {});\n\n\n    if (newRevIsDeleted) {\n      docInfo.data._deleted = true;\n    }\n\n    function attachmentSaved(err) {\n      recv++;\n      collectResults(err);\n    }\n\n    attachments.forEach(function (key) {\n      var att = docInfo.data._attachments[key];\n      if (!att.stub) {\n        var data = att.data;\n        delete att.data;\n        att.revpos = parseInt(winningRev$$1, 10);\n        var digest = att.digest;\n        saveAttachment(digest, data, attachmentSaved);\n      } else {\n        recv++;\n        collectResults();\n      }\n    });\n\n    if (!attachments.length) {\n      finish();\n    }\n\n    function dataWritten(tx, seq) {\n      var id = docInfo.metadata.id;\n\n      var revsToCompact = docInfo.stemmedRevs || [];\n      if (isUpdate && api.auto_compaction) {\n        revsToCompact = compactTree(docInfo.metadata).concat(revsToCompact);\n      }\n      if (revsToCompact.length) {\n        compactRevs$1(revsToCompact, id, tx);\n      }\n\n      docInfo.metadata.seq = seq;\n      var rev = docInfo.metadata.rev;\n      delete docInfo.metadata.rev;\n\n      var sql = isUpdate ?\n      'UPDATE ' + DOC_STORE$1 +\n      ' SET json=?, max_seq=?, winningseq=' +\n      '(SELECT seq FROM ' + BY_SEQ_STORE$1 +\n      ' WHERE doc_id=' + DOC_STORE$1 + '.id AND rev=?) WHERE id=?'\n        : 'INSERT INTO ' + DOC_STORE$1 +\n      ' (id, winningseq, max_seq, json) VALUES (?,?,?,?);';\n      var metadataStr = safeJsonStringify(docInfo.metadata);\n      var params = isUpdate ?\n        [metadataStr, seq, winningRev$$1, id] :\n        [id, seq, seq, metadataStr];\n      tx.executeSql(sql, params, function () {\n        results[resultsIdx] = {\n          ok: true,\n          id: docInfo.metadata.id,\n          rev: rev\n        };\n        fetchedDocs.set(id, docInfo.metadata);\n        callback();\n      });\n    }\n  }\n\n  function websqlProcessDocs() {\n    processDocs(dbOpts.revs_limit, docInfos, api, fetchedDocs, tx,\n                results, writeDoc, opts);\n  }\n\n  function fetchExistingDocs(callback) {\n    if (!docInfos.length) {\n      return callback();\n    }\n\n    var numFetched = 0;\n\n    function checkDone() {\n      if (++numFetched === docInfos.length) {\n        callback();\n      }\n    }\n\n    docInfos.forEach(function (docInfo) {\n      if (docInfo._id && isLocalId(docInfo._id)) {\n        return checkDone(); // skip local docs\n      }\n      var id = docInfo.metadata.id;\n      tx.executeSql('SELECT json FROM ' + DOC_STORE$1 +\n      ' WHERE id = ?', [id], function (tx, result) {\n        if (result.rows.length) {\n          var metadata = safeJsonParse(result.rows.item(0).json);\n          fetchedDocs.set(id, metadata);\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function saveAttachment(digest, data, callback) {\n    var sql = 'SELECT digest FROM ' + ATTACH_STORE$1 + ' WHERE digest=?';\n    tx.executeSql(sql, [digest], function (tx, result) {\n      if (result.rows.length) { // attachment already exists\n        return callback();\n      }\n      // we could just insert before selecting and catch the error,\n      // but my hunch is that it's cheaper not to serialize the blob\n      // from JS to C if we don't have to (TODO: confirm this)\n      sql = 'INSERT INTO ' + ATTACH_STORE$1 +\n      ' (digest, body, escaped) VALUES (?,?,1)';\n      tx.executeSql(sql, [digest, escapeBlob(data)], function () {\n        callback();\n      }, function () {\n        // ignore constaint errors, means it already exists\n        callback();\n        return false; // ack we handled the error\n      });\n    });\n  }\n\n  preprocessAttachments(docInfos, 'binary', function (err) {\n    if (err) {\n      return callback(err);\n    }\n    db.transaction(function (txn) {\n      tx = txn;\n      verifyAttachments(function (err) {\n        if (err) {\n          preconditionErrored = err;\n        } else {\n          fetchExistingDocs(websqlProcessDocs);\n        }\n      });\n    }, websqlError(callback), complete);\n  });\n}\n\nvar cachedDatabases = new ExportedMap();\n\n// openDatabase passed in through opts (e.g. for node-websql)\nfunction openDatabaseWithOpts(opts) {\n  return opts.websql(opts.name, opts.version, opts.description, opts.size);\n}\n\nfunction openDBSafely(opts) {\n  try {\n    return {\n      db: openDatabaseWithOpts(opts)\n    };\n  } catch (err) {\n    return {\n      error: err\n    };\n  }\n}\n\nfunction openDB(opts) {\n  var cachedResult = cachedDatabases.get(opts.name);\n  if (!cachedResult) {\n    cachedResult = openDBSafely(opts);\n    cachedDatabases.set(opts.name, cachedResult);\n  }\n  return cachedResult;\n}\n\nvar websqlChanges = new Changes();\n\nfunction fetchAttachmentsIfNecessary$1(doc, opts, api, txn, cb) {\n  var attachments = Object.keys(doc._attachments || {});\n  if (!attachments.length) {\n    return cb && cb();\n  }\n  var numDone = 0;\n\n  function checkDone() {\n    if (++numDone === attachments.length && cb) {\n      cb();\n    }\n  }\n\n  function fetchAttachment(doc, att) {\n    var attObj = doc._attachments[att];\n    var attOpts = {binary: opts.binary, ctx: txn};\n    api._getAttachment(doc._id, att, attObj, attOpts, function (_, data) {\n      doc._attachments[att] = $inject_Object_assign(\n        pick(attObj, ['digest', 'content_type']),\n        { data: data }\n      );\n      checkDone();\n    });\n  }\n\n  attachments.forEach(function (att) {\n    if (opts.attachments && opts.include_docs) {\n      fetchAttachment(doc, att);\n    } else {\n      doc._attachments[att].stub = true;\n      checkDone();\n    }\n  });\n}\n\nvar POUCH_VERSION = 1;\n\n// these indexes cover the ground for most allDocs queries\nvar BY_SEQ_STORE_DELETED_INDEX_SQL =\n  'CREATE INDEX IF NOT EXISTS \\'by-seq-deleted-idx\\' ON ' +\n  BY_SEQ_STORE$1 + ' (seq, deleted)';\nvar BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL =\n  'CREATE UNIQUE INDEX IF NOT EXISTS \\'by-seq-doc-id-rev\\' ON ' +\n    BY_SEQ_STORE$1 + ' (doc_id, rev)';\nvar DOC_STORE_WINNINGSEQ_INDEX_SQL =\n  'CREATE INDEX IF NOT EXISTS \\'doc-winningseq-idx\\' ON ' +\n  DOC_STORE$1 + ' (winningseq)';\nvar ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL =\n  'CREATE INDEX IF NOT EXISTS \\'attach-seq-seq-idx\\' ON ' +\n    ATTACH_AND_SEQ_STORE$1 + ' (seq)';\nvar ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL =\n  'CREATE UNIQUE INDEX IF NOT EXISTS \\'attach-seq-digest-idx\\' ON ' +\n    ATTACH_AND_SEQ_STORE$1 + ' (digest, seq)';\n\nvar DOC_STORE_AND_BY_SEQ_JOINER = BY_SEQ_STORE$1 +\n  '.seq = ' + DOC_STORE$1 + '.winningseq';\n\nvar SELECT_DOCS = BY_SEQ_STORE$1 + '.seq AS seq, ' +\n  BY_SEQ_STORE$1 + '.deleted AS deleted, ' +\n  BY_SEQ_STORE$1 + '.json AS data, ' +\n  BY_SEQ_STORE$1 + '.rev AS rev, ' +\n  DOC_STORE$1 + '.json AS metadata';\n\nfunction WebSqlPouch(opts, callback) {\n  var api = this;\n  var instanceId = null;\n  var size = getSize(opts);\n  var idRequests = [];\n  var encoding;\n\n  api._name = opts.name;\n\n  // extend the options here, because sqlite plugin has a ton of options\n  // and they are constantly changing, so it's more prudent to allow anything\n  var websqlOpts = $inject_Object_assign({}, opts, {\n    version: POUCH_VERSION,\n    description: opts.name,\n    size: size\n  });\n  var openDBResult = openDB(websqlOpts);\n  if (openDBResult.error) {\n    return websqlError(callback)(openDBResult.error);\n  }\n  var db = openDBResult.db;\n  if (typeof db.readTransaction !== 'function') {\n    // doesn't exist in sqlite plugin\n    db.readTransaction = db.transaction;\n  }\n\n  function dbCreated() {\n    // note the db name in case the browser upgrades to idb\n    if (hasLocalStorage()) {\n      window.localStorage['_pouch__websqldb_' + api._name] = true;\n    }\n    callback(null, api);\n  }\n\n  // In this migration, we added the 'deleted' and 'local' columns to the\n  // by-seq and doc store tables.\n  // To preserve existing user data, we re-process all the existing JSON\n  // and add these values.\n  // Called migration2 because it corresponds to adapter version (db_version) #2\n  function runMigration2(tx, callback) {\n    // index used for the join in the allDocs query\n    tx.executeSql(DOC_STORE_WINNINGSEQ_INDEX_SQL);\n\n    tx.executeSql('ALTER TABLE ' + BY_SEQ_STORE$1 +\n      ' ADD COLUMN deleted TINYINT(1) DEFAULT 0', [], function () {\n      tx.executeSql(BY_SEQ_STORE_DELETED_INDEX_SQL);\n      tx.executeSql('ALTER TABLE ' + DOC_STORE$1 +\n        ' ADD COLUMN local TINYINT(1) DEFAULT 0', [], function () {\n        tx.executeSql('CREATE INDEX IF NOT EXISTS \\'doc-store-local-idx\\' ON ' +\n          DOC_STORE$1 + ' (local, id)');\n\n        var sql = 'SELECT ' + DOC_STORE$1 + '.winningseq AS seq, ' + DOC_STORE$1 +\n          '.json AS metadata FROM ' + BY_SEQ_STORE$1 + ' JOIN ' + DOC_STORE$1 +\n          ' ON ' + BY_SEQ_STORE$1 + '.seq = ' + DOC_STORE$1 + '.winningseq';\n\n        tx.executeSql(sql, [], function (tx, result) {\n\n          var deleted = [];\n          var local = [];\n\n          for (var i = 0; i < result.rows.length; i++) {\n            var item = result.rows.item(i);\n            var seq = item.seq;\n            var metadata = JSON.parse(item.metadata);\n            if (isDeleted(metadata)) {\n              deleted.push(seq);\n            }\n            if (isLocalId(metadata.id)) {\n              local.push(metadata.id);\n            }\n          }\n          tx.executeSql('UPDATE ' + DOC_STORE$1 + 'SET local = 1 WHERE id IN ' +\n            qMarks(local.length), local, function () {\n            tx.executeSql('UPDATE ' + BY_SEQ_STORE$1 +\n              ' SET deleted = 1 WHERE seq IN ' +\n              qMarks(deleted.length), deleted, callback);\n          });\n        });\n      });\n    });\n  }\n\n  // in this migration, we make all the local docs unversioned\n  function runMigration3(tx, callback) {\n    var local = 'CREATE TABLE IF NOT EXISTS ' + LOCAL_STORE$1 +\n      ' (id UNIQUE, rev, json)';\n    tx.executeSql(local, [], function () {\n      var sql = 'SELECT ' + DOC_STORE$1 + '.id AS id, ' +\n        BY_SEQ_STORE$1 + '.json AS data ' +\n        'FROM ' + BY_SEQ_STORE$1 + ' JOIN ' +\n        DOC_STORE$1 + ' ON ' + BY_SEQ_STORE$1 + '.seq = ' +\n        DOC_STORE$1 + '.winningseq WHERE local = 1';\n      tx.executeSql(sql, [], function (tx, res) {\n        var rows = [];\n        for (var i = 0; i < res.rows.length; i++) {\n          rows.push(res.rows.item(i));\n        }\n        function doNext() {\n          if (!rows.length) {\n            return callback(tx);\n          }\n          var row = rows.shift();\n          var rev$$1 = JSON.parse(row.data)._rev;\n          tx.executeSql('INSERT INTO ' + LOCAL_STORE$1 +\n              ' (id, rev, json) VALUES (?,?,?)',\n              [row.id, rev$$1, row.data], function (tx) {\n            tx.executeSql('DELETE FROM ' + DOC_STORE$1 + ' WHERE id=?',\n                [row.id], function (tx) {\n              tx.executeSql('DELETE FROM ' + BY_SEQ_STORE$1 + ' WHERE seq=?',\n                  [row.seq], function () {\n                doNext();\n              });\n            });\n          });\n        }\n        doNext();\n      });\n    });\n  }\n\n  // in this migration, we remove doc_id_rev and just use rev\n  function runMigration4(tx, callback) {\n\n    function updateRows(rows) {\n      function doNext() {\n        if (!rows.length) {\n          return callback(tx);\n        }\n        var row = rows.shift();\n        var doc_id_rev = parseHexString(row.hex, encoding);\n        var idx = doc_id_rev.lastIndexOf('::');\n        var doc_id = doc_id_rev.substring(0, idx);\n        var rev$$1 = doc_id_rev.substring(idx + 2);\n        var sql = 'UPDATE ' + BY_SEQ_STORE$1 +\n          ' SET doc_id=?, rev=? WHERE doc_id_rev=?';\n        tx.executeSql(sql, [doc_id, rev$$1, doc_id_rev], function () {\n          doNext();\n        });\n      }\n      doNext();\n    }\n\n    var sql = 'ALTER TABLE ' + BY_SEQ_STORE$1 + ' ADD COLUMN doc_id';\n    tx.executeSql(sql, [], function (tx) {\n      var sql = 'ALTER TABLE ' + BY_SEQ_STORE$1 + ' ADD COLUMN rev';\n      tx.executeSql(sql, [], function (tx) {\n        tx.executeSql(BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL, [], function (tx) {\n          var sql = 'SELECT hex(doc_id_rev) as hex FROM ' + BY_SEQ_STORE$1;\n          tx.executeSql(sql, [], function (tx, res) {\n            var rows = [];\n            for (var i = 0; i < res.rows.length; i++) {\n              rows.push(res.rows.item(i));\n            }\n            updateRows(rows);\n          });\n        });\n      });\n    });\n  }\n\n  // in this migration, we add the attach_and_seq table\n  // for issue #2818\n  function runMigration5(tx, callback) {\n\n    function migrateAttsAndSeqs(tx) {\n      // need to actually populate the table. this is the expensive part,\n      // so as an optimization, check first that this database even\n      // contains attachments\n      var sql = 'SELECT COUNT(*) AS cnt FROM ' + ATTACH_STORE$1;\n      tx.executeSql(sql, [], function (tx, res) {\n        var count = res.rows.item(0).cnt;\n        if (!count) {\n          return callback(tx);\n        }\n\n        var offset = 0;\n        var pageSize = 10;\n        function nextPage() {\n          var sql = select(\n            SELECT_DOCS + ', ' + DOC_STORE$1 + '.id AS id',\n            [DOC_STORE$1, BY_SEQ_STORE$1],\n            DOC_STORE_AND_BY_SEQ_JOINER,\n            null,\n            DOC_STORE$1 + '.id '\n          );\n          sql += ' LIMIT ' + pageSize + ' OFFSET ' + offset;\n          offset += pageSize;\n          tx.executeSql(sql, [], function (tx, res) {\n            if (!res.rows.length) {\n              return callback(tx);\n            }\n            var digestSeqs = {};\n            function addDigestSeq(digest, seq) {\n              // uniq digest/seq pairs, just in case there are dups\n              var seqs = digestSeqs[digest] = (digestSeqs[digest] || []);\n              if (seqs.indexOf(seq) === -1) {\n                seqs.push(seq);\n              }\n            }\n            for (var i = 0; i < res.rows.length; i++) {\n              var row = res.rows.item(i);\n              var doc = unstringifyDoc(row.data, row.id, row.rev);\n              var atts = Object.keys(doc._attachments || {});\n              for (var j = 0; j < atts.length; j++) {\n                var att = doc._attachments[atts[j]];\n                addDigestSeq(att.digest, row.seq);\n              }\n            }\n            var digestSeqPairs = [];\n            Object.keys(digestSeqs).forEach(function (digest) {\n              var seqs = digestSeqs[digest];\n              seqs.forEach(function (seq) {\n                digestSeqPairs.push([digest, seq]);\n              });\n            });\n            if (!digestSeqPairs.length) {\n              return nextPage();\n            }\n            var numDone = 0;\n            digestSeqPairs.forEach(function (pair) {\n              var sql = 'INSERT INTO ' + ATTACH_AND_SEQ_STORE$1 +\n                ' (digest, seq) VALUES (?,?)';\n              tx.executeSql(sql, pair, function () {\n                if (++numDone === digestSeqPairs.length) {\n                  nextPage();\n                }\n              });\n            });\n          });\n        }\n        nextPage();\n      });\n    }\n\n    var attachAndRev = 'CREATE TABLE IF NOT EXISTS ' +\n      ATTACH_AND_SEQ_STORE$1 + ' (digest, seq INTEGER)';\n    tx.executeSql(attachAndRev, [], function (tx) {\n      tx.executeSql(\n        ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL, [], function (tx) {\n          tx.executeSql(\n            ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL, [],\n            migrateAttsAndSeqs);\n        });\n    });\n  }\n\n  // in this migration, we use escapeBlob() and unescapeBlob()\n  // instead of reading out the binary as HEX, which is slow\n  function runMigration6(tx, callback) {\n    var sql = 'ALTER TABLE ' + ATTACH_STORE$1 +\n      ' ADD COLUMN escaped TINYINT(1) DEFAULT 0';\n    tx.executeSql(sql, [], callback);\n  }\n\n  // issue #3136, in this migration we need a \"latest seq\" as well\n  // as the \"winning seq\" in the doc store\n  function runMigration7(tx, callback) {\n    var sql = 'ALTER TABLE ' + DOC_STORE$1 +\n      ' ADD COLUMN max_seq INTEGER';\n    tx.executeSql(sql, [], function (tx) {\n      var sql = 'UPDATE ' + DOC_STORE$1 + ' SET max_seq=(SELECT MAX(seq) FROM ' +\n        BY_SEQ_STORE$1 + ' WHERE doc_id=id)';\n      tx.executeSql(sql, [], function (tx) {\n        // add unique index after filling, else we'll get a constraint\n        // error when we do the ALTER TABLE\n        var sql =\n          'CREATE UNIQUE INDEX IF NOT EXISTS \\'doc-max-seq-idx\\' ON ' +\n          DOC_STORE$1 + ' (max_seq)';\n        tx.executeSql(sql, [], callback);\n      });\n    });\n  }\n\n  function checkEncoding(tx, cb) {\n    // UTF-8 on chrome/android, UTF-16 on safari < 7.1\n    tx.executeSql('SELECT HEX(\"a\") AS hex', [], function (tx, res) {\n        var hex = res.rows.item(0).hex;\n        encoding = hex.length === 2 ? 'UTF-8' : 'UTF-16';\n        cb();\n      }\n    );\n  }\n\n  function onGetInstanceId() {\n    while (idRequests.length > 0) {\n      var idCallback = idRequests.pop();\n      idCallback(null, instanceId);\n    }\n  }\n\n  function onGetVersion(tx, dbVersion) {\n    if (dbVersion === 0) {\n      // initial schema\n\n      var meta = 'CREATE TABLE IF NOT EXISTS ' + META_STORE$1 +\n        ' (dbid, db_version INTEGER)';\n      var attach = 'CREATE TABLE IF NOT EXISTS ' + ATTACH_STORE$1 +\n        ' (digest UNIQUE, escaped TINYINT(1), body BLOB)';\n      var attachAndRev = 'CREATE TABLE IF NOT EXISTS ' +\n        ATTACH_AND_SEQ_STORE$1 + ' (digest, seq INTEGER)';\n      // TODO: migrate winningseq to INTEGER\n      var doc = 'CREATE TABLE IF NOT EXISTS ' + DOC_STORE$1 +\n        ' (id unique, json, winningseq, max_seq INTEGER UNIQUE)';\n      var seq = 'CREATE TABLE IF NOT EXISTS ' + BY_SEQ_STORE$1 +\n        ' (seq INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, ' +\n        'json, deleted TINYINT(1), doc_id, rev)';\n      var local = 'CREATE TABLE IF NOT EXISTS ' + LOCAL_STORE$1 +\n        ' (id UNIQUE, rev, json)';\n\n      // creates\n      tx.executeSql(attach);\n      tx.executeSql(local);\n      tx.executeSql(attachAndRev, [], function () {\n        tx.executeSql(ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL);\n        tx.executeSql(ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL);\n      });\n      tx.executeSql(doc, [], function () {\n        tx.executeSql(DOC_STORE_WINNINGSEQ_INDEX_SQL);\n        tx.executeSql(seq, [], function () {\n          tx.executeSql(BY_SEQ_STORE_DELETED_INDEX_SQL);\n          tx.executeSql(BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL);\n          tx.executeSql(meta, [], function () {\n            // mark the db version, and new dbid\n            var initSeq = 'INSERT INTO ' + META_STORE$1 +\n              ' (db_version, dbid) VALUES (?,?)';\n            instanceId = uuid();\n            var initSeqArgs = [ADAPTER_VERSION$1, instanceId];\n            tx.executeSql(initSeq, initSeqArgs, function () {\n              onGetInstanceId();\n            });\n          });\n        });\n      });\n    } else { // version > 0\n\n      var setupDone = function () {\n        var migrated = dbVersion < ADAPTER_VERSION$1;\n        if (migrated) {\n          // update the db version within this transaction\n          tx.executeSql('UPDATE ' + META_STORE$1 + ' SET db_version = ' +\n            ADAPTER_VERSION$1);\n        }\n        // notify db.id() callers\n        var sql = 'SELECT dbid FROM ' + META_STORE$1;\n        tx.executeSql(sql, [], function (tx, result) {\n          instanceId = result.rows.item(0).dbid;\n          onGetInstanceId();\n        });\n      };\n\n      // would love to use promises here, but then websql\n      // ends the transaction early\n      var tasks = [\n        runMigration2,\n        runMigration3,\n        runMigration4,\n        runMigration5,\n        runMigration6,\n        runMigration7,\n        setupDone\n      ];\n\n      // run each migration sequentially\n      var i = dbVersion;\n      var nextMigration = function (tx) {\n        tasks[i - 1](tx, nextMigration);\n        i++;\n      };\n      nextMigration(tx);\n    }\n  }\n\n  function setup() {\n    db.transaction(function (tx) {\n      // first check the encoding\n      checkEncoding(tx, function () {\n        // then get the version\n        fetchVersion(tx);\n      });\n    }, websqlError(callback), dbCreated);\n  }\n\n  function fetchVersion(tx) {\n    var sql = 'SELECT sql FROM sqlite_master WHERE tbl_name = ' + META_STORE$1;\n    tx.executeSql(sql, [], function (tx, result) {\n      if (!result.rows.length) {\n        // database hasn't even been created yet (version 0)\n        onGetVersion(tx, 0);\n      } else if (!/db_version/.test(result.rows.item(0).sql)) {\n        // table was created, but without the new db_version column,\n        // so add it.\n        tx.executeSql('ALTER TABLE ' + META_STORE$1 +\n          ' ADD COLUMN db_version INTEGER', [], function () {\n          // before version 2, this column didn't even exist\n          onGetVersion(tx, 1);\n        });\n      } else { // column exists, we can safely get it\n        tx.executeSql('SELECT db_version FROM ' + META_STORE$1,\n          [], function (tx, result) {\n          var dbVersion = result.rows.item(0).db_version;\n          onGetVersion(tx, dbVersion);\n        });\n      }\n    });\n  }\n\n  setup();\n\n  function getMaxSeq(tx, callback) {\n    var sql = 'SELECT MAX(seq) AS seq FROM ' + BY_SEQ_STORE$1;\n    tx.executeSql(sql, [], function (tx, res) {\n      var updateSeq = res.rows.item(0).seq || 0;\n      callback(updateSeq);\n    });\n  }\n\n  function countDocs(tx, callback) {\n    // count the total rows\n    var sql = select(\n      'COUNT(' + DOC_STORE$1 + '.id) AS \\'num\\'',\n      [DOC_STORE$1, BY_SEQ_STORE$1],\n      DOC_STORE_AND_BY_SEQ_JOINER,\n      BY_SEQ_STORE$1 + '.deleted=0');\n\n    tx.executeSql(sql, [], function (tx, result) {\n      callback(result.rows.item(0).num);\n    });\n  }\n\n  api._remote = false;\n  api.type = function () {\n    return 'websql';\n  };\n\n  api._id = toPromise(function (callback) {\n    callback(null, instanceId);\n  });\n\n  api._info = function (callback) {\n    var seq;\n    var docCount;\n    db.readTransaction(function (tx) {\n      getMaxSeq(tx, function (theSeq) {\n        seq = theSeq;\n      });\n      countDocs(tx, function (theDocCount) {\n        docCount = theDocCount;\n      });\n    }, websqlError(callback), function () {\n      callback(null, {\n        doc_count: docCount,\n        update_seq: seq,\n        websql_encoding: encoding\n      });\n    });\n  };\n\n  api._bulkDocs = function (req, reqOpts, callback) {\n    websqlBulkDocs(opts, req, reqOpts, api, db, websqlChanges, callback);\n  };\n\n  function latest$$1(tx, id, rev$$1, callback, finish) {\n    var sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE_AND_BY_SEQ_JOINER,\n        DOC_STORE$1 + '.id=?');\n    var sqlArgs = [id];\n\n    tx.executeSql(sql, sqlArgs, function (a, results) {\n      if (!results.rows.length) {\n        var err = createError(MISSING_DOC, 'missing');\n        return finish(err);\n      }\n      var item = results.rows.item(0);\n      var metadata = safeJsonParse(item.metadata);\n      callback(latest(rev$$1, metadata));\n    });\n  }\n\n  api._get = function (id, opts, callback) {\n    var doc;\n    var metadata;\n    var tx = opts.ctx;\n    if (!tx) {\n      return db.readTransaction(function (txn) {\n        api._get(id, $inject_Object_assign({ctx: txn}, opts), callback);\n      });\n    }\n\n    function finish(err) {\n      callback(err, {doc: doc, metadata: metadata, ctx: tx});\n    }\n\n    var sql;\n    var sqlArgs;\n\n    if (!opts.rev) {\n      sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE_AND_BY_SEQ_JOINER,\n        DOC_STORE$1 + '.id=?');\n      sqlArgs = [id];\n    } else if (opts.latest) {\n      latest$$1(tx, id, opts.rev, function (latestRev) {\n        opts.latest = false;\n        opts.rev = latestRev;\n        api._get(id, opts, callback);\n      }, finish);\n      return;\n    } else {\n      sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE$1 + '.id=' + BY_SEQ_STORE$1 + '.doc_id',\n        [BY_SEQ_STORE$1 + '.doc_id=?', BY_SEQ_STORE$1 + '.rev=?']);\n      sqlArgs = [id, opts.rev];\n    }\n\n    tx.executeSql(sql, sqlArgs, function (a, results) {\n      if (!results.rows.length) {\n        var missingErr = createError(MISSING_DOC, 'missing');\n        return finish(missingErr);\n      }\n      var item = results.rows.item(0);\n      metadata = safeJsonParse(item.metadata);\n      if (item.deleted && !opts.rev) {\n        var deletedErr = createError(MISSING_DOC, 'deleted');\n        return finish(deletedErr);\n      }\n      doc = unstringifyDoc(item.data, metadata.id, item.rev);\n      finish();\n    });\n  };\n\n  api._allDocs = function (opts, callback) {\n    var results = [];\n    var totalRows;\n    var updateSeq;\n\n    var start = 'startkey' in opts ? opts.startkey : false;\n    var end = 'endkey' in opts ? opts.endkey : false;\n    var key = 'key' in opts ? opts.key : false;\n    var keys = 'keys' in opts ? opts.keys : false;\n    var descending = 'descending' in opts ? opts.descending : false;\n    var limit = 'limit' in opts ? opts.limit : -1;\n    var offset = 'skip' in opts ? opts.skip : 0;\n    var inclusiveEnd = opts.inclusive_end !== false;\n    \n    var sqlArgs = [];\n    var criteria = [];\n\n    if (keys) {\n      var destinctKeys = [];\n      var bindingStr = \"\";\n      keys.forEach(function (key) {\n        if (destinctKeys.indexOf(key) === -1) {\n          destinctKeys.push(key);\n          bindingStr += '?,';\n        }\n      });\n      bindingStr = bindingStr.substring(0, bindingStr.length - 1); // keys is never empty\n      criteria.push(DOC_STORE$1 + '.id IN (' + bindingStr + ')');\n      sqlArgs = sqlArgs.concat(destinctKeys);\n    } else if (key !== false) {\n      criteria.push(DOC_STORE$1 + '.id = ?');\n      sqlArgs.push(key);\n    } else if (start !== false || end !== false) {\n      if (start !== false) {\n        criteria.push(DOC_STORE$1 + '.id ' + (descending ? '<=' : '>=') + ' ?');\n        sqlArgs.push(start);\n      }\n      if (end !== false) {\n        var comparator = descending ? '>' : '<';\n        if (inclusiveEnd) {\n          comparator += '=';\n        }\n        criteria.push(DOC_STORE$1 + '.id ' + comparator + ' ?');\n        sqlArgs.push(end);\n      }\n      if (key !== false) {\n        criteria.push(DOC_STORE$1 + '.id = ?');\n        sqlArgs.push(key);\n      }\n    }\n\n    if (!keys) {\n      // report deleted if keys are specified\n      criteria.push(BY_SEQ_STORE$1 + '.deleted = 0');\n    }\n\n    db.readTransaction(function (tx) {\n      // count the docs in parallel to other operations\n      countDocs(tx, function (docCount) {\n        totalRows = docCount;\n      });\n\n      /* istanbul ignore if */\n      if (opts.update_seq) {\n        // get max sequence in parallel to other operations\n        getMaxSeq(tx, function (theSeq) {\n          updateSeq = theSeq;\n        });\n      }\n\n      if (limit === 0) {\n        return;\n      }\n\n      // do a single query to fetch the documents\n      var sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE_AND_BY_SEQ_JOINER,\n        criteria,\n        DOC_STORE$1 + '.id ' + (descending ? 'DESC' : 'ASC')\n        );\n      sql += ' LIMIT ' + limit + ' OFFSET ' + offset;\n\n      tx.executeSql(sql, sqlArgs, function (tx, result) {\n        for (var i = 0, l = result.rows.length; i < l; i++) {\n          var item = result.rows.item(i);\n          var metadata = safeJsonParse(item.metadata);\n          var id = metadata.id;\n          var data = unstringifyDoc(item.data, id, item.rev);\n          var winningRev$$1 = data._rev;\n          var doc = {\n            id: id,\n            key: id,\n            value: {rev: winningRev$$1}\n          };\n          if (opts.include_docs) {\n            doc.doc = data;\n            doc.doc._rev = winningRev$$1;\n            if (opts.conflicts) {\n              var conflicts = collectConflicts(metadata);\n              if (conflicts.length) {\n                doc.doc._conflicts = conflicts;\n              }\n            }\n            fetchAttachmentsIfNecessary$1(doc.doc, opts, api, tx);\n          }\n          if (item.deleted) {\n            if (keys) {\n              doc.value.deleted = true;\n              doc.doc = null;\n            } else {\n              // propably should not happen\n              continue;\n            }\n          }\n          if (!keys) {\n            results.push(doc);\n          } else {\n            var index = keys.indexOf(id, index);\n            do {\n              results[index] = doc;\n              index = keys.indexOf(id, index + 1);\n            } while (index > -1 && index < keys.length);\n          }\n        }\n        if (keys) {\n          keys.forEach(function (key, index) {\n            if (!results[index]) {\n              results[index] = {key: key, error: 'not_found'};\n            }\n          });\n        }\n      });\n    }, websqlError(callback), function () {\n      var returnVal = {\n        total_rows: totalRows,\n        offset: opts.skip,\n        rows: results\n      };\n\n      /* istanbul ignore if */\n      if (opts.update_seq) {\n        returnVal.update_seq = updateSeq;\n      }\n      callback(null, returnVal);\n    });\n  };\n\n  api._changes = function (opts) {\n    opts = clone(opts);\n\n    if (opts.continuous) {\n      var id = api._name + ':' + uuid();\n      websqlChanges.addListener(api._name, id, api, opts);\n      websqlChanges.notify(api._name);\n      return {\n        cancel: function () {\n          websqlChanges.removeListener(api._name, id);\n        }\n      };\n    }\n\n    var descending = opts.descending;\n\n    // Ignore the `since` parameter when `descending` is true\n    opts.since = opts.since && !descending ? opts.since : 0;\n\n    var limit = 'limit' in opts ? opts.limit : -1;\n    if (limit === 0) {\n      limit = 1; // per CouchDB _changes spec\n    }\n\n    var returnDocs;\n    if ('return_docs' in opts) {\n      returnDocs = opts.return_docs;\n    } else if ('returnDocs' in opts) {\n      // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n      returnDocs = opts.returnDocs;\n    } else {\n      returnDocs = true;\n    }\n    var results = [];\n    var numResults = 0;\n\n    function fetchChanges() {\n\n      var selectStmt =\n        DOC_STORE$1 + '.json AS metadata, ' +\n        DOC_STORE$1 + '.max_seq AS maxSeq, ' +\n        BY_SEQ_STORE$1 + '.json AS winningDoc, ' +\n        BY_SEQ_STORE$1 + '.rev AS winningRev ';\n\n      var from = DOC_STORE$1 + ' JOIN ' + BY_SEQ_STORE$1;\n\n      var joiner = DOC_STORE$1 + '.id=' + BY_SEQ_STORE$1 + '.doc_id' +\n        ' AND ' + DOC_STORE$1 + '.winningseq=' + BY_SEQ_STORE$1 + '.seq';\n\n      var criteria = ['maxSeq > ?'];\n      var sqlArgs = [opts.since];\n\n      if (opts.doc_ids) {\n        criteria.push(DOC_STORE$1 + '.id IN ' + qMarks(opts.doc_ids.length));\n        sqlArgs = sqlArgs.concat(opts.doc_ids);\n      }\n\n      var orderBy = 'maxSeq ' + (descending ? 'DESC' : 'ASC');\n\n      var sql = select(selectStmt, from, joiner, criteria, orderBy);\n\n      var filter = filterChange(opts);\n      if (!opts.view && !opts.filter) {\n        // we can just limit in the query\n        sql += ' LIMIT ' + limit;\n      }\n\n      var lastSeq = opts.since || 0;\n      db.readTransaction(function (tx) {\n        tx.executeSql(sql, sqlArgs, function (tx, result) {\n          function reportChange(change) {\n            return function () {\n              opts.onChange(change);\n            };\n          }\n          for (var i = 0, l = result.rows.length; i < l; i++) {\n            var item = result.rows.item(i);\n            var metadata = safeJsonParse(item.metadata);\n            lastSeq = item.maxSeq;\n\n            var doc = unstringifyDoc(item.winningDoc, metadata.id,\n              item.winningRev);\n            var change = opts.processChange(doc, metadata, opts);\n            change.seq = item.maxSeq;\n\n            var filtered = filter(change);\n            if (typeof filtered === 'object') {\n              return opts.complete(filtered);\n            }\n\n            if (filtered) {\n              numResults++;\n              if (returnDocs) {\n                results.push(change);\n              }\n              // process the attachment immediately\n              // for the benefit of live listeners\n              if (opts.attachments && opts.include_docs) {\n                fetchAttachmentsIfNecessary$1(doc, opts, api, tx,\n                  reportChange(change));\n              } else {\n                reportChange(change)();\n              }\n            }\n            if (numResults === limit) {\n              break;\n            }\n          }\n        });\n      }, websqlError(opts.complete), function () {\n        if (!opts.continuous) {\n          opts.complete(null, {\n            results: results,\n            last_seq: lastSeq\n          });\n        }\n      });\n    }\n\n    fetchChanges();\n  };\n\n  api._close = function (callback) {\n    //WebSQL databases do not need to be closed\n    callback();\n  };\n\n  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n    var res;\n    var tx = opts.ctx;\n    var digest = attachment.digest;\n    var type = attachment.content_type;\n    var sql = 'SELECT escaped, ' +\n      'CASE WHEN escaped = 1 THEN body ELSE HEX(body) END AS body FROM ' +\n      ATTACH_STORE$1 + ' WHERE digest=?';\n    tx.executeSql(sql, [digest], function (tx, result) {\n      // websql has a bug where \\u0000 causes early truncation in strings\n      // and blobs. to work around this, we used to use the hex() function,\n      // but that's not performant. after migration 6, we remove \\u0000\n      // and add it back in afterwards\n      var item = result.rows.item(0);\n      var data = item.escaped ? unescapeBlob(item.body) :\n        parseHexString(item.body, encoding);\n      if (opts.binary) {\n        res = binStringToBluffer(data, type);\n      } else {\n        res = thisBtoa(data);\n      }\n      callback(null, res);\n    });\n  };\n\n  api._getRevisionTree = function (docId, callback) {\n    db.readTransaction(function (tx) {\n      var sql = 'SELECT json AS metadata FROM ' + DOC_STORE$1 + ' WHERE id = ?';\n      tx.executeSql(sql, [docId], function (tx, result) {\n        if (!result.rows.length) {\n          callback(createError(MISSING_DOC));\n        } else {\n          var data = safeJsonParse(result.rows.item(0).metadata);\n          callback(null, data.rev_tree);\n        }\n      });\n    });\n  };\n\n  api._doCompaction = function (docId, revs, callback) {\n    if (!revs.length) {\n      return callback();\n    }\n    db.transaction(function (tx) {\n\n      // update doc store\n      var sql = 'SELECT json AS metadata FROM ' + DOC_STORE$1 + ' WHERE id = ?';\n      tx.executeSql(sql, [docId], function (tx, result) {\n        var metadata = safeJsonParse(result.rows.item(0).metadata);\n        traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                                           revHash, ctx, opts) {\n          var rev$$1 = pos + '-' + revHash;\n          if (revs.indexOf(rev$$1) !== -1) {\n            opts.status = 'missing';\n          }\n        });\n\n        var sql = 'UPDATE ' + DOC_STORE$1 + ' SET json = ? WHERE id = ?';\n        tx.executeSql(sql, [safeJsonStringify(metadata), docId]);\n      });\n\n      compactRevs$1(revs, docId, tx);\n    }, websqlError(callback), function () {\n      callback();\n    });\n  };\n\n  api._getLocal = function (id, callback) {\n    db.readTransaction(function (tx) {\n      var sql = 'SELECT json, rev FROM ' + LOCAL_STORE$1 + ' WHERE id=?';\n      tx.executeSql(sql, [id], function (tx, res) {\n        if (res.rows.length) {\n          var item = res.rows.item(0);\n          var doc = unstringifyDoc(item.json, id, item.rev);\n          callback(null, doc);\n        } else {\n          callback(createError(MISSING_DOC));\n        }\n      });\n    });\n  };\n\n  api._putLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    delete doc._revisions; // ignore this, trust the rev\n    var oldRev = doc._rev;\n    var id = doc._id;\n    var newRev;\n    if (!oldRev) {\n      newRev = doc._rev = '0-1';\n    } else {\n      newRev = doc._rev = '0-' + (parseInt(oldRev.split('-')[1], 10) + 1);\n    }\n    var json = stringifyDoc(doc);\n\n    var ret;\n    function putLocal(tx) {\n      var sql;\n      var values;\n      if (oldRev) {\n        sql = 'UPDATE ' + LOCAL_STORE$1 + ' SET rev=?, json=? ' +\n          'WHERE id=? AND rev=?';\n        values = [newRev, json, id, oldRev];\n      } else {\n        sql = 'INSERT INTO ' + LOCAL_STORE$1 + ' (id, rev, json) VALUES (?,?,?)';\n        values = [id, newRev, json];\n      }\n      tx.executeSql(sql, values, function (tx, res) {\n        if (res.rowsAffected) {\n          ret = {ok: true, id: id, rev: newRev};\n          if (opts.ctx) { // return immediately\n            callback(null, ret);\n          }\n        } else {\n          callback(createError(REV_CONFLICT));\n        }\n      }, function () {\n        callback(createError(REV_CONFLICT));\n        return false; // ack that we handled the error\n      });\n    }\n\n    if (opts.ctx) {\n      putLocal(opts.ctx);\n    } else {\n      db.transaction(putLocal, websqlError(callback), function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      });\n    }\n  };\n\n  api._removeLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var ret;\n\n    function removeLocal(tx) {\n      var sql = 'DELETE FROM ' + LOCAL_STORE$1 + ' WHERE id=? AND rev=?';\n      var params = [doc._id, doc._rev];\n      tx.executeSql(sql, params, function (tx, res) {\n        if (!res.rowsAffected) {\n          return callback(createError(MISSING_DOC));\n        }\n        ret = {ok: true, id: doc._id, rev: '0-0'};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      });\n    }\n\n    if (opts.ctx) {\n      removeLocal(opts.ctx);\n    } else {\n      db.transaction(removeLocal, websqlError(callback), function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      });\n    }\n  };\n\n  api._destroy = function (opts, callback) {\n    websqlChanges.removeAllListeners(api._name);\n    db.transaction(function (tx) {\n      var stores = [DOC_STORE$1, BY_SEQ_STORE$1, ATTACH_STORE$1, META_STORE$1,\n        LOCAL_STORE$1, ATTACH_AND_SEQ_STORE$1];\n      stores.forEach(function (store) {\n        tx.executeSql('DROP TABLE IF EXISTS ' + store, []);\n      });\n    }, websqlError(callback), function () {\n      if (hasLocalStorage()) {\n        delete window.localStorage['_pouch__websqldb_' + api._name];\n        delete window.localStorage[api._name];\n      }\n      callback(null, {'ok': true});\n    });\n  };\n}\n\nfunction canOpenTestDB() {\n  try {\n    openDatabase('_pouch_validate_websql', 1, '', 1);\n    return true;\n  } catch (err) {\n    return false;\n  }\n}\n\n// WKWebView had a bug where WebSQL would throw a DOM Exception 18\n// (see https://bugs.webkit.org/show_bug.cgi?id=137760 and\n// https://github.com/pouchdb/pouchdb/issues/5079)\n// This has been fixed in latest WebKit, so we try to detect it here.\nfunction isValidWebSQL() {\n  // WKWebView UA:\n  //   Mozilla/5.0 (iPhone; CPU iPhone OS 9_2 like Mac OS X)\n  //   AppleWebKit/601.1.46 (KHTML, like Gecko) Mobile/13C75\n  // Chrome for iOS UA:\n  //   Mozilla/5.0 (iPhone; U; CPU iPhone OS 5_1_1 like Mac OS X; en)\n  //   AppleWebKit/534.46.0 (KHTML, like Gecko) CriOS/19.0.1084.60\n  //   Mobile/9B206 Safari/7534.48.3\n  // Firefox for iOS UA:\n  //   Mozilla/5.0 (iPhone; CPU iPhone OS 8_3 like Mac OS X) AppleWebKit/600.1.4\n  //   (KHTML, like Gecko) FxiOS/1.0 Mobile/12F69 Safari/600.1.4\n\n  // indexedDB is null on some UIWebViews and undefined in others\n  // see: https://bugs.webkit.org/show_bug.cgi?id=137034\n  if (typeof indexedDB === 'undefined' || indexedDB === null ||\n      !/iP(hone|od|ad)/.test(navigator.userAgent)) {\n    // definitely not WKWebView, avoid creating an unnecessary database\n    return true;\n  }\n  // Cache the result in LocalStorage. Reason we do this is because if we\n  // call openDatabase() too many times, Safari craps out in SauceLabs and\n  // starts throwing DOM Exception 14s.\n  var hasLS = hasLocalStorage();\n  // Include user agent in the hash, so that if Safari is upgraded, we don't\n  // continually think it's broken.\n  var localStorageKey = '_pouch__websqldb_valid_' + navigator.userAgent;\n  if (hasLS && localStorage[localStorageKey]) {\n    return localStorage[localStorageKey] === '1';\n  }\n  var openedTestDB = canOpenTestDB();\n  if (hasLS) {\n    localStorage[localStorageKey] = openedTestDB ? '1' : '0';\n  }\n  return openedTestDB;\n}\n\nfunction valid() {\n  if (typeof openDatabase !== 'function') {\n    return false;\n  }\n  return isValidWebSQL();\n}\n\nfunction openDB$2(name, version, description, size) {\n  // Traditional WebSQL API\n  return openDatabase(name, version, description, size);\n}\n\nfunction WebSQLPouch(opts, callback) {\n  var msg = 'WebSQL is deprecated and will be removed in future releases of PouchDB. ' +\n      'Please migrate to IndexedDB: https://pouchdb.com/2018/01/23/pouchdb-6.4.2.html';\n  guardedConsole('warn', msg);\n  var _opts = $inject_Object_assign({\n    websql: openDB$2\n  }, opts);\n\n  WebSqlPouch.call(this, _opts, callback);\n}\n\nWebSQLPouch.valid = valid;\n\nWebSQLPouch.use_prefix = true;\n\nfunction WebSqlPouch$1 (PouchDB) {\n  PouchDB.adapter('websql', WebSQLPouch, true);\n}\n\n/* global fetch */\n/* global Headers */\nfunction wrappedFetch() {\n  var wrappedPromise = {};\n\n  var promise = new PouchPromise(function (resolve, reject) {\n    wrappedPromise.resolve = resolve;\n    wrappedPromise.reject = reject;\n  });\n\n  var args = new Array(arguments.length);\n\n  for (var i = 0; i < args.length; i++) {\n    args[i] = arguments[i];\n  }\n\n  wrappedPromise.promise = promise;\n\n  PouchPromise.resolve().then(function () {\n    return fetch.apply(null, args);\n  }).then(function (response) {\n    wrappedPromise.resolve(response);\n  }).catch(function (error) {\n    wrappedPromise.reject(error);\n  });\n\n  return wrappedPromise;\n}\n\nfunction fetchRequest(options, callback) {\n  var wrappedPromise, timer, response;\n\n  var headers = new Headers();\n\n  var fetchOptions = {\n    method: options.method,\n    credentials: 'include',\n    headers: headers\n  };\n\n  if (options.json) {\n    headers.set('Accept', 'application/json');\n    headers.set('Content-Type', options.headers['Content-Type'] ||\n      'application/json');\n  }\n\n  if (options.body &&\n      options.processData &&\n      typeof options.body !== 'string') {\n    fetchOptions.body = JSON.stringify(options.body);\n  } else if ('body' in options) {\n    fetchOptions.body = options.body;\n  } else {\n    fetchOptions.body = null;\n  }\n\n  Object.keys(options.headers).forEach(function (key) {\n    if (options.headers.hasOwnProperty(key)) {\n      headers.set(key, options.headers[key]);\n    }\n  });\n\n  wrappedPromise = wrappedFetch(options.url, fetchOptions);\n\n  if (options.timeout > 0) {\n    timer = setTimeout(function () {\n      wrappedPromise.reject(new Error('Load timeout for resource: ' +\n        options.url));\n    }, options.timeout);\n  }\n\n  wrappedPromise.promise.then(function (fetchResponse) {\n    response = {\n      statusCode: fetchResponse.status\n    };\n\n    if (options.timeout > 0) {\n      clearTimeout(timer);\n    }\n\n    if (response.statusCode >= 200 && response.statusCode < 300) {\n      return options.binary ? fetchResponse.blob() : fetchResponse.text();\n    }\n\n    return fetchResponse.json();\n  }).then(function (result) {\n    if (response.statusCode >= 200 && response.statusCode < 300) {\n      callback(null, response, result);\n    } else {\n      result.status = response.statusCode;\n      callback(result);\n    }\n  }).catch(function (error) {\n    if (!error) {\n      // this happens when the listener is canceled\n      error = new Error('canceled');\n    }\n    callback(error);\n  });\n\n  return {abort: wrappedPromise.reject};\n}\n\nfunction xhRequest(options, callback) {\n\n  var xhr, timer;\n  var timedout = false;\n\n  var abortReq = function () {\n    xhr.abort();\n    cleanUp();\n  };\n\n  var timeoutReq = function () {\n    timedout = true;\n    xhr.abort();\n    cleanUp();\n  };\n\n  var ret = {abort: abortReq};\n\n  var cleanUp = function () {\n    clearTimeout(timer);\n    ret.abort = function () {};\n    if (xhr) {\n      xhr.onprogress = undefined;\n      if (xhr.upload) {\n        xhr.upload.onprogress = undefined;\n      }\n      xhr.onreadystatechange = undefined;\n      xhr = undefined;\n    }\n  };\n\n  if (options.xhr) {\n    xhr = new options.xhr();\n  } else {\n    xhr = new XMLHttpRequest();\n  }\n\n  try {\n    xhr.open(options.method, options.url);\n  } catch (exception) {\n    return callback(new Error(exception.name || 'Url is invalid'));\n  }\n\n  xhr.withCredentials = ('withCredentials' in options) ?\n    options.withCredentials : true;\n\n  if (options.method === 'GET') {\n    delete options.headers['Content-Type'];\n  } else if (options.json) {\n    options.headers.Accept = 'application/json';\n    options.headers['Content-Type'] = options.headers['Content-Type'] ||\n      'application/json';\n    if (options.body &&\n        options.processData &&\n        typeof options.body !== \"string\") {\n      options.body = JSON.stringify(options.body);\n    }\n  }\n\n  if (options.binary) {\n    xhr.responseType = 'arraybuffer';\n  }\n\n  if (!('body' in options)) {\n    options.body = null;\n  }\n\n  for (var key in options.headers) {\n    if (options.headers.hasOwnProperty(key)) {\n      xhr.setRequestHeader(key, options.headers[key]);\n    }\n  }\n\n  if (options.timeout > 0) {\n    timer = setTimeout(timeoutReq, options.timeout);\n    xhr.onprogress = function () {\n      clearTimeout(timer);\n      if (xhr.readyState !== 4) {\n        timer = setTimeout(timeoutReq, options.timeout);\n      }\n    };\n    if (typeof xhr.upload !== 'undefined') { // does not exist in ie9\n      xhr.upload.onprogress = xhr.onprogress;\n    }\n  }\n\n  xhr.onreadystatechange = function () {\n    if (xhr.readyState !== 4) {\n      return;\n    }\n\n    var response = {\n      statusCode: xhr.status\n    };\n\n    if (xhr.status >= 200 && xhr.status < 300) {\n      var data;\n      if (options.binary) {\n        data = createBlob([xhr.response || ''], {\n          type: xhr.getResponseHeader('Content-Type')\n        });\n      } else {\n        data = xhr.responseText;\n      }\n      callback(null, response, data);\n    } else {\n      var err = {};\n      if (timedout) {\n        err = new Error('ETIMEDOUT');\n        err.code = 'ETIMEDOUT';\n      } else if (typeof xhr.response === 'string' && xhr.response !== '') {\n        try {\n          err = JSON.parse(xhr.response);\n        } catch (e) {}\n      }\n\n      err.status = xhr.status;\n\n      callback(err);\n    }\n    cleanUp();\n  };\n\n  if (options.body && (options.body instanceof Blob)) {\n    readAsArrayBuffer(options.body, function (arrayBuffer) {\n      xhr.send(arrayBuffer);\n    });\n  } else {\n    xhr.send(options.body);\n  }\n\n  return ret;\n}\n\nfunction testXhr() {\n  try {\n    new XMLHttpRequest();\n    return true;\n  } catch (err) {\n    return false;\n  }\n}\n\nvar hasXhr = testXhr();\n\nfunction ajax(options, callback) {\n  if (!false && (hasXhr || options.xhr)) {\n    return xhRequest(options, callback);\n  } else {\n    return fetchRequest(options, callback);\n  }\n}\n\n// the blob already has a type; do nothing\n\nfunction defaultBody() {\n  return '';\n}\n\nfunction ajaxCore(options, callback) {\n\n  options = clone(options);\n\n  var defaultOptions = {\n    method : \"GET\",\n    headers: {},\n    json: true,\n    processData: true,\n    timeout: 10000,\n    cache: false\n  };\n\n  options = $inject_Object_assign(defaultOptions, options);\n\n  function onSuccess(obj, resp, cb) {\n    if (!options.binary && options.json && typeof obj === 'string') {\n      /* istanbul ignore next */\n      try {\n        obj = JSON.parse(obj);\n      } catch (e) {\n        // Probably a malformed JSON from server\n        return cb(e);\n      }\n    }\n    if (Array.isArray(obj)) {\n      obj = obj.map(function (v) {\n        if (v.error || v.missing) {\n          return generateErrorFromResponse(v);\n        } else {\n          return v;\n        }\n      });\n    }\n    if (options.binary) {\n      \n    }\n    cb(null, obj, resp);\n  }\n\n  if (options.json) {\n    if (!options.binary) {\n      options.headers.Accept = 'application/json';\n    }\n    options.headers['Content-Type'] = options.headers['Content-Type'] ||\n      'application/json';\n  }\n\n  if (options.binary) {\n    options.encoding = null;\n    options.json = false;\n  }\n\n  if (!options.processData) {\n    options.json = false;\n  }\n\n  return ajax(options, function (err, response, body) {\n\n    if (err) {\n      return callback(generateErrorFromResponse(err));\n    }\n\n    var error;\n    var content_type = response.headers && response.headers['content-type'];\n    var data = body || defaultBody();\n\n    // CouchDB doesn't always return the right content-type for JSON data, so\n    // we check for ^{ and }$ (ignoring leading/trailing whitespace)\n    if (!options.binary && (options.json || !options.processData) &&\n        typeof data !== 'object' &&\n        (/json/.test(content_type) ||\n         (/^[\\s]*\\{/.test(data) && /\\}[\\s]*$/.test(data)))) {\n      try {\n        data = JSON.parse(data.toString());\n      } catch (e) {}\n    }\n\n    if (response.statusCode >= 200 && response.statusCode < 300) {\n      onSuccess(data, response, callback);\n    } else {\n      error = generateErrorFromResponse(data);\n      error.status = response.statusCode;\n      callback(error);\n    }\n  });\n}\n\nfunction ajax$1(opts, callback) {\n\n  // cache-buster, specifically designed to work around IE's aggressive caching\n  // see http://www.dashbay.com/2011/05/internet-explorer-caches-ajax/\n  // Also Safari caches POSTs, so we need to cache-bust those too.\n  var ua = (navigator && navigator.userAgent) ?\n    navigator.userAgent.toLowerCase() : '';\n\n  var isSafari = ua.indexOf('safari') !== -1 && ua.indexOf('chrome') === -1;\n  var isIE = ua.indexOf('msie') !== -1;\n  var isTrident = ua.indexOf('trident') !== -1;\n  var isEdge = ua.indexOf('edge') !== -1;\n\n  // it appears the new version of safari also caches GETs,\n  // see https://github.com/pouchdb/pouchdb/issues/5010\n  var shouldCacheBust = (isSafari ||\n    ((isIE || isTrident || isEdge) && opts.method === 'GET'));\n\n  var cache = 'cache' in opts ? opts.cache : true;\n\n  var isBlobUrl = /^blob:/.test(opts.url); // don't append nonces for blob URLs\n\n  if (!isBlobUrl && (shouldCacheBust || !cache)) {\n    var hasArgs = opts.url.indexOf('?') !== -1;\n    opts.url += (hasArgs ? '&' : '?') + '_nonce=' + Date.now();\n  }\n\n  return ajaxCore(opts, callback);\n}\n\n// dead simple promise pool, inspired by https://github.com/timdp/es6-promise-pool\n// but much smaller in code size. limits the number of concurrent promises that are executed\n\n\nfunction pool(promiseFactories, limit) {\n  return new PouchPromise(function (resolve, reject) {\n    var running = 0;\n    var current = 0;\n    var done = 0;\n    var len = promiseFactories.length;\n    var err;\n\n    function runNext() {\n      running++;\n      promiseFactories[current++]().then(onSuccess, onError);\n    }\n\n    function doNext() {\n      if (++done === len) {\n        /* istanbul ignore if */\n        if (err) {\n          reject(err);\n        } else {\n          resolve();\n        }\n      } else {\n        runNextBatch();\n      }\n    }\n\n    function onSuccess() {\n      running--;\n      doNext();\n    }\n\n    /* istanbul ignore next */\n    function onError(thisErr) {\n      running--;\n      err = err || thisErr;\n      doNext();\n    }\n\n    function runNextBatch() {\n      while (running < limit && current < len) {\n        runNext();\n      }\n    }\n\n    runNextBatch();\n  });\n}\n\nvar CHANGES_BATCH_SIZE = 25;\nvar MAX_SIMULTANEOUS_REVS = 50;\nvar CHANGES_TIMEOUT_BUFFER = 5000;\nvar DEFAULT_HEARTBEAT = 10000;\n\nvar supportsBulkGetMap = {};\n\nfunction readAttachmentsAsBlobOrBuffer(row) {\n  var doc = row.doc || row.ok;\n  var atts = doc._attachments;\n  if (!atts) {\n    return;\n  }\n  Object.keys(atts).forEach(function (filename) {\n    var att = atts[filename];\n    att.data = b64ToBluffer(att.data, att.content_type);\n  });\n}\n\nfunction encodeDocId(id) {\n  if (/^_design/.test(id)) {\n    return '_design/' + encodeURIComponent(id.slice(8));\n  }\n  if (/^_local/.test(id)) {\n    return '_local/' + encodeURIComponent(id.slice(7));\n  }\n  return encodeURIComponent(id);\n}\n\nfunction preprocessAttachments$2(doc) {\n  if (!doc._attachments || !Object.keys(doc._attachments)) {\n    return PouchPromise.resolve();\n  }\n\n  return PouchPromise.all(Object.keys(doc._attachments).map(function (key) {\n    var attachment = doc._attachments[key];\n    if (attachment.data && typeof attachment.data !== 'string') {\n      return new PouchPromise(function (resolve) {\n        blobToBase64(attachment.data, resolve);\n      }).then(function (b64) {\n        attachment.data = b64;\n      });\n    }\n  }));\n}\n\nfunction hasUrlPrefix(opts) {\n  if (!opts.prefix) {\n    return false;\n  }\n\n  var protocol = parseUri(opts.prefix).protocol;\n\n  return protocol === 'http' || protocol === 'https';\n}\n\n// Get all the information you possibly can about the URI given by name and\n// return it as a suitable object.\nfunction getHost(name, opts) {\n\n  // encode db name if opts.prefix is a url (#5574)\n  if (hasUrlPrefix(opts)) {\n    var dbName = opts.name.substr(opts.prefix.length);\n    name = opts.prefix + encodeURIComponent(dbName);\n  }\n\n  // Prase the URI into all its little bits\n  var uri = parseUri(name);\n\n  // Store the user and password as a separate auth object\n  if (uri.user || uri.password) {\n    uri.auth = {username: uri.user, password: uri.password};\n  }\n\n  // Split the path part of the URI into parts using '/' as the delimiter\n  // after removing any leading '/' and any trailing '/'\n  var parts = uri.path.replace(/(^\\/|\\/$)/g, '').split('/');\n\n  // Store the first part as the database name and remove it from the parts\n  // array\n  uri.db = parts.pop();\n  // Prevent double encoding of URI component\n  if (uri.db.indexOf('%') === -1) {\n    uri.db = encodeURIComponent(uri.db);\n  }\n\n  // Restore the path by joining all the remaining parts (all the parts\n  // except for the database name) with '/'s\n  uri.path = parts.join('/');\n\n  return uri;\n}\n\n// Generate a URL with the host data given by opts and the given path\nfunction genDBUrl(opts, path) {\n  return genUrl(opts, opts.db + '/' + path);\n}\n\n// Generate a URL with the host data given by opts and the given path\nfunction genUrl(opts, path) {\n  // If the host already has a path, then we need to have a path delimiter\n  // Otherwise, the path delimiter is the empty string\n  var pathDel = !opts.path ? '' : '/';\n\n  // If the host already has a path, then we need to have a path delimiter\n  // Otherwise, the path delimiter is the empty string\n  return opts.protocol + '://' + opts.host +\n         (opts.port ? (':' + opts.port) : '') +\n         '/' + opts.path + pathDel + path;\n}\n\nfunction paramsToStr(params) {\n  return '?' + Object.keys(params).map(function (k) {\n    return k + '=' + encodeURIComponent(params[k]);\n  }).join('&');\n}\n\n// Implements the PouchDB API for dealing with CouchDB instances over HTTP\nfunction HttpPouch(opts, callback) {\n\n  // The functions that will be publicly available for HttpPouch\n  var api = this;\n\n  var host = getHost(opts.name, opts);\n  var dbUrl = genDBUrl(host, '');\n\n  opts = clone(opts);\n  var ajaxOpts = opts.ajax || {};\n\n  if (opts.auth || host.auth) {\n    var nAuth = opts.auth || host.auth;\n    var str = nAuth.username + ':' + nAuth.password;\n    var token = thisBtoa(unescape(encodeURIComponent(str)));\n    ajaxOpts.headers = ajaxOpts.headers || {};\n    ajaxOpts.headers.Authorization = 'Basic ' + token;\n  }\n\n  // Not strictly necessary, but we do this because numerous tests\n  // rely on swapping ajax in and out.\n  api._ajax = ajax$1;\n\n  function ajax(userOpts, options, callback) {\n    var reqAjax = (userOpts || {}).ajax || {};\n    var reqOpts = $inject_Object_assign(clone(ajaxOpts), reqAjax, options);\n    var defaultHeaders = clone(ajaxOpts.headers || {});\n    reqOpts.headers = $inject_Object_assign(defaultHeaders, reqAjax.headers,\n      options.headers || {});\n    /* istanbul ignore if */\n    if (api.constructor.listeners('debug').length) {\n      api.constructor.emit('debug', ['http', reqOpts.method, reqOpts.url]);\n    }\n    return api._ajax(reqOpts, callback);\n  }\n\n  function ajaxPromise(userOpts, opts) {\n    return new PouchPromise(function (resolve, reject) {\n      ajax(userOpts, opts, function (err, res) {\n        /* istanbul ignore if */\n        if (err) {\n          return reject(err);\n        }\n        resolve(res);\n      });\n    });\n  }\n\n  function adapterFun$$1(name, fun) {\n    return adapterFun(name, __WEBPACK_IMPORTED_MODULE_1_argsarray___default()(function (args) {\n      setup().then(function () {\n        return fun.apply(this, args);\n      }).catch(function (e) {\n        var callback = args.pop();\n        callback(e);\n      });\n    }));\n  }\n\n  var setupPromise;\n\n  function setup() {\n    // TODO: Remove `skipSetup` in favor of `skip_setup` in a future release\n    if (opts.skipSetup || opts.skip_setup) {\n      return PouchPromise.resolve();\n    }\n\n    // If there is a setup in process or previous successful setup\n    // done then we will use that\n    // If previous setups have been rejected we will try again\n    if (setupPromise) {\n      return setupPromise;\n    }\n\n    var checkExists = {method: 'GET', url: dbUrl};\n    setupPromise = ajaxPromise({}, checkExists).catch(function (err) {\n      if (err && err.status && err.status === 404) {\n        // Doesnt exist, create it\n        explainError(404, 'PouchDB is just detecting if the remote exists.');\n        return ajaxPromise({}, {method: 'PUT', url: dbUrl});\n      } else {\n        return PouchPromise.reject(err);\n      }\n    }).catch(function (err) {\n      // If we try to create a database that already exists, skipped in\n      // istanbul since its catching a race condition.\n      /* istanbul ignore if */\n      if (err && err.status && err.status === 412) {\n        return true;\n      }\n      return PouchPromise.reject(err);\n    });\n\n    setupPromise.catch(function () {\n      setupPromise = null;\n    });\n\n    return setupPromise;\n  }\n\n  __WEBPACK_IMPORTED_MODULE_2_immediate___default()(function () {\n    callback(null, api);\n  });\n\n  api._remote = true;\n  /* istanbul ignore next */\n  api.type = function () {\n    return 'http';\n  };\n\n  api.id = adapterFun$$1('id', function (callback) {\n    ajax({}, {method: 'GET', url: genUrl(host, '')}, function (err, result) {\n      var uuid$$1 = (result && result.uuid) ?\n        (result.uuid + host.db) : genDBUrl(host, '');\n      callback(null, uuid$$1);\n    });\n  });\n\n  api.request = adapterFun$$1('request', function (options, callback) {\n    options.url = genDBUrl(host, options.url);\n    ajax({}, options, callback);\n  });\n\n  // Sends a POST request to the host calling the couchdb _compact function\n  //    version: The version of CouchDB it is running\n  api.compact = adapterFun$$1('compact', function (opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n    ajax(opts, {\n      url: genDBUrl(host, '_compact'),\n      method: 'POST'\n    }, function () {\n      function ping() {\n        api.info(function (err, res) {\n          // CouchDB may send a \"compact_running:true\" if it's\n          // already compacting. PouchDB Server doesn't.\n          /* istanbul ignore else */\n          if (res && !res.compact_running) {\n            callback(null, {ok: true});\n          } else {\n            setTimeout(ping, opts.interval || 200);\n          }\n        });\n      }\n      // Ping the http if it's finished compaction\n      ping();\n    });\n  });\n\n  api.bulkGet = adapterFun('bulkGet', function (opts, callback) {\n    var self = this;\n\n    function doBulkGet(cb) {\n      var params = {};\n      if (opts.revs) {\n        params.revs = true;\n      }\n      if (opts.attachments) {\n        /* istanbul ignore next */\n        params.attachments = true;\n      }\n      if (opts.latest) {\n        params.latest = true;\n      }\n      ajax(opts, {\n        url: genDBUrl(host, '_bulk_get' + paramsToStr(params)),\n        method: 'POST',\n        body: { docs: opts.docs}\n      }, function (err, result) {\n        if (!err && opts.attachments && opts.binary) {\n          result.results.forEach(function (res) {\n            res.docs.forEach(readAttachmentsAsBlobOrBuffer);\n          });\n        }\n        cb(err, result);\n      });\n    }\n\n    /* istanbul ignore next */\n    function doBulkGetShim() {\n      // avoid \"url too long error\" by splitting up into multiple requests\n      var batchSize = MAX_SIMULTANEOUS_REVS;\n      var numBatches = Math.ceil(opts.docs.length / batchSize);\n      var numDone = 0;\n      var results = new Array(numBatches);\n\n      function onResult(batchNum) {\n        return function (err, res) {\n          // err is impossible because shim returns a list of errs in that case\n          results[batchNum] = res.results;\n          if (++numDone === numBatches) {\n            callback(null, {results: flatten(results)});\n          }\n        };\n      }\n\n      for (var i = 0; i < numBatches; i++) {\n        var subOpts = pick(opts, ['revs', 'attachments', 'binary', 'latest']);\n        subOpts.ajax = ajaxOpts;\n        subOpts.docs = opts.docs.slice(i * batchSize,\n          Math.min(opts.docs.length, (i + 1) * batchSize));\n        bulkGet(self, subOpts, onResult(i));\n      }\n    }\n\n    // mark the whole database as either supporting or not supporting _bulk_get\n    var dbUrl = genUrl(host, '');\n    var supportsBulkGet = supportsBulkGetMap[dbUrl];\n\n    /* istanbul ignore next */\n    if (typeof supportsBulkGet !== 'boolean') {\n      // check if this database supports _bulk_get\n      doBulkGet(function (err, res) {\n        if (err) {\n          supportsBulkGetMap[dbUrl] = false;\n          explainError(\n            err.status,\n            'PouchDB is just detecting if the remote ' +\n            'supports the _bulk_get API.'\n          );\n          doBulkGetShim();\n        } else {\n          supportsBulkGetMap[dbUrl] = true;\n          callback(null, res);\n        }\n      });\n    } else if (supportsBulkGet) {\n      doBulkGet(callback);\n    } else {\n      doBulkGetShim();\n    }\n  });\n\n  // Calls GET on the host, which gets back a JSON string containing\n  //    couchdb: A welcome string\n  //    version: The version of CouchDB it is running\n  api._info = function (callback) {\n    setup().then(function () {\n      ajax({}, {\n        method: 'GET',\n        url: genDBUrl(host, '')\n      }, function (err, res) {\n        /* istanbul ignore next */\n        if (err) {\n        return callback(err);\n        }\n        res.host = genDBUrl(host, '');\n        callback(null, res);\n      });\n    }).catch(callback);\n  };\n\n  // Get the document with the given id from the database given by host.\n  // The id could be solely the _id in the database, or it may be a\n  // _design/ID or _local/ID path\n  api.get = adapterFun$$1('get', function (id, opts, callback) {\n    // If no options were given, set the callback to the second parameter\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n\n    // List of parameters to add to the GET request\n    var params = {};\n\n    if (opts.revs) {\n      params.revs = true;\n    }\n\n    if (opts.revs_info) {\n      params.revs_info = true;\n    }\n\n    if (opts.latest) {\n      params.latest = true;\n    }\n\n    if (opts.open_revs) {\n      if (opts.open_revs !== \"all\") {\n        opts.open_revs = JSON.stringify(opts.open_revs);\n      }\n      params.open_revs = opts.open_revs;\n    }\n\n    if (opts.rev) {\n      params.rev = opts.rev;\n    }\n\n    if (opts.conflicts) {\n      params.conflicts = opts.conflicts;\n    }\n\n    /* istanbul ignore if */\n    if (opts.update_seq) {\n      params.update_seq = opts.update_seq;\n    }\n\n    id = encodeDocId(id);\n\n    // Set the options for the ajax call\n    var options = {\n      method: 'GET',\n      url: genDBUrl(host, id + paramsToStr(params))\n    };\n\n    function fetchAttachments(doc) {\n      var atts = doc._attachments;\n      var filenames = atts && Object.keys(atts);\n      if (!atts || !filenames.length) {\n        return;\n      }\n      // we fetch these manually in separate XHRs, because\n      // Sync Gateway would normally send it back as multipart/mixed,\n      // which we cannot parse. Also, this is more efficient than\n      // receiving attachments as base64-encoded strings.\n      function fetch(filename) {\n        var att = atts[filename];\n        var path = encodeDocId(doc._id) + '/' + encodeAttachmentId(filename) +\n          '?rev=' + doc._rev;\n        return ajaxPromise(opts, {\n          method: 'GET',\n          url: genDBUrl(host, path),\n          binary: true\n        }).then(function (blob) {\n          if (opts.binary) {\n            return blob;\n          }\n          return new PouchPromise(function (resolve) {\n            blobToBase64(blob, resolve);\n          });\n        }).then(function (data) {\n          delete att.stub;\n          delete att.length;\n          att.data = data;\n        });\n      }\n\n      var promiseFactories = filenames.map(function (filename) {\n        return function () {\n          return fetch(filename);\n        };\n      });\n\n      // This limits the number of parallel xhr requests to 5 any time\n      // to avoid issues with maximum browser request limits\n      return pool(promiseFactories, 5);\n    }\n\n    function fetchAllAttachments(docOrDocs) {\n      if (Array.isArray(docOrDocs)) {\n        return PouchPromise.all(docOrDocs.map(function (doc) {\n          if (doc.ok) {\n            return fetchAttachments(doc.ok);\n          }\n        }));\n      }\n      return fetchAttachments(docOrDocs);\n    }\n\n    ajaxPromise(opts, options).then(function (res) {\n      return PouchPromise.resolve().then(function () {\n        if (opts.attachments) {\n          return fetchAllAttachments(res);\n        }\n      }).then(function () {\n        callback(null, res);\n      });\n    }).catch(function (e) {\n      e.docId = id;\n      callback(e);\n    });\n  });\n\n  // Delete the document given by doc from the database given by host.\n  api.remove = adapterFun$$1('remove',\n      function (docOrId, optsOrRev, opts, callback) {\n    var doc;\n    if (typeof optsOrRev === 'string') {\n      // id, rev, opts, callback style\n      doc = {\n        _id: docOrId,\n        _rev: optsOrRev\n      };\n      if (typeof opts === 'function') {\n        callback = opts;\n        opts = {};\n      }\n    } else {\n      // doc, opts, callback style\n      doc = docOrId;\n      if (typeof optsOrRev === 'function') {\n        callback = optsOrRev;\n        opts = {};\n      } else {\n        callback = opts;\n        opts = optsOrRev;\n      }\n    }\n\n    var rev$$1 = (doc._rev || opts.rev);\n\n    // Delete the document\n    ajax(opts, {\n      method: 'DELETE',\n      url: genDBUrl(host, encodeDocId(doc._id)) + '?rev=' + rev$$1\n    }, callback);\n  });\n\n  function encodeAttachmentId(attachmentId) {\n    return attachmentId.split(\"/\").map(encodeURIComponent).join(\"/\");\n  }\n\n  // Get the attachment\n  api.getAttachment =\n    adapterFun$$1('getAttachment', function (docId, attachmentId, opts,\n                                                callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var params = opts.rev ? ('?rev=' + opts.rev) : '';\n    var url = genDBUrl(host, encodeDocId(docId)) + '/' +\n      encodeAttachmentId(attachmentId) + params;\n    ajax(opts, {\n      method: 'GET',\n      url: url,\n      binary: true\n    }, callback);\n  });\n\n  // Remove the attachment given by the id and rev\n  api.removeAttachment =\n    adapterFun$$1('removeAttachment', function (docId, attachmentId, rev$$1,\n                                                   callback) {\n\n    var url = genDBUrl(host, encodeDocId(docId) + '/' +\n      encodeAttachmentId(attachmentId)) + '?rev=' + rev$$1;\n\n    ajax({}, {\n      method: 'DELETE',\n      url: url\n    }, callback);\n  });\n\n  // Add the attachment given by blob and its contentType property\n  // to the document with the given id, the revision given by rev, and\n  // add it to the database given by host.\n  api.putAttachment =\n    adapterFun$$1('putAttachment', function (docId, attachmentId, rev$$1, blob,\n                                                type, callback) {\n    if (typeof type === 'function') {\n      callback = type;\n      type = blob;\n      blob = rev$$1;\n      rev$$1 = null;\n    }\n    var id = encodeDocId(docId) + '/' + encodeAttachmentId(attachmentId);\n    var url = genDBUrl(host, id);\n    if (rev$$1) {\n      url += '?rev=' + rev$$1;\n    }\n\n    if (typeof blob === 'string') {\n      // input is assumed to be a base64 string\n      var binary;\n      try {\n        binary = thisAtob(blob);\n      } catch (err) {\n        return callback(createError(BAD_ARG,\n                        'Attachment is not a valid base64 string'));\n      }\n      blob = binary ? binStringToBluffer(binary, type) : '';\n    }\n\n    var opts = {\n      headers: {'Content-Type': type},\n      method: 'PUT',\n      url: url,\n      processData: false,\n      body: blob,\n      timeout: ajaxOpts.timeout || 60000\n    };\n    // Add the attachment\n    ajax({}, opts, callback);\n  });\n\n  // Update/create multiple documents given by req in the database\n  // given by host.\n  api._bulkDocs = function (req, opts, callback) {\n    // If new_edits=false then it prevents the database from creating\n    // new revision numbers for the documents. Instead it just uses\n    // the old ones. This is used in database replication.\n    req.new_edits = opts.new_edits;\n\n    setup().then(function () {\n      return PouchPromise.all(req.docs.map(preprocessAttachments$2));\n    }).then(function () {\n      // Update/create the documents\n      ajax(opts, {\n        method: 'POST',\n        url: genDBUrl(host, '_bulk_docs'),\n        timeout: opts.timeout,\n        body: req\n      }, function (err, results) {\n        if (err) {\n          return callback(err);\n        }\n        results.forEach(function (result) {\n          result.ok = true; // smooths out cloudant not adding this\n        });\n        callback(null, results);\n      });\n    }).catch(callback);\n  };\n\n\n  // Update/create document\n  api._put = function (doc, opts, callback) {\n    setup().then(function () {\n      return preprocessAttachments$2(doc);\n    }).then(function () {\n      // Update/create the document\n      ajax(opts, {\n        method: 'PUT',\n        url: genDBUrl(host, encodeDocId(doc._id)),\n        body: doc\n      }, function (err, result) {\n        if (err) {\n          err.docId = doc && doc._id;\n          return callback(err);\n        }\n        callback(null, result);\n      });\n    }).catch(callback);\n  };\n\n\n  // Get a listing of the documents in the database given\n  // by host and ordered by increasing id.\n  api.allDocs = adapterFun$$1('allDocs', function (opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n\n    // List of parameters to add to the GET request\n    var params = {};\n    var body;\n    var method = 'GET';\n\n    if (opts.conflicts) {\n      params.conflicts = true;\n    }\n\n    /* istanbul ignore if */\n    if (opts.update_seq) {\n      params.update_seq = true;\n    }\n\n    if (opts.descending) {\n      params.descending = true;\n    }\n\n    if (opts.include_docs) {\n      params.include_docs = true;\n    }\n\n    // added in CouchDB 1.6.0\n    if (opts.attachments) {\n      params.attachments = true;\n    }\n\n    if (opts.key) {\n      params.key = JSON.stringify(opts.key);\n    }\n\n    if (opts.start_key) {\n      opts.startkey = opts.start_key;\n    }\n\n    if (opts.startkey) {\n      params.startkey = JSON.stringify(opts.startkey);\n    }\n\n    if (opts.end_key) {\n      opts.endkey = opts.end_key;\n    }\n\n    if (opts.endkey) {\n      params.endkey = JSON.stringify(opts.endkey);\n    }\n\n    if (typeof opts.inclusive_end !== 'undefined') {\n      params.inclusive_end = !!opts.inclusive_end;\n    }\n\n    if (typeof opts.limit !== 'undefined') {\n      params.limit = opts.limit;\n    }\n\n    if (typeof opts.skip !== 'undefined') {\n      params.skip = opts.skip;\n    }\n\n    var paramStr = paramsToStr(params);\n\n    if (typeof opts.keys !== 'undefined') {\n      method = 'POST';\n      body = {keys: opts.keys};\n    }\n\n    // Get the document listing\n    ajaxPromise(opts, {\n      method: method,\n      url: genDBUrl(host, '_all_docs' + paramStr),\n      body: body\n    }).then(function (res) {\n      if (opts.include_docs && opts.attachments && opts.binary) {\n        res.rows.forEach(readAttachmentsAsBlobOrBuffer);\n      }\n      callback(null, res);\n    }).catch(callback);\n  });\n\n  // Get a list of changes made to documents in the database given by host.\n  // TODO According to the README, there should be two other methods here,\n  // api.changes.addListener and api.changes.removeListener.\n  api._changes = function (opts) {\n\n    // We internally page the results of a changes request, this means\n    // if there is a large set of changes to be returned we can start\n    // processing them quicker instead of waiting on the entire\n    // set of changes to return and attempting to process them at once\n    var batchSize = 'batch_size' in opts ? opts.batch_size : CHANGES_BATCH_SIZE;\n\n    opts = clone(opts);\n\n    if (opts.continuous && !('heartbeat' in opts)) {\n      opts.heartbeat = DEFAULT_HEARTBEAT;\n    }\n\n    var requestTimeout = ('timeout' in opts) ? opts.timeout :\n      ('timeout' in ajaxOpts) ? ajaxOpts.timeout :\n      30 * 1000;\n\n    // ensure CHANGES_TIMEOUT_BUFFER applies\n    if ('timeout' in opts && opts.timeout &&\n      (requestTimeout - opts.timeout) < CHANGES_TIMEOUT_BUFFER) {\n        requestTimeout = opts.timeout + CHANGES_TIMEOUT_BUFFER;\n    }\n\n    if ('heartbeat' in opts && opts.heartbeat &&\n       (requestTimeout - opts.heartbeat) < CHANGES_TIMEOUT_BUFFER) {\n        requestTimeout = opts.heartbeat + CHANGES_TIMEOUT_BUFFER;\n    }\n\n    var params = {};\n    if ('timeout' in opts && opts.timeout) {\n      params.timeout = opts.timeout;\n    }\n\n    var limit = (typeof opts.limit !== 'undefined') ? opts.limit : false;\n    var returnDocs;\n    if ('return_docs' in opts) {\n      returnDocs = opts.return_docs;\n    } else if ('returnDocs' in opts) {\n      // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n      returnDocs = opts.returnDocs;\n    } else {\n      returnDocs = true;\n    }\n    //\n    var leftToFetch = limit;\n\n    if (opts.style) {\n      params.style = opts.style;\n    }\n\n    if (opts.include_docs || opts.filter && typeof opts.filter === 'function') {\n      params.include_docs = true;\n    }\n\n    if (opts.attachments) {\n      params.attachments = true;\n    }\n\n    if (opts.continuous) {\n      params.feed = 'longpoll';\n    }\n\n    if (opts.seq_interval) {\n      params.seq_interval = opts.seq_interval;\n    }\n\n    if (opts.conflicts) {\n      params.conflicts = true;\n    }\n\n    if (opts.descending) {\n      params.descending = true;\n    }\n    \n    /* istanbul ignore if */\n    if (opts.update_seq) {\n      params.update_seq = true;\n    }\n\n    if ('heartbeat' in opts) {\n      // If the heartbeat value is false, it disables the default heartbeat\n      if (opts.heartbeat) {\n        params.heartbeat = opts.heartbeat;\n      }\n    }\n\n    if (opts.filter && typeof opts.filter === 'string') {\n      params.filter = opts.filter;\n    }\n\n    if (opts.view && typeof opts.view === 'string') {\n      params.filter = '_view';\n      params.view = opts.view;\n    }\n\n    // If opts.query_params exists, pass it through to the changes request.\n    // These parameters may be used by the filter on the source database.\n    if (opts.query_params && typeof opts.query_params === 'object') {\n      for (var param_name in opts.query_params) {\n        /* istanbul ignore else */\n        if (opts.query_params.hasOwnProperty(param_name)) {\n          params[param_name] = opts.query_params[param_name];\n        }\n      }\n    }\n\n    var method = 'GET';\n    var body;\n\n    if (opts.doc_ids) {\n      // set this automagically for the user; it's annoying that couchdb\n      // requires both a \"filter\" and a \"doc_ids\" param.\n      params.filter = '_doc_ids';\n      method = 'POST';\n      body = {doc_ids: opts.doc_ids };\n    }\n    /* istanbul ignore next */\n    else if (opts.selector) {\n      // set this automagically for the user, similar to above\n      params.filter = '_selector';\n      method = 'POST';\n      body = {selector: opts.selector };\n    }\n\n    var xhr;\n    var lastFetchedSeq;\n\n    // Get all the changes starting wtih the one immediately after the\n    // sequence number given by since.\n    var fetch = function (since, callback) {\n      if (opts.aborted) {\n        return;\n      }\n      params.since = since;\n      // \"since\" can be any kind of json object in Coudant/CouchDB 2.x\n      /* istanbul ignore next */\n      if (typeof params.since === \"object\") {\n        params.since = JSON.stringify(params.since);\n      }\n\n      if (opts.descending) {\n        if (limit) {\n          params.limit = leftToFetch;\n        }\n      } else {\n        params.limit = (!limit || leftToFetch > batchSize) ?\n          batchSize : leftToFetch;\n      }\n\n      // Set the options for the ajax call\n      var xhrOpts = {\n        method: method,\n        url: genDBUrl(host, '_changes' + paramsToStr(params)),\n        timeout: requestTimeout,\n        body: body\n      };\n      lastFetchedSeq = since;\n\n      /* istanbul ignore if */\n      if (opts.aborted) {\n        return;\n      }\n\n      // Get the changes\n      setup().then(function () {\n        xhr = ajax(opts, xhrOpts, callback);\n      }).catch(callback);\n    };\n\n    // If opts.since exists, get all the changes from the sequence\n    // number given by opts.since. Otherwise, get all the changes\n    // from the sequence number 0.\n    var results = {results: []};\n\n    var fetched = function (err, res) {\n      if (opts.aborted) {\n        return;\n      }\n      var raw_results_length = 0;\n      // If the result of the ajax call (res) contains changes (res.results)\n      if (res && res.results) {\n        raw_results_length = res.results.length;\n        results.last_seq = res.last_seq;\n        var pending = null;\n        var lastSeq = null;\n        // Attach 'pending' property if server supports it (CouchDB 2.0+)\n        /* istanbul ignore if */\n        if (typeof res.pending === 'number') {\n          pending = res.pending;\n        }\n        if (typeof results.last_seq === 'string' || typeof results.last_seq === 'number') {\n          lastSeq = results.last_seq;\n        }\n        // For each change\n        var req = {};\n        req.query = opts.query_params;\n        res.results = res.results.filter(function (c) {\n          leftToFetch--;\n          var ret = filterChange(opts)(c);\n          if (ret) {\n            if (opts.include_docs && opts.attachments && opts.binary) {\n              readAttachmentsAsBlobOrBuffer(c);\n            }\n            if (returnDocs) {\n              results.results.push(c);\n            }\n            opts.onChange(c, pending, lastSeq);\n          }\n          return ret;\n        });\n      } else if (err) {\n        // In case of an error, stop listening for changes and call\n        // opts.complete\n        opts.aborted = true;\n        opts.complete(err);\n        return;\n      }\n\n      // The changes feed may have timed out with no results\n      // if so reuse last update sequence\n      if (res && res.last_seq) {\n        lastFetchedSeq = res.last_seq;\n      }\n\n      var finished = (limit && leftToFetch <= 0) ||\n        (res && raw_results_length < batchSize) ||\n        (opts.descending);\n\n      if ((opts.continuous && !(limit && leftToFetch <= 0)) || !finished) {\n        // Queue a call to fetch again with the newest sequence number\n        __WEBPACK_IMPORTED_MODULE_2_immediate___default()(function () { fetch(lastFetchedSeq, fetched); });\n      } else {\n        // We're done, call the callback\n        opts.complete(null, results);\n      }\n    };\n\n    fetch(opts.since || 0, fetched);\n\n    // Return a method to cancel this method from processing any more\n    return {\n      cancel: function () {\n        opts.aborted = true;\n        if (xhr) {\n          xhr.abort();\n        }\n      }\n    };\n  };\n\n  // Given a set of document/revision IDs (given by req), tets the subset of\n  // those that do NOT correspond to revisions stored in the database.\n  // See http://wiki.apache.org/couchdb/HttpPostRevsDiff\n  api.revsDiff = adapterFun$$1('revsDiff', function (req, opts, callback) {\n    // If no options were given, set the callback to be the second parameter\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n\n    // Get the missing document/revision IDs\n    ajax(opts, {\n      method: 'POST',\n      url: genDBUrl(host, '_revs_diff'),\n      body: req\n    }, callback);\n  });\n\n  api._close = function (callback) {\n    callback();\n  };\n\n  api._destroy = function (options, callback) {\n    ajax(options, {\n      url: genDBUrl(host, ''),\n      method: 'DELETE'\n    }, function (err, resp) {\n      if (err && err.status && err.status !== 404) {\n        return callback(err);\n      }\n      callback(null, resp);\n    });\n  };\n}\n\n// HttpPouch is a valid adapter.\nHttpPouch.valid = function () {\n  return true;\n};\n\nfunction HttpPouch$1 (PouchDB) {\n  PouchDB.adapter('http', HttpPouch, false);\n  PouchDB.adapter('https', HttpPouch, false);\n}\n\nfunction QueryParseError(message) {\n  this.status = 400;\n  this.name = 'query_parse_error';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, QueryParseError);\n  } catch (e) {}\n}\n\n__WEBPACK_IMPORTED_MODULE_4_inherits___default()(QueryParseError, Error);\n\nfunction NotFoundError(message) {\n  this.status = 404;\n  this.name = 'not_found';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, NotFoundError);\n  } catch (e) {}\n}\n\n__WEBPACK_IMPORTED_MODULE_4_inherits___default()(NotFoundError, Error);\n\nfunction BuiltInError(message) {\n  this.status = 500;\n  this.name = 'invalid_value';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, BuiltInError);\n  } catch (e) {}\n}\n\n__WEBPACK_IMPORTED_MODULE_4_inherits___default()(BuiltInError, Error);\n\nfunction promisedCallback(promise, callback) {\n  if (callback) {\n    promise.then(function (res) {\n      __WEBPACK_IMPORTED_MODULE_2_immediate___default()(function () {\n        callback(null, res);\n      });\n    }, function (reason) {\n      __WEBPACK_IMPORTED_MODULE_2_immediate___default()(function () {\n        callback(reason);\n      });\n    });\n  }\n  return promise;\n}\n\nfunction callbackify(fun) {\n  return __WEBPACK_IMPORTED_MODULE_1_argsarray___default()(function (args) {\n    var cb = args.pop();\n    var promise = fun.apply(this, args);\n    if (typeof cb === 'function') {\n      promisedCallback(promise, cb);\n    }\n    return promise;\n  });\n}\n\n// Promise finally util similar to Q.finally\nfunction fin(promise, finalPromiseFactory) {\n  return promise.then(function (res) {\n    return finalPromiseFactory().then(function () {\n      return res;\n    });\n  }, function (reason) {\n    return finalPromiseFactory().then(function () {\n      throw reason;\n    });\n  });\n}\n\nfunction sequentialize(queue, promiseFactory) {\n  return function () {\n    var args = arguments;\n    var that = this;\n    return queue.add(function () {\n      return promiseFactory.apply(that, args);\n    });\n  };\n}\n\n// uniq an array of strings, order not guaranteed\n// similar to underscore/lodash _.uniq\nfunction uniq(arr) {\n  var theSet = new ExportedSet(arr);\n  var result = new Array(theSet.size);\n  var index = -1;\n  theSet.forEach(function (value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\nfunction mapToKeysArray(map) {\n  var result = new Array(map.size);\n  var index = -1;\n  map.forEach(function (value, key) {\n    result[++index] = key;\n  });\n  return result;\n}\n\nfunction createBuiltInError(name) {\n  var message = 'builtin ' + name +\n    ' function requires map values to be numbers' +\n    ' or number arrays';\n  return new BuiltInError(message);\n}\n\nfunction sum(values) {\n  var result = 0;\n  for (var i = 0, len = values.length; i < len; i++) {\n    var num = values[i];\n    if (typeof num !== 'number') {\n      if (Array.isArray(num)) {\n        // lists of numbers are also allowed, sum them separately\n        result = typeof result === 'number' ? [result] : result;\n        for (var j = 0, jLen = num.length; j < jLen; j++) {\n          var jNum = num[j];\n          if (typeof jNum !== 'number') {\n            throw createBuiltInError('_sum');\n          } else if (typeof result[j] === 'undefined') {\n            result.push(jNum);\n          } else {\n            result[j] += jNum;\n          }\n        }\n      } else { // not array/number\n        throw createBuiltInError('_sum');\n      }\n    } else if (typeof result === 'number') {\n      result += num;\n    } else { // add number to array\n      result[0] += num;\n    }\n  }\n  return result;\n}\n\nvar log = guardedConsole.bind(null, 'log');\nvar isArray = Array.isArray;\nvar toJSON = JSON.parse;\n\nfunction evalFunctionWithEval(func, emit) {\n  return scopeEval(\n    \"return (\" + func.replace(/;\\s*$/, \"\") + \");\",\n    {\n      emit: emit,\n      sum: sum,\n      log: log,\n      isArray: isArray,\n      toJSON: toJSON\n    }\n  );\n}\n\n/*\n * Simple task queue to sequentialize actions. Assumes\n * callbacks will eventually fire (once).\n */\n\n\nfunction TaskQueue$2() {\n  this.promise = new PouchPromise(function (fulfill) {fulfill(); });\n}\nTaskQueue$2.prototype.add = function (promiseFactory) {\n  this.promise = this.promise.catch(function () {\n    // just recover\n  }).then(function () {\n    return promiseFactory();\n  });\n  return this.promise;\n};\nTaskQueue$2.prototype.finish = function () {\n  return this.promise;\n};\n\nfunction stringify(input) {\n  if (!input) {\n    return 'undefined'; // backwards compat for empty reduce\n  }\n  // for backwards compat with mapreduce, functions/strings are stringified\n  // as-is. everything else is JSON-stringified.\n  switch (typeof input) {\n    case 'function':\n      // e.g. a mapreduce map\n      return input.toString();\n    case 'string':\n      // e.g. a mapreduce built-in _reduce function\n      return input.toString();\n    default:\n      // e.g. a JSON object in the case of mango queries\n      return JSON.stringify(input);\n  }\n}\n\n/* create a string signature for a view so we can cache it and uniq it */\nfunction createViewSignature(mapFun, reduceFun) {\n  // the \"undefined\" part is for backwards compatibility\n  return stringify(mapFun) + stringify(reduceFun) + 'undefined';\n}\n\nfunction createView(sourceDB, viewName, mapFun, reduceFun, temporary, localDocName) {\n  var viewSignature = createViewSignature(mapFun, reduceFun);\n\n  var cachedViews;\n  if (!temporary) {\n    // cache this to ensure we don't try to update the same view twice\n    cachedViews = sourceDB._cachedViews = sourceDB._cachedViews || {};\n    if (cachedViews[viewSignature]) {\n      return cachedViews[viewSignature];\n    }\n  }\n\n  var promiseForView = sourceDB.info().then(function (info) {\n\n    var depDbName = info.db_name + '-mrview-' +\n      (temporary ? 'temp' : stringMd5(viewSignature));\n\n    // save the view name in the source db so it can be cleaned up if necessary\n    // (e.g. when the _design doc is deleted, remove all associated view data)\n    function diffFunction(doc) {\n      doc.views = doc.views || {};\n      var fullViewName = viewName;\n      if (fullViewName.indexOf('/') === -1) {\n        fullViewName = viewName + '/' + viewName;\n      }\n      var depDbs = doc.views[fullViewName] = doc.views[fullViewName] || {};\n      /* istanbul ignore if */\n      if (depDbs[depDbName]) {\n        return; // no update necessary\n      }\n      depDbs[depDbName] = true;\n      return doc;\n    }\n    return upsert(sourceDB, '_local/' + localDocName, diffFunction).then(function () {\n      return sourceDB.registerDependentDatabase(depDbName).then(function (res) {\n        var db = res.db;\n        db.auto_compaction = true;\n        var view = {\n          name: depDbName,\n          db: db,\n          sourceDB: sourceDB,\n          adapter: sourceDB.adapter,\n          mapFun: mapFun,\n          reduceFun: reduceFun\n        };\n        return view.db.get('_local/lastSeq').catch(function (err) {\n          /* istanbul ignore if */\n          if (err.status !== 404) {\n            throw err;\n          }\n        }).then(function (lastSeqDoc) {\n          view.seq = lastSeqDoc ? lastSeqDoc.seq : 0;\n          if (cachedViews) {\n            view.db.once('destroyed', function () {\n              delete cachedViews[viewSignature];\n            });\n          }\n          return view;\n        });\n      });\n    });\n  });\n\n  if (cachedViews) {\n    cachedViews[viewSignature] = promiseForView;\n  }\n  return promiseForView;\n}\n\nvar persistentQueues = {};\nvar tempViewQueue = new TaskQueue$2();\nvar CHANGES_BATCH_SIZE$1 = 50;\n\nfunction parseViewName(name) {\n  // can be either 'ddocname/viewname' or just 'viewname'\n  // (where the ddoc name is the same)\n  return name.indexOf('/') === -1 ? [name, name] : name.split('/');\n}\n\nfunction isGenOne(changes) {\n  // only return true if the current change is 1-\n  // and there are no other leafs\n  return changes.length === 1 && /^1-/.test(changes[0].rev);\n}\n\nfunction emitError(db, e) {\n  try {\n    db.emit('error', e);\n  } catch (err) {\n    guardedConsole('error',\n      'The user\\'s map/reduce function threw an uncaught error.\\n' +\n      'You can debug this error by doing:\\n' +\n      'myDatabase.on(\\'error\\', function (err) { debugger; });\\n' +\n      'Please double-check your map/reduce function.');\n    guardedConsole('error', e);\n  }\n}\n\n/**\n * Returns an \"abstract\" mapreduce object of the form:\n *\n *   {\n *     query: queryFun,\n *     viewCleanup: viewCleanupFun\n *   }\n *\n * Arguments are:\n *\n * localDoc: string\n *   This is for the local doc that gets saved in order to track the\n *   \"dependent\" DBs and clean them up for viewCleanup. It should be\n *   unique, so that indexer plugins don't collide with each other.\n * mapper: function (mapFunDef, emit)\n *   Returns a map function based on the mapFunDef, which in the case of\n *   normal map/reduce is just the de-stringified function, but may be\n *   something else, such as an object in the case of pouchdb-find.\n * reducer: function (reduceFunDef)\n *   Ditto, but for reducing. Modules don't have to support reducing\n *   (e.g. pouchdb-find).\n * ddocValidator: function (ddoc, viewName)\n *   Throws an error if the ddoc or viewName is not valid.\n *   This could be a way to communicate to the user that the configuration for the\n *   indexer is invalid.\n */\nfunction createAbstractMapReduce(localDocName, mapper, reducer, ddocValidator) {\n\n  function tryMap(db, fun, doc) {\n    // emit an event if there was an error thrown by a map function.\n    // putting try/catches in a single function also avoids deoptimizations.\n    try {\n      fun(doc);\n    } catch (e) {\n      emitError(db, e);\n    }\n  }\n\n  function tryReduce(db, fun, keys, values, rereduce) {\n    // same as above, but returning the result or an error. there are two separate\n    // functions to avoid extra memory allocations since the tryCode() case is used\n    // for custom map functions (common) vs this function, which is only used for\n    // custom reduce functions (rare)\n    try {\n      return {output : fun(keys, values, rereduce)};\n    } catch (e) {\n      emitError(db, e);\n      return {error: e};\n    }\n  }\n\n  function sortByKeyThenValue(x, y) {\n    var keyCompare = collate(x.key, y.key);\n    return keyCompare !== 0 ? keyCompare : collate(x.value, y.value);\n  }\n\n  function sliceResults(results, limit, skip) {\n    skip = skip || 0;\n    if (typeof limit === 'number') {\n      return results.slice(skip, limit + skip);\n    } else if (skip > 0) {\n      return results.slice(skip);\n    }\n    return results;\n  }\n\n  function rowToDocId(row) {\n    var val = row.value;\n    // Users can explicitly specify a joined doc _id, or it\n    // defaults to the doc _id that emitted the key/value.\n    var docId = (val && typeof val === 'object' && val._id) || row.id;\n    return docId;\n  }\n\n  function readAttachmentsAsBlobOrBuffer(res) {\n    res.rows.forEach(function (row) {\n      var atts = row.doc && row.doc._attachments;\n      if (!atts) {\n        return;\n      }\n      Object.keys(atts).forEach(function (filename) {\n        var att = atts[filename];\n        atts[filename].data = b64ToBluffer(att.data, att.content_type);\n      });\n    });\n  }\n\n  function postprocessAttachments(opts) {\n    return function (res) {\n      if (opts.include_docs && opts.attachments && opts.binary) {\n        readAttachmentsAsBlobOrBuffer(res);\n      }\n      return res;\n    };\n  }\n\n  function addHttpParam(paramName, opts, params, asJson) {\n    // add an http param from opts to params, optionally json-encoded\n    var val = opts[paramName];\n    if (typeof val !== 'undefined') {\n      if (asJson) {\n        val = encodeURIComponent(JSON.stringify(val));\n      }\n      params.push(paramName + '=' + val);\n    }\n  }\n\n  function coerceInteger(integerCandidate) {\n    if (typeof integerCandidate !== 'undefined') {\n      var asNumber = Number(integerCandidate);\n      // prevents e.g. '1foo' or '1.1' being coerced to 1\n      if (!isNaN(asNumber) && asNumber === parseInt(integerCandidate, 10)) {\n        return asNumber;\n      } else {\n        return integerCandidate;\n      }\n    }\n  }\n\n  function coerceOptions(opts) {\n    opts.group_level = coerceInteger(opts.group_level);\n    opts.limit = coerceInteger(opts.limit);\n    opts.skip = coerceInteger(opts.skip);\n    return opts;\n  }\n\n  function checkPositiveInteger(number) {\n    if (number) {\n      if (typeof number !== 'number') {\n        return  new QueryParseError('Invalid value for integer: \"' +\n          number + '\"');\n      }\n      if (number < 0) {\n        return new QueryParseError('Invalid value for positive integer: ' +\n          '\"' + number + '\"');\n      }\n    }\n  }\n\n  function checkQueryParseError(options, fun) {\n    var startkeyName = options.descending ? 'endkey' : 'startkey';\n    var endkeyName = options.descending ? 'startkey' : 'endkey';\n\n    if (typeof options[startkeyName] !== 'undefined' &&\n      typeof options[endkeyName] !== 'undefined' &&\n      collate(options[startkeyName], options[endkeyName]) > 0) {\n      throw new QueryParseError('No rows can match your key range, ' +\n        'reverse your start_key and end_key or set {descending : true}');\n    } else if (fun.reduce && options.reduce !== false) {\n      if (options.include_docs) {\n        throw new QueryParseError('{include_docs:true} is invalid for reduce');\n      } else if (options.keys && options.keys.length > 1 &&\n        !options.group && !options.group_level) {\n        throw new QueryParseError('Multi-key fetches for reduce views must use ' +\n          '{group: true}');\n      }\n    }\n    ['group_level', 'limit', 'skip'].forEach(function (optionName) {\n      var error = checkPositiveInteger(options[optionName]);\n      if (error) {\n        throw error;\n      }\n    });\n  }\n\n  function httpQuery(db, fun, opts) {\n    // List of parameters to add to the PUT request\n    var params = [];\n    var body;\n    var method = 'GET';\n\n    // If opts.reduce exists and is defined, then add it to the list\n    // of parameters.\n    // If reduce=false then the results are that of only the map function\n    // not the final result of map and reduce.\n    addHttpParam('reduce', opts, params);\n    addHttpParam('include_docs', opts, params);\n    addHttpParam('attachments', opts, params);\n    addHttpParam('limit', opts, params);\n    addHttpParam('descending', opts, params);\n    addHttpParam('group', opts, params);\n    addHttpParam('group_level', opts, params);\n    addHttpParam('skip', opts, params);\n    addHttpParam('stale', opts, params);\n    addHttpParam('conflicts', opts, params);\n    addHttpParam('startkey', opts, params, true);\n    addHttpParam('start_key', opts, params, true);\n    addHttpParam('endkey', opts, params, true);\n    addHttpParam('end_key', opts, params, true);\n    addHttpParam('inclusive_end', opts, params);\n    addHttpParam('key', opts, params, true);\n    addHttpParam('update_seq', opts, params);\n\n    // Format the list of parameters into a valid URI query string\n    params = params.join('&');\n    params = params === '' ? '' : '?' + params;\n\n    // If keys are supplied, issue a POST to circumvent GET query string limits\n    // see http://wiki.apache.org/couchdb/HTTP_view_API#Querying_Options\n    if (typeof opts.keys !== 'undefined') {\n      var MAX_URL_LENGTH = 2000;\n      // according to http://stackoverflow.com/a/417184/680742,\n      // the de facto URL length limit is 2000 characters\n\n      var keysAsString =\n        'keys=' + encodeURIComponent(JSON.stringify(opts.keys));\n      if (keysAsString.length + params.length + 1 <= MAX_URL_LENGTH) {\n        // If the keys are short enough, do a GET. we do this to work around\n        // Safari not understanding 304s on POSTs (see pouchdb/pouchdb#1239)\n        params += (params[0] === '?' ? '&' : '?') + keysAsString;\n      } else {\n        method = 'POST';\n        if (typeof fun === 'string') {\n          body = {keys: opts.keys};\n        } else { // fun is {map : mapfun}, so append to this\n          fun.keys = opts.keys;\n        }\n      }\n    }\n\n    // We are referencing a query defined in the design doc\n    if (typeof fun === 'string') {\n      var parts = parseViewName(fun);\n      return db.request({\n        method: method,\n        url: '_design/' + parts[0] + '/_view/' + parts[1] + params,\n        body: body\n      }).then(\n        /* istanbul ignore next */\n        function (result) {\n          // fail the entire request if the result contains an error\n          result.rows.forEach(function (row) {\n            if (row.value && row.value.error && row.value.error === \"builtin_reduce_error\") {\n              throw new Error(row.reason);\n            }\n          });\n\n          return result;\n      })\n      .then(postprocessAttachments(opts));\n    }\n\n    // We are using a temporary view, terrible for performance, good for testing\n    body = body || {};\n    Object.keys(fun).forEach(function (key) {\n      if (Array.isArray(fun[key])) {\n        body[key] = fun[key];\n      } else {\n        body[key] = fun[key].toString();\n      }\n    });\n    return db.request({\n      method: 'POST',\n      url: '_temp_view' + params,\n      body: body\n    }).then(postprocessAttachments(opts));\n  }\n\n  // custom adapters can define their own api._query\n  // and override the default behavior\n  /* istanbul ignore next */\n  function customQuery(db, fun, opts) {\n    return new PouchPromise(function (resolve, reject) {\n      db._query(fun, opts, function (err, res) {\n        if (err) {\n          return reject(err);\n        }\n        resolve(res);\n      });\n    });\n  }\n\n  // custom adapters can define their own api._viewCleanup\n  // and override the default behavior\n  /* istanbul ignore next */\n  function customViewCleanup(db) {\n    return new PouchPromise(function (resolve, reject) {\n      db._viewCleanup(function (err, res) {\n        if (err) {\n          return reject(err);\n        }\n        resolve(res);\n      });\n    });\n  }\n\n  function defaultsTo(value) {\n    return function (reason) {\n      /* istanbul ignore else */\n      if (reason.status === 404) {\n        return value;\n      } else {\n        throw reason;\n      }\n    };\n  }\n\n  // returns a promise for a list of docs to update, based on the input docId.\n  // the order doesn't matter, because post-3.2.0, bulkDocs\n  // is an atomic operation in all three adapters.\n  function getDocsToPersist(docId, view, docIdsToChangesAndEmits) {\n    var metaDocId = '_local/doc_' + docId;\n    var defaultMetaDoc = {_id: metaDocId, keys: []};\n    var docData = docIdsToChangesAndEmits.get(docId);\n    var indexableKeysToKeyValues = docData[0];\n    var changes = docData[1];\n\n    function getMetaDoc() {\n      if (isGenOne(changes)) {\n        // generation 1, so we can safely assume initial state\n        // for performance reasons (avoids unnecessary GETs)\n        return PouchPromise.resolve(defaultMetaDoc);\n      }\n      return view.db.get(metaDocId).catch(defaultsTo(defaultMetaDoc));\n    }\n\n    function getKeyValueDocs(metaDoc) {\n      if (!metaDoc.keys.length) {\n        // no keys, no need for a lookup\n        return PouchPromise.resolve({rows: []});\n      }\n      return view.db.allDocs({\n        keys: metaDoc.keys,\n        include_docs: true\n      });\n    }\n\n    function processKeyValueDocs(metaDoc, kvDocsRes) {\n      var kvDocs = [];\n      var oldKeys = new ExportedSet();\n\n      for (var i = 0, len = kvDocsRes.rows.length; i < len; i++) {\n        var row = kvDocsRes.rows[i];\n        var doc = row.doc;\n        if (!doc) { // deleted\n          continue;\n        }\n        kvDocs.push(doc);\n        oldKeys.add(doc._id);\n        doc._deleted = !indexableKeysToKeyValues.has(doc._id);\n        if (!doc._deleted) {\n          var keyValue = indexableKeysToKeyValues.get(doc._id);\n          if ('value' in keyValue) {\n            doc.value = keyValue.value;\n          }\n        }\n      }\n      var newKeys = mapToKeysArray(indexableKeysToKeyValues);\n      newKeys.forEach(function (key) {\n        if (!oldKeys.has(key)) {\n          // new doc\n          var kvDoc = {\n            _id: key\n          };\n          var keyValue = indexableKeysToKeyValues.get(key);\n          if ('value' in keyValue) {\n            kvDoc.value = keyValue.value;\n          }\n          kvDocs.push(kvDoc);\n        }\n      });\n      metaDoc.keys = uniq(newKeys.concat(metaDoc.keys));\n      kvDocs.push(metaDoc);\n\n      return kvDocs;\n    }\n\n    return getMetaDoc().then(function (metaDoc) {\n      return getKeyValueDocs(metaDoc).then(function (kvDocsRes) {\n        return processKeyValueDocs(metaDoc, kvDocsRes);\n      });\n    });\n  }\n\n  // updates all emitted key/value docs and metaDocs in the mrview database\n  // for the given batch of documents from the source database\n  function saveKeyValues(view, docIdsToChangesAndEmits, seq) {\n    var seqDocId = '_local/lastSeq';\n    return view.db.get(seqDocId)\n      .catch(defaultsTo({_id: seqDocId, seq: 0}))\n      .then(function (lastSeqDoc) {\n        var docIds = mapToKeysArray(docIdsToChangesAndEmits);\n        return PouchPromise.all(docIds.map(function (docId) {\n          return getDocsToPersist(docId, view, docIdsToChangesAndEmits);\n        })).then(function (listOfDocsToPersist) {\n          var docsToPersist = flatten(listOfDocsToPersist);\n          lastSeqDoc.seq = seq;\n          docsToPersist.push(lastSeqDoc);\n          // write all docs in a single operation, update the seq once\n          return view.db.bulkDocs({docs : docsToPersist});\n        });\n      });\n  }\n\n  function getQueue(view) {\n    var viewName = typeof view === 'string' ? view : view.name;\n    var queue = persistentQueues[viewName];\n    if (!queue) {\n      queue = persistentQueues[viewName] = new TaskQueue$2();\n    }\n    return queue;\n  }\n\n  function updateView(view) {\n    return sequentialize(getQueue(view), function () {\n      return updateViewInQueue(view);\n    })();\n  }\n\n  function updateViewInQueue(view) {\n    // bind the emit function once\n    var mapResults;\n    var doc;\n\n    function emit(key, value) {\n      var output = {id: doc._id, key: normalizeKey(key)};\n      // Don't explicitly store the value unless it's defined and non-null.\n      // This saves on storage space, because often people don't use it.\n      if (typeof value !== 'undefined' && value !== null) {\n        output.value = normalizeKey(value);\n      }\n      mapResults.push(output);\n    }\n\n    var mapFun = mapper(view.mapFun, emit);\n\n    var currentSeq = view.seq || 0;\n\n    function processChange(docIdsToChangesAndEmits, seq) {\n      return function () {\n        return saveKeyValues(view, docIdsToChangesAndEmits, seq);\n      };\n    }\n\n    var queue = new TaskQueue$2();\n\n    function processNextBatch() {\n      return view.sourceDB.changes({\n        conflicts: true,\n        include_docs: true,\n        style: 'all_docs',\n        since: currentSeq,\n        limit: CHANGES_BATCH_SIZE$1\n      }).then(processBatch);\n    }\n\n    function processBatch(response) {\n      var results = response.results;\n      if (!results.length) {\n        return;\n      }\n      var docIdsToChangesAndEmits = createDocIdsToChangesAndEmits(results);\n      queue.add(processChange(docIdsToChangesAndEmits, currentSeq));\n      if (results.length < CHANGES_BATCH_SIZE$1) {\n        return;\n      }\n      return processNextBatch();\n    }\n\n    function createDocIdsToChangesAndEmits(results) {\n      var docIdsToChangesAndEmits = new ExportedMap();\n      for (var i = 0, len = results.length; i < len; i++) {\n        var change = results[i];\n        if (change.doc._id[0] !== '_') {\n          mapResults = [];\n          doc = change.doc;\n\n          if (!doc._deleted) {\n            tryMap(view.sourceDB, mapFun, doc);\n          }\n          mapResults.sort(sortByKeyThenValue);\n\n          var indexableKeysToKeyValues = createIndexableKeysToKeyValues(mapResults);\n          docIdsToChangesAndEmits.set(change.doc._id, [\n            indexableKeysToKeyValues,\n            change.changes\n          ]);\n        }\n        currentSeq = change.seq;\n      }\n      return docIdsToChangesAndEmits;\n    }\n\n    function createIndexableKeysToKeyValues(mapResults) {\n      var indexableKeysToKeyValues = new ExportedMap();\n      var lastKey;\n      for (var i = 0, len = mapResults.length; i < len; i++) {\n        var emittedKeyValue = mapResults[i];\n        var complexKey = [emittedKeyValue.key, emittedKeyValue.id];\n        if (i > 0 && collate(emittedKeyValue.key, lastKey) === 0) {\n          complexKey.push(i); // dup key+id, so make it unique\n        }\n        indexableKeysToKeyValues.set(toIndexableString(complexKey), emittedKeyValue);\n        lastKey = emittedKeyValue.key;\n      }\n      return indexableKeysToKeyValues;\n    }\n\n    return processNextBatch().then(function () {\n      return queue.finish();\n    }).then(function () {\n      view.seq = currentSeq;\n    });\n  }\n\n  function reduceView(view, results, options) {\n    if (options.group_level === 0) {\n      delete options.group_level;\n    }\n\n    var shouldGroup = options.group || options.group_level;\n\n    var reduceFun = reducer(view.reduceFun);\n\n    var groups = [];\n    var lvl = isNaN(options.group_level) ? Number.POSITIVE_INFINITY :\n      options.group_level;\n    results.forEach(function (e) {\n      var last = groups[groups.length - 1];\n      var groupKey = shouldGroup ? e.key : null;\n\n      // only set group_level for array keys\n      if (shouldGroup && Array.isArray(groupKey)) {\n        groupKey = groupKey.slice(0, lvl);\n      }\n\n      if (last && collate(last.groupKey, groupKey) === 0) {\n        last.keys.push([e.key, e.id]);\n        last.values.push(e.value);\n        return;\n      }\n      groups.push({\n        keys: [[e.key, e.id]],\n        values: [e.value],\n        groupKey: groupKey\n      });\n    });\n    results = [];\n    for (var i = 0, len = groups.length; i < len; i++) {\n      var e = groups[i];\n      var reduceTry = tryReduce(view.sourceDB, reduceFun, e.keys, e.values, false);\n      if (reduceTry.error && reduceTry.error instanceof BuiltInError) {\n        // CouchDB returns an error if a built-in errors out\n        throw reduceTry.error;\n      }\n      results.push({\n        // CouchDB just sets the value to null if a non-built-in errors out\n        value: reduceTry.error ? null : reduceTry.output,\n        key: e.groupKey\n      });\n    }\n    // no total_rows/offset when reducing\n    return {rows: sliceResults(results, options.limit, options.skip)};\n  }\n\n  function queryView(view, opts) {\n    return sequentialize(getQueue(view), function () {\n      return queryViewInQueue(view, opts);\n    })();\n  }\n\n  function queryViewInQueue(view, opts) {\n    var totalRows;\n    var shouldReduce = view.reduceFun && opts.reduce !== false;\n    var skip = opts.skip || 0;\n    if (typeof opts.keys !== 'undefined' && !opts.keys.length) {\n      // equivalent query\n      opts.limit = 0;\n      delete opts.keys;\n    }\n\n    function fetchFromView(viewOpts) {\n      viewOpts.include_docs = true;\n      return view.db.allDocs(viewOpts).then(function (res) {\n        totalRows = res.total_rows;\n        return res.rows.map(function (result) {\n\n          // implicit migration - in older versions of PouchDB,\n          // we explicitly stored the doc as {id: ..., key: ..., value: ...}\n          // this is tested in a migration test\n          /* istanbul ignore next */\n          if ('value' in result.doc && typeof result.doc.value === 'object' &&\n            result.doc.value !== null) {\n            var keys = Object.keys(result.doc.value).sort();\n            // this detection method is not perfect, but it's unlikely the user\n            // emitted a value which was an object with these 3 exact keys\n            var expectedKeys = ['id', 'key', 'value'];\n            if (!(keys < expectedKeys || keys > expectedKeys)) {\n              return result.doc.value;\n            }\n          }\n\n          var parsedKeyAndDocId = parseIndexableString(result.doc._id);\n          return {\n            key: parsedKeyAndDocId[0],\n            id: parsedKeyAndDocId[1],\n            value: ('value' in result.doc ? result.doc.value : null)\n          };\n        });\n      });\n    }\n\n    function onMapResultsReady(rows) {\n      var finalResults;\n      if (shouldReduce) {\n        finalResults = reduceView(view, rows, opts);\n      } else {\n        finalResults = {\n          total_rows: totalRows,\n          offset: skip,\n          rows: rows\n        };\n      }\n      /* istanbul ignore if */\n      if (opts.update_seq) {\n        finalResults.update_seq = view.seq;\n      }\n      if (opts.include_docs) {\n        var docIds = uniq(rows.map(rowToDocId));\n\n        return view.sourceDB.allDocs({\n          keys: docIds,\n          include_docs: true,\n          conflicts: opts.conflicts,\n          attachments: opts.attachments,\n          binary: opts.binary\n        }).then(function (allDocsRes) {\n          var docIdsToDocs = new ExportedMap();\n          allDocsRes.rows.forEach(function (row) {\n            docIdsToDocs.set(row.id, row.doc);\n          });\n          rows.forEach(function (row) {\n            var docId = rowToDocId(row);\n            var doc = docIdsToDocs.get(docId);\n            if (doc) {\n              row.doc = doc;\n            }\n          });\n          return finalResults;\n        });\n      } else {\n        return finalResults;\n      }\n    }\n\n    if (typeof opts.keys !== 'undefined') {\n      var keys = opts.keys;\n      var fetchPromises = keys.map(function (key) {\n        var viewOpts = {\n          startkey : toIndexableString([key]),\n          endkey   : toIndexableString([key, {}])\n        };\n        /* istanbul ignore if */\n        if (opts.update_seq) {\n          viewOpts.update_seq = true;\n        }\n        return fetchFromView(viewOpts);\n      });\n      return PouchPromise.all(fetchPromises).then(flatten).then(onMapResultsReady);\n    } else { // normal query, no 'keys'\n      var viewOpts = {\n        descending : opts.descending\n      };\n      /* istanbul ignore if */\n      if (opts.update_seq) {\n        viewOpts.update_seq = true;\n      }\n      var startkey;\n      var endkey;\n      if ('start_key' in opts) {\n        startkey = opts.start_key;\n      }\n      if ('startkey' in opts) {\n        startkey = opts.startkey;\n      }\n      if ('end_key' in opts) {\n        endkey = opts.end_key;\n      }\n      if ('endkey' in opts) {\n        endkey = opts.endkey;\n      }\n      if (typeof startkey !== 'undefined') {\n        viewOpts.startkey = opts.descending ?\n          toIndexableString([startkey, {}]) :\n          toIndexableString([startkey]);\n      }\n      if (typeof endkey !== 'undefined') {\n        var inclusiveEnd = opts.inclusive_end !== false;\n        if (opts.descending) {\n          inclusiveEnd = !inclusiveEnd;\n        }\n\n        viewOpts.endkey = toIndexableString(\n          inclusiveEnd ? [endkey, {}] : [endkey]);\n      }\n      if (typeof opts.key !== 'undefined') {\n        var keyStart = toIndexableString([opts.key]);\n        var keyEnd = toIndexableString([opts.key, {}]);\n        if (viewOpts.descending) {\n          viewOpts.endkey = keyStart;\n          viewOpts.startkey = keyEnd;\n        } else {\n          viewOpts.startkey = keyStart;\n          viewOpts.endkey = keyEnd;\n        }\n      }\n      if (!shouldReduce) {\n        if (typeof opts.limit === 'number') {\n          viewOpts.limit = opts.limit;\n        }\n        viewOpts.skip = skip;\n      }\n      return fetchFromView(viewOpts).then(onMapResultsReady);\n    }\n  }\n\n  function httpViewCleanup(db) {\n    return db.request({\n      method: 'POST',\n      url: '_view_cleanup'\n    });\n  }\n\n  function localViewCleanup(db) {\n    return db.get('_local/' + localDocName).then(function (metaDoc) {\n      var docsToViews = new ExportedMap();\n      Object.keys(metaDoc.views).forEach(function (fullViewName) {\n        var parts = parseViewName(fullViewName);\n        var designDocName = '_design/' + parts[0];\n        var viewName = parts[1];\n        var views = docsToViews.get(designDocName);\n        if (!views) {\n          views = new ExportedSet();\n          docsToViews.set(designDocName, views);\n        }\n        views.add(viewName);\n      });\n      var opts = {\n        keys : mapToKeysArray(docsToViews),\n        include_docs : true\n      };\n      return db.allDocs(opts).then(function (res) {\n        var viewsToStatus = {};\n        res.rows.forEach(function (row) {\n          var ddocName = row.key.substring(8); // cuts off '_design/'\n          docsToViews.get(row.key).forEach(function (viewName) {\n            var fullViewName = ddocName + '/' + viewName;\n            /* istanbul ignore if */\n            if (!metaDoc.views[fullViewName]) {\n              // new format, without slashes, to support PouchDB 2.2.0\n              // migration test in pouchdb's browser.migration.js verifies this\n              fullViewName = viewName;\n            }\n            var viewDBNames = Object.keys(metaDoc.views[fullViewName]);\n            // design doc deleted, or view function nonexistent\n            var statusIsGood = row.doc && row.doc.views &&\n              row.doc.views[viewName];\n            viewDBNames.forEach(function (viewDBName) {\n              viewsToStatus[viewDBName] =\n                viewsToStatus[viewDBName] || statusIsGood;\n            });\n          });\n        });\n        var dbsToDelete = Object.keys(viewsToStatus).filter(\n          function (viewDBName) { return !viewsToStatus[viewDBName]; });\n        var destroyPromises = dbsToDelete.map(function (viewDBName) {\n          return sequentialize(getQueue(viewDBName), function () {\n            return new db.constructor(viewDBName, db.__opts).destroy();\n          })();\n        });\n        return PouchPromise.all(destroyPromises).then(function () {\n          return {ok: true};\n        });\n      });\n    }, defaultsTo({ok: true}));\n  }\n\n  function queryPromised(db, fun, opts) {\n    /* istanbul ignore next */\n    if (typeof db._query === 'function') {\n      return customQuery(db, fun, opts);\n    }\n    if (isRemote(db)) {\n      return httpQuery(db, fun, opts);\n    }\n    \n    if (typeof fun !== 'string') {\n      // temp_view\n      checkQueryParseError(opts, fun);\n\n      tempViewQueue.add(function () {\n        var createViewPromise = createView(\n          /* sourceDB */ db,\n          /* viewName */ 'temp_view/temp_view',\n          /* mapFun */ fun.map,\n          /* reduceFun */ fun.reduce,\n          /* temporary */ true,\n          /* localDocName */ localDocName);\n        return createViewPromise.then(function (view) {\n          return fin(updateView(view).then(function () {\n            return queryView(view, opts);\n          }), function () {\n            return view.db.destroy();\n          });\n        });\n      });\n      return tempViewQueue.finish();\n    } else {\n      // persistent view\n      var fullViewName = fun;\n      var parts = parseViewName(fullViewName);\n      var designDocName = parts[0];\n      var viewName = parts[1];\n      return db.get('_design/' + designDocName).then(function (doc) {\n        var fun = doc.views && doc.views[viewName];\n\n        if (!fun) {\n          // basic validator; it's assumed that every subclass would want this\n          throw new NotFoundError('ddoc ' + doc._id + ' has no view named ' +\n            viewName);\n        }\n\n        ddocValidator(doc, viewName);\n        checkQueryParseError(opts, fun);\n\n        var createViewPromise = createView(\n          /* sourceDB */ db,\n          /* viewName */ fullViewName,\n          /* mapFun */ fun.map,\n          /* reduceFun */ fun.reduce,\n          /* temporary */ false,\n          /* localDocName */ localDocName);\n        return createViewPromise.then(function (view) {\n          if (opts.stale === 'ok' || opts.stale === 'update_after') {\n            if (opts.stale === 'update_after') {\n              __WEBPACK_IMPORTED_MODULE_2_immediate___default()(function () {\n                updateView(view);\n              });\n            }\n            return queryView(view, opts);\n          } else { // stale not ok\n            return updateView(view).then(function () {\n              return queryView(view, opts);\n            });\n          }\n        });\n      });\n    }\n  }\n\n  function abstractQuery(fun, opts, callback) {\n    var db = this;\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = opts ? coerceOptions(opts) : {};\n\n    if (typeof fun === 'function') {\n      fun = {map : fun};\n    }\n\n    var promise = PouchPromise.resolve().then(function () {\n      return queryPromised(db, fun, opts);\n    });\n    promisedCallback(promise, callback);\n    return promise;\n  }\n\n  var abstractViewCleanup = callbackify(function () {\n    var db = this;\n    /* istanbul ignore next */\n    if (typeof db._viewCleanup === 'function') {\n      return customViewCleanup(db);\n    }\n    if (isRemote(db)) {\n      return httpViewCleanup(db);\n    }\n    return localViewCleanup(db);\n  });\n\n  return {\n    query: abstractQuery,\n    viewCleanup: abstractViewCleanup\n  };\n}\n\nvar builtInReduce = {\n  _sum: function (keys, values) {\n    return sum(values);\n  },\n\n  _count: function (keys, values) {\n    return values.length;\n  },\n\n  _stats: function (keys, values) {\n    // no need to implement rereduce=true, because Pouch\n    // will never call it\n    function sumsqr(values) {\n      var _sumsqr = 0;\n      for (var i = 0, len = values.length; i < len; i++) {\n        var num = values[i];\n        _sumsqr += (num * num);\n      }\n      return _sumsqr;\n    }\n    return {\n      sum     : sum(values),\n      min     : Math.min.apply(null, values),\n      max     : Math.max.apply(null, values),\n      count   : values.length,\n      sumsqr : sumsqr(values)\n    };\n  }\n};\n\nfunction getBuiltIn(reduceFunString) {\n  if (/^_sum/.test(reduceFunString)) {\n    return builtInReduce._sum;\n  } else if (/^_count/.test(reduceFunString)) {\n    return builtInReduce._count;\n  } else if (/^_stats/.test(reduceFunString)) {\n    return builtInReduce._stats;\n  } else if (/^_/.test(reduceFunString)) {\n    throw new Error(reduceFunString + ' is not a supported reduce function.');\n  }\n}\n\nfunction mapper(mapFun, emit) {\n  // for temp_views one can use emit(doc, emit), see #38\n  if (typeof mapFun === \"function\" && mapFun.length === 2) {\n    var origMap = mapFun;\n    return function (doc) {\n      return origMap(doc, emit);\n    };\n  } else {\n    return evalFunctionWithEval(mapFun.toString(), emit);\n  }\n}\n\nfunction reducer(reduceFun) {\n  var reduceFunString = reduceFun.toString();\n  var builtIn = getBuiltIn(reduceFunString);\n  if (builtIn) {\n    return builtIn;\n  } else {\n    return evalFunctionWithEval(reduceFunString);\n  }\n}\n\nfunction ddocValidator(ddoc, viewName) {\n  var fun = ddoc.views && ddoc.views[viewName];\n  if (typeof fun.map !== 'string') {\n    throw new NotFoundError('ddoc ' + ddoc._id + ' has no string view named ' +\n      viewName + ', instead found object of type: ' + typeof fun.map);\n  }\n}\n\nvar localDocName = 'mrviews';\nvar abstract = createAbstractMapReduce(localDocName, mapper, reducer, ddocValidator);\n\nfunction query(fun, opts, callback) {\n  return abstract.query.call(this, fun, opts, callback);\n}\n\nfunction viewCleanup(callback) {\n  return abstract.viewCleanup.call(this, callback);\n}\n\nvar mapreduce = {\n  query: query,\n  viewCleanup: viewCleanup\n};\n\nfunction isGenOne$1(rev$$1) {\n  return /^1-/.test(rev$$1);\n}\n\nfunction fileHasChanged(localDoc, remoteDoc, filename) {\n  return !localDoc._attachments ||\n         !localDoc._attachments[filename] ||\n         localDoc._attachments[filename].digest !== remoteDoc._attachments[filename].digest;\n}\n\nfunction getDocAttachments(db, doc) {\n  var filenames = Object.keys(doc._attachments);\n  return PouchPromise.all(filenames.map(function (filename) {\n    return db.getAttachment(doc._id, filename, {rev: doc._rev});\n  }));\n}\n\nfunction getDocAttachmentsFromTargetOrSource(target, src, doc) {\n  var doCheckForLocalAttachments = isRemote(src) && !isRemote(target);\n  var filenames = Object.keys(doc._attachments);\n\n  if (!doCheckForLocalAttachments) {\n    return getDocAttachments(src, doc);\n  }\n\n  return target.get(doc._id).then(function (localDoc) {\n    return PouchPromise.all(filenames.map(function (filename) {\n      if (fileHasChanged(localDoc, doc, filename)) {\n        return src.getAttachment(doc._id, filename);\n      }\n\n      return target.getAttachment(localDoc._id, filename);\n    }));\n  }).catch(function (error) {\n    /* istanbul ignore if */\n    if (error.status !== 404) {\n      throw error;\n    }\n\n    return getDocAttachments(src, doc);\n  });\n}\n\nfunction createBulkGetOpts(diffs) {\n  var requests = [];\n  Object.keys(diffs).forEach(function (id) {\n    var missingRevs = diffs[id].missing;\n    missingRevs.forEach(function (missingRev) {\n      requests.push({\n        id: id,\n        rev: missingRev\n      });\n    });\n  });\n\n  return {\n    docs: requests,\n    revs: true,\n    latest: true\n  };\n}\n\n//\n// Fetch all the documents from the src as described in the \"diffs\",\n// which is a mapping of docs IDs to revisions. If the state ever\n// changes to \"cancelled\", then the returned promise will be rejected.\n// Else it will be resolved with a list of fetched documents.\n//\nfunction getDocs(src, target, diffs, state) {\n  diffs = clone(diffs); // we do not need to modify this\n\n  var resultDocs = [],\n      ok = true;\n\n  function getAllDocs() {\n\n    var bulkGetOpts = createBulkGetOpts(diffs);\n\n    if (!bulkGetOpts.docs.length) { // optimization: skip empty requests\n      return;\n    }\n\n    return src.bulkGet(bulkGetOpts).then(function (bulkGetResponse) {\n      /* istanbul ignore if */\n      if (state.cancelled) {\n        throw new Error('cancelled');\n      }\n      return PouchPromise.all(bulkGetResponse.results.map(function (bulkGetInfo) {\n        return PouchPromise.all(bulkGetInfo.docs.map(function (doc) {\n          var remoteDoc = doc.ok;\n\n          if (doc.error) {\n            // when AUTO_COMPACTION is set, docs can be returned which look\n            // like this: {\"missing\":\"1-7c3ac256b693c462af8442f992b83696\"}\n            ok = false;\n          }\n\n          if (!remoteDoc || !remoteDoc._attachments) {\n            return remoteDoc;\n          }\n\n          return getDocAttachmentsFromTargetOrSource(target, src, remoteDoc)\n                   .then(function (attachments) {\n                           var filenames = Object.keys(remoteDoc._attachments);\n                           attachments\n                             .forEach(function (attachment, i) {\n                                        var att = remoteDoc._attachments[filenames[i]];\n                                        delete att.stub;\n                                        delete att.length;\n                                        att.data = attachment;\n                                      });\n\n                                      return remoteDoc;\n                                    });\n        }));\n      }))\n\n      .then(function (results) {\n        resultDocs = resultDocs.concat(flatten(results).filter(Boolean));\n      });\n    });\n  }\n\n  function hasAttachments(doc) {\n    return doc._attachments && Object.keys(doc._attachments).length > 0;\n  }\n\n  function hasConflicts(doc) {\n    return doc._conflicts && doc._conflicts.length > 0;\n  }\n\n  function fetchRevisionOneDocs(ids) {\n    // Optimization: fetch gen-1 docs and attachments in\n    // a single request using _all_docs\n    return src.allDocs({\n      keys: ids,\n      include_docs: true,\n      conflicts: true\n    }).then(function (res) {\n      if (state.cancelled) {\n        throw new Error('cancelled');\n      }\n      res.rows.forEach(function (row) {\n        if (row.deleted || !row.doc || !isGenOne$1(row.value.rev) ||\n            hasAttachments(row.doc) || hasConflicts(row.doc)) {\n          // if any of these conditions apply, we need to fetch using get()\n          return;\n        }\n\n        // strip _conflicts array to appease CSG (#5793)\n        /* istanbul ignore if */\n        if (row.doc._conflicts) {\n          delete row.doc._conflicts;\n        }\n\n        // the doc we got back from allDocs() is sufficient\n        resultDocs.push(row.doc);\n        delete diffs[row.id];\n      });\n    });\n  }\n\n  function getRevisionOneDocs() {\n    // filter out the generation 1 docs and get them\n    // leaving the non-generation one docs to be got otherwise\n    var ids = Object.keys(diffs).filter(function (id) {\n      var missing = diffs[id].missing;\n      return missing.length === 1 && isGenOne$1(missing[0]);\n    });\n    if (ids.length > 0) {\n      return fetchRevisionOneDocs(ids);\n    }\n  }\n\n  function returnResult() {\n    return { ok:ok, docs:resultDocs };\n  }\n\n  return PouchPromise.resolve()\n    .then(getRevisionOneDocs)\n    .then(getAllDocs)\n    .then(returnResult);\n}\n\nvar CHECKPOINT_VERSION = 1;\nvar REPLICATOR = \"pouchdb\";\n// This is an arbitrary number to limit the\n// amount of replication history we save in the checkpoint.\n// If we save too much, the checkpoing docs will become very big,\n// if we save fewer, we'll run a greater risk of having to\n// read all the changes from 0 when checkpoint PUTs fail\n// CouchDB 2.0 has a more involved history pruning,\n// but let's go for the simple version for now.\nvar CHECKPOINT_HISTORY_SIZE = 5;\nvar LOWEST_SEQ = 0;\n\nfunction updateCheckpoint(db, id, checkpoint, session, returnValue) {\n  return db.get(id).catch(function (err) {\n    if (err.status === 404) {\n      if (db.adapter === 'http' || db.adapter === 'https') {\n        explainError(\n          404, 'PouchDB is just checking if a remote checkpoint exists.'\n        );\n      }\n      return {\n        session_id: session,\n        _id: id,\n        history: [],\n        replicator: REPLICATOR,\n        version: CHECKPOINT_VERSION\n      };\n    }\n    throw err;\n  }).then(function (doc) {\n    if (returnValue.cancelled) {\n      return;\n    }\n\n    // if the checkpoint has not changed, do not update\n    if (doc.last_seq === checkpoint) {\n      return;\n    }\n\n    // Filter out current entry for this replication\n    doc.history = (doc.history || []).filter(function (item) {\n      return item.session_id !== session;\n    });\n\n    // Add the latest checkpoint to history\n    doc.history.unshift({\n      last_seq: checkpoint,\n      session_id: session\n    });\n\n    // Just take the last pieces in history, to\n    // avoid really big checkpoint docs.\n    // see comment on history size above\n    doc.history = doc.history.slice(0, CHECKPOINT_HISTORY_SIZE);\n\n    doc.version = CHECKPOINT_VERSION;\n    doc.replicator = REPLICATOR;\n\n    doc.session_id = session;\n    doc.last_seq = checkpoint;\n\n    return db.put(doc).catch(function (err) {\n      if (err.status === 409) {\n        // retry; someone is trying to write a checkpoint simultaneously\n        return updateCheckpoint(db, id, checkpoint, session, returnValue);\n      }\n      throw err;\n    });\n  });\n}\n\nfunction Checkpointer(src, target, id, returnValue, opts) {\n  this.src = src;\n  this.target = target;\n  this.id = id;\n  this.returnValue = returnValue;\n  this.opts = opts || {};\n}\n\nCheckpointer.prototype.writeCheckpoint = function (checkpoint, session) {\n  var self = this;\n  return this.updateTarget(checkpoint, session).then(function () {\n    return self.updateSource(checkpoint, session);\n  });\n};\n\nCheckpointer.prototype.updateTarget = function (checkpoint, session) {\n  if (this.opts.writeTargetCheckpoint) {\n    return updateCheckpoint(this.target, this.id, checkpoint,\n      session, this.returnValue);\n  } else {\n    return PouchPromise.resolve(true);\n  }\n};\n\nCheckpointer.prototype.updateSource = function (checkpoint, session) {\n  if (this.opts.writeSourceCheckpoint) {\n    var self = this;\n    return updateCheckpoint(this.src, this.id, checkpoint,\n      session, this.returnValue)\n      .catch(function (err) {\n        if (isForbiddenError(err)) {\n          self.opts.writeSourceCheckpoint = false;\n          return true;\n        }\n        throw err;\n      });\n  } else {\n    return PouchPromise.resolve(true);\n  }\n};\n\nvar comparisons = {\n  \"undefined\": function (targetDoc, sourceDoc) {\n    // This is the previous comparison function\n    if (collate(targetDoc.last_seq, sourceDoc.last_seq) === 0) {\n      return sourceDoc.last_seq;\n    }\n    /* istanbul ignore next */\n    return 0;\n  },\n  \"1\": function (targetDoc, sourceDoc) {\n    // This is the comparison function ported from CouchDB\n    return compareReplicationLogs(sourceDoc, targetDoc).last_seq;\n  }\n};\n\nCheckpointer.prototype.getCheckpoint = function () {\n  var self = this;\n\n  if (self.opts && self.opts.writeSourceCheckpoint && !self.opts.writeTargetCheckpoint) {\n    return self.src.get(self.id).then(function (sourceDoc) {\n      return sourceDoc.last_seq || LOWEST_SEQ;\n    }).catch(function (err) {\n      /* istanbul ignore if */\n      if (err.status !== 404) {\n        throw err;\n      }\n      return LOWEST_SEQ;\n    });\n  }\n\n  return self.target.get(self.id).then(function (targetDoc) {\n    if (self.opts && self.opts.writeTargetCheckpoint && !self.opts.writeSourceCheckpoint) {\n      return targetDoc.last_seq || LOWEST_SEQ;\n    }\n\n    return self.src.get(self.id).then(function (sourceDoc) {\n      // Since we can't migrate an old version doc to a new one\n      // (no session id), we just go with the lowest seq in this case\n      /* istanbul ignore if */\n      if (targetDoc.version !== sourceDoc.version) {\n        return LOWEST_SEQ;\n      }\n\n      var version;\n      if (targetDoc.version) {\n        version = targetDoc.version.toString();\n      } else {\n        version = \"undefined\";\n      }\n\n      if (version in comparisons) {\n        return comparisons[version](targetDoc, sourceDoc);\n      }\n      /* istanbul ignore next */\n      return LOWEST_SEQ;\n    }, function (err) {\n      if (err.status === 404 && targetDoc.last_seq) {\n        return self.src.put({\n          _id: self.id,\n          last_seq: LOWEST_SEQ\n        }).then(function () {\n          return LOWEST_SEQ;\n        }, function (err) {\n          if (isForbiddenError(err)) {\n            self.opts.writeSourceCheckpoint = false;\n            return targetDoc.last_seq;\n          }\n          /* istanbul ignore next */\n          return LOWEST_SEQ;\n        });\n      }\n      throw err;\n    });\n  }).catch(function (err) {\n    if (err.status !== 404) {\n      throw err;\n    }\n    return LOWEST_SEQ;\n  });\n};\n// This checkpoint comparison is ported from CouchDBs source\n// they come from here:\n// https://github.com/apache/couchdb-couch-replicator/blob/master/src/couch_replicator.erl#L863-L906\n\nfunction compareReplicationLogs(srcDoc, tgtDoc) {\n  if (srcDoc.session_id === tgtDoc.session_id) {\n    return {\n      last_seq: srcDoc.last_seq,\n      history: srcDoc.history\n    };\n  }\n\n  return compareReplicationHistory(srcDoc.history, tgtDoc.history);\n}\n\nfunction compareReplicationHistory(sourceHistory, targetHistory) {\n  // the erlang loop via function arguments is not so easy to repeat in JS\n  // therefore, doing this as recursion\n  var S = sourceHistory[0];\n  var sourceRest = sourceHistory.slice(1);\n  var T = targetHistory[0];\n  var targetRest = targetHistory.slice(1);\n\n  if (!S || targetHistory.length === 0) {\n    return {\n      last_seq: LOWEST_SEQ,\n      history: []\n    };\n  }\n\n  var sourceId = S.session_id;\n  /* istanbul ignore if */\n  if (hasSessionId(sourceId, targetHistory)) {\n    return {\n      last_seq: S.last_seq,\n      history: sourceHistory\n    };\n  }\n\n  var targetId = T.session_id;\n  if (hasSessionId(targetId, sourceRest)) {\n    return {\n      last_seq: T.last_seq,\n      history: targetRest\n    };\n  }\n\n  return compareReplicationHistory(sourceRest, targetRest);\n}\n\nfunction hasSessionId(sessionId, history) {\n  var props = history[0];\n  var rest = history.slice(1);\n\n  if (!sessionId || history.length === 0) {\n    return false;\n  }\n\n  if (sessionId === props.session_id) {\n    return true;\n  }\n\n  return hasSessionId(sessionId, rest);\n}\n\nfunction isForbiddenError(err) {\n  return typeof err.status === 'number' && Math.floor(err.status / 100) === 4;\n}\n\nvar STARTING_BACK_OFF = 0;\n\nfunction backOff(opts, returnValue, error, callback) {\n  if (opts.retry === false) {\n    returnValue.emit('error', error);\n    returnValue.removeAllListeners();\n    return;\n  }\n  if (typeof opts.back_off_function !== 'function') {\n    opts.back_off_function = defaultBackOff;\n  }\n  returnValue.emit('requestError', error);\n  if (returnValue.state === 'active' || returnValue.state === 'pending') {\n    returnValue.emit('paused', error);\n    returnValue.state = 'stopped';\n    var backOffSet = function backoffTimeSet() {\n      opts.current_back_off = STARTING_BACK_OFF;\n    };\n    var removeBackOffSetter = function removeBackOffTimeSet() {\n      returnValue.removeListener('active', backOffSet);\n    };\n    returnValue.once('paused', removeBackOffSetter);\n    returnValue.once('active', backOffSet);\n  }\n\n  opts.current_back_off = opts.current_back_off || STARTING_BACK_OFF;\n  opts.current_back_off = opts.back_off_function(opts.current_back_off);\n  setTimeout(callback, opts.current_back_off);\n}\n\nfunction sortObjectPropertiesByKey(queryParams) {\n  return Object.keys(queryParams).sort(collate).reduce(function (result, key) {\n    result[key] = queryParams[key];\n    return result;\n  }, {});\n}\n\n// Generate a unique id particular to this replication.\n// Not guaranteed to align perfectly with CouchDB's rep ids.\nfunction generateReplicationId(src, target, opts) {\n  var docIds = opts.doc_ids ? opts.doc_ids.sort(collate) : '';\n  var filterFun = opts.filter ? opts.filter.toString() : '';\n  var queryParams = '';\n  var filterViewName =  '';\n  var selector = '';\n\n  // possibility for checkpoints to be lost here as behaviour of\n  // JSON.stringify is not stable (see #6226)\n  /* istanbul ignore if */\n  if (opts.selector) {\n    selector = JSON.stringify(opts.selector);\n  }\n\n  if (opts.filter && opts.query_params) {\n    queryParams = JSON.stringify(sortObjectPropertiesByKey(opts.query_params));\n  }\n\n  if (opts.filter && opts.filter === '_view') {\n    filterViewName = opts.view.toString();\n  }\n\n  return PouchPromise.all([src.id(), target.id()]).then(function (res) {\n    var queryData = res[0] + res[1] + filterFun + filterViewName +\n      queryParams + docIds + selector;\n    return new PouchPromise(function (resolve) {\n      binaryMd5(queryData, resolve);\n    });\n  }).then(function (md5sum) {\n    // can't use straight-up md5 alphabet, because\n    // the char '/' is interpreted as being for attachments,\n    // and + is also not url-safe\n    md5sum = md5sum.replace(/\\//g, '.').replace(/\\+/g, '_');\n    return '_local/' + md5sum;\n  });\n}\n\nfunction replicate(src, target, opts, returnValue, result) {\n  var batches = [];               // list of batches to be processed\n  var currentBatch;               // the batch currently being processed\n  var pendingBatch = {\n    seq: 0,\n    changes: [],\n    docs: []\n  }; // next batch, not yet ready to be processed\n  var writingCheckpoint = false;  // true while checkpoint is being written\n  var changesCompleted = false;   // true when all changes received\n  var replicationCompleted = false; // true when replication has completed\n  var last_seq = 0;\n  var continuous = opts.continuous || opts.live || false;\n  var batch_size = opts.batch_size || 100;\n  var batches_limit = opts.batches_limit || 10;\n  var changesPending = false;     // true while src.changes is running\n  var doc_ids = opts.doc_ids;\n  var selector = opts.selector;\n  var repId;\n  var checkpointer;\n  var changedDocs = [];\n  // Like couchdb, every replication gets a unique session id\n  var session = uuid();\n  var seq_interval = opts.seq_interval;\n\n  result = result || {\n    ok: true,\n    start_time: new Date(),\n    docs_read: 0,\n    docs_written: 0,\n    doc_write_failures: 0,\n    errors: []\n  };\n\n  var changesOpts = {};\n  returnValue.ready(src, target);\n\n  function initCheckpointer() {\n    if (checkpointer) {\n      return PouchPromise.resolve();\n    }\n    return generateReplicationId(src, target, opts).then(function (res) {\n      repId = res;\n\n      var checkpointOpts = {};\n      if (opts.checkpoint === false) {\n        checkpointOpts = { writeSourceCheckpoint: false, writeTargetCheckpoint: false };\n      } else if (opts.checkpoint === 'source') {\n        checkpointOpts = { writeSourceCheckpoint: true, writeTargetCheckpoint: false };\n      } else if (opts.checkpoint === 'target') {\n        checkpointOpts = { writeSourceCheckpoint: false, writeTargetCheckpoint: true };\n      } else {\n        checkpointOpts = { writeSourceCheckpoint: true, writeTargetCheckpoint: true };\n      }\n\n      checkpointer = new Checkpointer(src, target, repId, returnValue, checkpointOpts);\n    });\n  }\n\n  function writeDocs() {\n    changedDocs = [];\n\n    if (currentBatch.docs.length === 0) {\n      return;\n    }\n    var docs = currentBatch.docs;\n    var bulkOpts = {timeout: opts.timeout};\n    return target.bulkDocs({docs: docs, new_edits: false}, bulkOpts).then(function (res) {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n\n      // `res` doesn't include full documents (which live in `docs`), so we create a map of \n      // (id -> error), and check for errors while iterating over `docs`\n      var errorsById = Object.create(null);\n      res.forEach(function (res) {\n        if (res.error) {\n          errorsById[res.id] = res;\n        }\n      });\n\n      var errorsNo = Object.keys(errorsById).length;\n      result.doc_write_failures += errorsNo;\n      result.docs_written += docs.length - errorsNo;\n\n      docs.forEach(function (doc) {\n        var error = errorsById[doc._id];\n        if (error) {\n          result.errors.push(error);\n          // Normalize error name. i.e. 'Unauthorized' -> 'unauthorized' (eg Sync Gateway)\n          var errorName = (error.name || '').toLowerCase();\n          if (errorName === 'unauthorized' || errorName === 'forbidden') {\n            returnValue.emit('denied', clone(error));\n          } else {\n            throw error;\n          }\n        } else {\n          changedDocs.push(doc);\n        }\n      });\n\n    }, function (err) {\n      result.doc_write_failures += docs.length;\n      throw err;\n    });\n  }\n\n  function finishBatch() {\n    if (currentBatch.error) {\n      throw new Error('There was a problem getting docs.');\n    }\n    result.last_seq = last_seq = currentBatch.seq;\n    var outResult = clone(result);\n    if (changedDocs.length) {\n      outResult.docs = changedDocs;\n      // Attach 'pending' property if server supports it (CouchDB 2.0+)\n      /* istanbul ignore if */\n      if (typeof currentBatch.pending === 'number') {\n        outResult.pending = currentBatch.pending;\n        delete currentBatch.pending;\n      }\n      returnValue.emit('change', outResult);\n    }\n    writingCheckpoint = true;\n    return checkpointer.writeCheckpoint(currentBatch.seq,\n        session).then(function () {\n      writingCheckpoint = false;\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n      currentBatch = undefined;\n      getChanges();\n    }).catch(function (err) {\n      onCheckpointError(err);\n      throw err;\n    });\n  }\n\n  function getDiffs() {\n    var diff = {};\n    currentBatch.changes.forEach(function (change) {\n      // Couchbase Sync Gateway emits these, but we can ignore them\n      /* istanbul ignore if */\n      if (change.id === \"_user/\") {\n        return;\n      }\n      diff[change.id] = change.changes.map(function (x) {\n        return x.rev;\n      });\n    });\n    return target.revsDiff(diff).then(function (diffs) {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n      // currentBatch.diffs elements are deleted as the documents are written\n      currentBatch.diffs = diffs;\n    });\n  }\n\n  function getBatchDocs() {\n    return getDocs(src, target, currentBatch.diffs, returnValue).then(function (got) {\n      currentBatch.error = !got.ok;\n      got.docs.forEach(function (doc) {\n        delete currentBatch.diffs[doc._id];\n        result.docs_read++;\n        currentBatch.docs.push(doc);\n      });\n    });\n  }\n\n  function startNextBatch() {\n    if (returnValue.cancelled || currentBatch) {\n      return;\n    }\n    if (batches.length === 0) {\n      processPendingBatch(true);\n      return;\n    }\n    currentBatch = batches.shift();\n    getDiffs()\n      .then(getBatchDocs)\n      .then(writeDocs)\n      .then(finishBatch)\n      .then(startNextBatch)\n      .catch(function (err) {\n        abortReplication('batch processing terminated with error', err);\n      });\n  }\n\n\n  function processPendingBatch(immediate) {\n    if (pendingBatch.changes.length === 0) {\n      if (batches.length === 0 && !currentBatch) {\n        if ((continuous && changesOpts.live) || changesCompleted) {\n          returnValue.state = 'pending';\n          returnValue.emit('paused');\n        }\n        if (changesCompleted) {\n          completeReplication();\n        }\n      }\n      return;\n    }\n    if (\n      immediate ||\n      changesCompleted ||\n      pendingBatch.changes.length >= batch_size\n    ) {\n      batches.push(pendingBatch);\n      pendingBatch = {\n        seq: 0,\n        changes: [],\n        docs: []\n      };\n      if (returnValue.state === 'pending' || returnValue.state === 'stopped') {\n        returnValue.state = 'active';\n        returnValue.emit('active');\n      }\n      startNextBatch();\n    }\n  }\n\n\n  function abortReplication(reason, err) {\n    if (replicationCompleted) {\n      return;\n    }\n    if (!err.message) {\n      err.message = reason;\n    }\n    result.ok = false;\n    result.status = 'aborting';\n    batches = [];\n    pendingBatch = {\n      seq: 0,\n      changes: [],\n      docs: []\n    };\n    completeReplication(err);\n  }\n\n\n  function completeReplication(fatalError) {\n    if (replicationCompleted) {\n      return;\n    }\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      result.status = 'cancelled';\n      if (writingCheckpoint) {\n        return;\n      }\n    }\n    result.status = result.status || 'complete';\n    result.end_time = new Date();\n    result.last_seq = last_seq;\n    replicationCompleted = true;\n\n    if (fatalError) {\n      // need to extend the error because Firefox considers \".result\" read-only\n      fatalError = createError(fatalError);\n      fatalError.result = result;\n\n      // Normalize error name. i.e. 'Unauthorized' -> 'unauthorized' (eg Sync Gateway)\n      var errorName = (fatalError.name || '').toLowerCase();\n      if (errorName === 'unauthorized' || errorName === 'forbidden') {\n        returnValue.emit('error', fatalError);\n        returnValue.removeAllListeners();\n      } else {\n        backOff(opts, returnValue, fatalError, function () {\n          replicate(src, target, opts, returnValue);\n        });\n      }\n    } else {\n      returnValue.emit('complete', result);\n      returnValue.removeAllListeners();\n    }\n  }\n\n\n  function onChange(change, pending, lastSeq) {\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n    // Attach 'pending' property if server supports it (CouchDB 2.0+)\n    /* istanbul ignore if */\n    if (typeof pending === 'number') {\n      pendingBatch.pending = pending;\n    }\n\n    var filter = filterChange(opts)(change);\n    if (!filter) {\n      return;\n    }\n    pendingBatch.seq = change.seq || lastSeq;\n    pendingBatch.changes.push(change);\n    processPendingBatch(batches.length === 0 && changesOpts.live);\n  }\n\n\n  function onChangesComplete(changes) {\n    changesPending = false;\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n\n    // if no results were returned then we're done,\n    // else fetch more\n    if (changes.results.length > 0) {\n      changesOpts.since = changes.last_seq;\n      getChanges();\n      processPendingBatch(true);\n    } else {\n\n      var complete = function () {\n        if (continuous) {\n          changesOpts.live = true;\n          getChanges();\n        } else {\n          changesCompleted = true;\n        }\n        processPendingBatch(true);\n      };\n\n      // update the checkpoint so we start from the right seq next time\n      if (!currentBatch && changes.results.length === 0) {\n        writingCheckpoint = true;\n        checkpointer.writeCheckpoint(changes.last_seq,\n            session).then(function () {\n          writingCheckpoint = false;\n          result.last_seq = last_seq = changes.last_seq;\n          complete();\n        })\n        .catch(onCheckpointError);\n      } else {\n        complete();\n      }\n    }\n  }\n\n\n  function onChangesError(err) {\n    changesPending = false;\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n    abortReplication('changes rejected', err);\n  }\n\n\n  function getChanges() {\n    if (!(\n      !changesPending &&\n      !changesCompleted &&\n      batches.length < batches_limit\n      )) {\n      return;\n    }\n    changesPending = true;\n    function abortChanges() {\n      changes.cancel();\n    }\n    function removeListener() {\n      returnValue.removeListener('cancel', abortChanges);\n    }\n\n    if (returnValue._changes) { // remove old changes() and listeners\n      returnValue.removeListener('cancel', returnValue._abortChanges);\n      returnValue._changes.cancel();\n    }\n    returnValue.once('cancel', abortChanges);\n\n    var changes = src.changes(changesOpts)\n      .on('change', onChange);\n    changes.then(removeListener, removeListener);\n    changes.then(onChangesComplete)\n      .catch(onChangesError);\n\n    if (opts.retry) {\n      // save for later so we can cancel if necessary\n      returnValue._changes = changes;\n      returnValue._abortChanges = abortChanges;\n    }\n  }\n\n\n  function startChanges() {\n    initCheckpointer().then(function () {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        return;\n      }\n      return checkpointer.getCheckpoint().then(function (checkpoint) {\n        last_seq = checkpoint;\n        changesOpts = {\n          since: last_seq,\n          limit: batch_size,\n          batch_size: batch_size,\n          style: 'all_docs',\n          doc_ids: doc_ids,\n          selector: selector,\n          return_docs: true // required so we know when we're done\n        };\n        if (seq_interval !== false) {\n          changesOpts.seq_interval = seq_interval || batch_size;\n        }\n        if (opts.filter) {\n          if (typeof opts.filter !== 'string') {\n            // required for the client-side filter in onChange\n            changesOpts.include_docs = true;\n          } else { // ddoc filter\n            changesOpts.filter = opts.filter;\n          }\n        }\n        if ('heartbeat' in opts) {\n          changesOpts.heartbeat = opts.heartbeat;\n        }\n        if ('timeout' in opts) {\n          changesOpts.timeout = opts.timeout;\n        }\n        if (opts.query_params) {\n          changesOpts.query_params = opts.query_params;\n        }\n        if (opts.view) {\n          changesOpts.view = opts.view;\n        }\n        getChanges();\n      });\n    }).catch(function (err) {\n      abortReplication('getCheckpoint rejected with ', err);\n    });\n  }\n\n  /* istanbul ignore next */\n  function onCheckpointError(err) {\n    writingCheckpoint = false;\n    abortReplication('writeCheckpoint completed with error', err);\n  }\n\n  /* istanbul ignore if */\n  if (returnValue.cancelled) { // cancelled immediately\n    completeReplication();\n    return;\n  }\n\n  if (!returnValue._addedListeners) {\n    returnValue.once('cancel', completeReplication);\n\n    if (typeof opts.complete === 'function') {\n      returnValue.once('error', opts.complete);\n      returnValue.once('complete', function (result) {\n        opts.complete(null, result);\n      });\n    }\n    returnValue._addedListeners = true;\n  }\n\n  if (typeof opts.since === 'undefined') {\n    startChanges();\n  } else {\n    initCheckpointer().then(function () {\n      writingCheckpoint = true;\n      return checkpointer.writeCheckpoint(opts.since, session);\n    }).then(function () {\n      writingCheckpoint = false;\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        return;\n      }\n      last_seq = opts.since;\n      startChanges();\n    }).catch(onCheckpointError);\n  }\n}\n\n// We create a basic promise so the caller can cancel the replication possibly\n// before we have actually started listening to changes etc\n__WEBPACK_IMPORTED_MODULE_4_inherits___default()(Replication, __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"]);\nfunction Replication() {\n  __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"].call(this);\n  this.cancelled = false;\n  this.state = 'pending';\n  var self = this;\n  var promise = new PouchPromise(function (fulfill, reject) {\n    self.once('complete', fulfill);\n    self.once('error', reject);\n  });\n  self.then = function (resolve, reject) {\n    return promise.then(resolve, reject);\n  };\n  self.catch = function (reject) {\n    return promise.catch(reject);\n  };\n  // As we allow error handling via \"error\" event as well,\n  // put a stub in here so that rejecting never throws UnhandledError.\n  self.catch(function () {});\n}\n\nReplication.prototype.cancel = function () {\n  this.cancelled = true;\n  this.state = 'cancelled';\n  this.emit('cancel');\n};\n\nReplication.prototype.ready = function (src, target) {\n  var self = this;\n  if (self._readyCalled) {\n    return;\n  }\n  self._readyCalled = true;\n\n  function onDestroy() {\n    self.cancel();\n  }\n  src.once('destroyed', onDestroy);\n  target.once('destroyed', onDestroy);\n  function cleanup() {\n    src.removeListener('destroyed', onDestroy);\n    target.removeListener('destroyed', onDestroy);\n  }\n  self.once('complete', cleanup);\n};\n\nfunction toPouch(db, opts) {\n  var PouchConstructor = opts.PouchConstructor;\n  if (typeof db === 'string') {\n    return new PouchConstructor(db, opts);\n  } else {\n    return db;\n  }\n}\n\nfunction replicateWrapper(src, target, opts, callback) {\n\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof opts === 'undefined') {\n    opts = {};\n  }\n\n  if (opts.doc_ids && !Array.isArray(opts.doc_ids)) {\n    throw createError(BAD_REQUEST,\n                       \"`doc_ids` filter parameter is not a list.\");\n  }\n\n  opts.complete = callback;\n  opts = clone(opts);\n  opts.continuous = opts.continuous || opts.live;\n  opts.retry = ('retry' in opts) ? opts.retry : false;\n  /*jshint validthis:true */\n  opts.PouchConstructor = opts.PouchConstructor || this;\n  var replicateRet = new Replication(opts);\n  var srcPouch = toPouch(src, opts);\n  var targetPouch = toPouch(target, opts);\n  replicate(srcPouch, targetPouch, opts, replicateRet);\n  return replicateRet;\n}\n\n__WEBPACK_IMPORTED_MODULE_4_inherits___default()(Sync, __WEBPACK_IMPORTED_MODULE_3_events__[\"EventEmitter\"]);\nfunction sync$1(src, target, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof opts === 'undefined') {\n    opts = {};\n  }\n  opts = clone(opts);\n  /*jshint validthis:true */\n  opts.PouchConstructor = opts.PouchConstructor || this;\n  src = toPouch(src, opts);\n  target = toPouch(target, opts);\n  return new Sync(src, target, opts, callback);\n}\n\nfunction Sync(src, target, opts, callback) {\n  var self = this;\n  this.canceled = false;\n\n  var optsPush = opts.push ? $inject_Object_assign({}, opts, opts.push) : opts;\n  var optsPull = opts.pull ? $inject_Object_assign({}, opts, opts.pull) : opts;\n\n  this.push = replicateWrapper(src, target, optsPush);\n  this.pull = replicateWrapper(target, src, optsPull);\n\n  this.pushPaused = true;\n  this.pullPaused = true;\n\n  function pullChange(change) {\n    self.emit('change', {\n      direction: 'pull',\n      change: change\n    });\n  }\n  function pushChange(change) {\n    self.emit('change', {\n      direction: 'push',\n      change: change\n    });\n  }\n  function pushDenied(doc) {\n    self.emit('denied', {\n      direction: 'push',\n      doc: doc\n    });\n  }\n  function pullDenied(doc) {\n    self.emit('denied', {\n      direction: 'pull',\n      doc: doc\n    });\n  }\n  function pushPaused() {\n    self.pushPaused = true;\n    /* istanbul ignore if */\n    if (self.pullPaused) {\n      self.emit('paused');\n    }\n  }\n  function pullPaused() {\n    self.pullPaused = true;\n    /* istanbul ignore if */\n    if (self.pushPaused) {\n      self.emit('paused');\n    }\n  }\n  function pushActive() {\n    self.pushPaused = false;\n    /* istanbul ignore if */\n    if (self.pullPaused) {\n      self.emit('active', {\n        direction: 'push'\n      });\n    }\n  }\n  function pullActive() {\n    self.pullPaused = false;\n    /* istanbul ignore if */\n    if (self.pushPaused) {\n      self.emit('active', {\n        direction: 'pull'\n      });\n    }\n  }\n\n  var removed = {};\n\n  function removeAll(type) { // type is 'push' or 'pull'\n    return function (event, func) {\n      var isChange = event === 'change' &&\n        (func === pullChange || func === pushChange);\n      var isDenied = event === 'denied' &&\n        (func === pullDenied || func === pushDenied);\n      var isPaused = event === 'paused' &&\n        (func === pullPaused || func === pushPaused);\n      var isActive = event === 'active' &&\n        (func === pullActive || func === pushActive);\n\n      if (isChange || isDenied || isPaused || isActive) {\n        if (!(event in removed)) {\n          removed[event] = {};\n        }\n        removed[event][type] = true;\n        if (Object.keys(removed[event]).length === 2) {\n          // both push and pull have asked to be removed\n          self.removeAllListeners(event);\n        }\n      }\n    };\n  }\n\n  if (opts.live) {\n    this.push.on('complete', self.pull.cancel.bind(self.pull));\n    this.pull.on('complete', self.push.cancel.bind(self.push));\n  }\n\n  function addOneListener(ee, event, listener) {\n    if (ee.listeners(event).indexOf(listener) == -1) {\n      ee.on(event, listener);\n    }\n  }\n\n  this.on('newListener', function (event) {\n    if (event === 'change') {\n      addOneListener(self.pull, 'change', pullChange);\n      addOneListener(self.push, 'change', pushChange);\n    } else if (event === 'denied') {\n      addOneListener(self.pull, 'denied', pullDenied);\n      addOneListener(self.push, 'denied', pushDenied);\n    } else if (event === 'active') {\n      addOneListener(self.pull, 'active', pullActive);\n      addOneListener(self.push, 'active', pushActive);\n    } else if (event === 'paused') {\n      addOneListener(self.pull, 'paused', pullPaused);\n      addOneListener(self.push, 'paused', pushPaused);\n    }\n  });\n\n  this.on('removeListener', function (event) {\n    if (event === 'change') {\n      self.pull.removeListener('change', pullChange);\n      self.push.removeListener('change', pushChange);\n    } else if (event === 'denied') {\n      self.pull.removeListener('denied', pullDenied);\n      self.push.removeListener('denied', pushDenied);\n    } else if (event === 'active') {\n      self.pull.removeListener('active', pullActive);\n      self.push.removeListener('active', pushActive);\n    } else if (event === 'paused') {\n      self.pull.removeListener('paused', pullPaused);\n      self.push.removeListener('paused', pushPaused);\n    }\n  });\n\n  this.pull.on('removeListener', removeAll('pull'));\n  this.push.on('removeListener', removeAll('push'));\n\n  var promise = PouchPromise.all([\n    this.push,\n    this.pull\n  ]).then(function (resp) {\n    var out = {\n      push: resp[0],\n      pull: resp[1]\n    };\n    self.emit('complete', out);\n    if (callback) {\n      callback(null, out);\n    }\n    self.removeAllListeners();\n    return out;\n  }, function (err) {\n    self.cancel();\n    if (callback) {\n      // if there's a callback, then the callback can receive\n      // the error event\n      callback(err);\n    } else {\n      // if there's no callback, then we're safe to emit an error\n      // event, which would otherwise throw an unhandled error\n      // due to 'error' being a special event in EventEmitters\n      self.emit('error', err);\n    }\n    self.removeAllListeners();\n    if (callback) {\n      // no sense throwing if we're already emitting an 'error' event\n      throw err;\n    }\n  });\n\n  this.then = function (success, err) {\n    return promise.then(success, err);\n  };\n\n  this.catch = function (err) {\n    return promise.catch(err);\n  };\n}\n\nSync.prototype.cancel = function () {\n  if (!this.canceled) {\n    this.canceled = true;\n    this.push.cancel();\n    this.pull.cancel();\n  }\n};\n\nfunction replication(PouchDB) {\n  PouchDB.replicate = replicateWrapper;\n  PouchDB.sync = sync$1;\n\n  Object.defineProperty(PouchDB.prototype, 'replicate', {\n    get: function () {\n      var self = this;\n      if (typeof this.replicateMethods === 'undefined') {\n        this.replicateMethods = {\n          from: function (other, opts, callback) {\n            return self.constructor.replicate(other, self, opts, callback);\n          },\n          to: function (other, opts, callback) {\n            return self.constructor.replicate(self, other, opts, callback);\n          }\n        };\n      }\n      return this.replicateMethods;\n    }\n  });\n\n  PouchDB.prototype.sync = function (dbName, opts, callback) {\n    return this.constructor.sync(this, dbName, opts, callback);\n  };\n}\n\nPouchDB.plugin(IDBPouch)\n  .plugin(WebSqlPouch$1)\n  .plugin(HttpPouch$1)\n  .plugin(mapreduce)\n  .plugin(replication);\n\n// Pull from src because pouchdb-node/pouchdb-browser themselves\n// are aggressively optimized and jsnext:main would normally give us this\n// aggressive bundle.\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (PouchDB);\n\n/* WEBPACK VAR INJECTION */}.call(__webpack_exports__, __webpack_require__(12)))\n\n/***/ }),\n/* 180 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar immediate = __webpack_require__(117);\n\n/* istanbul ignore next */\nfunction INTERNAL() {}\n\nvar handlers = {};\n\nvar REJECTED = ['REJECTED'];\nvar FULFILLED = ['FULFILLED'];\nvar PENDING = ['PENDING'];\n\nmodule.exports = Promise;\n\nfunction Promise(resolver) {\n  if (typeof resolver !== 'function') {\n    throw new TypeError('resolver must be a function');\n  }\n  this.state = PENDING;\n  this.queue = [];\n  this.outcome = void 0;\n  if (resolver !== INTERNAL) {\n    safelyResolveThenable(this, resolver);\n  }\n}\n\nPromise.prototype[\"catch\"] = function (onRejected) {\n  return this.then(null, onRejected);\n};\nPromise.prototype.then = function (onFulfilled, onRejected) {\n  if (typeof onFulfilled !== 'function' && this.state === FULFILLED ||\n    typeof onRejected !== 'function' && this.state === REJECTED) {\n    return this;\n  }\n  var promise = new this.constructor(INTERNAL);\n  if (this.state !== PENDING) {\n    var resolver = this.state === FULFILLED ? onFulfilled : onRejected;\n    unwrap(promise, resolver, this.outcome);\n  } else {\n    this.queue.push(new QueueItem(promise, onFulfilled, onRejected));\n  }\n\n  return promise;\n};\nfunction QueueItem(promise, onFulfilled, onRejected) {\n  this.promise = promise;\n  if (typeof onFulfilled === 'function') {\n    this.onFulfilled = onFulfilled;\n    this.callFulfilled = this.otherCallFulfilled;\n  }\n  if (typeof onRejected === 'function') {\n    this.onRejected = onRejected;\n    this.callRejected = this.otherCallRejected;\n  }\n}\nQueueItem.prototype.callFulfilled = function (value) {\n  handlers.resolve(this.promise, value);\n};\nQueueItem.prototype.otherCallFulfilled = function (value) {\n  unwrap(this.promise, this.onFulfilled, value);\n};\nQueueItem.prototype.callRejected = function (value) {\n  handlers.reject(this.promise, value);\n};\nQueueItem.prototype.otherCallRejected = function (value) {\n  unwrap(this.promise, this.onRejected, value);\n};\n\nfunction unwrap(promise, func, value) {\n  immediate(function () {\n    var returnValue;\n    try {\n      returnValue = func(value);\n    } catch (e) {\n      return handlers.reject(promise, e);\n    }\n    if (returnValue === promise) {\n      handlers.reject(promise, new TypeError('Cannot resolve promise with itself'));\n    } else {\n      handlers.resolve(promise, returnValue);\n    }\n  });\n}\n\nhandlers.resolve = function (self, value) {\n  var result = tryCatch(getThen, value);\n  if (result.status === 'error') {\n    return handlers.reject(self, result.value);\n  }\n  var thenable = result.value;\n\n  if (thenable) {\n    safelyResolveThenable(self, thenable);\n  } else {\n    self.state = FULFILLED;\n    self.outcome = value;\n    var i = -1;\n    var len = self.queue.length;\n    while (++i < len) {\n      self.queue[i].callFulfilled(value);\n    }\n  }\n  return self;\n};\nhandlers.reject = function (self, error) {\n  self.state = REJECTED;\n  self.outcome = error;\n  var i = -1;\n  var len = self.queue.length;\n  while (++i < len) {\n    self.queue[i].callRejected(error);\n  }\n  return self;\n};\n\nfunction getThen(obj) {\n  // Make sure we only access the accessor once as required by the spec\n  var then = obj && obj.then;\n  if (obj && (typeof obj === 'object' || typeof obj === 'function') && typeof then === 'function') {\n    return function appyThen() {\n      then.apply(obj, arguments);\n    };\n  }\n}\n\nfunction safelyResolveThenable(self, thenable) {\n  // Either fulfill, reject or reject with error\n  var called = false;\n  function onError(value) {\n    if (called) {\n      return;\n    }\n    called = true;\n    handlers.reject(self, value);\n  }\n\n  function onSuccess(value) {\n    if (called) {\n      return;\n    }\n    called = true;\n    handlers.resolve(self, value);\n  }\n\n  function tryToUnwrap() {\n    thenable(onSuccess, onError);\n  }\n\n  var result = tryCatch(tryToUnwrap);\n  if (result.status === 'error') {\n    onError(result.value);\n  }\n}\n\nfunction tryCatch(func, value) {\n  var out = {};\n  try {\n    out.value = func(value);\n    out.status = 'success';\n  } catch (e) {\n    out.status = 'error';\n    out.value = e;\n  }\n  return out;\n}\n\nPromise.resolve = resolve;\nfunction resolve(value) {\n  if (value instanceof this) {\n    return value;\n  }\n  return handlers.resolve(new this(INTERNAL), value);\n}\n\nPromise.reject = reject;\nfunction reject(reason) {\n  var promise = new this(INTERNAL);\n  return handlers.reject(promise, reason);\n}\n\nPromise.all = all;\nfunction all(iterable) {\n  var self = this;\n  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n    return this.reject(new TypeError('must be an array'));\n  }\n\n  var len = iterable.length;\n  var called = false;\n  if (!len) {\n    return this.resolve([]);\n  }\n\n  var values = new Array(len);\n  var resolved = 0;\n  var i = -1;\n  var promise = new this(INTERNAL);\n\n  while (++i < len) {\n    allResolver(iterable[i], i);\n  }\n  return promise;\n  function allResolver(value, i) {\n    self.resolve(value).then(resolveFromAll, function (error) {\n      if (!called) {\n        called = true;\n        handlers.reject(promise, error);\n      }\n    });\n    function resolveFromAll(outValue) {\n      values[i] = outValue;\n      if (++resolved === len && !called) {\n        called = true;\n        handlers.resolve(promise, values);\n      }\n    }\n  }\n}\n\nPromise.race = race;\nfunction race(iterable) {\n  var self = this;\n  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n    return this.reject(new TypeError('must be an array'));\n  }\n\n  var len = iterable.length;\n  var called = false;\n  if (!len) {\n    return this.resolve([]);\n  }\n\n  var i = -1;\n  var promise = new this(INTERNAL);\n\n  while (++i < len) {\n    resolver(iterable[i]);\n  }\n  return promise;\n  function resolver(value) {\n    self.resolve(value).then(function (response) {\n      if (!called) {\n        called = true;\n        handlers.resolve(promise, response);\n      }\n    }, function (error) {\n      if (!called) {\n        called = true;\n        handlers.reject(promise, error);\n      }\n    });\n  }\n}\n\n\n/***/ }),\n/* 181 */\n/***/ (function(module, exports) {\n\n// Unique ID creation requires a high quality random # generator.  In the\n// browser this is a little complicated due to unknown quality of Math.random()\n// and inconsistent support for the `crypto` API.  We do the best we can via\n// feature-detection\n\n// getRandomValues needs to be invoked in a context where \"this\" is a Crypto implementation.\nvar getRandomValues = (typeof(crypto) != 'undefined' && crypto.getRandomValues.bind(crypto)) ||\n                      (typeof(msCrypto) != 'undefined' && msCrypto.getRandomValues.bind(msCrypto));\nif (getRandomValues) {\n  // WHATWG crypto RNG - http://wiki.whatwg.org/wiki/Crypto\n  var rnds8 = new Uint8Array(16); // eslint-disable-line no-undef\n\n  module.exports = function whatwgRNG() {\n    getRandomValues(rnds8);\n    return rnds8;\n  };\n} else {\n  // Math.random()-based (RNG)\n  //\n  // If all else fails, use Math.random().  It's fast, but is of unspecified\n  // quality.\n  var rnds = new Array(16);\n\n  module.exports = function mathRNG() {\n    for (var i = 0, r; i < 16; i++) {\n      if ((i & 0x03) === 0) r = Math.random() * 0x100000000;\n      rnds[i] = r >>> ((i & 0x03) << 3) & 0xff;\n    }\n\n    return rnds;\n  };\n}\n\n\n/***/ }),\n/* 182 */\n/***/ (function(module, exports) {\n\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\nvar byteToHex = [];\nfor (var i = 0; i < 256; ++i) {\n  byteToHex[i] = (i + 0x100).toString(16).substr(1);\n}\n\nfunction bytesToUuid(buf, offset) {\n  var i = offset || 0;\n  var bth = byteToHex;\n  return bth[buf[i++]] + bth[buf[i++]] +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] +\n          bth[buf[i++]] + bth[buf[i++]] +\n          bth[buf[i++]] + bth[buf[i++]];\n}\n\nmodule.exports = bytesToUuid;\n\n\n/***/ }),\n/* 183 */\n/***/ (function(module, exports, __webpack_require__) {\n\n(function (factory) {\n    if (true) {\n        // Node/CommonJS\n        module.exports = factory();\n    } else if (typeof define === 'function' && define.amd) {\n        // AMD\n        define(factory);\n    } else {\n        // Browser globals (with support for web workers)\n        var glob;\n\n        try {\n            glob = window;\n        } catch (e) {\n            glob = self;\n        }\n\n        glob.SparkMD5 = factory();\n    }\n}(function (undefined) {\n\n    'use strict';\n\n    /*\n     * Fastest md5 implementation around (JKM md5).\n     * Credits: Joseph Myers\n     *\n     * @see http://www.myersdaily.org/joseph/javascript/md5-text.html\n     * @see http://jsperf.com/md5-shootout/7\n     */\n\n    /* this function is much faster,\n      so if possible we use it. Some IEs\n      are the only ones I know of that\n      need the idiotic second function,\n      generated by an if clause.  */\n    var add32 = function (a, b) {\n        return (a + b) & 0xFFFFFFFF;\n    },\n        hex_chr = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'];\n\n\n    function cmn(q, a, b, x, s, t) {\n        a = add32(add32(a, q), add32(x, t));\n        return add32((a << s) | (a >>> (32 - s)), b);\n    }\n\n    function md5cycle(x, k) {\n        var a = x[0],\n            b = x[1],\n            c = x[2],\n            d = x[3];\n\n        a += (b & c | ~b & d) + k[0] - 680876936 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[1] - 389564586 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[2] + 606105819 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[3] - 1044525330 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[4] - 176418897 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[5] + 1200080426 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[6] - 1473231341 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[7] - 45705983 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[8] + 1770035416 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[9] - 1958414417 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[10] - 42063 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[11] - 1990404162 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[12] + 1804603682 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[13] - 40341101 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[14] - 1502002290 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[15] + 1236535329 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n\n        a += (b & d | c & ~d) + k[1] - 165796510 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[6] - 1069501632 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[11] + 643717713 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[0] - 373897302 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[5] - 701558691 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[10] + 38016083 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[15] - 660478335 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[4] - 405537848 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[9] + 568446438 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[14] - 1019803690 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[3] - 187363961 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[8] + 1163531501 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[13] - 1444681467 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[2] - 51403784 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[7] + 1735328473 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[12] - 1926607734 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n\n        a += (b ^ c ^ d) + k[5] - 378558 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[8] - 2022574463 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[11] + 1839030562 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[14] - 35309556 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[1] - 1530992060 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[4] + 1272893353 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[7] - 155497632 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[10] - 1094730640 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[13] + 681279174 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[0] - 358537222 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[3] - 722521979 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[6] + 76029189 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[9] - 640364487 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[12] - 421815835 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[15] + 530742520 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[2] - 995338651 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n\n        a += (c ^ (b | ~d)) + k[0] - 198630844 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[7] + 1126891415 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[14] - 1416354905 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[5] - 57434055 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[12] + 1700485571 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[3] - 1894986606 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[10] - 1051523 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[1] - 2054922799 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[8] + 1873313359 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[15] - 30611744 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[6] - 1560198380 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[13] + 1309151649 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[4] - 145523070 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[11] - 1120210379 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[2] + 718787259 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[9] - 343485551 | 0;\n        b  = (b << 21 | b >>> 11) + c | 0;\n\n        x[0] = a + x[0] | 0;\n        x[1] = b + x[1] | 0;\n        x[2] = c + x[2] | 0;\n        x[3] = d + x[3] | 0;\n    }\n\n    function md5blk(s) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = s.charCodeAt(i) + (s.charCodeAt(i + 1) << 8) + (s.charCodeAt(i + 2) << 16) + (s.charCodeAt(i + 3) << 24);\n        }\n        return md5blks;\n    }\n\n    function md5blk_array(a) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = a[i] + (a[i + 1] << 8) + (a[i + 2] << 16) + (a[i + 3] << 24);\n        }\n        return md5blks;\n    }\n\n    function md51(s) {\n        var n = s.length,\n            state = [1732584193, -271733879, -1732584194, 271733878],\n            i,\n            length,\n            tail,\n            tmp,\n            lo,\n            hi;\n\n        for (i = 64; i <= n; i += 64) {\n            md5cycle(state, md5blk(s.substring(i - 64, i)));\n        }\n        s = s.substring(i - 64);\n        length = s.length;\n        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= s.charCodeAt(i) << ((i % 4) << 3);\n        }\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Beware that the final length might not fit in 32 bits so we take care of that\n        tmp = n * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n\n        md5cycle(state, tail);\n        return state;\n    }\n\n    function md51_array(a) {\n        var n = a.length,\n            state = [1732584193, -271733879, -1732584194, 271733878],\n            i,\n            length,\n            tail,\n            tmp,\n            lo,\n            hi;\n\n        for (i = 64; i <= n; i += 64) {\n            md5cycle(state, md5blk_array(a.subarray(i - 64, i)));\n        }\n\n        // Not sure if it is a bug, however IE10 will always produce a sub array of length 1\n        // containing the last element of the parent array if the sub array specified starts\n        // beyond the length of the parent array - weird.\n        // https://connect.microsoft.com/IE/feedback/details/771452/typed-array-subarray-issue\n        a = (i - 64) < n ? a.subarray(i - 64) : new Uint8Array(0);\n\n        length = a.length;\n        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= a[i] << ((i % 4) << 3);\n        }\n\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Beware that the final length might not fit in 32 bits so we take care of that\n        tmp = n * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n\n        md5cycle(state, tail);\n\n        return state;\n    }\n\n    function rhex(n) {\n        var s = '',\n            j;\n        for (j = 0; j < 4; j += 1) {\n            s += hex_chr[(n >> (j * 8 + 4)) & 0x0F] + hex_chr[(n >> (j * 8)) & 0x0F];\n        }\n        return s;\n    }\n\n    function hex(x) {\n        var i;\n        for (i = 0; i < x.length; i += 1) {\n            x[i] = rhex(x[i]);\n        }\n        return x.join('');\n    }\n\n    // In some cases the fast add32 function cannot be used..\n    if (hex(md51('hello')) !== '5d41402abc4b2a76b9719d911017c592') {\n        add32 = function (x, y) {\n            var lsw = (x & 0xFFFF) + (y & 0xFFFF),\n                msw = (x >> 16) + (y >> 16) + (lsw >> 16);\n            return (msw << 16) | (lsw & 0xFFFF);\n        };\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * ArrayBuffer slice polyfill.\n     *\n     * @see https://github.com/ttaubert/node-arraybuffer-slice\n     */\n\n    if (typeof ArrayBuffer !== 'undefined' && !ArrayBuffer.prototype.slice) {\n        (function () {\n            function clamp(val, length) {\n                val = (val | 0) || 0;\n\n                if (val < 0) {\n                    return Math.max(val + length, 0);\n                }\n\n                return Math.min(val, length);\n            }\n\n            ArrayBuffer.prototype.slice = function (from, to) {\n                var length = this.byteLength,\n                    begin = clamp(from, length),\n                    end = length,\n                    num,\n                    target,\n                    targetArray,\n                    sourceArray;\n\n                if (to !== undefined) {\n                    end = clamp(to, length);\n                }\n\n                if (begin > end) {\n                    return new ArrayBuffer(0);\n                }\n\n                num = end - begin;\n                target = new ArrayBuffer(num);\n                targetArray = new Uint8Array(target);\n\n                sourceArray = new Uint8Array(this, begin, num);\n                targetArray.set(sourceArray);\n\n                return target;\n            };\n        })();\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * Helpers.\n     */\n\n    function toUtf8(str) {\n        if (/[\\u0080-\\uFFFF]/.test(str)) {\n            str = unescape(encodeURIComponent(str));\n        }\n\n        return str;\n    }\n\n    function utf8Str2ArrayBuffer(str, returnUInt8Array) {\n        var length = str.length,\n           buff = new ArrayBuffer(length),\n           arr = new Uint8Array(buff),\n           i;\n\n        for (i = 0; i < length; i += 1) {\n            arr[i] = str.charCodeAt(i);\n        }\n\n        return returnUInt8Array ? arr : buff;\n    }\n\n    function arrayBuffer2Utf8Str(buff) {\n        return String.fromCharCode.apply(null, new Uint8Array(buff));\n    }\n\n    function concatenateArrayBuffers(first, second, returnUInt8Array) {\n        var result = new Uint8Array(first.byteLength + second.byteLength);\n\n        result.set(new Uint8Array(first));\n        result.set(new Uint8Array(second), first.byteLength);\n\n        return returnUInt8Array ? result : result.buffer;\n    }\n\n    function hexToBinaryString(hex) {\n        var bytes = [],\n            length = hex.length,\n            x;\n\n        for (x = 0; x < length - 1; x += 2) {\n            bytes.push(parseInt(hex.substr(x, 2), 16));\n        }\n\n        return String.fromCharCode.apply(String, bytes);\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * SparkMD5 OOP implementation.\n     *\n     * Use this class to perform an incremental md5, otherwise use the\n     * static methods instead.\n     */\n\n    function SparkMD5() {\n        // call reset to init the instance\n        this.reset();\n    }\n\n    /**\n     * Appends a string.\n     * A conversion will be applied if an utf8 string is detected.\n     *\n     * @param {String} str The string to be appended\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.append = function (str) {\n        // Converts the string to utf8 bytes if necessary\n        // Then append as binary\n        this.appendBinary(toUtf8(str));\n\n        return this;\n    };\n\n    /**\n     * Appends a binary string.\n     *\n     * @param {String} contents The binary string to be appended\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.appendBinary = function (contents) {\n        this._buff += contents;\n        this._length += contents.length;\n\n        var length = this._buff.length,\n            i;\n\n        for (i = 64; i <= length; i += 64) {\n            md5cycle(this._hash, md5blk(this._buff.substring(i - 64, i)));\n        }\n\n        this._buff = this._buff.substring(i - 64);\n\n        return this;\n    };\n\n    /**\n     * Finishes the incremental computation, reseting the internal state and\n     * returning the result.\n     *\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.prototype.end = function (raw) {\n        var buff = this._buff,\n            length = buff.length,\n            i,\n            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            ret;\n\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= buff.charCodeAt(i) << ((i % 4) << 3);\n        }\n\n        this._finish(tail, length);\n        ret = hex(this._hash);\n\n        if (raw) {\n            ret = hexToBinaryString(ret);\n        }\n\n        this.reset();\n\n        return ret;\n    };\n\n    /**\n     * Resets the internal state of the computation.\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.reset = function () {\n        this._buff = '';\n        this._length = 0;\n        this._hash = [1732584193, -271733879, -1732584194, 271733878];\n\n        return this;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @return {Object} The state\n     */\n    SparkMD5.prototype.getState = function () {\n        return {\n            buff: this._buff,\n            length: this._length,\n            hash: this._hash\n        };\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @param {Object} state The state\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.setState = function (state) {\n        this._buff = state.buff;\n        this._length = state.length;\n        this._hash = state.hash;\n\n        return this;\n    };\n\n    /**\n     * Releases memory used by the incremental buffer and other additional\n     * resources. If you plan to use the instance again, use reset instead.\n     */\n    SparkMD5.prototype.destroy = function () {\n        delete this._hash;\n        delete this._buff;\n        delete this._length;\n    };\n\n    /**\n     * Finish the final calculation based on the tail.\n     *\n     * @param {Array}  tail   The tail (will be modified)\n     * @param {Number} length The length of the remaining buffer\n     */\n    SparkMD5.prototype._finish = function (tail, length) {\n        var i = length,\n            tmp,\n            lo,\n            hi;\n\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(this._hash, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Do the final computation based on the tail and length\n        // Beware that the final length may not fit in 32 bits so we take care of that\n        tmp = this._length * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n        md5cycle(this._hash, tail);\n    };\n\n    /**\n     * Performs the md5 hash on a string.\n     * A conversion will be applied if utf8 string is detected.\n     *\n     * @param {String}  str The string\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.hash = function (str, raw) {\n        // Converts the string to utf8 bytes if necessary\n        // Then compute it using the binary function\n        return SparkMD5.hashBinary(toUtf8(str), raw);\n    };\n\n    /**\n     * Performs the md5 hash on a binary string.\n     *\n     * @param {String}  content The binary string\n     * @param {Boolean} raw     True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.hashBinary = function (content, raw) {\n        var hash = md51(content),\n            ret = hex(hash);\n\n        return raw ? hexToBinaryString(ret) : ret;\n    };\n\n    // ---------------------------------------------------\n\n    /**\n     * SparkMD5 OOP implementation for array buffers.\n     *\n     * Use this class to perform an incremental md5 ONLY for array buffers.\n     */\n    SparkMD5.ArrayBuffer = function () {\n        // call reset to init the instance\n        this.reset();\n    };\n\n    /**\n     * Appends an array buffer.\n     *\n     * @param {ArrayBuffer} arr The array to be appended\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.append = function (arr) {\n        var buff = concatenateArrayBuffers(this._buff.buffer, arr, true),\n            length = buff.length,\n            i;\n\n        this._length += arr.byteLength;\n\n        for (i = 64; i <= length; i += 64) {\n            md5cycle(this._hash, md5blk_array(buff.subarray(i - 64, i)));\n        }\n\n        this._buff = (i - 64) < length ? new Uint8Array(buff.buffer.slice(i - 64)) : new Uint8Array(0);\n\n        return this;\n    };\n\n    /**\n     * Finishes the incremental computation, reseting the internal state and\n     * returning the result.\n     *\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.ArrayBuffer.prototype.end = function (raw) {\n        var buff = this._buff,\n            length = buff.length,\n            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            i,\n            ret;\n\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= buff[i] << ((i % 4) << 3);\n        }\n\n        this._finish(tail, length);\n        ret = hex(this._hash);\n\n        if (raw) {\n            ret = hexToBinaryString(ret);\n        }\n\n        this.reset();\n\n        return ret;\n    };\n\n    /**\n     * Resets the internal state of the computation.\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.reset = function () {\n        this._buff = new Uint8Array(0);\n        this._length = 0;\n        this._hash = [1732584193, -271733879, -1732584194, 271733878];\n\n        return this;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @return {Object} The state\n     */\n    SparkMD5.ArrayBuffer.prototype.getState = function () {\n        var state = SparkMD5.prototype.getState.call(this);\n\n        // Convert buffer to a string\n        state.buff = arrayBuffer2Utf8Str(state.buff);\n\n        return state;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @param {Object} state The state\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.setState = function (state) {\n        // Convert string to buffer\n        state.buff = utf8Str2ArrayBuffer(state.buff, true);\n\n        return SparkMD5.prototype.setState.call(this, state);\n    };\n\n    SparkMD5.ArrayBuffer.prototype.destroy = SparkMD5.prototype.destroy;\n\n    SparkMD5.ArrayBuffer.prototype._finish = SparkMD5.prototype._finish;\n\n    /**\n     * Performs the md5 hash on an array buffer.\n     *\n     * @param {ArrayBuffer} arr The array buffer\n     * @param {Boolean}     raw True to get the raw string, false to get the hex one\n     *\n     * @return {String} The result\n     */\n    SparkMD5.ArrayBuffer.hash = function (arr, raw) {\n        var hash = md51_array(new Uint8Array(arr)),\n            ret = hex(hash);\n\n        return raw ? hexToBinaryString(ret) : ret;\n    };\n\n    return SparkMD5;\n}));\n\n\n/***/ }),\n/* 184 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n/**\n * Stringify/parse functions that don't operate\n * recursively, so they avoid call stack exceeded\n * errors.\n */\nexports.stringify = function stringify(input) {\n  var queue = [];\n  queue.push({obj: input});\n\n  var res = '';\n  var next, obj, prefix, val, i, arrayPrefix, keys, k, key, value, objPrefix;\n  while ((next = queue.pop())) {\n    obj = next.obj;\n    prefix = next.prefix || '';\n    val = next.val || '';\n    res += prefix;\n    if (val) {\n      res += val;\n    } else if (typeof obj !== 'object') {\n      res += typeof obj === 'undefined' ? null : JSON.stringify(obj);\n    } else if (obj === null) {\n      res += 'null';\n    } else if (Array.isArray(obj)) {\n      queue.push({val: ']'});\n      for (i = obj.length - 1; i >= 0; i--) {\n        arrayPrefix = i === 0 ? '' : ',';\n        queue.push({obj: obj[i], prefix: arrayPrefix});\n      }\n      queue.push({val: '['});\n    } else { // object\n      keys = [];\n      for (k in obj) {\n        if (obj.hasOwnProperty(k)) {\n          keys.push(k);\n        }\n      }\n      queue.push({val: '}'});\n      for (i = keys.length - 1; i >= 0; i--) {\n        key = keys[i];\n        value = obj[key];\n        objPrefix = (i > 0 ? ',' : '');\n        objPrefix += JSON.stringify(key) + ':';\n        queue.push({obj: value, prefix: objPrefix});\n      }\n      queue.push({val: '{'});\n    }\n  }\n  return res;\n};\n\n// Convenience function for the parse function.\n// This pop function is basically copied from\n// pouchCollate.parseIndexableString\nfunction pop(obj, stack, metaStack) {\n  var lastMetaElement = metaStack[metaStack.length - 1];\n  if (obj === lastMetaElement.element) {\n    // popping a meta-element, e.g. an object whose value is another object\n    metaStack.pop();\n    lastMetaElement = metaStack[metaStack.length - 1];\n  }\n  var element = lastMetaElement.element;\n  var lastElementIndex = lastMetaElement.index;\n  if (Array.isArray(element)) {\n    element.push(obj);\n  } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n    var key = stack.pop();\n    element[key] = obj;\n  } else {\n    stack.push(obj); // obj with key only\n  }\n}\n\nexports.parse = function (str) {\n  var stack = [];\n  var metaStack = []; // stack for arrays and objects\n  var i = 0;\n  var collationIndex,parsedNum,numChar;\n  var parsedString,lastCh,numConsecutiveSlashes,ch;\n  var arrayElement, objElement;\n  while (true) {\n    collationIndex = str[i++];\n    if (collationIndex === '}' ||\n        collationIndex === ']' ||\n        typeof collationIndex === 'undefined') {\n      if (stack.length === 1) {\n        return stack.pop();\n      } else {\n        pop(stack.pop(), stack, metaStack);\n        continue;\n      }\n    }\n    switch (collationIndex) {\n      case ' ':\n      case '\\t':\n      case '\\n':\n      case ':':\n      case ',':\n        break;\n      case 'n':\n        i += 3; // 'ull'\n        pop(null, stack, metaStack);\n        break;\n      case 't':\n        i += 3; // 'rue'\n        pop(true, stack, metaStack);\n        break;\n      case 'f':\n        i += 4; // 'alse'\n        pop(false, stack, metaStack);\n        break;\n      case '0':\n      case '1':\n      case '2':\n      case '3':\n      case '4':\n      case '5':\n      case '6':\n      case '7':\n      case '8':\n      case '9':\n      case '-':\n        parsedNum = '';\n        i--;\n        while (true) {\n          numChar = str[i++];\n          if (/[\\d\\.\\-e\\+]/.test(numChar)) {\n            parsedNum += numChar;\n          } else {\n            i--;\n            break;\n          }\n        }\n        pop(parseFloat(parsedNum), stack, metaStack);\n        break;\n      case '\"':\n        parsedString = '';\n        lastCh = void 0;\n        numConsecutiveSlashes = 0;\n        while (true) {\n          ch = str[i++];\n          if (ch !== '\"' || (lastCh === '\\\\' &&\n              numConsecutiveSlashes % 2 === 1)) {\n            parsedString += ch;\n            lastCh = ch;\n            if (lastCh === '\\\\') {\n              numConsecutiveSlashes++;\n            } else {\n              numConsecutiveSlashes = 0;\n            }\n          } else {\n            break;\n          }\n        }\n        pop(JSON.parse('\"' + parsedString + '\"'), stack, metaStack);\n        break;\n      case '[':\n        arrayElement = { element: [], index: stack.length };\n        stack.push(arrayElement.element);\n        metaStack.push(arrayElement);\n        break;\n      case '{':\n        objElement = { element: {}, index: stack.length };\n        stack.push(objElement.element);\n        metaStack.push(objElement);\n        break;\n      default:\n        throw new Error(\n          'unexpectedly reached end of input: ' + collationIndex);\n    }\n  }\n};\n\n\n/***/ }),\n/* 185 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\nObject.defineProperty(__webpack_exports__, \"__esModule\", { value: true });\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_pouchdb_utils__ = __webpack_require__(119);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_pouchdb_adapter_leveldb_core__ = __webpack_require__(574);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2_memdown__ = __webpack_require__(645);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2_memdown___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_2_memdown__);\n\n\n\n\nfunction MemDownPouch(opts, callback) {\n  var _opts = Object(__WEBPACK_IMPORTED_MODULE_0_pouchdb_utils__[\"a\" /* assign */])({\n    db: __WEBPACK_IMPORTED_MODULE_2_memdown___default.a\n  }, opts);\n\n  __WEBPACK_IMPORTED_MODULE_1_pouchdb_adapter_leveldb_core__[\"a\" /* default */].call(this, _opts, callback);\n}\n\n// overrides for normal LevelDB behavior on Node\nMemDownPouch.valid = function () {\n  return true;\n};\nMemDownPouch.use_prefix = false;\n\nfunction index (PouchDB) {\n  PouchDB.adapter('memory', MemDownPouch, true);\n}\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (index);\n\n\n/***/ }),\n/* 186 */\n/***/ (function(module, exports) {\n\n// Unique ID creation requires a high quality random # generator.  In the\n// browser this is a little complicated due to unknown quality of Math.random()\n// and inconsistent support for the `crypto` API.  We do the best we can via\n// feature-detection\n\n// getRandomValues needs to be invoked in a context where \"this\" is a Crypto implementation.\nvar getRandomValues = (typeof(crypto) != 'undefined' && crypto.getRandomValues.bind(crypto)) ||\n                      (typeof(msCrypto) != 'undefined' && msCrypto.getRandomValues.bind(msCrypto));\nif (getRandomValues) {\n  // WHATWG crypto RNG - http://wiki.whatwg.org/wiki/Crypto\n  var rnds8 = new Uint8Array(16); // eslint-disable-line no-undef\n\n  module.exports = function whatwgRNG() {\n    getRandomValues(rnds8);\n    return rnds8;\n  };\n} else {\n  // Math.random()-based (RNG)\n  //\n  // If all else fails, use Math.random().  It's fast, but is of unspecified\n  // quality.\n  var rnds = new Array(16);\n\n  module.exports = function mathRNG() {\n    for (var i = 0, r; i < 16; i++) {\n      if ((i & 0x03) === 0) r = Math.random() * 0x100000000;\n      rnds[i] = r >>> ((i & 0x03) << 3) & 0xff;\n    }\n\n    return rnds;\n  };\n}\n\n\n/***/ }),\n/* 187 */\n/***/ (function(module, exports) {\n\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\nvar byteToHex = [];\nfor (var i = 0; i < 256; ++i) {\n  byteToHex[i] = (i + 0x100).toString(16).substr(1);\n}\n\nfunction bytesToUuid(buf, offset) {\n  var i = offset || 0;\n  var bth = byteToHex;\n  return bth[buf[i++]] + bth[buf[i++]] +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] + '-' +\n          bth[buf[i++]] + bth[buf[i++]] +\n          bth[buf[i++]] + bth[buf[i++]] +\n          bth[buf[i++]] + bth[buf[i++]];\n}\n\nmodule.exports = bytesToUuid;\n\n\n/***/ }),\n/* 188 */\n/***/ (function(module, exports, __webpack_require__) {\n\nexports.AbstractLevelDOWN    = __webpack_require__(189)\nexports.AbstractIterator     = __webpack_require__(190)\nexports.AbstractChainedBatch = __webpack_require__(191)\nexports.isLevelDOWN          = __webpack_require__(582)\n\n\n/***/ }),\n/* 189 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process, Buffer) {/* Copyright (c) 2017 Rod Vagg, MIT License */\n\nvar xtend                = __webpack_require__(66)\n  , AbstractIterator     = __webpack_require__(190)\n  , AbstractChainedBatch = __webpack_require__(191)\n\nfunction AbstractLevelDOWN (location) {\n  if (!arguments.length || location === undefined)\n    throw new Error('constructor requires at least a location argument')\n\n  if (typeof location != 'string')\n    throw new Error('constructor requires a location string argument')\n\n  this.location = location\n  this.status = 'new'\n}\n\nAbstractLevelDOWN.prototype.open = function (options, callback) {\n  var self      = this\n    , oldStatus = this.status\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof callback != 'function')\n    throw new Error('open() requires a callback argument')\n\n  if (typeof options != 'object')\n    options = {}\n\n  options.createIfMissing = options.createIfMissing != false\n  options.errorIfExists = !!options.errorIfExists\n\n  if (typeof this._open == 'function') {\n    this.status = 'opening'\n    this._open(options, function (err) {\n      if (err) {\n        self.status = oldStatus\n        return callback(err)\n      }\n      self.status = 'open'\n      callback()\n    })\n  } else {\n    this.status = 'open'\n    process.nextTick(callback)\n  }\n}\n\nAbstractLevelDOWN.prototype.close = function (callback) {\n  var self      = this\n    , oldStatus = this.status\n\n  if (typeof callback != 'function')\n    throw new Error('close() requires a callback argument')\n\n  if (typeof this._close == 'function') {\n    this.status = 'closing'\n    this._close(function (err) {\n      if (err) {\n        self.status = oldStatus\n        return callback(err)\n      }\n      self.status = 'closed'\n      callback()\n    })\n  } else {\n    this.status = 'closed'\n    process.nextTick(callback)\n  }\n}\n\nAbstractLevelDOWN.prototype.get = function (key, options, callback) {\n  var err\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof callback != 'function')\n    throw new Error('get() requires a callback argument')\n\n  if (err = this._checkKey(key, 'key'))\n    return callback(err)\n\n  key = this._serializeKey(key)\n\n  if (typeof options != 'object')\n    options = {}\n\n  options.asBuffer = options.asBuffer != false\n\n  if (typeof this._get == 'function')\n    return this._get(key, options, callback)\n\n  process.nextTick(function () { callback(new Error('NotFound')) })\n}\n\nAbstractLevelDOWN.prototype.put = function (key, value, options, callback) {\n  var err\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof callback != 'function')\n    throw new Error('put() requires a callback argument')\n\n  if (err = this._checkKey(key, 'key'))\n    return callback(err)\n\n  key = this._serializeKey(key)\n  value = this._serializeValue(value)\n\n  if (typeof options != 'object')\n    options = {}\n\n  if (typeof this._put == 'function')\n    return this._put(key, value, options, callback)\n\n  process.nextTick(callback)\n}\n\nAbstractLevelDOWN.prototype.del = function (key, options, callback) {\n  var err\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof callback != 'function')\n    throw new Error('del() requires a callback argument')\n\n  if (err = this._checkKey(key, 'key'))\n    return callback(err)\n\n  key = this._serializeKey(key)\n\n  if (typeof options != 'object')\n    options = {}\n\n  if (typeof this._del == 'function')\n    return this._del(key, options, callback)\n\n  process.nextTick(callback)\n}\n\nAbstractLevelDOWN.prototype.batch = function (array, options, callback) {\n  if (!arguments.length)\n    return this._chainedBatch()\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof array == 'function')\n    callback = array\n\n  if (typeof callback != 'function')\n    throw new Error('batch(array) requires a callback argument')\n\n  if (!Array.isArray(array))\n    return callback(new Error('batch(array) requires an array argument'))\n\n  if (!options || typeof options != 'object')\n    options = {}\n\n  var i = 0\n    , l = array.length\n    , e\n    , err\n\n  for (; i < l; i++) {\n    e = array[i]\n    if (typeof e != 'object')\n      continue\n\n    if (err = this._checkKey(e.type, 'type'))\n      return callback(err)\n\n    if (err = this._checkKey(e.key, 'key'))\n      return callback(err)\n  }\n\n  if (typeof this._batch == 'function')\n    return this._batch(array, options, callback)\n\n  process.nextTick(callback)\n}\n\n//TODO: remove from here, not a necessary primitive\nAbstractLevelDOWN.prototype.approximateSize = function (start, end, callback) {\n  if (   start == null\n      || end == null\n      || typeof start == 'function'\n      || typeof end == 'function') {\n    throw new Error('approximateSize() requires valid `start`, `end` and `callback` arguments')\n  }\n\n  if (typeof callback != 'function')\n    throw new Error('approximateSize() requires a callback argument')\n\n  start = this._serializeKey(start)\n  end = this._serializeKey(end)\n\n  if (typeof this._approximateSize == 'function')\n    return this._approximateSize(start, end, callback)\n\n  process.nextTick(function () {\n    callback(null, 0)\n  })\n}\n\nAbstractLevelDOWN.prototype._setupIteratorOptions = function (options) {\n  var self = this\n\n  options = xtend(options)\n\n  ;[ 'start', 'end', 'gt', 'gte', 'lt', 'lte' ].forEach(function (o) {\n    if (options[o] && self._isBuffer(options[o]) && options[o].length === 0)\n      delete options[o]\n  })\n\n  options.reverse = !!options.reverse\n  options.keys = options.keys != false\n  options.values = options.values != false\n  options.limit = 'limit' in options ? options.limit : -1\n  options.keyAsBuffer = options.keyAsBuffer != false\n  options.valueAsBuffer = options.valueAsBuffer != false\n\n  return options\n}\n\nAbstractLevelDOWN.prototype.iterator = function (options) {\n  if (typeof options != 'object')\n    options = {}\n\n  options = this._setupIteratorOptions(options)\n\n  if (typeof this._iterator == 'function')\n    return this._iterator(options)\n\n  return new AbstractIterator(this)\n}\n\nAbstractLevelDOWN.prototype._chainedBatch = function () {\n  return new AbstractChainedBatch(this)\n}\n\nAbstractLevelDOWN.prototype._isBuffer = function (obj) {\n  return Buffer.isBuffer(obj)\n}\n\nAbstractLevelDOWN.prototype._serializeKey = function (key) {\n  return this._isBuffer(key)\n    ? key\n    : String(key)\n}\n\nAbstractLevelDOWN.prototype._serializeValue = function (value) {\n  if (value == null) return ''\n  return this._isBuffer(value) || process.browser ? value : String(value)\n}\n\nAbstractLevelDOWN.prototype._checkKey = function (obj, type) {\n  if (obj === null || obj === undefined)\n    return new Error(type + ' cannot be `null` or `undefined`')\n\n  if (this._isBuffer(obj) && obj.length === 0)\n    return new Error(type + ' cannot be an empty Buffer')\n  else if (String(obj) === '')\n    return new Error(type + ' cannot be an empty String')\n}\n\nmodule.exports = AbstractLevelDOWN\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8), __webpack_require__(24).Buffer))\n\n/***/ }),\n/* 190 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process) {/* Copyright (c) 2017 Rod Vagg, MIT License */\n\nfunction AbstractIterator (db) {\n  this.db = db\n  this._ended = false\n  this._nexting = false\n}\n\nAbstractIterator.prototype.next = function (callback) {\n  var self = this\n\n  if (typeof callback != 'function')\n    throw new Error('next() requires a callback argument')\n\n  if (self._ended)\n    return callback(new Error('cannot call next() after end()'))\n  if (self._nexting)\n    return callback(new Error('cannot call next() before previous next() has completed'))\n\n  self._nexting = true\n  if (typeof self._next == 'function') {\n    return self._next(function () {\n      self._nexting = false\n      callback.apply(null, arguments)\n    })\n  }\n\n  process.nextTick(function () {\n    self._nexting = false\n    callback()\n  })\n}\n\nAbstractIterator.prototype.end = function (callback) {\n  if (typeof callback != 'function')\n    throw new Error('end() requires a callback argument')\n\n  if (this._ended)\n    return callback(new Error('end() already called on iterator'))\n\n  this._ended = true\n\n  if (typeof this._end == 'function')\n    return this._end(callback)\n\n  process.nextTick(callback)\n}\n\nmodule.exports = AbstractIterator\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8)))\n\n/***/ }),\n/* 191 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process) {/* Copyright (c) 2017 Rod Vagg, MIT License */\n\nfunction AbstractChainedBatch (db) {\n  this._db         = db\n  this._operations = []\n  this._written    = false\n}\n\nAbstractChainedBatch.prototype._serializeKey = function (key) {\n  return this._db._serializeKey(key)\n}\n\nAbstractChainedBatch.prototype._serializeValue = function (value) {\n  return this._db._serializeValue(value)\n}\n\nAbstractChainedBatch.prototype._checkWritten = function () {\n  if (this._written)\n    throw new Error('write() already called on this batch')\n}\n\nAbstractChainedBatch.prototype.put = function (key, value) {\n  this._checkWritten()\n\n  var err = this._db._checkKey(key, 'key', this._db._isBuffer)\n  if (err)\n    throw err\n\n  key = this._serializeKey(key)\n  value = this._serializeValue(value)\n\n  if (typeof this._put == 'function' )\n    this._put(key, value)\n  else\n    this._operations.push({ type: 'put', key: key, value: value })\n\n  return this\n}\n\nAbstractChainedBatch.prototype.del = function (key) {\n  this._checkWritten()\n\n  var err = this._db._checkKey(key, 'key', this._db._isBuffer)\n  if (err) throw err\n\n  key = this._serializeKey(key)\n\n  if (typeof this._del == 'function' )\n    this._del(key)\n  else\n    this._operations.push({ type: 'del', key: key })\n\n  return this\n}\n\nAbstractChainedBatch.prototype.clear = function () {\n  this._checkWritten()\n\n  this._operations = []\n\n  if (typeof this._clear == 'function' )\n    this._clear()\n\n  return this\n}\n\nAbstractChainedBatch.prototype.write = function (options, callback) {\n  this._checkWritten()\n\n  if (typeof options == 'function')\n    callback = options\n  if (typeof callback != 'function')\n    throw new Error('write() requires a callback argument')\n  if (typeof options != 'object')\n    options = {}\n\n  this._written = true\n\n  if (typeof this._write == 'function' )\n    return this._write(callback)\n\n  if (typeof this._db._batch == 'function')\n    return this._db._batch(this._operations, options, callback)\n\n  process.nextTick(callback)\n}\n\nmodule.exports = AbstractChainedBatch\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8)))\n\n/***/ }),\n/* 192 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global, process) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(25);\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = __webpack_require__(586);\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = __webpack_require__(23).EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(193);\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(35).Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = __webpack_require__(587);\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = __webpack_require__(588);\nvar destroyImpl = __webpack_require__(194);\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || __webpack_require__(60);\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = __webpack_require__(42).StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || __webpack_require__(60);\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = __webpack_require__(42).StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12), __webpack_require__(8)))\n\n/***/ }),\n/* 193 */\n/***/ (function(module, exports, __webpack_require__) {\n\nmodule.exports = __webpack_require__(23).EventEmitter;\n\n\n/***/ }),\n/* 194 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(25);\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};\n\n/***/ }),\n/* 195 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(process, setImmediate, global) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(25);\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: __webpack_require__(125)\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(193);\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(35).Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = __webpack_require__(194);\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || __webpack_require__(60);\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || __webpack_require__(60);\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8), __webpack_require__(124).setImmediate, __webpack_require__(12)))\n\n/***/ }),\n/* 196 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n\n\nmodule.exports = Transform;\n\nvar Duplex = __webpack_require__(60);\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}\n\n/***/ }),\n/* 197 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* Copyright (c) 2012-2017 LevelUP contributors\n * See list at <https://github.com/rvagg/node-levelup#contributing>\n * MIT License\n * <https://github.com/rvagg/node-levelup/blob/master/LICENSE.md>\n */\n\nvar createError = __webpack_require__(593).create\nvar LevelUPError = createError('LevelUPError')\nvar NotFoundError = createError('NotFoundError', LevelUPError)\n\nNotFoundError.prototype.notFound = true\nNotFoundError.prototype.status = 404\n\nmodule.exports = {\n  LevelUPError: LevelUPError,\n  InitializationError: createError('InitializationError', LevelUPError),\n  OpenError: createError('OpenError', LevelUPError),\n  ReadError: createError('ReadError', LevelUPError),\n  WriteError: createError('WriteError', LevelUPError),\n  NotFoundError: NotFoundError,\n  EncodingError: createError('EncodingError', LevelUPError)\n}\n\n\n/***/ }),\n/* 198 */\n/***/ (function(module, exports) {\n\n/* Copyright (c) 2012-2017 LevelUP contributors\n * See list at <https://github.com/level/levelup#contributing>\n * MIT License\n * <https://github.com/level/levelup/blob/master/LICENSE.md>\n */\n\nfunction promisify () {\n  var callback\n  var promise = new Promise(function (resolve, reject) {\n    callback = function callback (err, value) {\n      if (err) reject(err)\n      else resolve(value)\n    }\n  })\n  callback.promise = promise\n  return callback\n}\n\nmodule.exports = promisify\n\n\n/***/ }),\n/* 199 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global, process) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(25);\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = __webpack_require__(600);\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = __webpack_require__(23).EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(200);\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(35).Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = __webpack_require__(601);\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = __webpack_require__(602);\nvar destroyImpl = __webpack_require__(201);\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || __webpack_require__(53);\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = __webpack_require__(42).StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || __webpack_require__(53);\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = __webpack_require__(42).StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12), __webpack_require__(8)))\n\n/***/ }),\n/* 200 */\n/***/ (function(module, exports, __webpack_require__) {\n\nmodule.exports = __webpack_require__(23).EventEmitter;\n\n\n/***/ }),\n/* 201 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(25);\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};\n\n/***/ }),\n/* 202 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n\n\nmodule.exports = Transform;\n\nvar Duplex = __webpack_require__(53);\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}\n\n/***/ }),\n/* 203 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = __webpack_require__(609);\n/*</replacement>*/\n\n\n/*<replacement>*/\nvar Buffer = __webpack_require__(24).Buffer;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\nvar EE = __webpack_require__(23).EventEmitter;\n\n/*<replacement>*/\nif (!EE.listenerCount) EE.listenerCount = function(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\nvar Stream = __webpack_require__(126);\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nfunction ReadableState(options, stream) {\n  options = options || {};\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  this.highWaterMark = (hwm || hwm === 0) ? hwm : 16 * 1024;\n\n  // cast to ints.\n  this.highWaterMark = ~~this.highWaterMark;\n\n  this.buffer = [];\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = false;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // In streams that never have any data, and do push(null) right away,\n  // the consumer can miss the 'end' event if they do some I/O before\n  // consuming the stream.  So, we don't emit('end') until some reading\n  // happens.\n  this.calledRead = false;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, becuase any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // when piping, we only care about 'readable' events that happen\n  // after read()ing all the bytes and not getting any pushback.\n  this.ranOut = false;\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder)\n      StringDecoder = __webpack_require__(42).StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  if (!(this instanceof Readable))\n    return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  Stream.call(this);\n}\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function(chunk, encoding) {\n  var state = this._readableState;\n\n  if (typeof chunk === 'string' && !state.objectMode) {\n    encoding = encoding || state.defaultEncoding;\n    if (encoding !== state.encoding) {\n      chunk = new Buffer(chunk, encoding);\n      encoding = '';\n    }\n  }\n\n  return readableAddChunk(this, state, chunk, encoding, false);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function(chunk) {\n  var state = this._readableState;\n  return readableAddChunk(this, state, chunk, '', true);\n};\n\nfunction readableAddChunk(stream, state, chunk, encoding, addToFront) {\n  var er = chunkInvalid(state, chunk);\n  if (er) {\n    stream.emit('error', er);\n  } else if (chunk === null || chunk === undefined) {\n    state.reading = false;\n    if (!state.ended)\n      onEofChunk(stream, state);\n  } else if (state.objectMode || chunk && chunk.length > 0) {\n    if (state.ended && !addToFront) {\n      var e = new Error('stream.push() after EOF');\n      stream.emit('error', e);\n    } else if (state.endEmitted && addToFront) {\n      var e = new Error('stream.unshift() after end event');\n      stream.emit('error', e);\n    } else {\n      if (state.decoder && !addToFront && !encoding)\n        chunk = state.decoder.write(chunk);\n\n      // update the buffer info.\n      state.length += state.objectMode ? 1 : chunk.length;\n      if (addToFront) {\n        state.buffer.unshift(chunk);\n      } else {\n        state.reading = false;\n        state.buffer.push(chunk);\n      }\n\n      if (state.needReadable)\n        emitReadable(stream);\n\n      maybeReadMore(stream, state);\n    }\n  } else if (!addToFront) {\n    state.reading = false;\n  }\n\n  return needMoreData(state);\n}\n\n\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended &&\n         (state.needReadable ||\n          state.length < state.highWaterMark ||\n          state.length === 0);\n}\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function(enc) {\n  if (!StringDecoder)\n    StringDecoder = __webpack_require__(42).StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n};\n\n// Don't raise the hwm > 128MB\nvar MAX_HWM = 0x800000;\nfunction roundUpToNextPowerOf2(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2\n    n--;\n    for (var p = 1; p < 32; p <<= 1) n |= n >> p;\n    n++;\n  }\n  return n;\n}\n\nfunction howMuchToRead(n, state) {\n  if (state.length === 0 && state.ended)\n    return 0;\n\n  if (state.objectMode)\n    return n === 0 ? 0 : 1;\n\n  if (n === null || isNaN(n)) {\n    // only flow one buffer at a time\n    if (state.flowing && state.buffer.length)\n      return state.buffer[0].length;\n    else\n      return state.length;\n  }\n\n  if (n <= 0)\n    return 0;\n\n  // If we're asking for more than the target buffer level,\n  // then raise the water mark.  Bump up to the next highest\n  // power of 2, to prevent increasing it excessively in tiny\n  // amounts.\n  if (n > state.highWaterMark)\n    state.highWaterMark = roundUpToNextPowerOf2(n);\n\n  // don't have that much.  return null, unless we've ended.\n  if (n > state.length) {\n    if (!state.ended) {\n      state.needReadable = true;\n      return 0;\n    } else\n      return state.length;\n  }\n\n  return n;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function(n) {\n  var state = this._readableState;\n  state.calledRead = true;\n  var nOrig = n;\n  var ret;\n\n  if (typeof n !== 'number' || n > 0)\n    state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 &&\n      state.needReadable &&\n      (state.length >= state.highWaterMark || state.ended)) {\n    emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    ret = null;\n\n    // In cases where the decoder did not receive enough data\n    // to produce a full chunk, then immediately received an\n    // EOF, state.buffer will contain [<Buffer >, <Buffer 00 ...>].\n    // howMuchToRead will see this and coerce the amount to\n    // read to zero (because it's looking at the length of the\n    // first <Buffer > in state.buffer), and we'll end up here.\n    //\n    // This can only happen via state.decoder -- no other venue\n    // exists for pushing a zero-length chunk into state.buffer\n    // and triggering this behavior. In this case, we return our\n    // remaining data and end the stream, if appropriate.\n    if (state.length > 0 && state.decoder) {\n      ret = fromList(n, state);\n      state.length -= ret.length;\n    }\n\n    if (state.length === 0)\n      endReadable(this);\n\n    return ret;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length - n <= state.highWaterMark)\n    doRead = true;\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading)\n    doRead = false;\n\n  if (doRead) {\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0)\n      state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n  }\n\n  // If _read called its callback synchronously, then `reading`\n  // will be false, and we need to re-evaluate how much data we\n  // can return to the user.\n  if (doRead && !state.reading)\n    n = howMuchToRead(nOrig, state);\n\n  if (n > 0)\n    ret = fromList(n, state);\n  else\n    ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  }\n\n  state.length -= n;\n\n  // If we have nothing in the buffer, then we want to know\n  // as soon as we *do* get something into the buffer.\n  if (state.length === 0 && !state.ended)\n    state.needReadable = true;\n\n  // If we happened to read() exactly the remaining amount in the\n  // buffer, and the EOF has been seen at this point, then make sure\n  // that we emit 'end' on the very next tick.\n  if (state.ended && !state.endEmitted && state.length === 0)\n    endReadable(this);\n\n  return ret;\n};\n\nfunction chunkInvalid(state, chunk) {\n  var er = null;\n  if (!Buffer.isBuffer(chunk) &&\n      'string' !== typeof chunk &&\n      chunk !== null &&\n      chunk !== undefined &&\n      !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n\nfunction onEofChunk(stream, state) {\n  if (state.decoder && !state.ended) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // if we've ended and we have some data left, then emit\n  // 'readable' now to make sure it gets picked up.\n  if (state.length > 0)\n    emitReadable(stream);\n  else\n    endReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (state.emittedReadable)\n    return;\n\n  state.emittedReadable = true;\n  if (state.sync)\n    process.nextTick(function() {\n      emitReadable_(stream);\n    });\n  else\n    emitReadable_(stream);\n}\n\nfunction emitReadable_(stream) {\n  stream.emit('readable');\n}\n\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(function() {\n      maybeReadMore_(stream, state);\n    });\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended &&\n         state.length < state.highWaterMark) {\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;\n    else\n      len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function(n) {\n  this.emit('error', new Error('not implemented'));\n};\n\nReadable.prototype.pipe = function(dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) &&\n              dest !== process.stdout &&\n              dest !== process.stderr;\n\n  var endFn = doEnd ? onend : cleanup;\n  if (state.endEmitted)\n    process.nextTick(endFn);\n  else\n    src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable) {\n    if (readable !== src) return;\n    cleanup();\n  }\n\n  function onend() {\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  function cleanup() {\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', cleanup);\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (!dest._writableState || dest._writableState.needDrain)\n      ondrain();\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EE.listenerCount(dest, 'error') === 0)\n      dest.emit('error', er);\n  }\n  // This is a brutally ugly hack to make sure that our error handler\n  // is attached before any userland ones.  NEVER DO THIS.\n  if (!dest._events || !dest._events.error)\n    dest.on('error', onerror);\n  else if (isArray(dest._events.error))\n    dest._events.error.unshift(onerror);\n  else\n    dest._events.error = [onerror, dest._events.error];\n\n\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    // the handler that waits for readable events after all\n    // the data gets sucked out in flow.\n    // This would be easier to follow with a .once() handler\n    // in flow(), but that is too slow.\n    this.on('readable', pipeOnReadable);\n\n    state.flowing = true;\n    process.nextTick(function() {\n      flow(src);\n    });\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function() {\n    var dest = this;\n    var state = src._readableState;\n    state.awaitDrain--;\n    if (state.awaitDrain === 0)\n      flow(src);\n  };\n}\n\nfunction flow(src) {\n  var state = src._readableState;\n  var chunk;\n  state.awaitDrain = 0;\n\n  function write(dest, i, list) {\n    var written = dest.write(chunk);\n    if (false === written) {\n      state.awaitDrain++;\n    }\n  }\n\n  while (state.pipesCount && null !== (chunk = src.read())) {\n\n    if (state.pipesCount === 1)\n      write(state.pipes, 0, null);\n    else\n      forEach(state.pipes, write);\n\n    src.emit('data', chunk);\n\n    // if anyone needs a drain, then we have to wait for that.\n    if (state.awaitDrain > 0)\n      return;\n  }\n\n  // if every destination was unpiped, either before entering this\n  // function, or in the while loop, then stop flowing.\n  //\n  // NB: This is a pretty rare edge case.\n  if (state.pipesCount === 0) {\n    state.flowing = false;\n\n    // if there were data event listeners added, then switch to old mode.\n    if (EE.listenerCount(src, 'data') > 0)\n      emitDataEvents(src);\n    return;\n  }\n\n  // at this point, no one needed a drain, so we just ran out of data\n  // on the next readable event, start it over again.\n  state.ranOut = true;\n}\n\nfunction pipeOnReadable() {\n  if (this._readableState.ranOut) {\n    this._readableState.ranOut = false;\n    flow(this);\n  }\n}\n\n\nReadable.prototype.unpipe = function(dest) {\n  var state = this._readableState;\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0)\n    return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes)\n      return this;\n\n    if (!dest)\n      dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    this.removeListener('readable', pipeOnReadable);\n    state.flowing = false;\n    if (dest)\n      dest.emit('unpipe', this);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    this.removeListener('readable', pipeOnReadable);\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++)\n      dests[i].emit('unpipe', this);\n    return this;\n  }\n\n  // try to find the right one.\n  var i = indexOf(state.pipes, dest);\n  if (i === -1)\n    return this;\n\n  state.pipes.splice(i, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1)\n    state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function(ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data' && !this._readableState.flowing)\n    emitDataEvents(this);\n\n  if (ev === 'readable' && this.readable) {\n    var state = this._readableState;\n    if (!state.readableListening) {\n      state.readableListening = true;\n      state.emittedReadable = false;\n      state.needReadable = true;\n      if (!state.reading) {\n        this.read(0);\n      } else if (state.length) {\n        emitReadable(this, state);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function() {\n  emitDataEvents(this);\n  this.read(0);\n  this.emit('resume');\n};\n\nReadable.prototype.pause = function() {\n  emitDataEvents(this, true);\n  this.emit('pause');\n};\n\nfunction emitDataEvents(stream, startPaused) {\n  var state = stream._readableState;\n\n  if (state.flowing) {\n    // https://github.com/isaacs/readable-stream/issues/16\n    throw new Error('Cannot switch to old mode now.');\n  }\n\n  var paused = startPaused || false;\n  var readable = false;\n\n  // convert to an old-style stream.\n  stream.readable = true;\n  stream.pipe = Stream.prototype.pipe;\n  stream.on = stream.addListener = Stream.prototype.on;\n\n  stream.on('readable', function() {\n    readable = true;\n\n    var c;\n    while (!paused && (null !== (c = stream.read())))\n      stream.emit('data', c);\n\n    if (c === null) {\n      readable = false;\n      stream._readableState.needReadable = true;\n    }\n  });\n\n  stream.pause = function() {\n    paused = true;\n    this.emit('pause');\n  };\n\n  stream.resume = function() {\n    paused = false;\n    if (readable)\n      process.nextTick(function() {\n        stream.emit('readable');\n      });\n    else\n      this.read(0);\n    this.emit('resume');\n  };\n\n  // now make it start, just in case it hadn't already.\n  stream.emit('readable');\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function(stream) {\n  var state = this._readableState;\n  var paused = false;\n\n  var self = this;\n  stream.on('end', function() {\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length)\n        self.push(chunk);\n    }\n\n    self.push(null);\n  });\n\n  stream.on('data', function(chunk) {\n    if (state.decoder)\n      chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    //if (state.objectMode && util.isNullOrUndefined(chunk))\n    if (state.objectMode && (chunk === null || chunk === undefined))\n      return;\n    else if (!state.objectMode && (!chunk || !chunk.length))\n      return;\n\n    var ret = self.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (typeof stream[i] === 'function' &&\n        typeof this[i] === 'undefined') {\n      this[i] = function(method) { return function() {\n        return stream[method].apply(stream, arguments);\n      }}(i);\n    }\n  }\n\n  // proxy certain important events.\n  var events = ['error', 'close', 'destroy', 'pause', 'resume'];\n  forEach(events, function(ev) {\n    stream.on(ev, self.emit.bind(self, ev));\n  });\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  self._read = function(n) {\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return self;\n};\n\n\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\nfunction fromList(n, state) {\n  var list = state.buffer;\n  var length = state.length;\n  var stringMode = !!state.decoder;\n  var objectMode = !!state.objectMode;\n  var ret;\n\n  // nothing in the list, definitely empty.\n  if (list.length === 0)\n    return null;\n\n  if (length === 0)\n    ret = null;\n  else if (objectMode)\n    ret = list.shift();\n  else if (!n || n >= length) {\n    // read it all, truncate the array.\n    if (stringMode)\n      ret = list.join('');\n    else\n      ret = Buffer.concat(list, length);\n    list.length = 0;\n  } else {\n    // read just some of it.\n    if (n < list[0].length) {\n      // just take a part of the first list item.\n      // slice is the same for buffers and strings.\n      var buf = list[0];\n      ret = buf.slice(0, n);\n      list[0] = buf.slice(n);\n    } else if (n === list[0].length) {\n      // first list is a perfect match\n      ret = list.shift();\n    } else {\n      // complex case.\n      // we have enough to cover it, but it spans past the first buffer.\n      if (stringMode)\n        ret = '';\n      else\n        ret = new Buffer(n);\n\n      var c = 0;\n      for (var i = 0, l = list.length; i < l && c < n; i++) {\n        var buf = list[0];\n        var cpy = Math.min(n - c, buf.length);\n\n        if (stringMode)\n          ret += buf.slice(0, cpy);\n        else\n          buf.copy(ret, c, 0, cpy);\n\n        if (cpy < buf.length)\n          list[0] = buf.slice(cpy);\n        else\n          list.shift();\n\n        c += cpy;\n      }\n    }\n  }\n\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0)\n    throw new Error('endReadable called on non-empty stream');\n\n  if (!state.endEmitted && state.calledRead) {\n    state.ended = true;\n    process.nextTick(function() {\n      // Check that we didn't get one last unshift.\n      if (!state.endEmitted && state.length === 0) {\n        state.endEmitted = true;\n        stream.readable = false;\n        stream.emit('end');\n      }\n    });\n  }\n}\n\nfunction forEach (xs, f) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    f(xs[i], i);\n  }\n}\n\nfunction indexOf (xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8)))\n\n/***/ }),\n/* 204 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, cb), and it'll handle all\n// the drain event emission and buffering.\n\nmodule.exports = Writable;\n\n/*<replacement>*/\nvar Buffer = __webpack_require__(24).Buffer;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nvar Stream = __webpack_require__(126);\n\nutil.inherits(Writable, Stream);\n\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n}\n\nfunction WritableState(options, stream) {\n  options = options || {};\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  this.highWaterMark = (hwm || hwm === 0) ? hwm : 16 * 1024;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  // cast to ints.\n  this.highWaterMark = ~~this.highWaterMark;\n\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, becuase any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function(er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.buffer = [];\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n}\n\nfunction Writable(options) {\n  var Duplex = __webpack_require__(129);\n\n  // Writable ctor is applied to Duplexes, though they're not\n  // instanceof Writable, they're instanceof Readable.\n  if (!(this instanceof Writable) && !(this instanceof Duplex))\n    return new Writable(options);\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function() {\n  this.emit('error', new Error('Cannot pipe. Not readable.'));\n};\n\n\nfunction writeAfterEnd(stream, state, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  process.nextTick(function() {\n    cb(er);\n  });\n}\n\n// If we get something that is not a buffer, string, null, or undefined,\n// and we're not in objectMode, then that's an error.\n// Otherwise stream chunks are all considered to be of length=1, and the\n// watermarks determine how many objects to keep in the buffer, rather than\n// how many bytes or characters.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  if (!Buffer.isBuffer(chunk) &&\n      'string' !== typeof chunk &&\n      chunk !== null &&\n      chunk !== undefined &&\n      !state.objectMode) {\n    var er = new TypeError('Invalid non-string/buffer chunk');\n    stream.emit('error', er);\n    process.nextTick(function() {\n      cb(er);\n    });\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function(chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (Buffer.isBuffer(chunk))\n    encoding = 'buffer';\n  else if (!encoding)\n    encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function')\n    cb = function() {};\n\n  if (state.ended)\n    writeAfterEnd(this, state, cb);\n  else if (validChunk(this, state, chunk, cb))\n    ret = writeOrBuffer(this, state, chunk, encoding, cb);\n\n  return ret;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode &&\n      state.decodeStrings !== false &&\n      typeof chunk === 'string') {\n    chunk = new Buffer(chunk, encoding);\n  }\n  return chunk;\n}\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, chunk, encoding, cb) {\n  chunk = decodeChunk(state, chunk, encoding);\n  if (Buffer.isBuffer(chunk))\n    encoding = 'buffer';\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret)\n    state.needDrain = true;\n\n  if (state.writing)\n    state.buffer.push(new WriteReq(chunk, encoding, cb));\n  else\n    doWrite(stream, state, len, chunk, encoding, cb);\n\n  return ret;\n}\n\nfunction doWrite(stream, state, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  if (sync)\n    process.nextTick(function() {\n      cb(er);\n    });\n  else\n    cb(er);\n\n  stream._writableState.errorEmitted = true;\n  stream.emit('error', er);\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er)\n    onwriteError(stream, state, sync, er, cb);\n  else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(stream, state);\n\n    if (!finished && !state.bufferProcessing && state.buffer.length)\n      clearBuffer(stream, state);\n\n    if (sync) {\n      process.nextTick(function() {\n        afterWrite(stream, state, finished, cb);\n      });\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished)\n    onwriteDrain(stream, state);\n  cb();\n  if (finished)\n    finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n\n  for (var c = 0; c < state.buffer.length; c++) {\n    var entry = state.buffer[c];\n    var chunk = entry.chunk;\n    var encoding = entry.encoding;\n    var cb = entry.callback;\n    var len = state.objectMode ? 1 : chunk.length;\n\n    doWrite(stream, state, len, chunk, encoding, cb);\n\n    // if we didn't call the onwrite immediately, then\n    // it means that we need to wait until it does.\n    // also, that means that the chunk and cb are currently\n    // being processed, so move the buffer counter past them.\n    if (state.writing) {\n      c++;\n      break;\n    }\n  }\n\n  state.bufferProcessing = false;\n  if (c < state.buffer.length)\n    state.buffer = state.buffer.slice(c);\n  else\n    state.buffer.length = 0;\n}\n\nWritable.prototype._write = function(chunk, encoding, cb) {\n  cb(new Error('not implemented'));\n};\n\nWritable.prototype.end = function(chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (typeof chunk !== 'undefined' && chunk !== null)\n    this.write(chunk, encoding);\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished)\n    endWritable(this, state, cb);\n};\n\n\nfunction needFinish(stream, state) {\n  return (state.ending &&\n          state.length === 0 &&\n          !state.finished &&\n          !state.writing);\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(stream, state);\n  if (need) {\n    state.finished = true;\n    stream.emit('finish');\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished)\n      process.nextTick(cb);\n    else\n      stream.once('finish', cb);\n  }\n  state.ended = true;\n}\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8)))\n\n/***/ }),\n/* 205 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\nmodule.exports = Transform;\n\nvar Duplex = __webpack_require__(129);\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\n\nfunction TransformState(options, stream) {\n  this.afterTransform = function(er, data) {\n    return afterTransform(stream, er, data);\n  };\n\n  this.needTransform = false;\n  this.transforming = false;\n  this.writecb = null;\n  this.writechunk = null;\n}\n\nfunction afterTransform(stream, er, data) {\n  var ts = stream._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb)\n    return stream.emit('error', new Error('no writecb in Transform class'));\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data !== null && data !== undefined)\n    stream.push(data);\n\n  if (cb)\n    cb(er);\n\n  var rs = stream._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    stream._read(rs.highWaterMark);\n  }\n}\n\n\nfunction Transform(options) {\n  if (!(this instanceof Transform))\n    return new Transform(options);\n\n  Duplex.call(this, options);\n\n  var ts = this._transformState = new TransformState(options, this);\n\n  // when the writable side finishes, then flush out anything remaining.\n  var stream = this;\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  this.once('finish', function() {\n    if ('function' === typeof this._flush)\n      this._flush(function(er) {\n        done(stream, er);\n      });\n    else\n      done(stream);\n  });\n}\n\nTransform.prototype.push = function(chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function(chunk, encoding, cb) {\n  throw new Error('not implemented');\n};\n\nTransform.prototype._write = function(chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform ||\n        rs.needReadable ||\n        rs.length < rs.highWaterMark)\n      this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function(n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\n\nfunction done(stream, er) {\n  if (er)\n    return stream.emit('error', er);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  var ws = stream._writableState;\n  var rs = stream._readableState;\n  var ts = stream._transformState;\n\n  if (ws.length)\n    throw new Error('calling transform done when ws.length != 0');\n\n  if (ts.transforming)\n    throw new Error('calling transform done when still transforming');\n\n  return stream.push(null);\n}\n\n\n/***/ }),\n/* 206 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global, process) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(25);\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = __webpack_require__(616);\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = __webpack_require__(23).EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(207);\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(35).Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = __webpack_require__(617);\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = __webpack_require__(618);\nvar destroyImpl = __webpack_require__(208);\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || __webpack_require__(61);\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = __webpack_require__(42).StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || __webpack_require__(61);\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = __webpack_require__(42).StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12), __webpack_require__(8)))\n\n/***/ }),\n/* 207 */\n/***/ (function(module, exports, __webpack_require__) {\n\nmodule.exports = __webpack_require__(23).EventEmitter;\n\n\n/***/ }),\n/* 208 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(25);\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};\n\n/***/ }),\n/* 209 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(process, setImmediate, global) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(25);\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: __webpack_require__(125)\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(207);\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(35).Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = __webpack_require__(208);\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || __webpack_require__(61);\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || __webpack_require__(61);\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8), __webpack_require__(124).setImmediate, __webpack_require__(12)))\n\n/***/ }),\n/* 210 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n\n\nmodule.exports = Transform;\n\nvar Duplex = __webpack_require__(61);\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}\n\n/***/ }),\n/* 211 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Determine whether a given value is a function object.\n * @version 3.3.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module is-function-x\n */\n\n\n\nvar attempt = __webpack_require__(130);\nvar fToString = Function.prototype.toString;\nvar toBoolean = __webpack_require__(212);\nvar isFalsey = __webpack_require__(213);\nvar toStringTag = __webpack_require__(214);\nvar hasToStringTag = __webpack_require__(216);\nvar isPrimitive = __webpack_require__(132);\nvar normalise = __webpack_require__(625).normalizeSpace;\nvar deComment = __webpack_require__(627);\nvar funcTag = '[object Function]';\nvar genTag = '[object GeneratorFunction]';\nvar asyncTag = '[object AsyncFunction]';\nvar ctrRx = /^class /;\nvar test = ctrRx.test;\n\nvar hasNativeClass = attempt(function () {\n  // eslint-disable-next-line no-new-func\n  return Function('\"use strict\"; return class My {};')();\n}).threw === false;\n\nvar testClassstring = function _testClassstring(value) {\n  return test.call(ctrRx, normalise(deComment(fToString.call(value), ' ')));\n};\n\nvar isES6ClassFn = function isES6ClassFunc(value) {\n  var result = attempt(testClassstring, value);\n\n  return result.threw === false && result.value;\n};\n\n/**\n * Checks if `value` is classified as a `Function` object.\n *\n * @private\n * @param {*} value - The value to check.\n * @param {boolean} allowClass - Whether to filter ES6 classes.\n * @returns {boolean} Returns `true` if `value` is correctly classified,\n * else `false`.\n */\nvar tryFuncToString = function funcToString(value, allowClass) {\n  if (hasNativeClass && allowClass === false && isES6ClassFn(value)) {\n    return false;\n  }\n\n  return attempt.call(value, fToString).threw === false;\n};\n\n/**\n * Checks if `value` is classified as a `Function` object.\n *\n * @param {*} value - The value to check.\n * @param {boolean} [allowClass=false] - Whether to filter ES6 classes.\n * @returns {boolean} Returns `true` if `value` is correctly classified,\n * else `false`.\n * @example\n * var isFunction = require('is-function-x');\n *\n * isFunction(); // false\n * isFunction(Number.MIN_VALUE); // false\n * isFunction('abc'); // false\n * isFunction(true); // false\n * isFunction({ name: 'abc' }); // false\n * isFunction(function () {}); // true\n * isFunction(new Function ()); // true\n * isFunction(function* test1() {}); // true\n * isFunction(function test2(a, b) {}); // true\n * isFunction(async function test3() {}); // true\n * isFunction(class Test {}); // false\n * isFunction(class Test {}, true); // true\n * isFunction((x, y) => {return this;}); // true\n */\nmodule.exports = function isFunction(value) {\n  if (isPrimitive(value)) {\n    return false;\n  }\n\n  if (hasToStringTag) {\n    return tryFuncToString(value, toBoolean(arguments[1]));\n  }\n\n  if (hasNativeClass && isFalsey(arguments[1]) && isES6ClassFn(value)) {\n    return false;\n  }\n\n  var strTag = toStringTag(value);\n  return strTag === funcTag || strTag === genTag || strTag === asyncTag;\n};\n\n\n/***/ }),\n/* 212 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Converts argument to a value of type Boolean.\n * @version 1.0.3\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module to-boolean-x\n */\n\n\n\n/**\n * The abstract operation ToBoolean converts argument to a value of type Boolean.\n *\n * @param {*} value - The value to be converted.\n * @returns {boolean} 'true' if value is truthy; otherwise 'false'.\n * @example\n * var toBoolean = require('to-boolean-x');\n *\n * toBoolean(null); // false\n * toBoolean(''); // false\n * toBoolean(1); // true\n * toBoolean('0'); // true\n */\nmodule.exports = function toBoolean(value) {\n  return !!value;\n};\n\n\n/***/ }),\n/* 213 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Test if a given value is falsey.\n * @version 1.0.3\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module is-falsey-x\n */\n\n\n\nvar toBoolean = __webpack_require__(212);\n\n/**\n * This method tests if a given value is falsey.\n *\n * @param {*} value - The value to test.\n * @returns {boolean} `true` if the value is falsey: otherwise `false`.\n * @example\n * var isFalsey = require('is-falsey-x');\n *\n * isFalsey(); // true\n * isFalsey(0); // true\n * isFalsey(''); // true\n * isFalsey(false); // true\n * isFalsey(null); // true\n *\n * isFalsey(true); // false\n * isFalsey([]); // false\n * isFalsey(1); // false\n * isFalsey(function () {}); // false\n */\nmodule.exports = function isFalsey(value) {\n  return toBoolean(value) === false;\n};\n\n\n/***/ }),\n/* 214 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Get an object's ES6 @@toStringTag.\n * @see {@link http://www.ecma-international.org/ecma-262/6.0/#sec-object.prototype.tostring|19.1.3.6 Object.prototype.toString ( )}\n * @version 1.4.3\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module to-string-tag-x\n */\n\n\n\nvar isNull = __webpack_require__(215);\nvar isUndefined = __webpack_require__(131);\nvar toStr = {}.toString;\n\n/**\n * The `toStringTag` method returns \"[object type]\", where type is the\n * object type.\n *\n * @param {*} value - The object of which to get the object type string.\n * @returns {string} The object type string.\n * @example\n * var toStringTag = require('to-string-tag-x');\n *\n * var o = new Object();\n * toStringTag(o); // returns '[object Object]'\n */\nmodule.exports = function toStringTag(value) {\n  if (isNull(value)) {\n    return '[object Null]';\n  }\n\n  if (isUndefined(value)) {\n    return '[object Undefined]';\n  }\n\n  return toStr.call(value);\n};\n\n\n/***/ }),\n/* 215 */\n/***/ (function(module, exports) {\n\n/**\n * lodash 3.0.0 (Custom Build) <https://lodash.com/>\n * Build: `lodash modern modularize exports=\"npm\" -o ./`\n * Copyright 2012-2015 The Dojo Foundation <http://dojofoundation.org/>\n * Based on Underscore.js 1.7.0 <http://underscorejs.org/LICENSE>\n * Copyright 2009-2015 Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors\n * Available under MIT license <https://lodash.com/license>\n */\n\n/**\n * Checks if `value` is `null`.\n *\n * @static\n * @memberOf _\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is `null`, else `false`.\n * @example\n *\n * _.isNull(null);\n * // => true\n *\n * _.isNull(void 0);\n * // => false\n */\nfunction isNull(value) {\n  return value === null;\n}\n\nmodule.exports = isNull;\n\n\n/***/ }),\n/* 216 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Tests if ES6 @@toStringTag is supported.\n * @see {@link http://www.ecma-international.org/ecma-262/6.0/#sec-@@tostringtag|26.3.1 @@toStringTag}\n * @version 1.4.1\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module has-to-string-tag-x\n */\n\n\n\n/**\n * Indicates if `Symbol.toStringTag`exists and is the correct type.\n * `true`, if it exists and is the correct type, otherwise `false`.\n *\n * @type boolean\n */\nmodule.exports = __webpack_require__(67) && typeof Symbol.toStringTag === 'symbol';\n\n\n/***/ }),\n/* 217 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file This method removes whitespace from the left and right end of a string.\n * @version 3.0.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module trim-x\n */\n\n\n\nvar libTrimLeft = __webpack_require__(133);\nvar trimLeft2016 = libTrimLeft.trimLeft2016;\nvar trimLeft2018 = libTrimLeft.trimLeft2018;\nvar libTrimRight = __webpack_require__(626);\nvar trimRight2016 = libTrimRight.trimRight2016;\nvar trimRight2018 = libTrimRight.trimRight2016;\n\nvar $trim2016 = function trim2016(string) {\n  return trimLeft2016(trimRight2016(string));\n};\n\nvar $trim2018 = function trim2018(string) {\n  return trimLeft2018(trimRight2018(string));\n};\n\nmodule.exports = {\n  /**\n   * A reference to trim2018.\n   */\n  trim: $trim2018,\n\n  /**\n   * This method removes whitespace from the left and right end of a string.\n   * (ES2016)\n   * @param {string} string - The string to trim the whitespace from.\n   * @throws {TypeError} If string is null or undefined or not coercible.\n   * @returns {string} The trimmed string.\n   * @example\n   * var trim = require('trim-x');\n   *\n   * trim(' \\t\\na \\t\\n') === 'a'; // true\n   */\n  trim2016: $trim2016,\n\n  /**\n   * This method removes whitespace from the left and right end of a string.\n   * (ES2018)\n   *\n   * @param {string} string - The string to trim the whitespace from.\n   * @throws {TypeError} If string is null or undefined or not coercible.\n   * @returns {string} The trimmed string.\n   * @example\n   * var trim = require('trim-x');\n   *\n   * trim(' \\t\\na \\t\\n') === 'a'; // true\n   */\n  trim2018: $trim2018\n};\n\n\n/***/ }),\n/* 218 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Checks if `value` is `null` or `undefined`.\n * @version 1.4.2\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module is-nil-x\n */\n\n\n\nvar isUndefined = __webpack_require__(131);\nvar isNull = __webpack_require__(215);\n\n/**\n * Checks if `value` is `null` or `undefined`.\n *\n * @param {*} value - The value to check.\n * @returns {boolean} Returns `true` if `value` is nullish, else `false`.\n * @example\n * var isNil = require('is-nil-x');\n *\n * isNil(null); // => true\n * isNil(void 0); // => true\n * isNil(NaN); // => false\n */\nmodule.exports = function isNil(value) {\n  return isNull(value) || isUndefined(value);\n};\n\n\n/***/ }),\n/* 219 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Converts a JavaScript object to a primitive value.\n * @version 1.1.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module to-primitive-x\n */\n\n\n\nvar hasSymbols = __webpack_require__(67);\nvar isPrimitive = __webpack_require__(132);\nvar isDate = __webpack_require__(630);\nvar isSymbol = __webpack_require__(136);\nvar isFunction = __webpack_require__(211);\nvar requireObjectCoercible = __webpack_require__(135);\nvar isNil = __webpack_require__(218);\nvar isUndefined = __webpack_require__(131);\nvar symToPrimitive = hasSymbols && Symbol.toPrimitive;\nvar symValueOf = hasSymbols && Symbol.prototype.valueOf;\n\nvar toStringOrder = ['toString', 'valueOf'];\nvar toNumberOrder = ['valueOf', 'toString'];\nvar orderLength = 2;\n\nvar ordinaryToPrimitive = function _ordinaryToPrimitive(O, hint) {\n  requireObjectCoercible(O);\n  if (typeof hint !== 'string' || (hint !== 'number' && hint !== 'string')) {\n    throw new TypeError('hint must be \"string\" or \"number\"');\n  }\n\n  var methodNames = hint === 'string' ? toStringOrder : toNumberOrder;\n  var method;\n  var result;\n  for (var i = 0; i < orderLength; i += 1) {\n    method = O[methodNames[i]];\n    if (isFunction(method)) {\n      result = method.call(O);\n      if (isPrimitive(result)) {\n        return result;\n      }\n    }\n  }\n\n  throw new TypeError('No default value');\n};\n\nvar getMethod = function _getMethod(O, P) {\n  var func = O[P];\n  if (isNil(func) === false) {\n    if (isFunction(func) === false) {\n      throw new TypeError(func + ' returned for property ' + P + ' of object ' + O + ' is not a function');\n    }\n\n    return func;\n  }\n\n  return void 0;\n};\n\n// http://www.ecma-international.org/ecma-262/6.0/#sec-toprimitive\n\n/**\n * This method converts a JavaScript object to a primitive value.\n * Note: When toPrimitive is called with no hint, then it generally behaves as\n * if the hint were Number. However, objects may over-ride this behaviour by\n * defining a @@toPrimitive method. Of the objects defined in this specification\n * only Date objects (see 20.3.4.45) and Symbol objects (see 19.4.3.4) over-ride\n * the default ToPrimitive behaviour. Date objects treat no hint as if the hint\n * were String.\n *\n * @param {*} input - The input to convert.\n * @param {constructor} [prefferedtype] - The preffered type (String or Number).\n * @throws {TypeError} If unable to convert input to a primitive.\n * @returns {string|number} The converted input as a primitive.\n * @example\n * var toPrimitive = require('to-primitive-x');\n *\n * var date = new Date(0);\n * toPrimitive(date)); // Thu Jan 01 1970 01:00:00 GMT+0100 (CET)\n * toPrimitive(date, String)); // Thu Jan 01 1970 01:00:00 GMT+0100 (CET)\n * toPrimitive(date, Number)); // 0\n */\nmodule.exports = function toPrimitive(input, preferredType) {\n  if (isPrimitive(input)) {\n    return input;\n  }\n\n  var hint = 'default';\n  if (arguments.length > 1) {\n    if (preferredType === String) {\n      hint = 'string';\n    } else if (preferredType === Number) {\n      hint = 'number';\n    }\n  }\n\n  var exoticToPrim;\n  if (hasSymbols) {\n    if (symToPrimitive) {\n      exoticToPrim = getMethod(input, symToPrimitive);\n    } else if (isSymbol(input)) {\n      exoticToPrim = symValueOf;\n    }\n  }\n\n  if (isUndefined(exoticToPrim) === false) {\n    var result = exoticToPrim.call(input, hint);\n    if (isPrimitive(result)) {\n      return result;\n    }\n\n    throw new TypeError('unable to convert exotic object to primitive');\n  }\n\n  if (hint === 'default' && (isDate(input) || isSymbol(input))) {\n    hint = 'string';\n  }\n\n  return ordinaryToPrimitive(input, hint === 'default' ? 'number' : hint);\n};\n\n\n/***/ }),\n/* 220 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file The constant NaN derived mathematically by 0 / 0.\n * @version 1.0.2\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module nan-x\n */\n\n\n\n/**\n * The constant NaN derived mathematically by 0 / 0.\n *\n * @type number\n * @example\n * var NAN = require('nan-x');\n *\n * NAN !== NAN; // true\n * NAN === NAN; // false\n */\nmodule.exports = 0 / 0;\n\n\n/***/ }),\n/* 221 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return binaryMd5; });\n/* unused harmony export stringMd5 */\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_pouchdb_binary_utils__ = __webpack_require__(123);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_spark_md5__ = __webpack_require__(183);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_spark_md5___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_1_spark_md5__);\n\n\n\nvar setImmediateShim = global.setImmediate || global.setTimeout;\nvar MD5_CHUNK_SIZE = 32768;\n\nfunction rawToBase64(raw) {\n  return Object(__WEBPACK_IMPORTED_MODULE_0_pouchdb_binary_utils__[\"f\" /* btoa */])(raw);\n}\n\nfunction sliceBlob(blob, start, end) {\n  if (blob.webkitSlice) {\n    return blob.webkitSlice(start, end);\n  }\n  return blob.slice(start, end);\n}\n\nfunction appendBlob(buffer, blob, start, end, callback) {\n  if (start > 0 || end < blob.size) {\n    // only slice blob if we really need to\n    blob = sliceBlob(blob, start, end);\n  }\n  Object(__WEBPACK_IMPORTED_MODULE_0_pouchdb_binary_utils__[\"g\" /* readAsArrayBuffer */])(blob, function (arrayBuffer) {\n    buffer.append(arrayBuffer);\n    callback();\n  });\n}\n\nfunction appendString(buffer, string, start, end, callback) {\n  if (start > 0 || end < string.length) {\n    // only create a substring if we really need to\n    string = string.substring(start, end);\n  }\n  buffer.appendBinary(string);\n  callback();\n}\n\nfunction binaryMd5(data, callback) {\n  var inputIsString = typeof data === 'string';\n  var len = inputIsString ? data.length : data.size;\n  var chunkSize = Math.min(MD5_CHUNK_SIZE, len);\n  var chunks = Math.ceil(len / chunkSize);\n  var currentChunk = 0;\n  var buffer = inputIsString ? new __WEBPACK_IMPORTED_MODULE_1_spark_md5___default.a() : new __WEBPACK_IMPORTED_MODULE_1_spark_md5___default.a.ArrayBuffer();\n\n  var append = inputIsString ? appendString : appendBlob;\n\n  function next() {\n    setImmediateShim(loadNextChunk);\n  }\n\n  function done() {\n    var raw = buffer.end(true);\n    var base64 = rawToBase64(raw);\n    callback(base64);\n    buffer.destroy();\n  }\n\n  function loadNextChunk() {\n    var start = currentChunk * chunkSize;\n    var end = start + chunkSize;\n    currentChunk++;\n    if (currentChunk < chunks) {\n      append(buffer, data, start, end, next);\n    } else {\n      append(buffer, data, start, end, done);\n    }\n  }\n  loadNextChunk();\n}\n\nfunction stringMd5(string) {\n  return __WEBPACK_IMPORTED_MODULE_1_spark_md5___default.a.hash(string);\n}\n\n\n\n/* WEBPACK VAR INJECTION */}.call(__webpack_exports__, __webpack_require__(12)))\n\n/***/ }),\n/* 222 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return collectConflicts; });\n/* unused harmony export collectLeaves */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"b\", function() { return compactTree; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"c\", function() { return isDeleted; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"d\", function() { return isLocalId; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"f\", function() { return merge; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"g\", function() { return revExists; });\n/* unused harmony export rootToLeaf */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"h\", function() { return traverseRevTree; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"i\", function() { return winningRev; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"e\", function() { return latest; });\n// We fetch all leafs of the revision tree, and sort them based on tree length\n// and whether they were deleted, undeleted documents with the longest revision\n// tree (most edits) win\n// The final sort algorithm is slightly documented in a sidebar here:\n// http://guide.couchdb.org/draft/conflicts.html\nfunction winningRev(metadata) {\n  var winningId;\n  var winningPos;\n  var winningDeleted;\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var tree = node.ids;\n    var branches = tree[2];\n    var pos = node.pos;\n    if (branches.length) { // non-leaf\n      for (var i = 0, len = branches.length; i < len; i++) {\n        toVisit.push({pos: pos + 1, ids: branches[i]});\n      }\n      continue;\n    }\n    var deleted = !!tree[1].deleted;\n    var id = tree[0];\n    // sort by deleted, then pos, then id\n    if (!winningId || (winningDeleted !== deleted ? winningDeleted :\n        winningPos !== pos ? winningPos < pos : winningId < id)) {\n      winningId = id;\n      winningPos = pos;\n      winningDeleted = deleted;\n    }\n  }\n\n  return winningPos + '-' + winningId;\n}\n\n// Pretty much all below can be combined into a higher order function to\n// traverse revisions\n// The return value from the callback will be passed as context to all\n// children of that node\nfunction traverseRevTree(revs, callback) {\n  var toVisit = revs.slice();\n\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var branches = tree[2];\n    var newCtx =\n      callback(branches.length === 0, pos, tree[0], node.ctx, tree[1]);\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], ctx: newCtx});\n    }\n  }\n}\n\nfunction sortByPos(a, b) {\n  return a.pos - b.pos;\n}\n\nfunction collectLeaves(revs) {\n  var leaves = [];\n  traverseRevTree(revs, function (isLeaf, pos, id, acc, opts) {\n    if (isLeaf) {\n      leaves.push({rev: pos + \"-\" + id, pos: pos, opts: opts});\n    }\n  });\n  leaves.sort(sortByPos).reverse();\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    delete leaves[i].pos;\n  }\n  return leaves;\n}\n\n// returns revs of all conflicts that is leaves such that\n// 1. are not deleted and\n// 2. are different than winning revision\nfunction collectConflicts(metadata) {\n  var win = winningRev(metadata);\n  var leaves = collectLeaves(metadata.rev_tree);\n  var conflicts = [];\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    var leaf = leaves[i];\n    if (leaf.rev !== win && !leaf.opts.deleted) {\n      conflicts.push(leaf.rev);\n    }\n  }\n  return conflicts;\n}\n\n// compact a tree by marking its non-leafs as missing,\n// and return a list of revs to delete\nfunction compactTree(metadata) {\n  var revs = [];\n  traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                               revHash, ctx, opts) {\n    if (opts.status === 'available' && !isLeaf) {\n      revs.push(pos + '-' + revHash);\n      opts.status = 'missing';\n    }\n  });\n  return revs;\n}\n\n// build up a list of all the paths to the leafs in this revision tree\nfunction rootToLeaf(revs) {\n  var paths = [];\n  var toVisit = revs.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, opts: opts});\n    if (isLeaf) {\n      paths.push({pos: (pos + 1 - history.length), ids: history});\n    }\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], history: history});\n    }\n  }\n  return paths.reverse();\n}\n\n// for a better overview of what this is doing, read:\n// https://github.com/apache/couchdb-couch/blob/master/src/couch_key_tree.erl\n//\n// But for a quick intro, CouchDB uses a revision tree to store a documents\n// history, A -> B -> C, when a document has conflicts, that is a branch in the\n// tree, A -> (B1 | B2 -> C), We store these as a nested array in the format\n//\n// KeyTree = [Path ... ]\n// Path = {pos: position_from_root, ids: Tree}\n// Tree = [Key, Opts, [Tree, ...]], in particular single node: [Key, []]\n\nfunction sortByPos$1(a, b) {\n  return a.pos - b.pos;\n}\n\n// classic binary search\nfunction binarySearch(arr, item, comparator) {\n  var low = 0;\n  var high = arr.length;\n  var mid;\n  while (low < high) {\n    mid = (low + high) >>> 1;\n    if (comparator(arr[mid], item) < 0) {\n      low = mid + 1;\n    } else {\n      high = mid;\n    }\n  }\n  return low;\n}\n\n// assuming the arr is sorted, insert the item in the proper place\nfunction insertSorted(arr, item, comparator) {\n  var idx = binarySearch(arr, item, comparator);\n  arr.splice(idx, 0, item);\n}\n\n// Turn a path as a flat array into a tree with a single branch.\n// If any should be stemmed from the beginning of the array, that's passed\n// in as the second argument\nfunction pathToTree(path, numStemmed) {\n  var root;\n  var leaf;\n  for (var i = numStemmed, len = path.length; i < len; i++) {\n    var node = path[i];\n    var currentLeaf = [node.id, node.opts, []];\n    if (leaf) {\n      leaf[2].push(currentLeaf);\n      leaf = currentLeaf;\n    } else {\n      root = leaf = currentLeaf;\n    }\n  }\n  return root;\n}\n\n// compare the IDs of two trees\nfunction compareTree(a, b) {\n  return a[0] < b[0] ? -1 : 1;\n}\n\n// Merge two trees together\n// The roots of tree1 and tree2 must be the same revision\nfunction mergeTree(in_tree1, in_tree2) {\n  var queue = [{tree1: in_tree1, tree2: in_tree2}];\n  var conflicts = false;\n  while (queue.length > 0) {\n    var item = queue.pop();\n    var tree1 = item.tree1;\n    var tree2 = item.tree2;\n\n    if (tree1[1].status || tree2[1].status) {\n      tree1[1].status =\n        (tree1[1].status ===  'available' ||\n        tree2[1].status === 'available') ? 'available' : 'missing';\n    }\n\n    for (var i = 0; i < tree2[2].length; i++) {\n      if (!tree1[2][0]) {\n        conflicts = 'new_leaf';\n        tree1[2][0] = tree2[2][i];\n        continue;\n      }\n\n      var merged = false;\n      for (var j = 0; j < tree1[2].length; j++) {\n        if (tree1[2][j][0] === tree2[2][i][0]) {\n          queue.push({tree1: tree1[2][j], tree2: tree2[2][i]});\n          merged = true;\n        }\n      }\n      if (!merged) {\n        conflicts = 'new_branch';\n        insertSorted(tree1[2], tree2[2][i], compareTree);\n      }\n    }\n  }\n  return {conflicts: conflicts, tree: in_tree1};\n}\n\nfunction doMerge(tree, path, dontExpand) {\n  var restree = [];\n  var conflicts = false;\n  var merged = false;\n  var res;\n\n  if (!tree.length) {\n    return {tree: [path], conflicts: 'new_leaf'};\n  }\n\n  for (var i = 0, len = tree.length; i < len; i++) {\n    var branch = tree[i];\n    if (branch.pos === path.pos && branch.ids[0] === path.ids[0]) {\n      // Paths start at the same position and have the same root, so they need\n      // merged\n      res = mergeTree(branch.ids, path.ids);\n      restree.push({pos: branch.pos, ids: res.tree});\n      conflicts = conflicts || res.conflicts;\n      merged = true;\n    } else if (dontExpand !== true) {\n      // The paths start at a different position, take the earliest path and\n      // traverse up until it as at the same point from root as the path we\n      // want to merge.  If the keys match we return the longer path with the\n      // other merged After stemming we dont want to expand the trees\n\n      var t1 = branch.pos < path.pos ? branch : path;\n      var t2 = branch.pos < path.pos ? path : branch;\n      var diff = t2.pos - t1.pos;\n\n      var candidateParents = [];\n\n      var trees = [];\n      trees.push({ids: t1.ids, diff: diff, parent: null, parentIdx: null});\n      while (trees.length > 0) {\n        var item = trees.pop();\n        if (item.diff === 0) {\n          if (item.ids[0] === t2.ids[0]) {\n            candidateParents.push(item);\n          }\n          continue;\n        }\n        var elements = item.ids[2];\n        for (var j = 0, elementsLen = elements.length; j < elementsLen; j++) {\n          trees.push({\n            ids: elements[j],\n            diff: item.diff - 1,\n            parent: item.ids,\n            parentIdx: j\n          });\n        }\n      }\n\n      var el = candidateParents[0];\n\n      if (!el) {\n        restree.push(branch);\n      } else {\n        res = mergeTree(el.ids, t2.ids);\n        el.parent[2][el.parentIdx] = res.tree;\n        restree.push({pos: t1.pos, ids: t1.ids});\n        conflicts = conflicts || res.conflicts;\n        merged = true;\n      }\n    } else {\n      restree.push(branch);\n    }\n  }\n\n  // We didnt find\n  if (!merged) {\n    restree.push(path);\n  }\n\n  restree.sort(sortByPos$1);\n\n  return {\n    tree: restree,\n    conflicts: conflicts || 'internal_node'\n  };\n}\n\n// To ensure we dont grow the revision tree infinitely, we stem old revisions\nfunction stem(tree, depth) {\n  // First we break out the tree into a complete list of root to leaf paths\n  var paths = rootToLeaf(tree);\n  var stemmedRevs;\n\n  var result;\n  for (var i = 0, len = paths.length; i < len; i++) {\n    // Then for each path, we cut off the start of the path based on the\n    // `depth` to stem to, and generate a new set of flat trees\n    var path = paths[i];\n    var stemmed = path.ids;\n    var node;\n    if (stemmed.length > depth) {\n      // only do the stemming work if we actually need to stem\n      if (!stemmedRevs) {\n        stemmedRevs = {}; // avoid allocating this object unnecessarily\n      }\n      var numStemmed = stemmed.length - depth;\n      node = {\n        pos: path.pos + numStemmed,\n        ids: pathToTree(stemmed, numStemmed)\n      };\n\n      for (var s = 0; s < numStemmed; s++) {\n        var rev = (path.pos + s) + '-' + stemmed[s].id;\n        stemmedRevs[rev] = true;\n      }\n    } else { // no need to actually stem\n      node = {\n        pos: path.pos,\n        ids: pathToTree(stemmed, 0)\n      };\n    }\n\n    // Then we remerge all those flat trees together, ensuring that we dont\n    // connect trees that would go beyond the depth limit\n    if (result) {\n      result = doMerge(result, node, true).tree;\n    } else {\n      result = [node];\n    }\n  }\n\n  // this is memory-heavy per Chrome profiler, avoid unless we actually stemmed\n  if (stemmedRevs) {\n    traverseRevTree(result, function (isLeaf, pos, revHash) {\n      // some revisions may have been removed in a branch but not in another\n      delete stemmedRevs[pos + '-' + revHash];\n    });\n  }\n\n  return {\n    tree: result,\n    revs: stemmedRevs ? Object.keys(stemmedRevs) : []\n  };\n}\n\nfunction merge(tree, path, depth) {\n  var newTree = doMerge(tree, path);\n  var stemmed = stem(newTree.tree, depth);\n  return {\n    tree: stemmed.tree,\n    stemmedRevs: stemmed.revs,\n    conflicts: newTree.conflicts\n  };\n}\n\n// return true if a rev exists in the rev tree, false otherwise\nfunction revExists(revs, rev) {\n  var toVisit = revs.slice();\n  var splitRev = rev.split('-');\n  var targetPos = parseInt(splitRev[0], 10);\n  var targetId = splitRev[1];\n\n  var node;\n  while ((node = toVisit.pop())) {\n    if (node.pos === targetPos && node.ids[0] === targetId) {\n      return true;\n    }\n    var branches = node.ids[2];\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: node.pos + 1, ids: branches[i]});\n    }\n  }\n  return false;\n}\n\nfunction getTrees(node) {\n  return node.ids;\n}\n\n// check if a specific revision of a doc has been deleted\n//  - metadata: the metadata object from the doc store\n//  - rev: (optional) the revision to check. defaults to winning revision\nfunction isDeleted(metadata, rev) {\n  if (!rev) {\n    rev = winningRev(metadata);\n  }\n  var id = rev.substring(rev.indexOf('-') + 1);\n  var toVisit = metadata.rev_tree.map(getTrees);\n\n  var tree;\n  while ((tree = toVisit.pop())) {\n    if (tree[0] === id) {\n      return !!tree[1].deleted;\n    }\n    toVisit = toVisit.concat(tree[2]);\n  }\n}\n\nfunction isLocalId(id) {\n  return (/^_local/).test(id);\n}\n\n// returns the current leaf node for a given revision\nfunction latest(rev, metadata) {\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, pos: pos, opts: opts});\n\n    if (isLeaf) {\n      for (var i = 0, len = history.length; i < len; i++) {\n        var historyNode = history[i];\n        var historyRev = historyNode.pos + '-' + historyNode.id;\n\n        if (historyRev === rev) {\n          // return the rev of this leaf\n          return pos + '-' + id;\n        }\n      }\n    }\n\n    for (var j = 0, l = branches.length; j < l; j++) {\n      toVisit.push({pos: pos + 1, ids: branches[j], history: history});\n    }\n  }\n\n  /* istanbul ignore next */\n  throw new Error('Unable to resolve latest revision for id ' + metadata.id + ', rev ' + rev);\n}\n\n\n\n\n/***/ }),\n/* 223 */\n/***/ (function(module, exports, __webpack_require__) {\n\nexports.AbstractLevelDOWN    = __webpack_require__(224)\nexports.AbstractIterator     = __webpack_require__(225)\nexports.AbstractChainedBatch = __webpack_require__(226)\nexports.isLevelDOWN          = __webpack_require__(646)\n\n\n/***/ }),\n/* 224 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process, Buffer) {/* Copyright (c) 2013 Rod Vagg, MIT License */\n\nvar xtend                = __webpack_require__(66)\n  , AbstractIterator     = __webpack_require__(225)\n  , AbstractChainedBatch = __webpack_require__(226)\n\nfunction AbstractLevelDOWN (location) {\n  if (!arguments.length || location === undefined)\n    throw new Error('constructor requires at least a location argument')\n\n  if (typeof location != 'string')\n    throw new Error('constructor requires a location string argument')\n\n  this.location = location\n  this.status = 'new'\n}\n\nAbstractLevelDOWN.prototype.open = function (options, callback) {\n  var self      = this\n    , oldStatus = this.status\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof callback != 'function')\n    throw new Error('open() requires a callback argument')\n\n  if (typeof options != 'object')\n    options = {}\n\n  options.createIfMissing = options.createIfMissing != false\n  options.errorIfExists = !!options.errorIfExists\n\n  if (typeof this._open == 'function') {\n    this.status = 'opening'\n    this._open(options, function (err) {\n      if (err) {\n        self.status = oldStatus\n        return callback(err)\n      }\n      self.status = 'open'\n      callback()\n    })\n  } else {\n    this.status = 'open'\n    process.nextTick(callback)\n  }\n}\n\nAbstractLevelDOWN.prototype.close = function (callback) {\n  var self      = this\n    , oldStatus = this.status\n\n  if (typeof callback != 'function')\n    throw new Error('close() requires a callback argument')\n\n  if (typeof this._close == 'function') {\n    this.status = 'closing'\n    this._close(function (err) {\n      if (err) {\n        self.status = oldStatus\n        return callback(err)\n      }\n      self.status = 'closed'\n      callback()\n    })\n  } else {\n    this.status = 'closed'\n    process.nextTick(callback)\n  }\n}\n\nAbstractLevelDOWN.prototype.get = function (key, options, callback) {\n  var err\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof callback != 'function')\n    throw new Error('get() requires a callback argument')\n\n  if (err = this._checkKey(key, 'key', this._isBuffer))\n    return callback(err)\n\n  if (!this._isBuffer(key))\n    key = String(key)\n\n  if (typeof options != 'object')\n    options = {}\n\n  options.asBuffer = options.asBuffer != false\n\n  if (typeof this._get == 'function')\n    return this._get(key, options, callback)\n\n  process.nextTick(function () { callback(new Error('NotFound')) })\n}\n\nAbstractLevelDOWN.prototype.put = function (key, value, options, callback) {\n  var err\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof callback != 'function')\n    throw new Error('put() requires a callback argument')\n\n  if (err = this._checkKey(key, 'key', this._isBuffer))\n    return callback(err)\n\n  if (!this._isBuffer(key))\n    key = String(key)\n\n  // coerce value to string in node, don't touch it in browser\n  // (indexeddb can store any JS type)\n  if (value != null && !this._isBuffer(value) && !process.browser)\n    value = String(value)\n\n  if (typeof options != 'object')\n    options = {}\n\n  if (typeof this._put == 'function')\n    return this._put(key, value, options, callback)\n\n  process.nextTick(callback)\n}\n\nAbstractLevelDOWN.prototype.del = function (key, options, callback) {\n  var err\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof callback != 'function')\n    throw new Error('del() requires a callback argument')\n\n  if (err = this._checkKey(key, 'key', this._isBuffer))\n    return callback(err)\n\n  if (!this._isBuffer(key))\n    key = String(key)\n\n  if (typeof options != 'object')\n    options = {}\n\n  if (typeof this._del == 'function')\n    return this._del(key, options, callback)\n\n  process.nextTick(callback)\n}\n\nAbstractLevelDOWN.prototype.batch = function (array, options, callback) {\n  if (!arguments.length)\n    return this._chainedBatch()\n\n  if (typeof options == 'function')\n    callback = options\n\n  if (typeof array == 'function')\n    callback = array\n\n  if (typeof callback != 'function')\n    throw new Error('batch(array) requires a callback argument')\n\n  if (!Array.isArray(array))\n    return callback(new Error('batch(array) requires an array argument'))\n\n  if (!options || typeof options != 'object')\n    options = {}\n\n  var i = 0\n    , l = array.length\n    , e\n    , err\n\n  for (; i < l; i++) {\n    e = array[i]\n    if (typeof e != 'object')\n      continue\n\n    if (err = this._checkKey(e.type, 'type', this._isBuffer))\n      return callback(err)\n\n    if (err = this._checkKey(e.key, 'key', this._isBuffer))\n      return callback(err)\n  }\n\n  if (typeof this._batch == 'function')\n    return this._batch(array, options, callback)\n\n  process.nextTick(callback)\n}\n\n//TODO: remove from here, not a necessary primitive\nAbstractLevelDOWN.prototype.approximateSize = function (start, end, callback) {\n  if (   start == null\n      || end == null\n      || typeof start == 'function'\n      || typeof end == 'function') {\n    throw new Error('approximateSize() requires valid `start`, `end` and `callback` arguments')\n  }\n\n  if (typeof callback != 'function')\n    throw new Error('approximateSize() requires a callback argument')\n\n  if (!this._isBuffer(start))\n    start = String(start)\n\n  if (!this._isBuffer(end))\n    end = String(end)\n\n  if (typeof this._approximateSize == 'function')\n    return this._approximateSize(start, end, callback)\n\n  process.nextTick(function () {\n    callback(null, 0)\n  })\n}\n\nAbstractLevelDOWN.prototype._setupIteratorOptions = function (options) {\n  var self = this\n\n  options = xtend(options)\n\n  ;[ 'start', 'end', 'gt', 'gte', 'lt', 'lte' ].forEach(function (o) {\n    if (options[o] && self._isBuffer(options[o]) && options[o].length === 0)\n      delete options[o]\n  })\n\n  options.reverse = !!options.reverse\n  options.keys = options.keys != false\n  options.values = options.values != false\n  options.limit = 'limit' in options ? options.limit : -1\n  options.keyAsBuffer = options.keyAsBuffer != false\n  options.valueAsBuffer = options.valueAsBuffer != false\n\n  return options\n}\n\nAbstractLevelDOWN.prototype.iterator = function (options) {\n  if (typeof options != 'object')\n    options = {}\n\n  options = this._setupIteratorOptions(options)\n\n  if (typeof this._iterator == 'function')\n    return this._iterator(options)\n\n  return new AbstractIterator(this)\n}\n\nAbstractLevelDOWN.prototype._chainedBatch = function () {\n  return new AbstractChainedBatch(this)\n}\n\nAbstractLevelDOWN.prototype._isBuffer = function (obj) {\n  return Buffer.isBuffer(obj)\n}\n\nAbstractLevelDOWN.prototype._checkKey = function (obj, type) {\n\n  if (obj === null || obj === undefined)\n    return new Error(type + ' cannot be `null` or `undefined`')\n\n  if (this._isBuffer(obj)) {\n    if (obj.length === 0)\n      return new Error(type + ' cannot be an empty Buffer')\n  } else if (String(obj) === '')\n    return new Error(type + ' cannot be an empty String')\n}\n\nmodule.exports = AbstractLevelDOWN\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8), __webpack_require__(24).Buffer))\n\n/***/ }),\n/* 225 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process) {/* Copyright (c) 2013 Rod Vagg, MIT License */\n\nfunction AbstractIterator (db) {\n  this.db = db\n  this._ended = false\n  this._nexting = false\n}\n\nAbstractIterator.prototype.next = function (callback) {\n  var self = this\n\n  if (typeof callback != 'function')\n    throw new Error('next() requires a callback argument')\n\n  if (self._ended)\n    return callback(new Error('cannot call next() after end()'))\n  if (self._nexting)\n    return callback(new Error('cannot call next() before previous next() has completed'))\n\n  self._nexting = true\n  if (typeof self._next == 'function') {\n    return self._next(function () {\n      self._nexting = false\n      callback.apply(null, arguments)\n    })\n  }\n\n  process.nextTick(function () {\n    self._nexting = false\n    callback()\n  })\n}\n\nAbstractIterator.prototype.end = function (callback) {\n  if (typeof callback != 'function')\n    throw new Error('end() requires a callback argument')\n\n  if (this._ended)\n    return callback(new Error('end() already called on iterator'))\n\n  this._ended = true\n\n  if (typeof this._end == 'function')\n    return this._end(callback)\n\n  process.nextTick(callback)\n}\n\nmodule.exports = AbstractIterator\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8)))\n\n/***/ }),\n/* 226 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process) {/* Copyright (c) 2013 Rod Vagg, MIT License */\n\nfunction AbstractChainedBatch (db) {\n  this._db         = db\n  this._operations = []\n  this._written    = false\n}\n\nAbstractChainedBatch.prototype._checkWritten = function () {\n  if (this._written)\n    throw new Error('write() already called on this batch')\n}\n\nAbstractChainedBatch.prototype.put = function (key, value) {\n  this._checkWritten()\n\n  var err = this._db._checkKey(key, 'key', this._db._isBuffer)\n  if (err)\n    throw err\n\n  if (!this._db._isBuffer(key)) key = String(key)\n  if (!this._db._isBuffer(value)) value = String(value)\n\n  if (typeof this._put == 'function' )\n    this._put(key, value)\n  else\n    this._operations.push({ type: 'put', key: key, value: value })\n\n  return this\n}\n\nAbstractChainedBatch.prototype.del = function (key) {\n  this._checkWritten()\n\n  var err = this._db._checkKey(key, 'key', this._db._isBuffer)\n  if (err) throw err\n\n  if (!this._db._isBuffer(key)) key = String(key)\n\n  if (typeof this._del == 'function' )\n    this._del(key)\n  else\n    this._operations.push({ type: 'del', key: key })\n\n  return this\n}\n\nAbstractChainedBatch.prototype.clear = function () {\n  this._checkWritten()\n\n  this._operations = []\n\n  if (typeof this._clear == 'function' )\n    this._clear()\n\n  return this\n}\n\nAbstractChainedBatch.prototype.write = function (options, callback) {\n  this._checkWritten()\n\n  if (typeof options == 'function')\n    callback = options\n  if (typeof callback != 'function')\n    throw new Error('write() requires a callback argument')\n  if (typeof options != 'object')\n    options = {}\n\n  this._written = true\n\n  if (typeof this._write == 'function' )\n    return this._write(callback)\n\n  if (typeof this._db._batch == 'function')\n    return this._db._batch(this._operations, options, callback)\n\n  process.nextTick(callback)\n}\n\nmodule.exports = AbstractChainedBatch\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8)))\n\n/***/ }),\n/* 227 */,\n/* 228 */,\n/* 229 */,\n/* 230 */,\n/* 231 */,\n/* 232 */,\n/* 233 */,\n/* 234 */,\n/* 235 */,\n/* 236 */,\n/* 237 */,\n/* 238 */,\n/* 239 */,\n/* 240 */,\n/* 241 */,\n/* 242 */,\n/* 243 */,\n/* 244 */,\n/* 245 */,\n/* 246 */,\n/* 247 */,\n/* 248 */,\n/* 249 */,\n/* 250 */,\n/* 251 */,\n/* 252 */,\n/* 253 */,\n/* 254 */,\n/* 255 */,\n/* 256 */,\n/* 257 */,\n/* 258 */,\n/* 259 */,\n/* 260 */,\n/* 261 */,\n/* 262 */,\n/* 263 */,\n/* 264 */,\n/* 265 */,\n/* 266 */,\n/* 267 */,\n/* 268 */,\n/* 269 */,\n/* 270 */,\n/* 271 */,\n/* 272 */,\n/* 273 */,\n/* 274 */,\n/* 275 */,\n/* 276 */,\n/* 277 */,\n/* 278 */,\n/* 279 */,\n/* 280 */,\n/* 281 */,\n/* 282 */,\n/* 283 */,\n/* 284 */,\n/* 285 */,\n/* 286 */,\n/* 287 */,\n/* 288 */,\n/* 289 */,\n/* 290 */,\n/* 291 */,\n/* 292 */,\n/* 293 */,\n/* 294 */,\n/* 295 */,\n/* 296 */,\n/* 297 */,\n/* 298 */,\n/* 299 */,\n/* 300 */,\n/* 301 */,\n/* 302 */,\n/* 303 */,\n/* 304 */,\n/* 305 */,\n/* 306 */,\n/* 307 */,\n/* 308 */,\n/* 309 */,\n/* 310 */,\n/* 311 */,\n/* 312 */,\n/* 313 */,\n/* 314 */,\n/* 315 */,\n/* 316 */,\n/* 317 */,\n/* 318 */,\n/* 319 */,\n/* 320 */,\n/* 321 */,\n/* 322 */,\n/* 323 */,\n/* 324 */,\n/* 325 */,\n/* 326 */,\n/* 327 */,\n/* 328 */,\n/* 329 */,\n/* 330 */,\n/* 331 */,\n/* 332 */,\n/* 333 */,\n/* 334 */,\n/* 335 */,\n/* 336 */,\n/* 337 */,\n/* 338 */,\n/* 339 */,\n/* 340 */,\n/* 341 */,\n/* 342 */,\n/* 343 */,\n/* 344 */,\n/* 345 */,\n/* 346 */,\n/* 347 */,\n/* 348 */,\n/* 349 */,\n/* 350 */,\n/* 351 */,\n/* 352 */,\n/* 353 */,\n/* 354 */,\n/* 355 */,\n/* 356 */,\n/* 357 */,\n/* 358 */,\n/* 359 */,\n/* 360 */,\n/* 361 */,\n/* 362 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n__webpack_require__(363);\n\n__webpack_require__(179);\n\n__webpack_require__(185);\n\n/***/ }),\n/* 363 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global) {\n\n__webpack_require__(364);\n\n__webpack_require__(561);\n\n__webpack_require__(562);\n\nif (global._babelPolyfill) {\n  throw new Error(\"only one instance of babel-polyfill is allowed\");\n}\nglobal._babelPolyfill = true;\n\nvar DEFINE_PROPERTY = \"defineProperty\";\nfunction define(O, key, value) {\n  O[key] || Object[DEFINE_PROPERTY](O, key, {\n    writable: true,\n    configurable: true,\n    value: value\n  });\n}\n\ndefine(String.prototype, \"padLeft\", \"\".padStart);\ndefine(String.prototype, \"padRight\", \"\".padEnd);\n\n\"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill\".split(\",\").forEach(function (key) {\n  [][key] && define(Array, key, Function.call.bind([][key]));\n});\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12)))\n\n/***/ }),\n/* 364 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(365);\n__webpack_require__(367);\n__webpack_require__(368);\n__webpack_require__(369);\n__webpack_require__(370);\n__webpack_require__(371);\n__webpack_require__(372);\n__webpack_require__(373);\n__webpack_require__(374);\n__webpack_require__(375);\n__webpack_require__(376);\n__webpack_require__(377);\n__webpack_require__(378);\n__webpack_require__(379);\n__webpack_require__(380);\n__webpack_require__(381);\n__webpack_require__(383);\n__webpack_require__(384);\n__webpack_require__(385);\n__webpack_require__(386);\n__webpack_require__(387);\n__webpack_require__(388);\n__webpack_require__(389);\n__webpack_require__(390);\n__webpack_require__(391);\n__webpack_require__(392);\n__webpack_require__(393);\n__webpack_require__(394);\n__webpack_require__(395);\n__webpack_require__(396);\n__webpack_require__(397);\n__webpack_require__(398);\n__webpack_require__(399);\n__webpack_require__(400);\n__webpack_require__(401);\n__webpack_require__(402);\n__webpack_require__(403);\n__webpack_require__(404);\n__webpack_require__(405);\n__webpack_require__(406);\n__webpack_require__(407);\n__webpack_require__(408);\n__webpack_require__(409);\n__webpack_require__(410);\n__webpack_require__(411);\n__webpack_require__(412);\n__webpack_require__(413);\n__webpack_require__(414);\n__webpack_require__(415);\n__webpack_require__(416);\n__webpack_require__(417);\n__webpack_require__(418);\n__webpack_require__(419);\n__webpack_require__(420);\n__webpack_require__(421);\n__webpack_require__(422);\n__webpack_require__(423);\n__webpack_require__(424);\n__webpack_require__(425);\n__webpack_require__(426);\n__webpack_require__(427);\n__webpack_require__(428);\n__webpack_require__(429);\n__webpack_require__(430);\n__webpack_require__(431);\n__webpack_require__(432);\n__webpack_require__(433);\n__webpack_require__(434);\n__webpack_require__(435);\n__webpack_require__(436);\n__webpack_require__(437);\n__webpack_require__(438);\n__webpack_require__(439);\n__webpack_require__(440);\n__webpack_require__(441);\n__webpack_require__(442);\n__webpack_require__(443);\n__webpack_require__(445);\n__webpack_require__(446);\n__webpack_require__(448);\n__webpack_require__(449);\n__webpack_require__(450);\n__webpack_require__(451);\n__webpack_require__(452);\n__webpack_require__(453);\n__webpack_require__(454);\n__webpack_require__(456);\n__webpack_require__(457);\n__webpack_require__(458);\n__webpack_require__(459);\n__webpack_require__(460);\n__webpack_require__(461);\n__webpack_require__(462);\n__webpack_require__(463);\n__webpack_require__(464);\n__webpack_require__(465);\n__webpack_require__(466);\n__webpack_require__(467);\n__webpack_require__(468);\n__webpack_require__(112);\n__webpack_require__(469);\n__webpack_require__(470);\n__webpack_require__(163);\n__webpack_require__(471);\n__webpack_require__(472);\n__webpack_require__(473);\n__webpack_require__(474);\n__webpack_require__(475);\n__webpack_require__(166);\n__webpack_require__(168);\n__webpack_require__(169);\n__webpack_require__(476);\n__webpack_require__(477);\n__webpack_require__(478);\n__webpack_require__(479);\n__webpack_require__(480);\n__webpack_require__(481);\n__webpack_require__(482);\n__webpack_require__(483);\n__webpack_require__(484);\n__webpack_require__(485);\n__webpack_require__(486);\n__webpack_require__(487);\n__webpack_require__(488);\n__webpack_require__(489);\n__webpack_require__(490);\n__webpack_require__(491);\n__webpack_require__(492);\n__webpack_require__(493);\n__webpack_require__(494);\n__webpack_require__(495);\n__webpack_require__(496);\n__webpack_require__(497);\n__webpack_require__(498);\n__webpack_require__(499);\n__webpack_require__(500);\n__webpack_require__(501);\n__webpack_require__(502);\n__webpack_require__(503);\n__webpack_require__(504);\n__webpack_require__(505);\n__webpack_require__(506);\n__webpack_require__(507);\n__webpack_require__(508);\n__webpack_require__(509);\n__webpack_require__(510);\n__webpack_require__(511);\n__webpack_require__(512);\n__webpack_require__(513);\n__webpack_require__(514);\n__webpack_require__(515);\n__webpack_require__(516);\n__webpack_require__(517);\n__webpack_require__(518);\n__webpack_require__(519);\n__webpack_require__(520);\n__webpack_require__(521);\n__webpack_require__(522);\n__webpack_require__(523);\n__webpack_require__(524);\n__webpack_require__(525);\n__webpack_require__(526);\n__webpack_require__(527);\n__webpack_require__(528);\n__webpack_require__(529);\n__webpack_require__(530);\n__webpack_require__(531);\n__webpack_require__(532);\n__webpack_require__(533);\n__webpack_require__(534);\n__webpack_require__(535);\n__webpack_require__(536);\n__webpack_require__(537);\n__webpack_require__(538);\n__webpack_require__(539);\n__webpack_require__(540);\n__webpack_require__(541);\n__webpack_require__(542);\n__webpack_require__(543);\n__webpack_require__(544);\n__webpack_require__(545);\n__webpack_require__(546);\n__webpack_require__(547);\n__webpack_require__(548);\n__webpack_require__(549);\n__webpack_require__(550);\n__webpack_require__(551);\n__webpack_require__(552);\n__webpack_require__(553);\n__webpack_require__(554);\n__webpack_require__(555);\n__webpack_require__(556);\n__webpack_require__(557);\n__webpack_require__(558);\n__webpack_require__(559);\n__webpack_require__(560);\nmodule.exports = __webpack_require__(26);\n\n\n/***/ }),\n/* 365 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// ECMAScript 6 symbols shim\nvar global = __webpack_require__(3);\nvar has = __webpack_require__(19);\nvar DESCRIPTORS = __webpack_require__(9);\nvar $export = __webpack_require__(0);\nvar redefine = __webpack_require__(17);\nvar META = __webpack_require__(39).KEY;\nvar $fails = __webpack_require__(4);\nvar shared = __webpack_require__(70);\nvar setToStringTag = __webpack_require__(56);\nvar uid = __webpack_require__(44);\nvar wks = __webpack_require__(7);\nvar wksExt = __webpack_require__(146);\nvar wksDefine = __webpack_require__(92);\nvar enumKeys = __webpack_require__(366);\nvar isArray = __webpack_require__(73);\nvar anObject = __webpack_require__(2);\nvar isObject = __webpack_require__(5);\nvar toIObject = __webpack_require__(20);\nvar toPrimitive = __webpack_require__(30);\nvar createDesc = __webpack_require__(43);\nvar _create = __webpack_require__(47);\nvar gOPNExt = __webpack_require__(149);\nvar $GOPD = __webpack_require__(21);\nvar $DP = __webpack_require__(10);\nvar $keys = __webpack_require__(45);\nvar gOPD = $GOPD.f;\nvar dP = $DP.f;\nvar gOPN = gOPNExt.f;\nvar $Symbol = global.Symbol;\nvar $JSON = global.JSON;\nvar _stringify = $JSON && $JSON.stringify;\nvar PROTOTYPE = 'prototype';\nvar HIDDEN = wks('_hidden');\nvar TO_PRIMITIVE = wks('toPrimitive');\nvar isEnum = {}.propertyIsEnumerable;\nvar SymbolRegistry = shared('symbol-registry');\nvar AllSymbols = shared('symbols');\nvar OPSymbols = shared('op-symbols');\nvar ObjectProto = Object[PROTOTYPE];\nvar USE_NATIVE = typeof $Symbol == 'function';\nvar QObject = global.QObject;\n// Don't use setters in Qt Script, https://github.com/zloirock/core-js/issues/173\nvar setter = !QObject || !QObject[PROTOTYPE] || !QObject[PROTOTYPE].findChild;\n\n// fallback for old Android, https://code.google.com/p/v8/issues/detail?id=687\nvar setSymbolDesc = DESCRIPTORS && $fails(function () {\n  return _create(dP({}, 'a', {\n    get: function () { return dP(this, 'a', { value: 7 }).a; }\n  })).a != 7;\n}) ? function (it, key, D) {\n  var protoDesc = gOPD(ObjectProto, key);\n  if (protoDesc) delete ObjectProto[key];\n  dP(it, key, D);\n  if (protoDesc && it !== ObjectProto) dP(ObjectProto, key, protoDesc);\n} : dP;\n\nvar wrap = function (tag) {\n  var sym = AllSymbols[tag] = _create($Symbol[PROTOTYPE]);\n  sym._k = tag;\n  return sym;\n};\n\nvar isSymbol = USE_NATIVE && typeof $Symbol.iterator == 'symbol' ? function (it) {\n  return typeof it == 'symbol';\n} : function (it) {\n  return it instanceof $Symbol;\n};\n\nvar $defineProperty = function defineProperty(it, key, D) {\n  if (it === ObjectProto) $defineProperty(OPSymbols, key, D);\n  anObject(it);\n  key = toPrimitive(key, true);\n  anObject(D);\n  if (has(AllSymbols, key)) {\n    if (!D.enumerable) {\n      if (!has(it, HIDDEN)) dP(it, HIDDEN, createDesc(1, {}));\n      it[HIDDEN][key] = true;\n    } else {\n      if (has(it, HIDDEN) && it[HIDDEN][key]) it[HIDDEN][key] = false;\n      D = _create(D, { enumerable: createDesc(0, false) });\n    } return setSymbolDesc(it, key, D);\n  } return dP(it, key, D);\n};\nvar $defineProperties = function defineProperties(it, P) {\n  anObject(it);\n  var keys = enumKeys(P = toIObject(P));\n  var i = 0;\n  var l = keys.length;\n  var key;\n  while (l > i) $defineProperty(it, key = keys[i++], P[key]);\n  return it;\n};\nvar $create = function create(it, P) {\n  return P === undefined ? _create(it) : $defineProperties(_create(it), P);\n};\nvar $propertyIsEnumerable = function propertyIsEnumerable(key) {\n  var E = isEnum.call(this, key = toPrimitive(key, true));\n  if (this === ObjectProto && has(AllSymbols, key) && !has(OPSymbols, key)) return false;\n  return E || !has(this, key) || !has(AllSymbols, key) || has(this, HIDDEN) && this[HIDDEN][key] ? E : true;\n};\nvar $getOwnPropertyDescriptor = function getOwnPropertyDescriptor(it, key) {\n  it = toIObject(it);\n  key = toPrimitive(key, true);\n  if (it === ObjectProto && has(AllSymbols, key) && !has(OPSymbols, key)) return;\n  var D = gOPD(it, key);\n  if (D && has(AllSymbols, key) && !(has(it, HIDDEN) && it[HIDDEN][key])) D.enumerable = true;\n  return D;\n};\nvar $getOwnPropertyNames = function getOwnPropertyNames(it) {\n  var names = gOPN(toIObject(it));\n  var result = [];\n  var i = 0;\n  var key;\n  while (names.length > i) {\n    if (!has(AllSymbols, key = names[i++]) && key != HIDDEN && key != META) result.push(key);\n  } return result;\n};\nvar $getOwnPropertySymbols = function getOwnPropertySymbols(it) {\n  var IS_OP = it === ObjectProto;\n  var names = gOPN(IS_OP ? OPSymbols : toIObject(it));\n  var result = [];\n  var i = 0;\n  var key;\n  while (names.length > i) {\n    if (has(AllSymbols, key = names[i++]) && (IS_OP ? has(ObjectProto, key) : true)) result.push(AllSymbols[key]);\n  } return result;\n};\n\n// 19.4.1.1 Symbol([description])\nif (!USE_NATIVE) {\n  $Symbol = function Symbol() {\n    if (this instanceof $Symbol) throw TypeError('Symbol is not a constructor!');\n    var tag = uid(arguments.length > 0 ? arguments[0] : undefined);\n    var $set = function (value) {\n      if (this === ObjectProto) $set.call(OPSymbols, value);\n      if (has(this, HIDDEN) && has(this[HIDDEN], tag)) this[HIDDEN][tag] = false;\n      setSymbolDesc(this, tag, createDesc(1, value));\n    };\n    if (DESCRIPTORS && setter) setSymbolDesc(ObjectProto, tag, { configurable: true, set: $set });\n    return wrap(tag);\n  };\n  redefine($Symbol[PROTOTYPE], 'toString', function toString() {\n    return this._k;\n  });\n\n  $GOPD.f = $getOwnPropertyDescriptor;\n  $DP.f = $defineProperty;\n  __webpack_require__(48).f = gOPNExt.f = $getOwnPropertyNames;\n  __webpack_require__(63).f = $propertyIsEnumerable;\n  __webpack_require__(72).f = $getOwnPropertySymbols;\n\n  if (DESCRIPTORS && !__webpack_require__(40)) {\n    redefine(ObjectProto, 'propertyIsEnumerable', $propertyIsEnumerable, true);\n  }\n\n  wksExt.f = function (name) {\n    return wrap(wks(name));\n  };\n}\n\n$export($export.G + $export.W + $export.F * !USE_NATIVE, { Symbol: $Symbol });\n\nfor (var es6Symbols = (\n  // 19.4.2.2, 19.4.2.3, 19.4.2.4, 19.4.2.6, 19.4.2.8, 19.4.2.9, 19.4.2.10, 19.4.2.11, 19.4.2.12, 19.4.2.13, 19.4.2.14\n  'hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables'\n).split(','), j = 0; es6Symbols.length > j;)wks(es6Symbols[j++]);\n\nfor (var wellKnownSymbols = $keys(wks.store), k = 0; wellKnownSymbols.length > k;) wksDefine(wellKnownSymbols[k++]);\n\n$export($export.S + $export.F * !USE_NATIVE, 'Symbol', {\n  // 19.4.2.1 Symbol.for(key)\n  'for': function (key) {\n    return has(SymbolRegistry, key += '')\n      ? SymbolRegistry[key]\n      : SymbolRegistry[key] = $Symbol(key);\n  },\n  // 19.4.2.5 Symbol.keyFor(sym)\n  keyFor: function keyFor(sym) {\n    if (!isSymbol(sym)) throw TypeError(sym + ' is not a symbol!');\n    for (var key in SymbolRegistry) if (SymbolRegistry[key] === sym) return key;\n  },\n  useSetter: function () { setter = true; },\n  useSimple: function () { setter = false; }\n});\n\n$export($export.S + $export.F * !USE_NATIVE, 'Object', {\n  // 19.1.2.2 Object.create(O [, Properties])\n  create: $create,\n  // 19.1.2.4 Object.defineProperty(O, P, Attributes)\n  defineProperty: $defineProperty,\n  // 19.1.2.3 Object.defineProperties(O, Properties)\n  defineProperties: $defineProperties,\n  // 19.1.2.6 Object.getOwnPropertyDescriptor(O, P)\n  getOwnPropertyDescriptor: $getOwnPropertyDescriptor,\n  // 19.1.2.7 Object.getOwnPropertyNames(O)\n  getOwnPropertyNames: $getOwnPropertyNames,\n  // 19.1.2.8 Object.getOwnPropertySymbols(O)\n  getOwnPropertySymbols: $getOwnPropertySymbols\n});\n\n// 24.3.2 JSON.stringify(value [, replacer [, space]])\n$JSON && $export($export.S + $export.F * (!USE_NATIVE || $fails(function () {\n  var S = $Symbol();\n  // MS Edge converts symbol values to JSON as {}\n  // WebKit converts symbol values to JSON as null\n  // V8 throws on boxed symbols\n  return _stringify([S]) != '[null]' || _stringify({ a: S }) != '{}' || _stringify(Object(S)) != '{}';\n})), 'JSON', {\n  stringify: function stringify(it) {\n    var args = [it];\n    var i = 1;\n    var replacer, $replacer;\n    while (arguments.length > i) args.push(arguments[i++]);\n    $replacer = replacer = args[1];\n    if (!isObject(replacer) && it === undefined || isSymbol(it)) return; // IE8 returns string on undefined\n    if (!isArray(replacer)) replacer = function (key, value) {\n      if (typeof $replacer == 'function') value = $replacer.call(this, key, value);\n      if (!isSymbol(value)) return value;\n    };\n    args[1] = replacer;\n    return _stringify.apply($JSON, args);\n  }\n});\n\n// 19.4.3.4 Symbol.prototype[@@toPrimitive](hint)\n$Symbol[PROTOTYPE][TO_PRIMITIVE] || __webpack_require__(16)($Symbol[PROTOTYPE], TO_PRIMITIVE, $Symbol[PROTOTYPE].valueOf);\n// 19.4.3.5 Symbol.prototype[@@toStringTag]\nsetToStringTag($Symbol, 'Symbol');\n// 20.2.1.9 Math[@@toStringTag]\nsetToStringTag(Math, 'Math', true);\n// 24.3.3 JSON[@@toStringTag]\nsetToStringTag(global.JSON, 'JSON', true);\n\n\n/***/ }),\n/* 366 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// all enumerable object keys, includes symbols\nvar getKeys = __webpack_require__(45);\nvar gOPS = __webpack_require__(72);\nvar pIE = __webpack_require__(63);\nmodule.exports = function (it) {\n  var result = getKeys(it);\n  var getSymbols = gOPS.f;\n  if (getSymbols) {\n    var symbols = getSymbols(it);\n    var isEnum = pIE.f;\n    var i = 0;\n    var key;\n    while (symbols.length > i) if (isEnum.call(it, key = symbols[i++])) result.push(key);\n  } return result;\n};\n\n\n/***/ }),\n/* 367 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\n// 19.1.2.2 / 15.2.3.5 Object.create(O [, Properties])\n$export($export.S, 'Object', { create: __webpack_require__(47) });\n\n\n/***/ }),\n/* 368 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\n// 19.1.2.4 / 15.2.3.6 Object.defineProperty(O, P, Attributes)\n$export($export.S + $export.F * !__webpack_require__(9), 'Object', { defineProperty: __webpack_require__(10).f });\n\n\n/***/ }),\n/* 369 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\n// 19.1.2.3 / 15.2.3.7 Object.defineProperties(O, Properties)\n$export($export.S + $export.F * !__webpack_require__(9), 'Object', { defineProperties: __webpack_require__(148) });\n\n\n/***/ }),\n/* 370 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.6 Object.getOwnPropertyDescriptor(O, P)\nvar toIObject = __webpack_require__(20);\nvar $getOwnPropertyDescriptor = __webpack_require__(21).f;\n\n__webpack_require__(33)('getOwnPropertyDescriptor', function () {\n  return function getOwnPropertyDescriptor(it, key) {\n    return $getOwnPropertyDescriptor(toIObject(it), key);\n  };\n});\n\n\n/***/ }),\n/* 371 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.9 Object.getPrototypeOf(O)\nvar toObject = __webpack_require__(14);\nvar $getPrototypeOf = __webpack_require__(22);\n\n__webpack_require__(33)('getPrototypeOf', function () {\n  return function getPrototypeOf(it) {\n    return $getPrototypeOf(toObject(it));\n  };\n});\n\n\n/***/ }),\n/* 372 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.14 Object.keys(O)\nvar toObject = __webpack_require__(14);\nvar $keys = __webpack_require__(45);\n\n__webpack_require__(33)('keys', function () {\n  return function keys(it) {\n    return $keys(toObject(it));\n  };\n});\n\n\n/***/ }),\n/* 373 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.7 Object.getOwnPropertyNames(O)\n__webpack_require__(33)('getOwnPropertyNames', function () {\n  return __webpack_require__(149).f;\n});\n\n\n/***/ }),\n/* 374 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.5 Object.freeze(O)\nvar isObject = __webpack_require__(5);\nvar meta = __webpack_require__(39).onFreeze;\n\n__webpack_require__(33)('freeze', function ($freeze) {\n  return function freeze(it) {\n    return $freeze && isObject(it) ? $freeze(meta(it)) : it;\n  };\n});\n\n\n/***/ }),\n/* 375 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.17 Object.seal(O)\nvar isObject = __webpack_require__(5);\nvar meta = __webpack_require__(39).onFreeze;\n\n__webpack_require__(33)('seal', function ($seal) {\n  return function seal(it) {\n    return $seal && isObject(it) ? $seal(meta(it)) : it;\n  };\n});\n\n\n/***/ }),\n/* 376 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.15 Object.preventExtensions(O)\nvar isObject = __webpack_require__(5);\nvar meta = __webpack_require__(39).onFreeze;\n\n__webpack_require__(33)('preventExtensions', function ($preventExtensions) {\n  return function preventExtensions(it) {\n    return $preventExtensions && isObject(it) ? $preventExtensions(meta(it)) : it;\n  };\n});\n\n\n/***/ }),\n/* 377 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.12 Object.isFrozen(O)\nvar isObject = __webpack_require__(5);\n\n__webpack_require__(33)('isFrozen', function ($isFrozen) {\n  return function isFrozen(it) {\n    return isObject(it) ? $isFrozen ? $isFrozen(it) : false : true;\n  };\n});\n\n\n/***/ }),\n/* 378 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.13 Object.isSealed(O)\nvar isObject = __webpack_require__(5);\n\n__webpack_require__(33)('isSealed', function ($isSealed) {\n  return function isSealed(it) {\n    return isObject(it) ? $isSealed ? $isSealed(it) : false : true;\n  };\n});\n\n\n/***/ }),\n/* 379 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.2.11 Object.isExtensible(O)\nvar isObject = __webpack_require__(5);\n\n__webpack_require__(33)('isExtensible', function ($isExtensible) {\n  return function isExtensible(it) {\n    return isObject(it) ? $isExtensible ? $isExtensible(it) : true : false;\n  };\n});\n\n\n/***/ }),\n/* 380 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.3.1 Object.assign(target, source)\nvar $export = __webpack_require__(0);\n\n$export($export.S + $export.F, 'Object', { assign: __webpack_require__(150) });\n\n\n/***/ }),\n/* 381 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.3.10 Object.is(value1, value2)\nvar $export = __webpack_require__(0);\n$export($export.S, 'Object', { is: __webpack_require__(382) });\n\n\n/***/ }),\n/* 382 */\n/***/ (function(module, exports) {\n\n// 7.2.9 SameValue(x, y)\nmodule.exports = Object.is || function is(x, y) {\n  // eslint-disable-next-line no-self-compare\n  return x === y ? x !== 0 || 1 / x === 1 / y : x != x && y != y;\n};\n\n\n/***/ }),\n/* 383 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.1.3.19 Object.setPrototypeOf(O, proto)\nvar $export = __webpack_require__(0);\n$export($export.S, 'Object', { setPrototypeOf: __webpack_require__(96).set });\n\n\n/***/ }),\n/* 384 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// 19.1.3.6 Object.prototype.toString()\nvar classof = __webpack_require__(64);\nvar test = {};\ntest[__webpack_require__(7)('toStringTag')] = 'z';\nif (test + '' != '[object z]') {\n  __webpack_require__(17)(Object.prototype, 'toString', function toString() {\n    return '[object ' + classof(this) + ']';\n  }, true);\n}\n\n\n/***/ }),\n/* 385 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 19.2.3.2 / 15.3.4.5 Function.prototype.bind(thisArg, args...)\nvar $export = __webpack_require__(0);\n\n$export($export.P, 'Function', { bind: __webpack_require__(151) });\n\n\n/***/ }),\n/* 386 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar dP = __webpack_require__(10).f;\nvar FProto = Function.prototype;\nvar nameRE = /^\\s*function ([^ (]*)/;\nvar NAME = 'name';\n\n// 19.2.4.2 name\nNAME in FProto || __webpack_require__(9) && dP(FProto, NAME, {\n  configurable: true,\n  get: function () {\n    try {\n      return ('' + this).match(nameRE)[1];\n    } catch (e) {\n      return '';\n    }\n  }\n});\n\n\n/***/ }),\n/* 387 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar isObject = __webpack_require__(5);\nvar getPrototypeOf = __webpack_require__(22);\nvar HAS_INSTANCE = __webpack_require__(7)('hasInstance');\nvar FunctionProto = Function.prototype;\n// 19.2.3.6 Function.prototype[@@hasInstance](V)\nif (!(HAS_INSTANCE in FunctionProto)) __webpack_require__(10).f(FunctionProto, HAS_INSTANCE, { value: function (O) {\n  if (typeof this != 'function' || !isObject(O)) return false;\n  if (!isObject(this.prototype)) return O instanceof this;\n  // for environment w/o native `@@hasInstance` logic enough `instanceof`, but add this:\n  while (O = getPrototypeOf(O)) if (this.prototype === O) return true;\n  return false;\n} });\n\n\n/***/ }),\n/* 388 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\nvar $parseInt = __webpack_require__(153);\n// 18.2.5 parseInt(string, radix)\n$export($export.G + $export.F * (parseInt != $parseInt), { parseInt: $parseInt });\n\n\n/***/ }),\n/* 389 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\nvar $parseFloat = __webpack_require__(154);\n// 18.2.4 parseFloat(string)\n$export($export.G + $export.F * (parseFloat != $parseFloat), { parseFloat: $parseFloat });\n\n\n/***/ }),\n/* 390 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar global = __webpack_require__(3);\nvar has = __webpack_require__(19);\nvar cof = __webpack_require__(28);\nvar inheritIfRequired = __webpack_require__(98);\nvar toPrimitive = __webpack_require__(30);\nvar fails = __webpack_require__(4);\nvar gOPN = __webpack_require__(48).f;\nvar gOPD = __webpack_require__(21).f;\nvar dP = __webpack_require__(10).f;\nvar $trim = __webpack_require__(57).trim;\nvar NUMBER = 'Number';\nvar $Number = global[NUMBER];\nvar Base = $Number;\nvar proto = $Number.prototype;\n// Opera ~12 has broken Object#toString\nvar BROKEN_COF = cof(__webpack_require__(47)(proto)) == NUMBER;\nvar TRIM = 'trim' in String.prototype;\n\n// 7.1.3 ToNumber(argument)\nvar toNumber = function (argument) {\n  var it = toPrimitive(argument, false);\n  if (typeof it == 'string' && it.length > 2) {\n    it = TRIM ? it.trim() : $trim(it, 3);\n    var first = it.charCodeAt(0);\n    var third, radix, maxCode;\n    if (first === 43 || first === 45) {\n      third = it.charCodeAt(2);\n      if (third === 88 || third === 120) return NaN; // Number('+0x1') should be NaN, old V8 fix\n    } else if (first === 48) {\n      switch (it.charCodeAt(1)) {\n        case 66: case 98: radix = 2; maxCode = 49; break; // fast equal /^0b[01]+$/i\n        case 79: case 111: radix = 8; maxCode = 55; break; // fast equal /^0o[0-7]+$/i\n        default: return +it;\n      }\n      for (var digits = it.slice(2), i = 0, l = digits.length, code; i < l; i++) {\n        code = digits.charCodeAt(i);\n        // parseInt parses a string to a first unavailable symbol\n        // but ToNumber should return NaN if a string contains unavailable symbols\n        if (code < 48 || code > maxCode) return NaN;\n      } return parseInt(digits, radix);\n    }\n  } return +it;\n};\n\nif (!$Number(' 0o1') || !$Number('0b1') || $Number('+0x1')) {\n  $Number = function Number(value) {\n    var it = arguments.length < 1 ? 0 : value;\n    var that = this;\n    return that instanceof $Number\n      // check on 1..constructor(foo) case\n      && (BROKEN_COF ? fails(function () { proto.valueOf.call(that); }) : cof(that) != NUMBER)\n        ? inheritIfRequired(new Base(toNumber(it)), that, $Number) : toNumber(it);\n  };\n  for (var keys = __webpack_require__(9) ? gOPN(Base) : (\n    // ES3:\n    'MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,' +\n    // ES6 (in case, if modules with ES6 Number statics required before):\n    'EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,' +\n    'MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger'\n  ).split(','), j = 0, key; keys.length > j; j++) {\n    if (has(Base, key = keys[j]) && !has($Number, key)) {\n      dP($Number, key, gOPD(Base, key));\n    }\n  }\n  $Number.prototype = proto;\n  proto.constructor = $Number;\n  __webpack_require__(17)(global, NUMBER, $Number);\n}\n\n\n/***/ }),\n/* 391 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar toInteger = __webpack_require__(32);\nvar aNumberValue = __webpack_require__(155);\nvar repeat = __webpack_require__(99);\nvar $toFixed = 1.0.toFixed;\nvar floor = Math.floor;\nvar data = [0, 0, 0, 0, 0, 0];\nvar ERROR = 'Number.toFixed: incorrect invocation!';\nvar ZERO = '0';\n\nvar multiply = function (n, c) {\n  var i = -1;\n  var c2 = c;\n  while (++i < 6) {\n    c2 += n * data[i];\n    data[i] = c2 % 1e7;\n    c2 = floor(c2 / 1e7);\n  }\n};\nvar divide = function (n) {\n  var i = 6;\n  var c = 0;\n  while (--i >= 0) {\n    c += data[i];\n    data[i] = floor(c / n);\n    c = (c % n) * 1e7;\n  }\n};\nvar numToString = function () {\n  var i = 6;\n  var s = '';\n  while (--i >= 0) {\n    if (s !== '' || i === 0 || data[i] !== 0) {\n      var t = String(data[i]);\n      s = s === '' ? t : s + repeat.call(ZERO, 7 - t.length) + t;\n    }\n  } return s;\n};\nvar pow = function (x, n, acc) {\n  return n === 0 ? acc : n % 2 === 1 ? pow(x, n - 1, acc * x) : pow(x * x, n / 2, acc);\n};\nvar log = function (x) {\n  var n = 0;\n  var x2 = x;\n  while (x2 >= 4096) {\n    n += 12;\n    x2 /= 4096;\n  }\n  while (x2 >= 2) {\n    n += 1;\n    x2 /= 2;\n  } return n;\n};\n\n$export($export.P + $export.F * (!!$toFixed && (\n  0.00008.toFixed(3) !== '0.000' ||\n  0.9.toFixed(0) !== '1' ||\n  1.255.toFixed(2) !== '1.25' ||\n  1000000000000000128.0.toFixed(0) !== '1000000000000000128'\n) || !__webpack_require__(4)(function () {\n  // V8 ~ Android 4.3-\n  $toFixed.call({});\n})), 'Number', {\n  toFixed: function toFixed(fractionDigits) {\n    var x = aNumberValue(this, ERROR);\n    var f = toInteger(fractionDigits);\n    var s = '';\n    var m = ZERO;\n    var e, z, j, k;\n    if (f < 0 || f > 20) throw RangeError(ERROR);\n    // eslint-disable-next-line no-self-compare\n    if (x != x) return 'NaN';\n    if (x <= -1e21 || x >= 1e21) return String(x);\n    if (x < 0) {\n      s = '-';\n      x = -x;\n    }\n    if (x > 1e-21) {\n      e = log(x * pow(2, 69, 1)) - 69;\n      z = e < 0 ? x * pow(2, -e, 1) : x / pow(2, e, 1);\n      z *= 0x10000000000000;\n      e = 52 - e;\n      if (e > 0) {\n        multiply(0, z);\n        j = f;\n        while (j >= 7) {\n          multiply(1e7, 0);\n          j -= 7;\n        }\n        multiply(pow(10, j, 1), 0);\n        j = e - 1;\n        while (j >= 23) {\n          divide(1 << 23);\n          j -= 23;\n        }\n        divide(1 << j);\n        multiply(1, 1);\n        divide(2);\n        m = numToString();\n      } else {\n        multiply(0, z);\n        multiply(1 << -e, 0);\n        m = numToString() + repeat.call(ZERO, f);\n      }\n    }\n    if (f > 0) {\n      k = m.length;\n      m = s + (k <= f ? '0.' + repeat.call(ZERO, f - k) + m : m.slice(0, k - f) + '.' + m.slice(k - f));\n    } else {\n      m = s + m;\n    } return m;\n  }\n});\n\n\n/***/ }),\n/* 392 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar $fails = __webpack_require__(4);\nvar aNumberValue = __webpack_require__(155);\nvar $toPrecision = 1.0.toPrecision;\n\n$export($export.P + $export.F * ($fails(function () {\n  // IE7-\n  return $toPrecision.call(1, undefined) !== '1';\n}) || !$fails(function () {\n  // V8 ~ Android 4.3-\n  $toPrecision.call({});\n})), 'Number', {\n  toPrecision: function toPrecision(precision) {\n    var that = aNumberValue(this, 'Number#toPrecision: incorrect invocation!');\n    return precision === undefined ? $toPrecision.call(that) : $toPrecision.call(that, precision);\n  }\n});\n\n\n/***/ }),\n/* 393 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.1.2.1 Number.EPSILON\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Number', { EPSILON: Math.pow(2, -52) });\n\n\n/***/ }),\n/* 394 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.1.2.2 Number.isFinite(number)\nvar $export = __webpack_require__(0);\nvar _isFinite = __webpack_require__(3).isFinite;\n\n$export($export.S, 'Number', {\n  isFinite: function isFinite(it) {\n    return typeof it == 'number' && _isFinite(it);\n  }\n});\n\n\n/***/ }),\n/* 395 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.1.2.3 Number.isInteger(number)\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Number', { isInteger: __webpack_require__(156) });\n\n\n/***/ }),\n/* 396 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.1.2.4 Number.isNaN(number)\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Number', {\n  isNaN: function isNaN(number) {\n    // eslint-disable-next-line no-self-compare\n    return number != number;\n  }\n});\n\n\n/***/ }),\n/* 397 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.1.2.5 Number.isSafeInteger(number)\nvar $export = __webpack_require__(0);\nvar isInteger = __webpack_require__(156);\nvar abs = Math.abs;\n\n$export($export.S, 'Number', {\n  isSafeInteger: function isSafeInteger(number) {\n    return isInteger(number) && abs(number) <= 0x1fffffffffffff;\n  }\n});\n\n\n/***/ }),\n/* 398 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.1.2.6 Number.MAX_SAFE_INTEGER\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Number', { MAX_SAFE_INTEGER: 0x1fffffffffffff });\n\n\n/***/ }),\n/* 399 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.1.2.10 Number.MIN_SAFE_INTEGER\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Number', { MIN_SAFE_INTEGER: -0x1fffffffffffff });\n\n\n/***/ }),\n/* 400 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\nvar $parseFloat = __webpack_require__(154);\n// 20.1.2.12 Number.parseFloat(string)\n$export($export.S + $export.F * (Number.parseFloat != $parseFloat), 'Number', { parseFloat: $parseFloat });\n\n\n/***/ }),\n/* 401 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\nvar $parseInt = __webpack_require__(153);\n// 20.1.2.13 Number.parseInt(string, radix)\n$export($export.S + $export.F * (Number.parseInt != $parseInt), 'Number', { parseInt: $parseInt });\n\n\n/***/ }),\n/* 402 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.3 Math.acosh(x)\nvar $export = __webpack_require__(0);\nvar log1p = __webpack_require__(157);\nvar sqrt = Math.sqrt;\nvar $acosh = Math.acosh;\n\n$export($export.S + $export.F * !($acosh\n  // V8 bug: https://code.google.com/p/v8/issues/detail?id=3509\n  && Math.floor($acosh(Number.MAX_VALUE)) == 710\n  // Tor Browser bug: Math.acosh(Infinity) -> NaN\n  && $acosh(Infinity) == Infinity\n), 'Math', {\n  acosh: function acosh(x) {\n    return (x = +x) < 1 ? NaN : x > 94906265.62425156\n      ? Math.log(x) + Math.LN2\n      : log1p(x - 1 + sqrt(x - 1) * sqrt(x + 1));\n  }\n});\n\n\n/***/ }),\n/* 403 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.5 Math.asinh(x)\nvar $export = __webpack_require__(0);\nvar $asinh = Math.asinh;\n\nfunction asinh(x) {\n  return !isFinite(x = +x) || x == 0 ? x : x < 0 ? -asinh(-x) : Math.log(x + Math.sqrt(x * x + 1));\n}\n\n// Tor Browser bug: Math.asinh(0) -> -0\n$export($export.S + $export.F * !($asinh && 1 / $asinh(0) > 0), 'Math', { asinh: asinh });\n\n\n/***/ }),\n/* 404 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.7 Math.atanh(x)\nvar $export = __webpack_require__(0);\nvar $atanh = Math.atanh;\n\n// Tor Browser bug: Math.atanh(-0) -> 0\n$export($export.S + $export.F * !($atanh && 1 / $atanh(-0) < 0), 'Math', {\n  atanh: function atanh(x) {\n    return (x = +x) == 0 ? x : Math.log((1 + x) / (1 - x)) / 2;\n  }\n});\n\n\n/***/ }),\n/* 405 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.9 Math.cbrt(x)\nvar $export = __webpack_require__(0);\nvar sign = __webpack_require__(100);\n\n$export($export.S, 'Math', {\n  cbrt: function cbrt(x) {\n    return sign(x = +x) * Math.pow(Math.abs(x), 1 / 3);\n  }\n});\n\n\n/***/ }),\n/* 406 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.11 Math.clz32(x)\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', {\n  clz32: function clz32(x) {\n    return (x >>>= 0) ? 31 - Math.floor(Math.log(x + 0.5) * Math.LOG2E) : 32;\n  }\n});\n\n\n/***/ }),\n/* 407 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.12 Math.cosh(x)\nvar $export = __webpack_require__(0);\nvar exp = Math.exp;\n\n$export($export.S, 'Math', {\n  cosh: function cosh(x) {\n    return (exp(x = +x) + exp(-x)) / 2;\n  }\n});\n\n\n/***/ }),\n/* 408 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.14 Math.expm1(x)\nvar $export = __webpack_require__(0);\nvar $expm1 = __webpack_require__(101);\n\n$export($export.S + $export.F * ($expm1 != Math.expm1), 'Math', { expm1: $expm1 });\n\n\n/***/ }),\n/* 409 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.16 Math.fround(x)\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', { fround: __webpack_require__(158) });\n\n\n/***/ }),\n/* 410 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.17 Math.hypot([value1[, value2[,  ]]])\nvar $export = __webpack_require__(0);\nvar abs = Math.abs;\n\n$export($export.S, 'Math', {\n  hypot: function hypot(value1, value2) { // eslint-disable-line no-unused-vars\n    var sum = 0;\n    var i = 0;\n    var aLen = arguments.length;\n    var larg = 0;\n    var arg, div;\n    while (i < aLen) {\n      arg = abs(arguments[i++]);\n      if (larg < arg) {\n        div = larg / arg;\n        sum = sum * div * div + 1;\n        larg = arg;\n      } else if (arg > 0) {\n        div = arg / larg;\n        sum += div * div;\n      } else sum += arg;\n    }\n    return larg === Infinity ? Infinity : larg * Math.sqrt(sum);\n  }\n});\n\n\n/***/ }),\n/* 411 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.18 Math.imul(x, y)\nvar $export = __webpack_require__(0);\nvar $imul = Math.imul;\n\n// some WebKit versions fails with big numbers, some has wrong arity\n$export($export.S + $export.F * __webpack_require__(4)(function () {\n  return $imul(0xffffffff, 5) != -5 || $imul.length != 2;\n}), 'Math', {\n  imul: function imul(x, y) {\n    var UINT16 = 0xffff;\n    var xn = +x;\n    var yn = +y;\n    var xl = UINT16 & xn;\n    var yl = UINT16 & yn;\n    return 0 | xl * yl + ((UINT16 & xn >>> 16) * yl + xl * (UINT16 & yn >>> 16) << 16 >>> 0);\n  }\n});\n\n\n/***/ }),\n/* 412 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.21 Math.log10(x)\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', {\n  log10: function log10(x) {\n    return Math.log(x) * Math.LOG10E;\n  }\n});\n\n\n/***/ }),\n/* 413 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.20 Math.log1p(x)\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', { log1p: __webpack_require__(157) });\n\n\n/***/ }),\n/* 414 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.22 Math.log2(x)\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', {\n  log2: function log2(x) {\n    return Math.log(x) / Math.LN2;\n  }\n});\n\n\n/***/ }),\n/* 415 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.28 Math.sign(x)\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', { sign: __webpack_require__(100) });\n\n\n/***/ }),\n/* 416 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.30 Math.sinh(x)\nvar $export = __webpack_require__(0);\nvar expm1 = __webpack_require__(101);\nvar exp = Math.exp;\n\n// V8 near Chromium 38 has a problem with very small numbers\n$export($export.S + $export.F * __webpack_require__(4)(function () {\n  return !Math.sinh(-2e-17) != -2e-17;\n}), 'Math', {\n  sinh: function sinh(x) {\n    return Math.abs(x = +x) < 1\n      ? (expm1(x) - expm1(-x)) / 2\n      : (exp(x - 1) - exp(-x - 1)) * (Math.E / 2);\n  }\n});\n\n\n/***/ }),\n/* 417 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.33 Math.tanh(x)\nvar $export = __webpack_require__(0);\nvar expm1 = __webpack_require__(101);\nvar exp = Math.exp;\n\n$export($export.S, 'Math', {\n  tanh: function tanh(x) {\n    var a = expm1(x = +x);\n    var b = expm1(-x);\n    return a == Infinity ? 1 : b == Infinity ? -1 : (a - b) / (exp(x) + exp(-x));\n  }\n});\n\n\n/***/ }),\n/* 418 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.2.2.34 Math.trunc(x)\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', {\n  trunc: function trunc(it) {\n    return (it > 0 ? Math.floor : Math.ceil)(it);\n  }\n});\n\n\n/***/ }),\n/* 419 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\nvar toAbsoluteIndex = __webpack_require__(46);\nvar fromCharCode = String.fromCharCode;\nvar $fromCodePoint = String.fromCodePoint;\n\n// length should be 1, old FF problem\n$export($export.S + $export.F * (!!$fromCodePoint && $fromCodePoint.length != 1), 'String', {\n  // 21.1.2.2 String.fromCodePoint(...codePoints)\n  fromCodePoint: function fromCodePoint(x) { // eslint-disable-line no-unused-vars\n    var res = [];\n    var aLen = arguments.length;\n    var i = 0;\n    var code;\n    while (aLen > i) {\n      code = +arguments[i++];\n      if (toAbsoluteIndex(code, 0x10ffff) !== code) throw RangeError(code + ' is not a valid code point');\n      res.push(code < 0x10000\n        ? fromCharCode(code)\n        : fromCharCode(((code -= 0x10000) >> 10) + 0xd800, code % 0x400 + 0xdc00)\n      );\n    } return res.join('');\n  }\n});\n\n\n/***/ }),\n/* 420 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\nvar toIObject = __webpack_require__(20);\nvar toLength = __webpack_require__(11);\n\n$export($export.S, 'String', {\n  // 21.1.2.4 String.raw(callSite, ...substitutions)\n  raw: function raw(callSite) {\n    var tpl = toIObject(callSite.raw);\n    var len = toLength(tpl.length);\n    var aLen = arguments.length;\n    var res = [];\n    var i = 0;\n    while (len > i) {\n      res.push(String(tpl[i++]));\n      if (i < aLen) res.push(String(arguments[i]));\n    } return res.join('');\n  }\n});\n\n\n/***/ }),\n/* 421 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// 21.1.3.25 String.prototype.trim()\n__webpack_require__(57)('trim', function ($trim) {\n  return function trim() {\n    return $trim(this, 3);\n  };\n});\n\n\n/***/ }),\n/* 422 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $at = __webpack_require__(102)(true);\n\n// 21.1.3.27 String.prototype[@@iterator]()\n__webpack_require__(103)(String, 'String', function (iterated) {\n  this._t = String(iterated); // target\n  this._i = 0;                // next index\n// 21.1.5.2.1 %StringIteratorPrototype%.next()\n}, function () {\n  var O = this._t;\n  var index = this._i;\n  var point;\n  if (index >= O.length) return { value: undefined, done: true };\n  point = $at(O, index);\n  this._i += point.length;\n  return { value: point, done: false };\n});\n\n\n/***/ }),\n/* 423 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar $at = __webpack_require__(102)(false);\n$export($export.P, 'String', {\n  // 21.1.3.3 String.prototype.codePointAt(pos)\n  codePointAt: function codePointAt(pos) {\n    return $at(this, pos);\n  }\n});\n\n\n/***/ }),\n/* 424 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// 21.1.3.6 String.prototype.endsWith(searchString [, endPosition])\n\nvar $export = __webpack_require__(0);\nvar toLength = __webpack_require__(11);\nvar context = __webpack_require__(105);\nvar ENDS_WITH = 'endsWith';\nvar $endsWith = ''[ENDS_WITH];\n\n$export($export.P + $export.F * __webpack_require__(106)(ENDS_WITH), 'String', {\n  endsWith: function endsWith(searchString /* , endPosition = @length */) {\n    var that = context(this, searchString, ENDS_WITH);\n    var endPosition = arguments.length > 1 ? arguments[1] : undefined;\n    var len = toLength(that.length);\n    var end = endPosition === undefined ? len : Math.min(toLength(endPosition), len);\n    var search = String(searchString);\n    return $endsWith\n      ? $endsWith.call(that, search, end)\n      : that.slice(end - search.length, end) === search;\n  }\n});\n\n\n/***/ }),\n/* 425 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// 21.1.3.7 String.prototype.includes(searchString, position = 0)\n\nvar $export = __webpack_require__(0);\nvar context = __webpack_require__(105);\nvar INCLUDES = 'includes';\n\n$export($export.P + $export.F * __webpack_require__(106)(INCLUDES), 'String', {\n  includes: function includes(searchString /* , position = 0 */) {\n    return !!~context(this, searchString, INCLUDES)\n      .indexOf(searchString, arguments.length > 1 ? arguments[1] : undefined);\n  }\n});\n\n\n/***/ }),\n/* 426 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\n\n$export($export.P, 'String', {\n  // 21.1.3.13 String.prototype.repeat(count)\n  repeat: __webpack_require__(99)\n});\n\n\n/***/ }),\n/* 427 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// 21.1.3.18 String.prototype.startsWith(searchString [, position ])\n\nvar $export = __webpack_require__(0);\nvar toLength = __webpack_require__(11);\nvar context = __webpack_require__(105);\nvar STARTS_WITH = 'startsWith';\nvar $startsWith = ''[STARTS_WITH];\n\n$export($export.P + $export.F * __webpack_require__(106)(STARTS_WITH), 'String', {\n  startsWith: function startsWith(searchString /* , position = 0 */) {\n    var that = context(this, searchString, STARTS_WITH);\n    var index = toLength(Math.min(arguments.length > 1 ? arguments[1] : undefined, that.length));\n    var search = String(searchString);\n    return $startsWith\n      ? $startsWith.call(that, search, index)\n      : that.slice(index, index + search.length) === search;\n  }\n});\n\n\n/***/ }),\n/* 428 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.2 String.prototype.anchor(name)\n__webpack_require__(18)('anchor', function (createHTML) {\n  return function anchor(name) {\n    return createHTML(this, 'a', 'name', name);\n  };\n});\n\n\n/***/ }),\n/* 429 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.3 String.prototype.big()\n__webpack_require__(18)('big', function (createHTML) {\n  return function big() {\n    return createHTML(this, 'big', '', '');\n  };\n});\n\n\n/***/ }),\n/* 430 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.4 String.prototype.blink()\n__webpack_require__(18)('blink', function (createHTML) {\n  return function blink() {\n    return createHTML(this, 'blink', '', '');\n  };\n});\n\n\n/***/ }),\n/* 431 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.5 String.prototype.bold()\n__webpack_require__(18)('bold', function (createHTML) {\n  return function bold() {\n    return createHTML(this, 'b', '', '');\n  };\n});\n\n\n/***/ }),\n/* 432 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.6 String.prototype.fixed()\n__webpack_require__(18)('fixed', function (createHTML) {\n  return function fixed() {\n    return createHTML(this, 'tt', '', '');\n  };\n});\n\n\n/***/ }),\n/* 433 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.7 String.prototype.fontcolor(color)\n__webpack_require__(18)('fontcolor', function (createHTML) {\n  return function fontcolor(color) {\n    return createHTML(this, 'font', 'color', color);\n  };\n});\n\n\n/***/ }),\n/* 434 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.8 String.prototype.fontsize(size)\n__webpack_require__(18)('fontsize', function (createHTML) {\n  return function fontsize(size) {\n    return createHTML(this, 'font', 'size', size);\n  };\n});\n\n\n/***/ }),\n/* 435 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.9 String.prototype.italics()\n__webpack_require__(18)('italics', function (createHTML) {\n  return function italics() {\n    return createHTML(this, 'i', '', '');\n  };\n});\n\n\n/***/ }),\n/* 436 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.10 String.prototype.link(url)\n__webpack_require__(18)('link', function (createHTML) {\n  return function link(url) {\n    return createHTML(this, 'a', 'href', url);\n  };\n});\n\n\n/***/ }),\n/* 437 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.11 String.prototype.small()\n__webpack_require__(18)('small', function (createHTML) {\n  return function small() {\n    return createHTML(this, 'small', '', '');\n  };\n});\n\n\n/***/ }),\n/* 438 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.12 String.prototype.strike()\n__webpack_require__(18)('strike', function (createHTML) {\n  return function strike() {\n    return createHTML(this, 'strike', '', '');\n  };\n});\n\n\n/***/ }),\n/* 439 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.13 String.prototype.sub()\n__webpack_require__(18)('sub', function (createHTML) {\n  return function sub() {\n    return createHTML(this, 'sub', '', '');\n  };\n});\n\n\n/***/ }),\n/* 440 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// B.2.3.14 String.prototype.sup()\n__webpack_require__(18)('sup', function (createHTML) {\n  return function sup() {\n    return createHTML(this, 'sup', '', '');\n  };\n});\n\n\n/***/ }),\n/* 441 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.3.3.1 / 15.9.4.4 Date.now()\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Date', { now: function () { return new Date().getTime(); } });\n\n\n/***/ }),\n/* 442 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar toObject = __webpack_require__(14);\nvar toPrimitive = __webpack_require__(30);\n\n$export($export.P + $export.F * __webpack_require__(4)(function () {\n  return new Date(NaN).toJSON() !== null\n    || Date.prototype.toJSON.call({ toISOString: function () { return 1; } }) !== 1;\n}), 'Date', {\n  // eslint-disable-next-line no-unused-vars\n  toJSON: function toJSON(key) {\n    var O = toObject(this);\n    var pv = toPrimitive(O);\n    return typeof pv == 'number' && !isFinite(pv) ? null : O.toISOString();\n  }\n});\n\n\n/***/ }),\n/* 443 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 20.3.4.36 / 15.9.5.43 Date.prototype.toISOString()\nvar $export = __webpack_require__(0);\nvar toISOString = __webpack_require__(444);\n\n// PhantomJS / old WebKit has a broken implementations\n$export($export.P + $export.F * (Date.prototype.toISOString !== toISOString), 'Date', {\n  toISOString: toISOString\n});\n\n\n/***/ }),\n/* 444 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// 20.3.4.36 / 15.9.5.43 Date.prototype.toISOString()\nvar fails = __webpack_require__(4);\nvar getTime = Date.prototype.getTime;\nvar $toISOString = Date.prototype.toISOString;\n\nvar lz = function (num) {\n  return num > 9 ? num : '0' + num;\n};\n\n// PhantomJS / old WebKit has a broken implementations\nmodule.exports = (fails(function () {\n  return $toISOString.call(new Date(-5e13 - 1)) != '0385-07-25T07:06:39.999Z';\n}) || !fails(function () {\n  $toISOString.call(new Date(NaN));\n})) ? function toISOString() {\n  if (!isFinite(getTime.call(this))) throw RangeError('Invalid time value');\n  var d = this;\n  var y = d.getUTCFullYear();\n  var m = d.getUTCMilliseconds();\n  var s = y < 0 ? '-' : y > 9999 ? '+' : '';\n  return s + ('00000' + Math.abs(y)).slice(s ? -6 : -4) +\n    '-' + lz(d.getUTCMonth() + 1) + '-' + lz(d.getUTCDate()) +\n    'T' + lz(d.getUTCHours()) + ':' + lz(d.getUTCMinutes()) +\n    ':' + lz(d.getUTCSeconds()) + '.' + (m > 99 ? m : '0' + lz(m)) + 'Z';\n} : $toISOString;\n\n\n/***/ }),\n/* 445 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar DateProto = Date.prototype;\nvar INVALID_DATE = 'Invalid Date';\nvar TO_STRING = 'toString';\nvar $toString = DateProto[TO_STRING];\nvar getTime = DateProto.getTime;\nif (new Date(NaN) + '' != INVALID_DATE) {\n  __webpack_require__(17)(DateProto, TO_STRING, function toString() {\n    var value = getTime.call(this);\n    // eslint-disable-next-line no-self-compare\n    return value === value ? $toString.call(this) : INVALID_DATE;\n  });\n}\n\n\n/***/ }),\n/* 446 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar TO_PRIMITIVE = __webpack_require__(7)('toPrimitive');\nvar proto = Date.prototype;\n\nif (!(TO_PRIMITIVE in proto)) __webpack_require__(16)(proto, TO_PRIMITIVE, __webpack_require__(447));\n\n\n/***/ }),\n/* 447 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar anObject = __webpack_require__(2);\nvar toPrimitive = __webpack_require__(30);\nvar NUMBER = 'number';\n\nmodule.exports = function (hint) {\n  if (hint !== 'string' && hint !== NUMBER && hint !== 'default') throw TypeError('Incorrect hint');\n  return toPrimitive(anObject(this), hint != NUMBER);\n};\n\n\n/***/ }),\n/* 448 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 22.1.2.2 / 15.4.3.2 Array.isArray(arg)\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Array', { isArray: __webpack_require__(73) });\n\n\n/***/ }),\n/* 449 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar ctx = __webpack_require__(27);\nvar $export = __webpack_require__(0);\nvar toObject = __webpack_require__(14);\nvar call = __webpack_require__(159);\nvar isArrayIter = __webpack_require__(107);\nvar toLength = __webpack_require__(11);\nvar createProperty = __webpack_require__(108);\nvar getIterFn = __webpack_require__(109);\n\n$export($export.S + $export.F * !__webpack_require__(75)(function (iter) { Array.from(iter); }), 'Array', {\n  // 22.1.2.1 Array.from(arrayLike, mapfn = undefined, thisArg = undefined)\n  from: function from(arrayLike /* , mapfn = undefined, thisArg = undefined */) {\n    var O = toObject(arrayLike);\n    var C = typeof this == 'function' ? this : Array;\n    var aLen = arguments.length;\n    var mapfn = aLen > 1 ? arguments[1] : undefined;\n    var mapping = mapfn !== undefined;\n    var index = 0;\n    var iterFn = getIterFn(O);\n    var length, result, step, iterator;\n    if (mapping) mapfn = ctx(mapfn, aLen > 2 ? arguments[2] : undefined, 2);\n    // if object isn't iterable or it's array with default iterator - use simple case\n    if (iterFn != undefined && !(C == Array && isArrayIter(iterFn))) {\n      for (iterator = iterFn.call(O), result = new C(); !(step = iterator.next()).done; index++) {\n        createProperty(result, index, mapping ? call(iterator, mapfn, [step.value, index], true) : step.value);\n      }\n    } else {\n      length = toLength(O.length);\n      for (result = new C(length); length > index; index++) {\n        createProperty(result, index, mapping ? mapfn(O[index], index) : O[index]);\n      }\n    }\n    result.length = index;\n    return result;\n  }\n});\n\n\n/***/ }),\n/* 450 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar createProperty = __webpack_require__(108);\n\n// WebKit Array.of isn't generic\n$export($export.S + $export.F * __webpack_require__(4)(function () {\n  function F() { /* empty */ }\n  return !(Array.of.call(F) instanceof F);\n}), 'Array', {\n  // 22.1.2.3 Array.of( ...items)\n  of: function of(/* ...args */) {\n    var index = 0;\n    var aLen = arguments.length;\n    var result = new (typeof this == 'function' ? this : Array)(aLen);\n    while (aLen > index) createProperty(result, index, arguments[index++]);\n    result.length = aLen;\n    return result;\n  }\n});\n\n\n/***/ }),\n/* 451 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// 22.1.3.13 Array.prototype.join(separator)\nvar $export = __webpack_require__(0);\nvar toIObject = __webpack_require__(20);\nvar arrayJoin = [].join;\n\n// fallback for not array-like strings\n$export($export.P + $export.F * (__webpack_require__(62) != Object || !__webpack_require__(29)(arrayJoin)), 'Array', {\n  join: function join(separator) {\n    return arrayJoin.call(toIObject(this), separator === undefined ? ',' : separator);\n  }\n});\n\n\n/***/ }),\n/* 452 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar html = __webpack_require__(95);\nvar cof = __webpack_require__(28);\nvar toAbsoluteIndex = __webpack_require__(46);\nvar toLength = __webpack_require__(11);\nvar arraySlice = [].slice;\n\n// fallback for not array-like ES3 strings and DOM objects\n$export($export.P + $export.F * __webpack_require__(4)(function () {\n  if (html) arraySlice.call(html);\n}), 'Array', {\n  slice: function slice(begin, end) {\n    var len = toLength(this.length);\n    var klass = cof(this);\n    end = end === undefined ? len : end;\n    if (klass == 'Array') return arraySlice.call(this, begin, end);\n    var start = toAbsoluteIndex(begin, len);\n    var upTo = toAbsoluteIndex(end, len);\n    var size = toLength(upTo - start);\n    var cloned = new Array(size);\n    var i = 0;\n    for (; i < size; i++) cloned[i] = klass == 'String'\n      ? this.charAt(start + i)\n      : this[start + i];\n    return cloned;\n  }\n});\n\n\n/***/ }),\n/* 453 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar aFunction = __webpack_require__(15);\nvar toObject = __webpack_require__(14);\nvar fails = __webpack_require__(4);\nvar $sort = [].sort;\nvar test = [1, 2, 3];\n\n$export($export.P + $export.F * (fails(function () {\n  // IE8-\n  test.sort(undefined);\n}) || !fails(function () {\n  // V8 bug\n  test.sort(null);\n  // Old WebKit\n}) || !__webpack_require__(29)($sort)), 'Array', {\n  // 22.1.3.25 Array.prototype.sort(comparefn)\n  sort: function sort(comparefn) {\n    return comparefn === undefined\n      ? $sort.call(toObject(this))\n      : $sort.call(toObject(this), aFunction(comparefn));\n  }\n});\n\n\n/***/ }),\n/* 454 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar $forEach = __webpack_require__(34)(0);\nvar STRICT = __webpack_require__(29)([].forEach, true);\n\n$export($export.P + $export.F * !STRICT, 'Array', {\n  // 22.1.3.10 / 15.4.4.18 Array.prototype.forEach(callbackfn [, thisArg])\n  forEach: function forEach(callbackfn /* , thisArg */) {\n    return $forEach(this, callbackfn, arguments[1]);\n  }\n});\n\n\n/***/ }),\n/* 455 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar isObject = __webpack_require__(5);\nvar isArray = __webpack_require__(73);\nvar SPECIES = __webpack_require__(7)('species');\n\nmodule.exports = function (original) {\n  var C;\n  if (isArray(original)) {\n    C = original.constructor;\n    // cross-realm fallback\n    if (typeof C == 'function' && (C === Array || isArray(C.prototype))) C = undefined;\n    if (isObject(C)) {\n      C = C[SPECIES];\n      if (C === null) C = undefined;\n    }\n  } return C === undefined ? Array : C;\n};\n\n\n/***/ }),\n/* 456 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar $map = __webpack_require__(34)(1);\n\n$export($export.P + $export.F * !__webpack_require__(29)([].map, true), 'Array', {\n  // 22.1.3.15 / 15.4.4.19 Array.prototype.map(callbackfn [, thisArg])\n  map: function map(callbackfn /* , thisArg */) {\n    return $map(this, callbackfn, arguments[1]);\n  }\n});\n\n\n/***/ }),\n/* 457 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar $filter = __webpack_require__(34)(2);\n\n$export($export.P + $export.F * !__webpack_require__(29)([].filter, true), 'Array', {\n  // 22.1.3.7 / 15.4.4.20 Array.prototype.filter(callbackfn [, thisArg])\n  filter: function filter(callbackfn /* , thisArg */) {\n    return $filter(this, callbackfn, arguments[1]);\n  }\n});\n\n\n/***/ }),\n/* 458 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar $some = __webpack_require__(34)(3);\n\n$export($export.P + $export.F * !__webpack_require__(29)([].some, true), 'Array', {\n  // 22.1.3.23 / 15.4.4.17 Array.prototype.some(callbackfn [, thisArg])\n  some: function some(callbackfn /* , thisArg */) {\n    return $some(this, callbackfn, arguments[1]);\n  }\n});\n\n\n/***/ }),\n/* 459 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar $every = __webpack_require__(34)(4);\n\n$export($export.P + $export.F * !__webpack_require__(29)([].every, true), 'Array', {\n  // 22.1.3.5 / 15.4.4.16 Array.prototype.every(callbackfn [, thisArg])\n  every: function every(callbackfn /* , thisArg */) {\n    return $every(this, callbackfn, arguments[1]);\n  }\n});\n\n\n/***/ }),\n/* 460 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar $reduce = __webpack_require__(160);\n\n$export($export.P + $export.F * !__webpack_require__(29)([].reduce, true), 'Array', {\n  // 22.1.3.18 / 15.4.4.21 Array.prototype.reduce(callbackfn [, initialValue])\n  reduce: function reduce(callbackfn /* , initialValue */) {\n    return $reduce(this, callbackfn, arguments.length, arguments[1], false);\n  }\n});\n\n\n/***/ }),\n/* 461 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar $reduce = __webpack_require__(160);\n\n$export($export.P + $export.F * !__webpack_require__(29)([].reduceRight, true), 'Array', {\n  // 22.1.3.19 / 15.4.4.22 Array.prototype.reduceRight(callbackfn [, initialValue])\n  reduceRight: function reduceRight(callbackfn /* , initialValue */) {\n    return $reduce(this, callbackfn, arguments.length, arguments[1], true);\n  }\n});\n\n\n/***/ }),\n/* 462 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar $indexOf = __webpack_require__(71)(false);\nvar $native = [].indexOf;\nvar NEGATIVE_ZERO = !!$native && 1 / [1].indexOf(1, -0) < 0;\n\n$export($export.P + $export.F * (NEGATIVE_ZERO || !__webpack_require__(29)($native)), 'Array', {\n  // 22.1.3.11 / 15.4.4.14 Array.prototype.indexOf(searchElement [, fromIndex])\n  indexOf: function indexOf(searchElement /* , fromIndex = 0 */) {\n    return NEGATIVE_ZERO\n      // convert -0 to +0\n      ? $native.apply(this, arguments) || 0\n      : $indexOf(this, searchElement, arguments[1]);\n  }\n});\n\n\n/***/ }),\n/* 463 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar toIObject = __webpack_require__(20);\nvar toInteger = __webpack_require__(32);\nvar toLength = __webpack_require__(11);\nvar $native = [].lastIndexOf;\nvar NEGATIVE_ZERO = !!$native && 1 / [1].lastIndexOf(1, -0) < 0;\n\n$export($export.P + $export.F * (NEGATIVE_ZERO || !__webpack_require__(29)($native)), 'Array', {\n  // 22.1.3.14 / 15.4.4.15 Array.prototype.lastIndexOf(searchElement [, fromIndex])\n  lastIndexOf: function lastIndexOf(searchElement /* , fromIndex = @[*-1] */) {\n    // convert -0 to +0\n    if (NEGATIVE_ZERO) return $native.apply(this, arguments) || 0;\n    var O = toIObject(this);\n    var length = toLength(O.length);\n    var index = length - 1;\n    if (arguments.length > 1) index = Math.min(index, toInteger(arguments[1]));\n    if (index < 0) index = length + index;\n    for (;index >= 0; index--) if (index in O) if (O[index] === searchElement) return index || 0;\n    return -1;\n  }\n});\n\n\n/***/ }),\n/* 464 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 22.1.3.3 Array.prototype.copyWithin(target, start, end = this.length)\nvar $export = __webpack_require__(0);\n\n$export($export.P, 'Array', { copyWithin: __webpack_require__(161) });\n\n__webpack_require__(41)('copyWithin');\n\n\n/***/ }),\n/* 465 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 22.1.3.6 Array.prototype.fill(value, start = 0, end = this.length)\nvar $export = __webpack_require__(0);\n\n$export($export.P, 'Array', { fill: __webpack_require__(111) });\n\n__webpack_require__(41)('fill');\n\n\n/***/ }),\n/* 466 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// 22.1.3.8 Array.prototype.find(predicate, thisArg = undefined)\nvar $export = __webpack_require__(0);\nvar $find = __webpack_require__(34)(5);\nvar KEY = 'find';\nvar forced = true;\n// Shouldn't skip holes\nif (KEY in []) Array(1)[KEY](function () { forced = false; });\n$export($export.P + $export.F * forced, 'Array', {\n  find: function find(callbackfn /* , that = undefined */) {\n    return $find(this, callbackfn, arguments.length > 1 ? arguments[1] : undefined);\n  }\n});\n__webpack_require__(41)(KEY);\n\n\n/***/ }),\n/* 467 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// 22.1.3.9 Array.prototype.findIndex(predicate, thisArg = undefined)\nvar $export = __webpack_require__(0);\nvar $find = __webpack_require__(34)(6);\nvar KEY = 'findIndex';\nvar forced = true;\n// Shouldn't skip holes\nif (KEY in []) Array(1)[KEY](function () { forced = false; });\n$export($export.P + $export.F * forced, 'Array', {\n  findIndex: function findIndex(callbackfn /* , that = undefined */) {\n    return $find(this, callbackfn, arguments.length > 1 ? arguments[1] : undefined);\n  }\n});\n__webpack_require__(41)(KEY);\n\n\n/***/ }),\n/* 468 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(49)('Array');\n\n\n/***/ }),\n/* 469 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar global = __webpack_require__(3);\nvar inheritIfRequired = __webpack_require__(98);\nvar dP = __webpack_require__(10).f;\nvar gOPN = __webpack_require__(48).f;\nvar isRegExp = __webpack_require__(74);\nvar $flags = __webpack_require__(76);\nvar $RegExp = global.RegExp;\nvar Base = $RegExp;\nvar proto = $RegExp.prototype;\nvar re1 = /a/g;\nvar re2 = /a/g;\n// \"new\" creates a new object, old webkit buggy here\nvar CORRECT_NEW = new $RegExp(re1) !== re1;\n\nif (__webpack_require__(9) && (!CORRECT_NEW || __webpack_require__(4)(function () {\n  re2[__webpack_require__(7)('match')] = false;\n  // RegExp constructor can alter flags and IsRegExp works correct with @@match\n  return $RegExp(re1) != re1 || $RegExp(re2) == re2 || $RegExp(re1, 'i') != '/a/i';\n}))) {\n  $RegExp = function RegExp(p, f) {\n    var tiRE = this instanceof $RegExp;\n    var piRE = isRegExp(p);\n    var fiU = f === undefined;\n    return !tiRE && piRE && p.constructor === $RegExp && fiU ? p\n      : inheritIfRequired(CORRECT_NEW\n        ? new Base(piRE && !fiU ? p.source : p, f)\n        : Base((piRE = p instanceof $RegExp) ? p.source : p, piRE && fiU ? $flags.call(p) : f)\n      , tiRE ? this : proto, $RegExp);\n  };\n  var proxy = function (key) {\n    key in $RegExp || dP($RegExp, key, {\n      configurable: true,\n      get: function () { return Base[key]; },\n      set: function (it) { Base[key] = it; }\n    });\n  };\n  for (var keys = gOPN(Base), i = 0; keys.length > i;) proxy(keys[i++]);\n  proto.constructor = $RegExp;\n  $RegExp.prototype = proto;\n  __webpack_require__(17)(global, 'RegExp', $RegExp);\n}\n\n__webpack_require__(49)('RegExp');\n\n\n/***/ }),\n/* 470 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n__webpack_require__(163);\nvar anObject = __webpack_require__(2);\nvar $flags = __webpack_require__(76);\nvar DESCRIPTORS = __webpack_require__(9);\nvar TO_STRING = 'toString';\nvar $toString = /./[TO_STRING];\n\nvar define = function (fn) {\n  __webpack_require__(17)(RegExp.prototype, TO_STRING, fn, true);\n};\n\n// 21.2.5.14 RegExp.prototype.toString()\nif (__webpack_require__(4)(function () { return $toString.call({ source: 'a', flags: 'b' }) != '/a/b'; })) {\n  define(function toString() {\n    var R = anObject(this);\n    return '/'.concat(R.source, '/',\n      'flags' in R ? R.flags : !DESCRIPTORS && R instanceof RegExp ? $flags.call(R) : undefined);\n  });\n// FF44- RegExp#toString has a wrong name\n} else if ($toString.name != TO_STRING) {\n  define(function toString() {\n    return $toString.call(this);\n  });\n}\n\n\n/***/ }),\n/* 471 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// @@match logic\n__webpack_require__(77)('match', 1, function (defined, MATCH, $match) {\n  // 21.1.3.11 String.prototype.match(regexp)\n  return [function match(regexp) {\n    'use strict';\n    var O = defined(this);\n    var fn = regexp == undefined ? undefined : regexp[MATCH];\n    return fn !== undefined ? fn.call(regexp, O) : new RegExp(regexp)[MATCH](String(O));\n  }, $match];\n});\n\n\n/***/ }),\n/* 472 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// @@replace logic\n__webpack_require__(77)('replace', 2, function (defined, REPLACE, $replace) {\n  // 21.1.3.14 String.prototype.replace(searchValue, replaceValue)\n  return [function replace(searchValue, replaceValue) {\n    'use strict';\n    var O = defined(this);\n    var fn = searchValue == undefined ? undefined : searchValue[REPLACE];\n    return fn !== undefined\n      ? fn.call(searchValue, O, replaceValue)\n      : $replace.call(String(O), searchValue, replaceValue);\n  }, $replace];\n});\n\n\n/***/ }),\n/* 473 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// @@search logic\n__webpack_require__(77)('search', 1, function (defined, SEARCH, $search) {\n  // 21.1.3.15 String.prototype.search(regexp)\n  return [function search(regexp) {\n    'use strict';\n    var O = defined(this);\n    var fn = regexp == undefined ? undefined : regexp[SEARCH];\n    return fn !== undefined ? fn.call(regexp, O) : new RegExp(regexp)[SEARCH](String(O));\n  }, $search];\n});\n\n\n/***/ }),\n/* 474 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// @@split logic\n__webpack_require__(77)('split', 2, function (defined, SPLIT, $split) {\n  'use strict';\n  var isRegExp = __webpack_require__(74);\n  var _split = $split;\n  var $push = [].push;\n  var $SPLIT = 'split';\n  var LENGTH = 'length';\n  var LAST_INDEX = 'lastIndex';\n  if (\n    'abbc'[$SPLIT](/(b)*/)[1] == 'c' ||\n    'test'[$SPLIT](/(?:)/, -1)[LENGTH] != 4 ||\n    'ab'[$SPLIT](/(?:ab)*/)[LENGTH] != 2 ||\n    '.'[$SPLIT](/(.?)(.?)/)[LENGTH] != 4 ||\n    '.'[$SPLIT](/()()/)[LENGTH] > 1 ||\n    ''[$SPLIT](/.?/)[LENGTH]\n  ) {\n    var NPCG = /()??/.exec('')[1] === undefined; // nonparticipating capturing group\n    // based on es5-shim implementation, need to rework it\n    $split = function (separator, limit) {\n      var string = String(this);\n      if (separator === undefined && limit === 0) return [];\n      // If `separator` is not a regex, use native split\n      if (!isRegExp(separator)) return _split.call(string, separator, limit);\n      var output = [];\n      var flags = (separator.ignoreCase ? 'i' : '') +\n                  (separator.multiline ? 'm' : '') +\n                  (separator.unicode ? 'u' : '') +\n                  (separator.sticky ? 'y' : '');\n      var lastLastIndex = 0;\n      var splitLimit = limit === undefined ? 4294967295 : limit >>> 0;\n      // Make `global` and avoid `lastIndex` issues by working with a copy\n      var separatorCopy = new RegExp(separator.source, flags + 'g');\n      var separator2, match, lastIndex, lastLength, i;\n      // Doesn't need flags gy, but they don't hurt\n      if (!NPCG) separator2 = new RegExp('^' + separatorCopy.source + '$(?!\\\\s)', flags);\n      while (match = separatorCopy.exec(string)) {\n        // `separatorCopy.lastIndex` is not reliable cross-browser\n        lastIndex = match.index + match[0][LENGTH];\n        if (lastIndex > lastLastIndex) {\n          output.push(string.slice(lastLastIndex, match.index));\n          // Fix browsers whose `exec` methods don't consistently return `undefined` for NPCG\n          // eslint-disable-next-line no-loop-func\n          if (!NPCG && match[LENGTH] > 1) match[0].replace(separator2, function () {\n            for (i = 1; i < arguments[LENGTH] - 2; i++) if (arguments[i] === undefined) match[i] = undefined;\n          });\n          if (match[LENGTH] > 1 && match.index < string[LENGTH]) $push.apply(output, match.slice(1));\n          lastLength = match[0][LENGTH];\n          lastLastIndex = lastIndex;\n          if (output[LENGTH] >= splitLimit) break;\n        }\n        if (separatorCopy[LAST_INDEX] === match.index) separatorCopy[LAST_INDEX]++; // Avoid an infinite loop\n      }\n      if (lastLastIndex === string[LENGTH]) {\n        if (lastLength || !separatorCopy.test('')) output.push('');\n      } else output.push(string.slice(lastLastIndex));\n      return output[LENGTH] > splitLimit ? output.slice(0, splitLimit) : output;\n    };\n  // Chakra, V8\n  } else if ('0'[$SPLIT](undefined, 0)[LENGTH]) {\n    $split = function (separator, limit) {\n      return separator === undefined && limit === 0 ? [] : _split.call(this, separator, limit);\n    };\n  }\n  // 21.1.3.17 String.prototype.split(separator, limit)\n  return [function split(separator, limit) {\n    var O = defined(this);\n    var fn = separator == undefined ? undefined : separator[SPLIT];\n    return fn !== undefined ? fn.call(separator, O, limit) : $split.call(String(O), separator, limit);\n  }, $split];\n});\n\n\n/***/ }),\n/* 475 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar LIBRARY = __webpack_require__(40);\nvar global = __webpack_require__(3);\nvar ctx = __webpack_require__(27);\nvar classof = __webpack_require__(64);\nvar $export = __webpack_require__(0);\nvar isObject = __webpack_require__(5);\nvar aFunction = __webpack_require__(15);\nvar anInstance = __webpack_require__(50);\nvar forOf = __webpack_require__(51);\nvar speciesConstructor = __webpack_require__(78);\nvar task = __webpack_require__(113).set;\nvar microtask = __webpack_require__(114)();\nvar newPromiseCapabilityModule = __webpack_require__(115);\nvar perform = __webpack_require__(164);\nvar userAgent = __webpack_require__(79);\nvar promiseResolve = __webpack_require__(165);\nvar PROMISE = 'Promise';\nvar TypeError = global.TypeError;\nvar process = global.process;\nvar versions = process && process.versions;\nvar v8 = versions && versions.v8 || '';\nvar $Promise = global[PROMISE];\nvar isNode = classof(process) == 'process';\nvar empty = function () { /* empty */ };\nvar Internal, newGenericPromiseCapability, OwnPromiseCapability, Wrapper;\nvar newPromiseCapability = newGenericPromiseCapability = newPromiseCapabilityModule.f;\n\nvar USE_NATIVE = !!function () {\n  try {\n    // correct subclassing with @@species support\n    var promise = $Promise.resolve(1);\n    var FakePromise = (promise.constructor = {})[__webpack_require__(7)('species')] = function (exec) {\n      exec(empty, empty);\n    };\n    // unhandled rejections tracking support, NodeJS Promise without it fails @@species test\n    return (isNode || typeof PromiseRejectionEvent == 'function')\n      && promise.then(empty) instanceof FakePromise\n      // v8 6.6 (Node 10 and Chrome 66) have a bug with resolving custom thenables\n      // https://bugs.chromium.org/p/chromium/issues/detail?id=830565\n      // we can't detect it synchronously, so just check versions\n      && v8.indexOf('6.6') !== 0\n      && userAgent.indexOf('Chrome/66') === -1;\n  } catch (e) { /* empty */ }\n}();\n\n// helpers\nvar isThenable = function (it) {\n  var then;\n  return isObject(it) && typeof (then = it.then) == 'function' ? then : false;\n};\nvar notify = function (promise, isReject) {\n  if (promise._n) return;\n  promise._n = true;\n  var chain = promise._c;\n  microtask(function () {\n    var value = promise._v;\n    var ok = promise._s == 1;\n    var i = 0;\n    var run = function (reaction) {\n      var handler = ok ? reaction.ok : reaction.fail;\n      var resolve = reaction.resolve;\n      var reject = reaction.reject;\n      var domain = reaction.domain;\n      var result, then, exited;\n      try {\n        if (handler) {\n          if (!ok) {\n            if (promise._h == 2) onHandleUnhandled(promise);\n            promise._h = 1;\n          }\n          if (handler === true) result = value;\n          else {\n            if (domain) domain.enter();\n            result = handler(value); // may throw\n            if (domain) {\n              domain.exit();\n              exited = true;\n            }\n          }\n          if (result === reaction.promise) {\n            reject(TypeError('Promise-chain cycle'));\n          } else if (then = isThenable(result)) {\n            then.call(result, resolve, reject);\n          } else resolve(result);\n        } else reject(value);\n      } catch (e) {\n        if (domain && !exited) domain.exit();\n        reject(e);\n      }\n    };\n    while (chain.length > i) run(chain[i++]); // variable length - can't use forEach\n    promise._c = [];\n    promise._n = false;\n    if (isReject && !promise._h) onUnhandled(promise);\n  });\n};\nvar onUnhandled = function (promise) {\n  task.call(global, function () {\n    var value = promise._v;\n    var unhandled = isUnhandled(promise);\n    var result, handler, console;\n    if (unhandled) {\n      result = perform(function () {\n        if (isNode) {\n          process.emit('unhandledRejection', value, promise);\n        } else if (handler = global.onunhandledrejection) {\n          handler({ promise: promise, reason: value });\n        } else if ((console = global.console) && console.error) {\n          console.error('Unhandled promise rejection', value);\n        }\n      });\n      // Browsers should not trigger `rejectionHandled` event if it was handled here, NodeJS - should\n      promise._h = isNode || isUnhandled(promise) ? 2 : 1;\n    } promise._a = undefined;\n    if (unhandled && result.e) throw result.v;\n  });\n};\nvar isUnhandled = function (promise) {\n  return promise._h !== 1 && (promise._a || promise._c).length === 0;\n};\nvar onHandleUnhandled = function (promise) {\n  task.call(global, function () {\n    var handler;\n    if (isNode) {\n      process.emit('rejectionHandled', promise);\n    } else if (handler = global.onrejectionhandled) {\n      handler({ promise: promise, reason: promise._v });\n    }\n  });\n};\nvar $reject = function (value) {\n  var promise = this;\n  if (promise._d) return;\n  promise._d = true;\n  promise = promise._w || promise; // unwrap\n  promise._v = value;\n  promise._s = 2;\n  if (!promise._a) promise._a = promise._c.slice();\n  notify(promise, true);\n};\nvar $resolve = function (value) {\n  var promise = this;\n  var then;\n  if (promise._d) return;\n  promise._d = true;\n  promise = promise._w || promise; // unwrap\n  try {\n    if (promise === value) throw TypeError(\"Promise can't be resolved itself\");\n    if (then = isThenable(value)) {\n      microtask(function () {\n        var wrapper = { _w: promise, _d: false }; // wrap\n        try {\n          then.call(value, ctx($resolve, wrapper, 1), ctx($reject, wrapper, 1));\n        } catch (e) {\n          $reject.call(wrapper, e);\n        }\n      });\n    } else {\n      promise._v = value;\n      promise._s = 1;\n      notify(promise, false);\n    }\n  } catch (e) {\n    $reject.call({ _w: promise, _d: false }, e); // wrap\n  }\n};\n\n// constructor polyfill\nif (!USE_NATIVE) {\n  // 25.4.3.1 Promise(executor)\n  $Promise = function Promise(executor) {\n    anInstance(this, $Promise, PROMISE, '_h');\n    aFunction(executor);\n    Internal.call(this);\n    try {\n      executor(ctx($resolve, this, 1), ctx($reject, this, 1));\n    } catch (err) {\n      $reject.call(this, err);\n    }\n  };\n  // eslint-disable-next-line no-unused-vars\n  Internal = function Promise(executor) {\n    this._c = [];             // <- awaiting reactions\n    this._a = undefined;      // <- checked in isUnhandled reactions\n    this._s = 0;              // <- state\n    this._d = false;          // <- done\n    this._v = undefined;      // <- value\n    this._h = 0;              // <- rejection state, 0 - default, 1 - handled, 2 - unhandled\n    this._n = false;          // <- notify\n  };\n  Internal.prototype = __webpack_require__(52)($Promise.prototype, {\n    // 25.4.5.3 Promise.prototype.then(onFulfilled, onRejected)\n    then: function then(onFulfilled, onRejected) {\n      var reaction = newPromiseCapability(speciesConstructor(this, $Promise));\n      reaction.ok = typeof onFulfilled == 'function' ? onFulfilled : true;\n      reaction.fail = typeof onRejected == 'function' && onRejected;\n      reaction.domain = isNode ? process.domain : undefined;\n      this._c.push(reaction);\n      if (this._a) this._a.push(reaction);\n      if (this._s) notify(this, false);\n      return reaction.promise;\n    },\n    // 25.4.5.1 Promise.prototype.catch(onRejected)\n    'catch': function (onRejected) {\n      return this.then(undefined, onRejected);\n    }\n  });\n  OwnPromiseCapability = function () {\n    var promise = new Internal();\n    this.promise = promise;\n    this.resolve = ctx($resolve, promise, 1);\n    this.reject = ctx($reject, promise, 1);\n  };\n  newPromiseCapabilityModule.f = newPromiseCapability = function (C) {\n    return C === $Promise || C === Wrapper\n      ? new OwnPromiseCapability(C)\n      : newGenericPromiseCapability(C);\n  };\n}\n\n$export($export.G + $export.W + $export.F * !USE_NATIVE, { Promise: $Promise });\n__webpack_require__(56)($Promise, PROMISE);\n__webpack_require__(49)(PROMISE);\nWrapper = __webpack_require__(26)[PROMISE];\n\n// statics\n$export($export.S + $export.F * !USE_NATIVE, PROMISE, {\n  // 25.4.4.5 Promise.reject(r)\n  reject: function reject(r) {\n    var capability = newPromiseCapability(this);\n    var $$reject = capability.reject;\n    $$reject(r);\n    return capability.promise;\n  }\n});\n$export($export.S + $export.F * (LIBRARY || !USE_NATIVE), PROMISE, {\n  // 25.4.4.6 Promise.resolve(x)\n  resolve: function resolve(x) {\n    return promiseResolve(LIBRARY && this === Wrapper ? $Promise : this, x);\n  }\n});\n$export($export.S + $export.F * !(USE_NATIVE && __webpack_require__(75)(function (iter) {\n  $Promise.all(iter)['catch'](empty);\n})), PROMISE, {\n  // 25.4.4.1 Promise.all(iterable)\n  all: function all(iterable) {\n    var C = this;\n    var capability = newPromiseCapability(C);\n    var resolve = capability.resolve;\n    var reject = capability.reject;\n    var result = perform(function () {\n      var values = [];\n      var index = 0;\n      var remaining = 1;\n      forOf(iterable, false, function (promise) {\n        var $index = index++;\n        var alreadyCalled = false;\n        values.push(undefined);\n        remaining++;\n        C.resolve(promise).then(function (value) {\n          if (alreadyCalled) return;\n          alreadyCalled = true;\n          values[$index] = value;\n          --remaining || resolve(values);\n        }, reject);\n      });\n      --remaining || resolve(values);\n    });\n    if (result.e) reject(result.v);\n    return capability.promise;\n  },\n  // 25.4.4.4 Promise.race(iterable)\n  race: function race(iterable) {\n    var C = this;\n    var capability = newPromiseCapability(C);\n    var reject = capability.reject;\n    var result = perform(function () {\n      forOf(iterable, false, function (promise) {\n        C.resolve(promise).then(capability.resolve, reject);\n      });\n    });\n    if (result.e) reject(result.v);\n    return capability.promise;\n  }\n});\n\n\n/***/ }),\n/* 476 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar weak = __webpack_require__(170);\nvar validate = __webpack_require__(59);\nvar WEAK_SET = 'WeakSet';\n\n// 23.4 WeakSet Objects\n__webpack_require__(80)(WEAK_SET, function (get) {\n  return function WeakSet() { return get(this, arguments.length > 0 ? arguments[0] : undefined); };\n}, {\n  // 23.4.3.1 WeakSet.prototype.add(value)\n  add: function add(value) {\n    return weak.def(validate(this, WEAK_SET), value, true);\n  }\n}, weak, false, true);\n\n\n/***/ }),\n/* 477 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar $typed = __webpack_require__(81);\nvar buffer = __webpack_require__(116);\nvar anObject = __webpack_require__(2);\nvar toAbsoluteIndex = __webpack_require__(46);\nvar toLength = __webpack_require__(11);\nvar isObject = __webpack_require__(5);\nvar ArrayBuffer = __webpack_require__(3).ArrayBuffer;\nvar speciesConstructor = __webpack_require__(78);\nvar $ArrayBuffer = buffer.ArrayBuffer;\nvar $DataView = buffer.DataView;\nvar $isView = $typed.ABV && ArrayBuffer.isView;\nvar $slice = $ArrayBuffer.prototype.slice;\nvar VIEW = $typed.VIEW;\nvar ARRAY_BUFFER = 'ArrayBuffer';\n\n$export($export.G + $export.W + $export.F * (ArrayBuffer !== $ArrayBuffer), { ArrayBuffer: $ArrayBuffer });\n\n$export($export.S + $export.F * !$typed.CONSTR, ARRAY_BUFFER, {\n  // 24.1.3.1 ArrayBuffer.isView(arg)\n  isView: function isView(it) {\n    return $isView && $isView(it) || isObject(it) && VIEW in it;\n  }\n});\n\n$export($export.P + $export.U + $export.F * __webpack_require__(4)(function () {\n  return !new $ArrayBuffer(2).slice(1, undefined).byteLength;\n}), ARRAY_BUFFER, {\n  // 24.1.4.3 ArrayBuffer.prototype.slice(start, end)\n  slice: function slice(start, end) {\n    if ($slice !== undefined && end === undefined) return $slice.call(anObject(this), start); // FF fix\n    var len = anObject(this).byteLength;\n    var first = toAbsoluteIndex(start, len);\n    var fin = toAbsoluteIndex(end === undefined ? len : end, len);\n    var result = new (speciesConstructor(this, $ArrayBuffer))(toLength(fin - first));\n    var viewS = new $DataView(this);\n    var viewT = new $DataView(result);\n    var index = 0;\n    while (first < fin) {\n      viewT.setUint8(index++, viewS.getUint8(first++));\n    } return result;\n  }\n});\n\n__webpack_require__(49)(ARRAY_BUFFER);\n\n\n/***/ }),\n/* 478 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\n$export($export.G + $export.W + $export.F * !__webpack_require__(81).ABV, {\n  DataView: __webpack_require__(116).DataView\n});\n\n\n/***/ }),\n/* 479 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(36)('Int8', 1, function (init) {\n  return function Int8Array(data, byteOffset, length) {\n    return init(this, data, byteOffset, length);\n  };\n});\n\n\n/***/ }),\n/* 480 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(36)('Uint8', 1, function (init) {\n  return function Uint8Array(data, byteOffset, length) {\n    return init(this, data, byteOffset, length);\n  };\n});\n\n\n/***/ }),\n/* 481 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(36)('Uint8', 1, function (init) {\n  return function Uint8ClampedArray(data, byteOffset, length) {\n    return init(this, data, byteOffset, length);\n  };\n}, true);\n\n\n/***/ }),\n/* 482 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(36)('Int16', 2, function (init) {\n  return function Int16Array(data, byteOffset, length) {\n    return init(this, data, byteOffset, length);\n  };\n});\n\n\n/***/ }),\n/* 483 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(36)('Uint16', 2, function (init) {\n  return function Uint16Array(data, byteOffset, length) {\n    return init(this, data, byteOffset, length);\n  };\n});\n\n\n/***/ }),\n/* 484 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(36)('Int32', 4, function (init) {\n  return function Int32Array(data, byteOffset, length) {\n    return init(this, data, byteOffset, length);\n  };\n});\n\n\n/***/ }),\n/* 485 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(36)('Uint32', 4, function (init) {\n  return function Uint32Array(data, byteOffset, length) {\n    return init(this, data, byteOffset, length);\n  };\n});\n\n\n/***/ }),\n/* 486 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(36)('Float32', 4, function (init) {\n  return function Float32Array(data, byteOffset, length) {\n    return init(this, data, byteOffset, length);\n  };\n});\n\n\n/***/ }),\n/* 487 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(36)('Float64', 8, function (init) {\n  return function Float64Array(data, byteOffset, length) {\n    return init(this, data, byteOffset, length);\n  };\n});\n\n\n/***/ }),\n/* 488 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.1 Reflect.apply(target, thisArgument, argumentsList)\nvar $export = __webpack_require__(0);\nvar aFunction = __webpack_require__(15);\nvar anObject = __webpack_require__(2);\nvar rApply = (__webpack_require__(3).Reflect || {}).apply;\nvar fApply = Function.apply;\n// MS Edge argumentsList argument is optional\n$export($export.S + $export.F * !__webpack_require__(4)(function () {\n  rApply(function () { /* empty */ });\n}), 'Reflect', {\n  apply: function apply(target, thisArgument, argumentsList) {\n    var T = aFunction(target);\n    var L = anObject(argumentsList);\n    return rApply ? rApply(T, thisArgument, L) : fApply.call(T, thisArgument, L);\n  }\n});\n\n\n/***/ }),\n/* 489 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.2 Reflect.construct(target, argumentsList [, newTarget])\nvar $export = __webpack_require__(0);\nvar create = __webpack_require__(47);\nvar aFunction = __webpack_require__(15);\nvar anObject = __webpack_require__(2);\nvar isObject = __webpack_require__(5);\nvar fails = __webpack_require__(4);\nvar bind = __webpack_require__(151);\nvar rConstruct = (__webpack_require__(3).Reflect || {}).construct;\n\n// MS Edge supports only 2 arguments and argumentsList argument is optional\n// FF Nightly sets third argument as `new.target`, but does not create `this` from it\nvar NEW_TARGET_BUG = fails(function () {\n  function F() { /* empty */ }\n  return !(rConstruct(function () { /* empty */ }, [], F) instanceof F);\n});\nvar ARGS_BUG = !fails(function () {\n  rConstruct(function () { /* empty */ });\n});\n\n$export($export.S + $export.F * (NEW_TARGET_BUG || ARGS_BUG), 'Reflect', {\n  construct: function construct(Target, args /* , newTarget */) {\n    aFunction(Target);\n    anObject(args);\n    var newTarget = arguments.length < 3 ? Target : aFunction(arguments[2]);\n    if (ARGS_BUG && !NEW_TARGET_BUG) return rConstruct(Target, args, newTarget);\n    if (Target == newTarget) {\n      // w/o altered newTarget, optimization for 0-4 arguments\n      switch (args.length) {\n        case 0: return new Target();\n        case 1: return new Target(args[0]);\n        case 2: return new Target(args[0], args[1]);\n        case 3: return new Target(args[0], args[1], args[2]);\n        case 4: return new Target(args[0], args[1], args[2], args[3]);\n      }\n      // w/o altered newTarget, lot of arguments case\n      var $args = [null];\n      $args.push.apply($args, args);\n      return new (bind.apply(Target, $args))();\n    }\n    // with altered newTarget, not support built-in constructors\n    var proto = newTarget.prototype;\n    var instance = create(isObject(proto) ? proto : Object.prototype);\n    var result = Function.apply.call(Target, instance, args);\n    return isObject(result) ? result : instance;\n  }\n});\n\n\n/***/ }),\n/* 490 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.3 Reflect.defineProperty(target, propertyKey, attributes)\nvar dP = __webpack_require__(10);\nvar $export = __webpack_require__(0);\nvar anObject = __webpack_require__(2);\nvar toPrimitive = __webpack_require__(30);\n\n// MS Edge has broken Reflect.defineProperty - throwing instead of returning false\n$export($export.S + $export.F * __webpack_require__(4)(function () {\n  // eslint-disable-next-line no-undef\n  Reflect.defineProperty(dP.f({}, 1, { value: 1 }), 1, { value: 2 });\n}), 'Reflect', {\n  defineProperty: function defineProperty(target, propertyKey, attributes) {\n    anObject(target);\n    propertyKey = toPrimitive(propertyKey, true);\n    anObject(attributes);\n    try {\n      dP.f(target, propertyKey, attributes);\n      return true;\n    } catch (e) {\n      return false;\n    }\n  }\n});\n\n\n/***/ }),\n/* 491 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.4 Reflect.deleteProperty(target, propertyKey)\nvar $export = __webpack_require__(0);\nvar gOPD = __webpack_require__(21).f;\nvar anObject = __webpack_require__(2);\n\n$export($export.S, 'Reflect', {\n  deleteProperty: function deleteProperty(target, propertyKey) {\n    var desc = gOPD(anObject(target), propertyKey);\n    return desc && !desc.configurable ? false : delete target[propertyKey];\n  }\n});\n\n\n/***/ }),\n/* 492 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// 26.1.5 Reflect.enumerate(target)\nvar $export = __webpack_require__(0);\nvar anObject = __webpack_require__(2);\nvar Enumerate = function (iterated) {\n  this._t = anObject(iterated); // target\n  this._i = 0;                  // next index\n  var keys = this._k = [];      // keys\n  var key;\n  for (key in iterated) keys.push(key);\n};\n__webpack_require__(104)(Enumerate, 'Object', function () {\n  var that = this;\n  var keys = that._k;\n  var key;\n  do {\n    if (that._i >= keys.length) return { value: undefined, done: true };\n  } while (!((key = keys[that._i++]) in that._t));\n  return { value: key, done: false };\n});\n\n$export($export.S, 'Reflect', {\n  enumerate: function enumerate(target) {\n    return new Enumerate(target);\n  }\n});\n\n\n/***/ }),\n/* 493 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.6 Reflect.get(target, propertyKey [, receiver])\nvar gOPD = __webpack_require__(21);\nvar getPrototypeOf = __webpack_require__(22);\nvar has = __webpack_require__(19);\nvar $export = __webpack_require__(0);\nvar isObject = __webpack_require__(5);\nvar anObject = __webpack_require__(2);\n\nfunction get(target, propertyKey /* , receiver */) {\n  var receiver = arguments.length < 3 ? target : arguments[2];\n  var desc, proto;\n  if (anObject(target) === receiver) return target[propertyKey];\n  if (desc = gOPD.f(target, propertyKey)) return has(desc, 'value')\n    ? desc.value\n    : desc.get !== undefined\n      ? desc.get.call(receiver)\n      : undefined;\n  if (isObject(proto = getPrototypeOf(target))) return get(proto, propertyKey, receiver);\n}\n\n$export($export.S, 'Reflect', { get: get });\n\n\n/***/ }),\n/* 494 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.7 Reflect.getOwnPropertyDescriptor(target, propertyKey)\nvar gOPD = __webpack_require__(21);\nvar $export = __webpack_require__(0);\nvar anObject = __webpack_require__(2);\n\n$export($export.S, 'Reflect', {\n  getOwnPropertyDescriptor: function getOwnPropertyDescriptor(target, propertyKey) {\n    return gOPD.f(anObject(target), propertyKey);\n  }\n});\n\n\n/***/ }),\n/* 495 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.8 Reflect.getPrototypeOf(target)\nvar $export = __webpack_require__(0);\nvar getProto = __webpack_require__(22);\nvar anObject = __webpack_require__(2);\n\n$export($export.S, 'Reflect', {\n  getPrototypeOf: function getPrototypeOf(target) {\n    return getProto(anObject(target));\n  }\n});\n\n\n/***/ }),\n/* 496 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.9 Reflect.has(target, propertyKey)\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Reflect', {\n  has: function has(target, propertyKey) {\n    return propertyKey in target;\n  }\n});\n\n\n/***/ }),\n/* 497 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.10 Reflect.isExtensible(target)\nvar $export = __webpack_require__(0);\nvar anObject = __webpack_require__(2);\nvar $isExtensible = Object.isExtensible;\n\n$export($export.S, 'Reflect', {\n  isExtensible: function isExtensible(target) {\n    anObject(target);\n    return $isExtensible ? $isExtensible(target) : true;\n  }\n});\n\n\n/***/ }),\n/* 498 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.11 Reflect.ownKeys(target)\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Reflect', { ownKeys: __webpack_require__(172) });\n\n\n/***/ }),\n/* 499 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.12 Reflect.preventExtensions(target)\nvar $export = __webpack_require__(0);\nvar anObject = __webpack_require__(2);\nvar $preventExtensions = Object.preventExtensions;\n\n$export($export.S, 'Reflect', {\n  preventExtensions: function preventExtensions(target) {\n    anObject(target);\n    try {\n      if ($preventExtensions) $preventExtensions(target);\n      return true;\n    } catch (e) {\n      return false;\n    }\n  }\n});\n\n\n/***/ }),\n/* 500 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.13 Reflect.set(target, propertyKey, V [, receiver])\nvar dP = __webpack_require__(10);\nvar gOPD = __webpack_require__(21);\nvar getPrototypeOf = __webpack_require__(22);\nvar has = __webpack_require__(19);\nvar $export = __webpack_require__(0);\nvar createDesc = __webpack_require__(43);\nvar anObject = __webpack_require__(2);\nvar isObject = __webpack_require__(5);\n\nfunction set(target, propertyKey, V /* , receiver */) {\n  var receiver = arguments.length < 4 ? target : arguments[3];\n  var ownDesc = gOPD.f(anObject(target), propertyKey);\n  var existingDescriptor, proto;\n  if (!ownDesc) {\n    if (isObject(proto = getPrototypeOf(target))) {\n      return set(proto, propertyKey, V, receiver);\n    }\n    ownDesc = createDesc(0);\n  }\n  if (has(ownDesc, 'value')) {\n    if (ownDesc.writable === false || !isObject(receiver)) return false;\n    if (existingDescriptor = gOPD.f(receiver, propertyKey)) {\n      if (existingDescriptor.get || existingDescriptor.set || existingDescriptor.writable === false) return false;\n      existingDescriptor.value = V;\n      dP.f(receiver, propertyKey, existingDescriptor);\n    } else dP.f(receiver, propertyKey, createDesc(0, V));\n    return true;\n  }\n  return ownDesc.set === undefined ? false : (ownDesc.set.call(receiver, V), true);\n}\n\n$export($export.S, 'Reflect', { set: set });\n\n\n/***/ }),\n/* 501 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// 26.1.14 Reflect.setPrototypeOf(target, proto)\nvar $export = __webpack_require__(0);\nvar setProto = __webpack_require__(96);\n\nif (setProto) $export($export.S, 'Reflect', {\n  setPrototypeOf: function setPrototypeOf(target, proto) {\n    setProto.check(target, proto);\n    try {\n      setProto.set(target, proto);\n      return true;\n    } catch (e) {\n      return false;\n    }\n  }\n});\n\n\n/***/ }),\n/* 502 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://github.com/tc39/Array.prototype.includes\nvar $export = __webpack_require__(0);\nvar $includes = __webpack_require__(71)(true);\n\n$export($export.P, 'Array', {\n  includes: function includes(el /* , fromIndex = 0 */) {\n    return $includes(this, el, arguments.length > 1 ? arguments[1] : undefined);\n  }\n});\n\n__webpack_require__(41)('includes');\n\n\n/***/ }),\n/* 503 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://tc39.github.io/proposal-flatMap/#sec-Array.prototype.flatMap\nvar $export = __webpack_require__(0);\nvar flattenIntoArray = __webpack_require__(173);\nvar toObject = __webpack_require__(14);\nvar toLength = __webpack_require__(11);\nvar aFunction = __webpack_require__(15);\nvar arraySpeciesCreate = __webpack_require__(110);\n\n$export($export.P, 'Array', {\n  flatMap: function flatMap(callbackfn /* , thisArg */) {\n    var O = toObject(this);\n    var sourceLen, A;\n    aFunction(callbackfn);\n    sourceLen = toLength(O.length);\n    A = arraySpeciesCreate(O, 0);\n    flattenIntoArray(A, O, O, sourceLen, 0, 1, callbackfn, arguments[1]);\n    return A;\n  }\n});\n\n__webpack_require__(41)('flatMap');\n\n\n/***/ }),\n/* 504 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://tc39.github.io/proposal-flatMap/#sec-Array.prototype.flatten\nvar $export = __webpack_require__(0);\nvar flattenIntoArray = __webpack_require__(173);\nvar toObject = __webpack_require__(14);\nvar toLength = __webpack_require__(11);\nvar toInteger = __webpack_require__(32);\nvar arraySpeciesCreate = __webpack_require__(110);\n\n$export($export.P, 'Array', {\n  flatten: function flatten(/* depthArg = 1 */) {\n    var depthArg = arguments[0];\n    var O = toObject(this);\n    var sourceLen = toLength(O.length);\n    var A = arraySpeciesCreate(O, 0);\n    flattenIntoArray(A, O, O, sourceLen, 0, depthArg === undefined ? 1 : toInteger(depthArg));\n    return A;\n  }\n});\n\n__webpack_require__(41)('flatten');\n\n\n/***/ }),\n/* 505 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://github.com/mathiasbynens/String.prototype.at\nvar $export = __webpack_require__(0);\nvar $at = __webpack_require__(102)(true);\n\n$export($export.P, 'String', {\n  at: function at(pos) {\n    return $at(this, pos);\n  }\n});\n\n\n/***/ }),\n/* 506 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://github.com/tc39/proposal-string-pad-start-end\nvar $export = __webpack_require__(0);\nvar $pad = __webpack_require__(174);\nvar userAgent = __webpack_require__(79);\n\n// https://github.com/zloirock/core-js/issues/280\n$export($export.P + $export.F * /Version\\/10\\.\\d+(\\.\\d+)? Safari\\//.test(userAgent), 'String', {\n  padStart: function padStart(maxLength /* , fillString = ' ' */) {\n    return $pad(this, maxLength, arguments.length > 1 ? arguments[1] : undefined, true);\n  }\n});\n\n\n/***/ }),\n/* 507 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://github.com/tc39/proposal-string-pad-start-end\nvar $export = __webpack_require__(0);\nvar $pad = __webpack_require__(174);\nvar userAgent = __webpack_require__(79);\n\n// https://github.com/zloirock/core-js/issues/280\n$export($export.P + $export.F * /Version\\/10\\.\\d+(\\.\\d+)? Safari\\//.test(userAgent), 'String', {\n  padEnd: function padEnd(maxLength /* , fillString = ' ' */) {\n    return $pad(this, maxLength, arguments.length > 1 ? arguments[1] : undefined, false);\n  }\n});\n\n\n/***/ }),\n/* 508 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://github.com/sebmarkbage/ecmascript-string-left-right-trim\n__webpack_require__(57)('trimLeft', function ($trim) {\n  return function trimLeft() {\n    return $trim(this, 1);\n  };\n}, 'trimStart');\n\n\n/***/ }),\n/* 509 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://github.com/sebmarkbage/ecmascript-string-left-right-trim\n__webpack_require__(57)('trimRight', function ($trim) {\n  return function trimRight() {\n    return $trim(this, 2);\n  };\n}, 'trimEnd');\n\n\n/***/ }),\n/* 510 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://tc39.github.io/String.prototype.matchAll/\nvar $export = __webpack_require__(0);\nvar defined = __webpack_require__(31);\nvar toLength = __webpack_require__(11);\nvar isRegExp = __webpack_require__(74);\nvar getFlags = __webpack_require__(76);\nvar RegExpProto = RegExp.prototype;\n\nvar $RegExpStringIterator = function (regexp, string) {\n  this._r = regexp;\n  this._s = string;\n};\n\n__webpack_require__(104)($RegExpStringIterator, 'RegExp String', function next() {\n  var match = this._r.exec(this._s);\n  return { value: match, done: match === null };\n});\n\n$export($export.P, 'String', {\n  matchAll: function matchAll(regexp) {\n    defined(this);\n    if (!isRegExp(regexp)) throw TypeError(regexp + ' is not a regexp!');\n    var S = String(this);\n    var flags = 'flags' in RegExpProto ? String(regexp.flags) : getFlags.call(regexp);\n    var rx = new RegExp(regexp.source, ~flags.indexOf('g') ? flags : 'g' + flags);\n    rx.lastIndex = toLength(regexp.lastIndex);\n    return new $RegExpStringIterator(rx, S);\n  }\n});\n\n\n/***/ }),\n/* 511 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(92)('asyncIterator');\n\n\n/***/ }),\n/* 512 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(92)('observable');\n\n\n/***/ }),\n/* 513 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://github.com/tc39/proposal-object-getownpropertydescriptors\nvar $export = __webpack_require__(0);\nvar ownKeys = __webpack_require__(172);\nvar toIObject = __webpack_require__(20);\nvar gOPD = __webpack_require__(21);\nvar createProperty = __webpack_require__(108);\n\n$export($export.S, 'Object', {\n  getOwnPropertyDescriptors: function getOwnPropertyDescriptors(object) {\n    var O = toIObject(object);\n    var getDesc = gOPD.f;\n    var keys = ownKeys(O);\n    var result = {};\n    var i = 0;\n    var key, desc;\n    while (keys.length > i) {\n      desc = getDesc(O, key = keys[i++]);\n      if (desc !== undefined) createProperty(result, key, desc);\n    }\n    return result;\n  }\n});\n\n\n/***/ }),\n/* 514 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://github.com/tc39/proposal-object-values-entries\nvar $export = __webpack_require__(0);\nvar $values = __webpack_require__(175)(false);\n\n$export($export.S, 'Object', {\n  values: function values(it) {\n    return $values(it);\n  }\n});\n\n\n/***/ }),\n/* 515 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://github.com/tc39/proposal-object-values-entries\nvar $export = __webpack_require__(0);\nvar $entries = __webpack_require__(175)(true);\n\n$export($export.S, 'Object', {\n  entries: function entries(it) {\n    return $entries(it);\n  }\n});\n\n\n/***/ }),\n/* 516 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar toObject = __webpack_require__(14);\nvar aFunction = __webpack_require__(15);\nvar $defineProperty = __webpack_require__(10);\n\n// B.2.2.2 Object.prototype.__defineGetter__(P, getter)\n__webpack_require__(9) && $export($export.P + __webpack_require__(82), 'Object', {\n  __defineGetter__: function __defineGetter__(P, getter) {\n    $defineProperty.f(toObject(this), P, { get: aFunction(getter), enumerable: true, configurable: true });\n  }\n});\n\n\n/***/ }),\n/* 517 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar toObject = __webpack_require__(14);\nvar aFunction = __webpack_require__(15);\nvar $defineProperty = __webpack_require__(10);\n\n// B.2.2.3 Object.prototype.__defineSetter__(P, setter)\n__webpack_require__(9) && $export($export.P + __webpack_require__(82), 'Object', {\n  __defineSetter__: function __defineSetter__(P, setter) {\n    $defineProperty.f(toObject(this), P, { set: aFunction(setter), enumerable: true, configurable: true });\n  }\n});\n\n\n/***/ }),\n/* 518 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar toObject = __webpack_require__(14);\nvar toPrimitive = __webpack_require__(30);\nvar getPrototypeOf = __webpack_require__(22);\nvar getOwnPropertyDescriptor = __webpack_require__(21).f;\n\n// B.2.2.4 Object.prototype.__lookupGetter__(P)\n__webpack_require__(9) && $export($export.P + __webpack_require__(82), 'Object', {\n  __lookupGetter__: function __lookupGetter__(P) {\n    var O = toObject(this);\n    var K = toPrimitive(P, true);\n    var D;\n    do {\n      if (D = getOwnPropertyDescriptor(O, K)) return D.get;\n    } while (O = getPrototypeOf(O));\n  }\n});\n\n\n/***/ }),\n/* 519 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar $export = __webpack_require__(0);\nvar toObject = __webpack_require__(14);\nvar toPrimitive = __webpack_require__(30);\nvar getPrototypeOf = __webpack_require__(22);\nvar getOwnPropertyDescriptor = __webpack_require__(21).f;\n\n// B.2.2.5 Object.prototype.__lookupSetter__(P)\n__webpack_require__(9) && $export($export.P + __webpack_require__(82), 'Object', {\n  __lookupSetter__: function __lookupSetter__(P) {\n    var O = toObject(this);\n    var K = toPrimitive(P, true);\n    var D;\n    do {\n      if (D = getOwnPropertyDescriptor(O, K)) return D.set;\n    } while (O = getPrototypeOf(O));\n  }\n});\n\n\n/***/ }),\n/* 520 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://github.com/DavidBruant/Map-Set.prototype.toJSON\nvar $export = __webpack_require__(0);\n\n$export($export.P + $export.R, 'Map', { toJSON: __webpack_require__(176)('Map') });\n\n\n/***/ }),\n/* 521 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://github.com/DavidBruant/Map-Set.prototype.toJSON\nvar $export = __webpack_require__(0);\n\n$export($export.P + $export.R, 'Set', { toJSON: __webpack_require__(176)('Set') });\n\n\n/***/ }),\n/* 522 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://tc39.github.io/proposal-setmap-offrom/#sec-map.of\n__webpack_require__(83)('Map');\n\n\n/***/ }),\n/* 523 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://tc39.github.io/proposal-setmap-offrom/#sec-set.of\n__webpack_require__(83)('Set');\n\n\n/***/ }),\n/* 524 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://tc39.github.io/proposal-setmap-offrom/#sec-weakmap.of\n__webpack_require__(83)('WeakMap');\n\n\n/***/ }),\n/* 525 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://tc39.github.io/proposal-setmap-offrom/#sec-weakset.of\n__webpack_require__(83)('WeakSet');\n\n\n/***/ }),\n/* 526 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://tc39.github.io/proposal-setmap-offrom/#sec-map.from\n__webpack_require__(84)('Map');\n\n\n/***/ }),\n/* 527 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://tc39.github.io/proposal-setmap-offrom/#sec-set.from\n__webpack_require__(84)('Set');\n\n\n/***/ }),\n/* 528 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://tc39.github.io/proposal-setmap-offrom/#sec-weakmap.from\n__webpack_require__(84)('WeakMap');\n\n\n/***/ }),\n/* 529 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://tc39.github.io/proposal-setmap-offrom/#sec-weakset.from\n__webpack_require__(84)('WeakSet');\n\n\n/***/ }),\n/* 530 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://github.com/tc39/proposal-global\nvar $export = __webpack_require__(0);\n\n$export($export.G, { global: __webpack_require__(3) });\n\n\n/***/ }),\n/* 531 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://github.com/tc39/proposal-global\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'System', { global: __webpack_require__(3) });\n\n\n/***/ }),\n/* 532 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://github.com/ljharb/proposal-is-error\nvar $export = __webpack_require__(0);\nvar cof = __webpack_require__(28);\n\n$export($export.S, 'Error', {\n  isError: function isError(it) {\n    return cof(it) === 'Error';\n  }\n});\n\n\n/***/ }),\n/* 533 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://rwaldron.github.io/proposal-math-extensions/\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', {\n  clamp: function clamp(x, lower, upper) {\n    return Math.min(upper, Math.max(lower, x));\n  }\n});\n\n\n/***/ }),\n/* 534 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://rwaldron.github.io/proposal-math-extensions/\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', { DEG_PER_RAD: Math.PI / 180 });\n\n\n/***/ }),\n/* 535 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://rwaldron.github.io/proposal-math-extensions/\nvar $export = __webpack_require__(0);\nvar RAD_PER_DEG = 180 / Math.PI;\n\n$export($export.S, 'Math', {\n  degrees: function degrees(radians) {\n    return radians * RAD_PER_DEG;\n  }\n});\n\n\n/***/ }),\n/* 536 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://rwaldron.github.io/proposal-math-extensions/\nvar $export = __webpack_require__(0);\nvar scale = __webpack_require__(178);\nvar fround = __webpack_require__(158);\n\n$export($export.S, 'Math', {\n  fscale: function fscale(x, inLow, inHigh, outLow, outHigh) {\n    return fround(scale(x, inLow, inHigh, outLow, outHigh));\n  }\n});\n\n\n/***/ }),\n/* 537 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://gist.github.com/BrendanEich/4294d5c212a6d2254703\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', {\n  iaddh: function iaddh(x0, x1, y0, y1) {\n    var $x0 = x0 >>> 0;\n    var $x1 = x1 >>> 0;\n    var $y0 = y0 >>> 0;\n    return $x1 + (y1 >>> 0) + (($x0 & $y0 | ($x0 | $y0) & ~($x0 + $y0 >>> 0)) >>> 31) | 0;\n  }\n});\n\n\n/***/ }),\n/* 538 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://gist.github.com/BrendanEich/4294d5c212a6d2254703\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', {\n  isubh: function isubh(x0, x1, y0, y1) {\n    var $x0 = x0 >>> 0;\n    var $x1 = x1 >>> 0;\n    var $y0 = y0 >>> 0;\n    return $x1 - (y1 >>> 0) - ((~$x0 & $y0 | ~($x0 ^ $y0) & $x0 - $y0 >>> 0) >>> 31) | 0;\n  }\n});\n\n\n/***/ }),\n/* 539 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://gist.github.com/BrendanEich/4294d5c212a6d2254703\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', {\n  imulh: function imulh(u, v) {\n    var UINT16 = 0xffff;\n    var $u = +u;\n    var $v = +v;\n    var u0 = $u & UINT16;\n    var v0 = $v & UINT16;\n    var u1 = $u >> 16;\n    var v1 = $v >> 16;\n    var t = (u1 * v0 >>> 0) + (u0 * v0 >>> 16);\n    return u1 * v1 + (t >> 16) + ((u0 * v1 >>> 0) + (t & UINT16) >> 16);\n  }\n});\n\n\n/***/ }),\n/* 540 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://rwaldron.github.io/proposal-math-extensions/\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', { RAD_PER_DEG: 180 / Math.PI });\n\n\n/***/ }),\n/* 541 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://rwaldron.github.io/proposal-math-extensions/\nvar $export = __webpack_require__(0);\nvar DEG_PER_RAD = Math.PI / 180;\n\n$export($export.S, 'Math', {\n  radians: function radians(degrees) {\n    return degrees * DEG_PER_RAD;\n  }\n});\n\n\n/***/ }),\n/* 542 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://rwaldron.github.io/proposal-math-extensions/\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', { scale: __webpack_require__(178) });\n\n\n/***/ }),\n/* 543 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://gist.github.com/BrendanEich/4294d5c212a6d2254703\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', {\n  umulh: function umulh(u, v) {\n    var UINT16 = 0xffff;\n    var $u = +u;\n    var $v = +v;\n    var u0 = $u & UINT16;\n    var v0 = $v & UINT16;\n    var u1 = $u >>> 16;\n    var v1 = $v >>> 16;\n    var t = (u1 * v0 >>> 0) + (u0 * v0 >>> 16);\n    return u1 * v1 + (t >>> 16) + ((u0 * v1 >>> 0) + (t & UINT16) >>> 16);\n  }\n});\n\n\n/***/ }),\n/* 544 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// http://jfbastien.github.io/papers/Math.signbit.html\nvar $export = __webpack_require__(0);\n\n$export($export.S, 'Math', { signbit: function signbit(x) {\n  // eslint-disable-next-line no-self-compare\n  return (x = +x) != x ? x : x == 0 ? 1 / x == Infinity : x > 0;\n} });\n\n\n/***/ }),\n/* 545 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// https://github.com/tc39/proposal-promise-finally\n\nvar $export = __webpack_require__(0);\nvar core = __webpack_require__(26);\nvar global = __webpack_require__(3);\nvar speciesConstructor = __webpack_require__(78);\nvar promiseResolve = __webpack_require__(165);\n\n$export($export.P + $export.R, 'Promise', { 'finally': function (onFinally) {\n  var C = speciesConstructor(this, core.Promise || global.Promise);\n  var isFunction = typeof onFinally == 'function';\n  return this.then(\n    isFunction ? function (x) {\n      return promiseResolve(C, onFinally()).then(function () { return x; });\n    } : onFinally,\n    isFunction ? function (e) {\n      return promiseResolve(C, onFinally()).then(function () { throw e; });\n    } : onFinally\n  );\n} });\n\n\n/***/ }),\n/* 546 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://github.com/tc39/proposal-promise-try\nvar $export = __webpack_require__(0);\nvar newPromiseCapability = __webpack_require__(115);\nvar perform = __webpack_require__(164);\n\n$export($export.S, 'Promise', { 'try': function (callbackfn) {\n  var promiseCapability = newPromiseCapability.f(this);\n  var result = perform(callbackfn);\n  (result.e ? promiseCapability.reject : promiseCapability.resolve)(result.v);\n  return promiseCapability.promise;\n} });\n\n\n/***/ }),\n/* 547 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar metadata = __webpack_require__(37);\nvar anObject = __webpack_require__(2);\nvar toMetaKey = metadata.key;\nvar ordinaryDefineOwnMetadata = metadata.set;\n\nmetadata.exp({ defineMetadata: function defineMetadata(metadataKey, metadataValue, target, targetKey) {\n  ordinaryDefineOwnMetadata(metadataKey, metadataValue, anObject(target), toMetaKey(targetKey));\n} });\n\n\n/***/ }),\n/* 548 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar metadata = __webpack_require__(37);\nvar anObject = __webpack_require__(2);\nvar toMetaKey = metadata.key;\nvar getOrCreateMetadataMap = metadata.map;\nvar store = metadata.store;\n\nmetadata.exp({ deleteMetadata: function deleteMetadata(metadataKey, target /* , targetKey */) {\n  var targetKey = arguments.length < 3 ? undefined : toMetaKey(arguments[2]);\n  var metadataMap = getOrCreateMetadataMap(anObject(target), targetKey, false);\n  if (metadataMap === undefined || !metadataMap['delete'](metadataKey)) return false;\n  if (metadataMap.size) return true;\n  var targetMetadata = store.get(target);\n  targetMetadata['delete'](targetKey);\n  return !!targetMetadata.size || store['delete'](target);\n} });\n\n\n/***/ }),\n/* 549 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar metadata = __webpack_require__(37);\nvar anObject = __webpack_require__(2);\nvar getPrototypeOf = __webpack_require__(22);\nvar ordinaryHasOwnMetadata = metadata.has;\nvar ordinaryGetOwnMetadata = metadata.get;\nvar toMetaKey = metadata.key;\n\nvar ordinaryGetMetadata = function (MetadataKey, O, P) {\n  var hasOwn = ordinaryHasOwnMetadata(MetadataKey, O, P);\n  if (hasOwn) return ordinaryGetOwnMetadata(MetadataKey, O, P);\n  var parent = getPrototypeOf(O);\n  return parent !== null ? ordinaryGetMetadata(MetadataKey, parent, P) : undefined;\n};\n\nmetadata.exp({ getMetadata: function getMetadata(metadataKey, target /* , targetKey */) {\n  return ordinaryGetMetadata(metadataKey, anObject(target), arguments.length < 3 ? undefined : toMetaKey(arguments[2]));\n} });\n\n\n/***/ }),\n/* 550 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar Set = __webpack_require__(168);\nvar from = __webpack_require__(177);\nvar metadata = __webpack_require__(37);\nvar anObject = __webpack_require__(2);\nvar getPrototypeOf = __webpack_require__(22);\nvar ordinaryOwnMetadataKeys = metadata.keys;\nvar toMetaKey = metadata.key;\n\nvar ordinaryMetadataKeys = function (O, P) {\n  var oKeys = ordinaryOwnMetadataKeys(O, P);\n  var parent = getPrototypeOf(O);\n  if (parent === null) return oKeys;\n  var pKeys = ordinaryMetadataKeys(parent, P);\n  return pKeys.length ? oKeys.length ? from(new Set(oKeys.concat(pKeys))) : pKeys : oKeys;\n};\n\nmetadata.exp({ getMetadataKeys: function getMetadataKeys(target /* , targetKey */) {\n  return ordinaryMetadataKeys(anObject(target), arguments.length < 2 ? undefined : toMetaKey(arguments[1]));\n} });\n\n\n/***/ }),\n/* 551 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar metadata = __webpack_require__(37);\nvar anObject = __webpack_require__(2);\nvar ordinaryGetOwnMetadata = metadata.get;\nvar toMetaKey = metadata.key;\n\nmetadata.exp({ getOwnMetadata: function getOwnMetadata(metadataKey, target /* , targetKey */) {\n  return ordinaryGetOwnMetadata(metadataKey, anObject(target)\n    , arguments.length < 3 ? undefined : toMetaKey(arguments[2]));\n} });\n\n\n/***/ }),\n/* 552 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar metadata = __webpack_require__(37);\nvar anObject = __webpack_require__(2);\nvar ordinaryOwnMetadataKeys = metadata.keys;\nvar toMetaKey = metadata.key;\n\nmetadata.exp({ getOwnMetadataKeys: function getOwnMetadataKeys(target /* , targetKey */) {\n  return ordinaryOwnMetadataKeys(anObject(target), arguments.length < 2 ? undefined : toMetaKey(arguments[1]));\n} });\n\n\n/***/ }),\n/* 553 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar metadata = __webpack_require__(37);\nvar anObject = __webpack_require__(2);\nvar getPrototypeOf = __webpack_require__(22);\nvar ordinaryHasOwnMetadata = metadata.has;\nvar toMetaKey = metadata.key;\n\nvar ordinaryHasMetadata = function (MetadataKey, O, P) {\n  var hasOwn = ordinaryHasOwnMetadata(MetadataKey, O, P);\n  if (hasOwn) return true;\n  var parent = getPrototypeOf(O);\n  return parent !== null ? ordinaryHasMetadata(MetadataKey, parent, P) : false;\n};\n\nmetadata.exp({ hasMetadata: function hasMetadata(metadataKey, target /* , targetKey */) {\n  return ordinaryHasMetadata(metadataKey, anObject(target), arguments.length < 3 ? undefined : toMetaKey(arguments[2]));\n} });\n\n\n/***/ }),\n/* 554 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar metadata = __webpack_require__(37);\nvar anObject = __webpack_require__(2);\nvar ordinaryHasOwnMetadata = metadata.has;\nvar toMetaKey = metadata.key;\n\nmetadata.exp({ hasOwnMetadata: function hasOwnMetadata(metadataKey, target /* , targetKey */) {\n  return ordinaryHasOwnMetadata(metadataKey, anObject(target)\n    , arguments.length < 3 ? undefined : toMetaKey(arguments[2]));\n} });\n\n\n/***/ }),\n/* 555 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $metadata = __webpack_require__(37);\nvar anObject = __webpack_require__(2);\nvar aFunction = __webpack_require__(15);\nvar toMetaKey = $metadata.key;\nvar ordinaryDefineOwnMetadata = $metadata.set;\n\n$metadata.exp({ metadata: function metadata(metadataKey, metadataValue) {\n  return function decorator(target, targetKey) {\n    ordinaryDefineOwnMetadata(\n      metadataKey, metadataValue,\n      (targetKey !== undefined ? anObject : aFunction)(target),\n      toMetaKey(targetKey)\n    );\n  };\n} });\n\n\n/***/ }),\n/* 556 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://github.com/rwaldron/tc39-notes/blob/master/es6/2014-09/sept-25.md#510-globalasap-for-enqueuing-a-microtask\nvar $export = __webpack_require__(0);\nvar microtask = __webpack_require__(114)();\nvar process = __webpack_require__(3).process;\nvar isNode = __webpack_require__(28)(process) == 'process';\n\n$export($export.G, {\n  asap: function asap(fn) {\n    var domain = isNode && process.domain;\n    microtask(domain ? domain.bind(fn) : fn);\n  }\n});\n\n\n/***/ }),\n/* 557 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n// https://github.com/zenparsing/es-observable\nvar $export = __webpack_require__(0);\nvar global = __webpack_require__(3);\nvar core = __webpack_require__(26);\nvar microtask = __webpack_require__(114)();\nvar OBSERVABLE = __webpack_require__(7)('observable');\nvar aFunction = __webpack_require__(15);\nvar anObject = __webpack_require__(2);\nvar anInstance = __webpack_require__(50);\nvar redefineAll = __webpack_require__(52);\nvar hide = __webpack_require__(16);\nvar forOf = __webpack_require__(51);\nvar RETURN = forOf.RETURN;\n\nvar getMethod = function (fn) {\n  return fn == null ? undefined : aFunction(fn);\n};\n\nvar cleanupSubscription = function (subscription) {\n  var cleanup = subscription._c;\n  if (cleanup) {\n    subscription._c = undefined;\n    cleanup();\n  }\n};\n\nvar subscriptionClosed = function (subscription) {\n  return subscription._o === undefined;\n};\n\nvar closeSubscription = function (subscription) {\n  if (!subscriptionClosed(subscription)) {\n    subscription._o = undefined;\n    cleanupSubscription(subscription);\n  }\n};\n\nvar Subscription = function (observer, subscriber) {\n  anObject(observer);\n  this._c = undefined;\n  this._o = observer;\n  observer = new SubscriptionObserver(this);\n  try {\n    var cleanup = subscriber(observer);\n    var subscription = cleanup;\n    if (cleanup != null) {\n      if (typeof cleanup.unsubscribe === 'function') cleanup = function () { subscription.unsubscribe(); };\n      else aFunction(cleanup);\n      this._c = cleanup;\n    }\n  } catch (e) {\n    observer.error(e);\n    return;\n  } if (subscriptionClosed(this)) cleanupSubscription(this);\n};\n\nSubscription.prototype = redefineAll({}, {\n  unsubscribe: function unsubscribe() { closeSubscription(this); }\n});\n\nvar SubscriptionObserver = function (subscription) {\n  this._s = subscription;\n};\n\nSubscriptionObserver.prototype = redefineAll({}, {\n  next: function next(value) {\n    var subscription = this._s;\n    if (!subscriptionClosed(subscription)) {\n      var observer = subscription._o;\n      try {\n        var m = getMethod(observer.next);\n        if (m) return m.call(observer, value);\n      } catch (e) {\n        try {\n          closeSubscription(subscription);\n        } finally {\n          throw e;\n        }\n      }\n    }\n  },\n  error: function error(value) {\n    var subscription = this._s;\n    if (subscriptionClosed(subscription)) throw value;\n    var observer = subscription._o;\n    subscription._o = undefined;\n    try {\n      var m = getMethod(observer.error);\n      if (!m) throw value;\n      value = m.call(observer, value);\n    } catch (e) {\n      try {\n        cleanupSubscription(subscription);\n      } finally {\n        throw e;\n      }\n    } cleanupSubscription(subscription);\n    return value;\n  },\n  complete: function complete(value) {\n    var subscription = this._s;\n    if (!subscriptionClosed(subscription)) {\n      var observer = subscription._o;\n      subscription._o = undefined;\n      try {\n        var m = getMethod(observer.complete);\n        value = m ? m.call(observer, value) : undefined;\n      } catch (e) {\n        try {\n          cleanupSubscription(subscription);\n        } finally {\n          throw e;\n        }\n      } cleanupSubscription(subscription);\n      return value;\n    }\n  }\n});\n\nvar $Observable = function Observable(subscriber) {\n  anInstance(this, $Observable, 'Observable', '_f')._f = aFunction(subscriber);\n};\n\nredefineAll($Observable.prototype, {\n  subscribe: function subscribe(observer) {\n    return new Subscription(observer, this._f);\n  },\n  forEach: function forEach(fn) {\n    var that = this;\n    return new (core.Promise || global.Promise)(function (resolve, reject) {\n      aFunction(fn);\n      var subscription = that.subscribe({\n        next: function (value) {\n          try {\n            return fn(value);\n          } catch (e) {\n            reject(e);\n            subscription.unsubscribe();\n          }\n        },\n        error: reject,\n        complete: resolve\n      });\n    });\n  }\n});\n\nredefineAll($Observable, {\n  from: function from(x) {\n    var C = typeof this === 'function' ? this : $Observable;\n    var method = getMethod(anObject(x)[OBSERVABLE]);\n    if (method) {\n      var observable = anObject(method.call(x));\n      return observable.constructor === C ? observable : new C(function (observer) {\n        return observable.subscribe(observer);\n      });\n    }\n    return new C(function (observer) {\n      var done = false;\n      microtask(function () {\n        if (!done) {\n          try {\n            if (forOf(x, false, function (it) {\n              observer.next(it);\n              if (done) return RETURN;\n            }) === RETURN) return;\n          } catch (e) {\n            if (done) throw e;\n            observer.error(e);\n            return;\n          } observer.complete();\n        }\n      });\n      return function () { done = true; };\n    });\n  },\n  of: function of() {\n    for (var i = 0, l = arguments.length, items = new Array(l); i < l;) items[i] = arguments[i++];\n    return new (typeof this === 'function' ? this : $Observable)(function (observer) {\n      var done = false;\n      microtask(function () {\n        if (!done) {\n          for (var j = 0; j < items.length; ++j) {\n            observer.next(items[j]);\n            if (done) return;\n          } observer.complete();\n        }\n      });\n      return function () { done = true; };\n    });\n  }\n});\n\nhide($Observable.prototype, OBSERVABLE, function () { return this; });\n\n$export($export.G, { Observable: $Observable });\n\n__webpack_require__(49)('Observable');\n\n\n/***/ }),\n/* 558 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// ie9- setTimeout & setInterval additional parameters fix\nvar global = __webpack_require__(3);\nvar $export = __webpack_require__(0);\nvar userAgent = __webpack_require__(79);\nvar slice = [].slice;\nvar MSIE = /MSIE .\\./.test(userAgent); // <- dirty ie9- check\nvar wrap = function (set) {\n  return function (fn, time /* , ...args */) {\n    var boundArgs = arguments.length > 2;\n    var args = boundArgs ? slice.call(arguments, 2) : false;\n    return set(boundArgs ? function () {\n      // eslint-disable-next-line no-new-func\n      (typeof fn == 'function' ? fn : Function(fn)).apply(this, args);\n    } : fn, time);\n  };\n};\n$export($export.G + $export.B + $export.F * MSIE, {\n  setTimeout: wrap(global.setTimeout),\n  setInterval: wrap(global.setInterval)\n});\n\n\n/***/ }),\n/* 559 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $export = __webpack_require__(0);\nvar $task = __webpack_require__(113);\n$export($export.G + $export.B, {\n  setImmediate: $task.set,\n  clearImmediate: $task.clear\n});\n\n\n/***/ }),\n/* 560 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar $iterators = __webpack_require__(112);\nvar getKeys = __webpack_require__(45);\nvar redefine = __webpack_require__(17);\nvar global = __webpack_require__(3);\nvar hide = __webpack_require__(16);\nvar Iterators = __webpack_require__(58);\nvar wks = __webpack_require__(7);\nvar ITERATOR = wks('iterator');\nvar TO_STRING_TAG = wks('toStringTag');\nvar ArrayValues = Iterators.Array;\n\nvar DOMIterables = {\n  CSSRuleList: true, // TODO: Not spec compliant, should be false.\n  CSSStyleDeclaration: false,\n  CSSValueList: false,\n  ClientRectList: false,\n  DOMRectList: false,\n  DOMStringList: false,\n  DOMTokenList: true,\n  DataTransferItemList: false,\n  FileList: false,\n  HTMLAllCollection: false,\n  HTMLCollection: false,\n  HTMLFormElement: false,\n  HTMLSelectElement: false,\n  MediaList: true, // TODO: Not spec compliant, should be false.\n  MimeTypeArray: false,\n  NamedNodeMap: false,\n  NodeList: true,\n  PaintRequestList: false,\n  Plugin: false,\n  PluginArray: false,\n  SVGLengthList: false,\n  SVGNumberList: false,\n  SVGPathSegList: false,\n  SVGPointList: false,\n  SVGStringList: false,\n  SVGTransformList: false,\n  SourceBufferList: false,\n  StyleSheetList: true, // TODO: Not spec compliant, should be false.\n  TextTrackCueList: false,\n  TextTrackList: false,\n  TouchList: false\n};\n\nfor (var collections = getKeys(DOMIterables), i = 0; i < collections.length; i++) {\n  var NAME = collections[i];\n  var explicit = DOMIterables[NAME];\n  var Collection = global[NAME];\n  var proto = Collection && Collection.prototype;\n  var key;\n  if (proto) {\n    if (!proto[ITERATOR]) hide(proto, ITERATOR, ArrayValues);\n    if (!proto[TO_STRING_TAG]) hide(proto, TO_STRING_TAG, NAME);\n    Iterators[NAME] = ArrayValues;\n    if (explicit) for (key in $iterators) if (!proto[key]) redefine(proto, key, $iterators[key], true);\n  }\n}\n\n\n/***/ }),\n/* 561 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(global) {/**\n * Copyright (c) 2014, Facebook, Inc.\n * All rights reserved.\n *\n * This source code is licensed under the BSD-style license found in the\n * https://raw.github.com/facebook/regenerator/master/LICENSE file. An\n * additional grant of patent rights can be found in the PATENTS file in\n * the same directory.\n */\n\n!(function(global) {\n  \"use strict\";\n\n  var Op = Object.prototype;\n  var hasOwn = Op.hasOwnProperty;\n  var undefined; // More compressible than void 0.\n  var $Symbol = typeof Symbol === \"function\" ? Symbol : {};\n  var iteratorSymbol = $Symbol.iterator || \"@@iterator\";\n  var asyncIteratorSymbol = $Symbol.asyncIterator || \"@@asyncIterator\";\n  var toStringTagSymbol = $Symbol.toStringTag || \"@@toStringTag\";\n\n  var inModule = typeof module === \"object\";\n  var runtime = global.regeneratorRuntime;\n  if (runtime) {\n    if (inModule) {\n      // If regeneratorRuntime is defined globally and we're in a module,\n      // make the exports object identical to regeneratorRuntime.\n      module.exports = runtime;\n    }\n    // Don't bother evaluating the rest of this file if the runtime was\n    // already defined globally.\n    return;\n  }\n\n  // Define the runtime globally (as expected by generated code) as either\n  // module.exports (if we're in a module) or a new, empty object.\n  runtime = global.regeneratorRuntime = inModule ? module.exports : {};\n\n  function wrap(innerFn, outerFn, self, tryLocsList) {\n    // If outerFn provided and outerFn.prototype is a Generator, then outerFn.prototype instanceof Generator.\n    var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator;\n    var generator = Object.create(protoGenerator.prototype);\n    var context = new Context(tryLocsList || []);\n\n    // The ._invoke method unifies the implementations of the .next,\n    // .throw, and .return methods.\n    generator._invoke = makeInvokeMethod(innerFn, self, context);\n\n    return generator;\n  }\n  runtime.wrap = wrap;\n\n  // Try/catch helper to minimize deoptimizations. Returns a completion\n  // record like context.tryEntries[i].completion. This interface could\n  // have been (and was previously) designed to take a closure to be\n  // invoked without arguments, but in all the cases we care about we\n  // already have an existing method we want to call, so there's no need\n  // to create a new function object. We can even get away with assuming\n  // the method takes exactly one argument, since that happens to be true\n  // in every case, so we don't have to touch the arguments object. The\n  // only additional allocation required is the completion record, which\n  // has a stable shape and so hopefully should be cheap to allocate.\n  function tryCatch(fn, obj, arg) {\n    try {\n      return { type: \"normal\", arg: fn.call(obj, arg) };\n    } catch (err) {\n      return { type: \"throw\", arg: err };\n    }\n  }\n\n  var GenStateSuspendedStart = \"suspendedStart\";\n  var GenStateSuspendedYield = \"suspendedYield\";\n  var GenStateExecuting = \"executing\";\n  var GenStateCompleted = \"completed\";\n\n  // Returning this object from the innerFn has the same effect as\n  // breaking out of the dispatch switch statement.\n  var ContinueSentinel = {};\n\n  // Dummy constructor functions that we use as the .constructor and\n  // .constructor.prototype properties for functions that return Generator\n  // objects. For full spec compliance, you may wish to configure your\n  // minifier not to mangle the names of these two functions.\n  function Generator() {}\n  function GeneratorFunction() {}\n  function GeneratorFunctionPrototype() {}\n\n  // This is a polyfill for %IteratorPrototype% for environments that\n  // don't natively support it.\n  var IteratorPrototype = {};\n  IteratorPrototype[iteratorSymbol] = function () {\n    return this;\n  };\n\n  var getProto = Object.getPrototypeOf;\n  var NativeIteratorPrototype = getProto && getProto(getProto(values([])));\n  if (NativeIteratorPrototype &&\n      NativeIteratorPrototype !== Op &&\n      hasOwn.call(NativeIteratorPrototype, iteratorSymbol)) {\n    // This environment has a native %IteratorPrototype%; use it instead\n    // of the polyfill.\n    IteratorPrototype = NativeIteratorPrototype;\n  }\n\n  var Gp = GeneratorFunctionPrototype.prototype =\n    Generator.prototype = Object.create(IteratorPrototype);\n  GeneratorFunction.prototype = Gp.constructor = GeneratorFunctionPrototype;\n  GeneratorFunctionPrototype.constructor = GeneratorFunction;\n  GeneratorFunctionPrototype[toStringTagSymbol] =\n    GeneratorFunction.displayName = \"GeneratorFunction\";\n\n  // Helper for defining the .next, .throw, and .return methods of the\n  // Iterator interface in terms of a single ._invoke method.\n  function defineIteratorMethods(prototype) {\n    [\"next\", \"throw\", \"return\"].forEach(function(method) {\n      prototype[method] = function(arg) {\n        return this._invoke(method, arg);\n      };\n    });\n  }\n\n  runtime.isGeneratorFunction = function(genFun) {\n    var ctor = typeof genFun === \"function\" && genFun.constructor;\n    return ctor\n      ? ctor === GeneratorFunction ||\n        // For the native GeneratorFunction constructor, the best we can\n        // do is to check its .name property.\n        (ctor.displayName || ctor.name) === \"GeneratorFunction\"\n      : false;\n  };\n\n  runtime.mark = function(genFun) {\n    if (Object.setPrototypeOf) {\n      Object.setPrototypeOf(genFun, GeneratorFunctionPrototype);\n    } else {\n      genFun.__proto__ = GeneratorFunctionPrototype;\n      if (!(toStringTagSymbol in genFun)) {\n        genFun[toStringTagSymbol] = \"GeneratorFunction\";\n      }\n    }\n    genFun.prototype = Object.create(Gp);\n    return genFun;\n  };\n\n  // Within the body of any async function, `await x` is transformed to\n  // `yield regeneratorRuntime.awrap(x)`, so that the runtime can test\n  // `hasOwn.call(value, \"__await\")` to determine if the yielded value is\n  // meant to be awaited.\n  runtime.awrap = function(arg) {\n    return { __await: arg };\n  };\n\n  function AsyncIterator(generator) {\n    function invoke(method, arg, resolve, reject) {\n      var record = tryCatch(generator[method], generator, arg);\n      if (record.type === \"throw\") {\n        reject(record.arg);\n      } else {\n        var result = record.arg;\n        var value = result.value;\n        if (value &&\n            typeof value === \"object\" &&\n            hasOwn.call(value, \"__await\")) {\n          return Promise.resolve(value.__await).then(function(value) {\n            invoke(\"next\", value, resolve, reject);\n          }, function(err) {\n            invoke(\"throw\", err, resolve, reject);\n          });\n        }\n\n        return Promise.resolve(value).then(function(unwrapped) {\n          // When a yielded Promise is resolved, its final value becomes\n          // the .value of the Promise<{value,done}> result for the\n          // current iteration. If the Promise is rejected, however, the\n          // result for this iteration will be rejected with the same\n          // reason. Note that rejections of yielded Promises are not\n          // thrown back into the generator function, as is the case\n          // when an awaited Promise is rejected. This difference in\n          // behavior between yield and await is important, because it\n          // allows the consumer to decide what to do with the yielded\n          // rejection (swallow it and continue, manually .throw it back\n          // into the generator, abandon iteration, whatever). With\n          // await, by contrast, there is no opportunity to examine the\n          // rejection reason outside the generator function, so the\n          // only option is to throw it from the await expression, and\n          // let the generator function handle the exception.\n          result.value = unwrapped;\n          resolve(result);\n        }, reject);\n      }\n    }\n\n    if (typeof global.process === \"object\" && global.process.domain) {\n      invoke = global.process.domain.bind(invoke);\n    }\n\n    var previousPromise;\n\n    function enqueue(method, arg) {\n      function callInvokeWithMethodAndArg() {\n        return new Promise(function(resolve, reject) {\n          invoke(method, arg, resolve, reject);\n        });\n      }\n\n      return previousPromise =\n        // If enqueue has been called before, then we want to wait until\n        // all previous Promises have been resolved before calling invoke,\n        // so that results are always delivered in the correct order. If\n        // enqueue has not been called before, then it is important to\n        // call invoke immediately, without waiting on a callback to fire,\n        // so that the async generator function has the opportunity to do\n        // any necessary setup in a predictable way. This predictability\n        // is why the Promise constructor synchronously invokes its\n        // executor callback, and why async functions synchronously\n        // execute code before the first await. Since we implement simple\n        // async functions in terms of async generators, it is especially\n        // important to get this right, even though it requires care.\n        previousPromise ? previousPromise.then(\n          callInvokeWithMethodAndArg,\n          // Avoid propagating failures to Promises returned by later\n          // invocations of the iterator.\n          callInvokeWithMethodAndArg\n        ) : callInvokeWithMethodAndArg();\n    }\n\n    // Define the unified helper method that is used to implement .next,\n    // .throw, and .return (see defineIteratorMethods).\n    this._invoke = enqueue;\n  }\n\n  defineIteratorMethods(AsyncIterator.prototype);\n  AsyncIterator.prototype[asyncIteratorSymbol] = function () {\n    return this;\n  };\n  runtime.AsyncIterator = AsyncIterator;\n\n  // Note that simple async functions are implemented on top of\n  // AsyncIterator objects; they just return a Promise for the value of\n  // the final result produced by the iterator.\n  runtime.async = function(innerFn, outerFn, self, tryLocsList) {\n    var iter = new AsyncIterator(\n      wrap(innerFn, outerFn, self, tryLocsList)\n    );\n\n    return runtime.isGeneratorFunction(outerFn)\n      ? iter // If outerFn is a generator, return the full iterator.\n      : iter.next().then(function(result) {\n          return result.done ? result.value : iter.next();\n        });\n  };\n\n  function makeInvokeMethod(innerFn, self, context) {\n    var state = GenStateSuspendedStart;\n\n    return function invoke(method, arg) {\n      if (state === GenStateExecuting) {\n        throw new Error(\"Generator is already running\");\n      }\n\n      if (state === GenStateCompleted) {\n        if (method === \"throw\") {\n          throw arg;\n        }\n\n        // Be forgiving, per 25.3.3.3.3 of the spec:\n        // https://people.mozilla.org/~jorendorff/es6-draft.html#sec-generatorresume\n        return doneResult();\n      }\n\n      context.method = method;\n      context.arg = arg;\n\n      while (true) {\n        var delegate = context.delegate;\n        if (delegate) {\n          var delegateResult = maybeInvokeDelegate(delegate, context);\n          if (delegateResult) {\n            if (delegateResult === ContinueSentinel) continue;\n            return delegateResult;\n          }\n        }\n\n        if (context.method === \"next\") {\n          // Setting context._sent for legacy support of Babel's\n          // function.sent implementation.\n          context.sent = context._sent = context.arg;\n\n        } else if (context.method === \"throw\") {\n          if (state === GenStateSuspendedStart) {\n            state = GenStateCompleted;\n            throw context.arg;\n          }\n\n          context.dispatchException(context.arg);\n\n        } else if (context.method === \"return\") {\n          context.abrupt(\"return\", context.arg);\n        }\n\n        state = GenStateExecuting;\n\n        var record = tryCatch(innerFn, self, context);\n        if (record.type === \"normal\") {\n          // If an exception is thrown from innerFn, we leave state ===\n          // GenStateExecuting and loop back for another invocation.\n          state = context.done\n            ? GenStateCompleted\n            : GenStateSuspendedYield;\n\n          if (record.arg === ContinueSentinel) {\n            continue;\n          }\n\n          return {\n            value: record.arg,\n            done: context.done\n          };\n\n        } else if (record.type === \"throw\") {\n          state = GenStateCompleted;\n          // Dispatch the exception by looping back around to the\n          // context.dispatchException(context.arg) call above.\n          context.method = \"throw\";\n          context.arg = record.arg;\n        }\n      }\n    };\n  }\n\n  // Call delegate.iterator[context.method](context.arg) and handle the\n  // result, either by returning a { value, done } result from the\n  // delegate iterator, or by modifying context.method and context.arg,\n  // setting context.delegate to null, and returning the ContinueSentinel.\n  function maybeInvokeDelegate(delegate, context) {\n    var method = delegate.iterator[context.method];\n    if (method === undefined) {\n      // A .throw or .return when the delegate iterator has no .throw\n      // method always terminates the yield* loop.\n      context.delegate = null;\n\n      if (context.method === \"throw\") {\n        if (delegate.iterator.return) {\n          // If the delegate iterator has a return method, give it a\n          // chance to clean up.\n          context.method = \"return\";\n          context.arg = undefined;\n          maybeInvokeDelegate(delegate, context);\n\n          if (context.method === \"throw\") {\n            // If maybeInvokeDelegate(context) changed context.method from\n            // \"return\" to \"throw\", let that override the TypeError below.\n            return ContinueSentinel;\n          }\n        }\n\n        context.method = \"throw\";\n        context.arg = new TypeError(\n          \"The iterator does not provide a 'throw' method\");\n      }\n\n      return ContinueSentinel;\n    }\n\n    var record = tryCatch(method, delegate.iterator, context.arg);\n\n    if (record.type === \"throw\") {\n      context.method = \"throw\";\n      context.arg = record.arg;\n      context.delegate = null;\n      return ContinueSentinel;\n    }\n\n    var info = record.arg;\n\n    if (! info) {\n      context.method = \"throw\";\n      context.arg = new TypeError(\"iterator result is not an object\");\n      context.delegate = null;\n      return ContinueSentinel;\n    }\n\n    if (info.done) {\n      // Assign the result of the finished delegate to the temporary\n      // variable specified by delegate.resultName (see delegateYield).\n      context[delegate.resultName] = info.value;\n\n      // Resume execution at the desired location (see delegateYield).\n      context.next = delegate.nextLoc;\n\n      // If context.method was \"throw\" but the delegate handled the\n      // exception, let the outer generator proceed normally. If\n      // context.method was \"next\", forget context.arg since it has been\n      // \"consumed\" by the delegate iterator. If context.method was\n      // \"return\", allow the original .return call to continue in the\n      // outer generator.\n      if (context.method !== \"return\") {\n        context.method = \"next\";\n        context.arg = undefined;\n      }\n\n    } else {\n      // Re-yield the result returned by the delegate method.\n      return info;\n    }\n\n    // The delegate iterator is finished, so forget it and continue with\n    // the outer generator.\n    context.delegate = null;\n    return ContinueSentinel;\n  }\n\n  // Define Generator.prototype.{next,throw,return} in terms of the\n  // unified ._invoke helper method.\n  defineIteratorMethods(Gp);\n\n  Gp[toStringTagSymbol] = \"Generator\";\n\n  // A Generator should always return itself as the iterator object when the\n  // @@iterator function is called on it. Some browsers' implementations of the\n  // iterator prototype chain incorrectly implement this, causing the Generator\n  // object to not be returned from this call. This ensures that doesn't happen.\n  // See https://github.com/facebook/regenerator/issues/274 for more details.\n  Gp[iteratorSymbol] = function() {\n    return this;\n  };\n\n  Gp.toString = function() {\n    return \"[object Generator]\";\n  };\n\n  function pushTryEntry(locs) {\n    var entry = { tryLoc: locs[0] };\n\n    if (1 in locs) {\n      entry.catchLoc = locs[1];\n    }\n\n    if (2 in locs) {\n      entry.finallyLoc = locs[2];\n      entry.afterLoc = locs[3];\n    }\n\n    this.tryEntries.push(entry);\n  }\n\n  function resetTryEntry(entry) {\n    var record = entry.completion || {};\n    record.type = \"normal\";\n    delete record.arg;\n    entry.completion = record;\n  }\n\n  function Context(tryLocsList) {\n    // The root entry object (effectively a try statement without a catch\n    // or a finally block) gives us a place to store values thrown from\n    // locations where there is no enclosing try statement.\n    this.tryEntries = [{ tryLoc: \"root\" }];\n    tryLocsList.forEach(pushTryEntry, this);\n    this.reset(true);\n  }\n\n  runtime.keys = function(object) {\n    var keys = [];\n    for (var key in object) {\n      keys.push(key);\n    }\n    keys.reverse();\n\n    // Rather than returning an object with a next method, we keep\n    // things simple and return the next function itself.\n    return function next() {\n      while (keys.length) {\n        var key = keys.pop();\n        if (key in object) {\n          next.value = key;\n          next.done = false;\n          return next;\n        }\n      }\n\n      // To avoid creating an additional object, we just hang the .value\n      // and .done properties off the next function object itself. This\n      // also ensures that the minifier will not anonymize the function.\n      next.done = true;\n      return next;\n    };\n  };\n\n  function values(iterable) {\n    if (iterable) {\n      var iteratorMethod = iterable[iteratorSymbol];\n      if (iteratorMethod) {\n        return iteratorMethod.call(iterable);\n      }\n\n      if (typeof iterable.next === \"function\") {\n        return iterable;\n      }\n\n      if (!isNaN(iterable.length)) {\n        var i = -1, next = function next() {\n          while (++i < iterable.length) {\n            if (hasOwn.call(iterable, i)) {\n              next.value = iterable[i];\n              next.done = false;\n              return next;\n            }\n          }\n\n          next.value = undefined;\n          next.done = true;\n\n          return next;\n        };\n\n        return next.next = next;\n      }\n    }\n\n    // Return an iterator with no values.\n    return { next: doneResult };\n  }\n  runtime.values = values;\n\n  function doneResult() {\n    return { value: undefined, done: true };\n  }\n\n  Context.prototype = {\n    constructor: Context,\n\n    reset: function(skipTempReset) {\n      this.prev = 0;\n      this.next = 0;\n      // Resetting context._sent for legacy support of Babel's\n      // function.sent implementation.\n      this.sent = this._sent = undefined;\n      this.done = false;\n      this.delegate = null;\n\n      this.method = \"next\";\n      this.arg = undefined;\n\n      this.tryEntries.forEach(resetTryEntry);\n\n      if (!skipTempReset) {\n        for (var name in this) {\n          // Not sure about the optimal order of these conditions:\n          if (name.charAt(0) === \"t\" &&\n              hasOwn.call(this, name) &&\n              !isNaN(+name.slice(1))) {\n            this[name] = undefined;\n          }\n        }\n      }\n    },\n\n    stop: function() {\n      this.done = true;\n\n      var rootEntry = this.tryEntries[0];\n      var rootRecord = rootEntry.completion;\n      if (rootRecord.type === \"throw\") {\n        throw rootRecord.arg;\n      }\n\n      return this.rval;\n    },\n\n    dispatchException: function(exception) {\n      if (this.done) {\n        throw exception;\n      }\n\n      var context = this;\n      function handle(loc, caught) {\n        record.type = \"throw\";\n        record.arg = exception;\n        context.next = loc;\n\n        if (caught) {\n          // If the dispatched exception was caught by a catch block,\n          // then let that catch block handle the exception normally.\n          context.method = \"next\";\n          context.arg = undefined;\n        }\n\n        return !! caught;\n      }\n\n      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n        var entry = this.tryEntries[i];\n        var record = entry.completion;\n\n        if (entry.tryLoc === \"root\") {\n          // Exception thrown outside of any try block that could handle\n          // it, so set the completion value of the entire function to\n          // throw the exception.\n          return handle(\"end\");\n        }\n\n        if (entry.tryLoc <= this.prev) {\n          var hasCatch = hasOwn.call(entry, \"catchLoc\");\n          var hasFinally = hasOwn.call(entry, \"finallyLoc\");\n\n          if (hasCatch && hasFinally) {\n            if (this.prev < entry.catchLoc) {\n              return handle(entry.catchLoc, true);\n            } else if (this.prev < entry.finallyLoc) {\n              return handle(entry.finallyLoc);\n            }\n\n          } else if (hasCatch) {\n            if (this.prev < entry.catchLoc) {\n              return handle(entry.catchLoc, true);\n            }\n\n          } else if (hasFinally) {\n            if (this.prev < entry.finallyLoc) {\n              return handle(entry.finallyLoc);\n            }\n\n          } else {\n            throw new Error(\"try statement without catch or finally\");\n          }\n        }\n      }\n    },\n\n    abrupt: function(type, arg) {\n      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n        var entry = this.tryEntries[i];\n        if (entry.tryLoc <= this.prev &&\n            hasOwn.call(entry, \"finallyLoc\") &&\n            this.prev < entry.finallyLoc) {\n          var finallyEntry = entry;\n          break;\n        }\n      }\n\n      if (finallyEntry &&\n          (type === \"break\" ||\n           type === \"continue\") &&\n          finallyEntry.tryLoc <= arg &&\n          arg <= finallyEntry.finallyLoc) {\n        // Ignore the finally entry if control is not jumping to a\n        // location outside the try/catch block.\n        finallyEntry = null;\n      }\n\n      var record = finallyEntry ? finallyEntry.completion : {};\n      record.type = type;\n      record.arg = arg;\n\n      if (finallyEntry) {\n        this.method = \"next\";\n        this.next = finallyEntry.finallyLoc;\n        return ContinueSentinel;\n      }\n\n      return this.complete(record);\n    },\n\n    complete: function(record, afterLoc) {\n      if (record.type === \"throw\") {\n        throw record.arg;\n      }\n\n      if (record.type === \"break\" ||\n          record.type === \"continue\") {\n        this.next = record.arg;\n      } else if (record.type === \"return\") {\n        this.rval = this.arg = record.arg;\n        this.method = \"return\";\n        this.next = \"end\";\n      } else if (record.type === \"normal\" && afterLoc) {\n        this.next = afterLoc;\n      }\n\n      return ContinueSentinel;\n    },\n\n    finish: function(finallyLoc) {\n      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n        var entry = this.tryEntries[i];\n        if (entry.finallyLoc === finallyLoc) {\n          this.complete(entry.completion, entry.afterLoc);\n          resetTryEntry(entry);\n          return ContinueSentinel;\n        }\n      }\n    },\n\n    \"catch\": function(tryLoc) {\n      for (var i = this.tryEntries.length - 1; i >= 0; --i) {\n        var entry = this.tryEntries[i];\n        if (entry.tryLoc === tryLoc) {\n          var record = entry.completion;\n          if (record.type === \"throw\") {\n            var thrown = record.arg;\n            resetTryEntry(entry);\n          }\n          return thrown;\n        }\n      }\n\n      // The context.catch method must only be called with a location\n      // argument that corresponds to a known catch block.\n      throw new Error(\"illegal catch attempt\");\n    },\n\n    delegateYield: function(iterable, resultName, nextLoc) {\n      this.delegate = {\n        iterator: values(iterable),\n        resultName: resultName,\n        nextLoc: nextLoc\n      };\n\n      if (this.method === \"next\") {\n        // Deliberately forget the last sent value so that we don't\n        // accidentally pass it on to the delegate.\n        this.arg = undefined;\n      }\n\n      return ContinueSentinel;\n    }\n  };\n})(\n  // Among the various tricks for obtaining a reference to the global\n  // object, this seems to be the most reliable technique that does not\n  // use indirect eval (which violates Content Security Policy).\n  typeof global === \"object\" ? global :\n  typeof window === \"object\" ? window :\n  typeof self === \"object\" ? self : this\n);\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12)))\n\n/***/ }),\n/* 562 */\n/***/ (function(module, exports, __webpack_require__) {\n\n__webpack_require__(563);\nmodule.exports = __webpack_require__(26).RegExp.escape;\n\n\n/***/ }),\n/* 563 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// https://github.com/benjamingr/RexExp.escape\nvar $export = __webpack_require__(0);\nvar $re = __webpack_require__(564)(/[\\\\^$*+?.()|[\\]{}]/g, '\\\\$&');\n\n$export($export.S, 'RegExp', { escape: function escape(it) { return $re(it); } });\n\n\n/***/ }),\n/* 564 */\n/***/ (function(module, exports) {\n\nmodule.exports = function (regExp, replace) {\n  var replacer = replace === Object(replace) ? function (part) {\n    return replace[part];\n  } : replace;\n  return function (it) {\n    return String(it).replace(regExp, replacer);\n  };\n};\n\n\n/***/ }),\n/* 565 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar v1 = __webpack_require__(566);\nvar v4 = __webpack_require__(567);\n\nvar uuid = v4;\nuuid.v1 = v1;\nuuid.v4 = v4;\n\nmodule.exports = uuid;\n\n\n/***/ }),\n/* 566 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar rng = __webpack_require__(181);\nvar bytesToUuid = __webpack_require__(182);\n\n// **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\n\nvar _nodeId;\nvar _clockseq;\n\n// Previous uuid creation time\nvar _lastMSecs = 0;\nvar _lastNSecs = 0;\n\n// See https://github.com/broofa/node-uuid for API details\nfunction v1(options, buf, offset) {\n  var i = buf && offset || 0;\n  var b = buf || [];\n\n  options = options || {};\n  var node = options.node || _nodeId;\n  var clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq;\n\n  // node and clockseq need to be initialized to random values if they're not\n  // specified.  We do this lazily to minimize issues related to insufficient\n  // system entropy.  See #189\n  if (node == null || clockseq == null) {\n    var seedBytes = rng();\n    if (node == null) {\n      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)\n      node = _nodeId = [\n        seedBytes[0] | 0x01,\n        seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]\n      ];\n    }\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n    }\n  }\n\n  // UUID timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so\n  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n  var msecs = options.msecs !== undefined ? options.msecs : new Date().getTime();\n\n  // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n  var nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1;\n\n  // Time since last uuid creation (in msecs)\n  var dt = (msecs - _lastMSecs) + (nsecs - _lastNSecs)/10000;\n\n  // Per 4.2.1.2, Bump clockseq on clock regression\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  }\n\n  // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  }\n\n  // Per 4.2.1.2 Throw error if too many uuids are requested\n  if (nsecs >= 10000) {\n    throw new Error('uuid.v1(): Can\\'t create more than 10M uuids/sec');\n  }\n\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq;\n\n  // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n  msecs += 12219292800000;\n\n  // `time_low`\n  var tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff;\n\n  // `time_mid`\n  var tmh = (msecs / 0x100000000 * 10000) & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff;\n\n  // `time_high_and_version`\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n  b[i++] = tmh >>> 16 & 0xff;\n\n  // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n  b[i++] = clockseq >>> 8 | 0x80;\n\n  // `clock_seq_low`\n  b[i++] = clockseq & 0xff;\n\n  // `node`\n  for (var n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n\n  return buf ? buf : bytesToUuid(b);\n}\n\nmodule.exports = v1;\n\n\n/***/ }),\n/* 567 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar rng = __webpack_require__(181);\nvar bytesToUuid = __webpack_require__(182);\n\nfunction v4(options, buf, offset) {\n  var i = buf && offset || 0;\n\n  if (typeof(options) == 'string') {\n    buf = options === 'binary' ? new Array(16) : null;\n    options = null;\n  }\n  options = options || {};\n\n  var rnds = options.random || (options.rng || rng)();\n\n  // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n  rnds[6] = (rnds[6] & 0x0f) | 0x40;\n  rnds[8] = (rnds[8] & 0x3f) | 0x80;\n\n  // Copy bytes to buffer, if provided\n  if (buf) {\n    for (var ii = 0; ii < 16; ++ii) {\n      buf[i + ii] = rnds[ii];\n    }\n  }\n\n  return buf || bytesToUuid(rnds);\n}\n\nmodule.exports = v4;\n\n\n/***/ }),\n/* 568 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process) {/**\n * This is the web browser implementation of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = __webpack_require__(569);\nexports.log = log;\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = 'undefined' != typeof chrome\n               && 'undefined' != typeof chrome.storage\n                  ? chrome.storage.local\n                  : localstorage();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n  '#0000CC', '#0000FF', '#0033CC', '#0033FF', '#0066CC', '#0066FF', '#0099CC',\n  '#0099FF', '#00CC00', '#00CC33', '#00CC66', '#00CC99', '#00CCCC', '#00CCFF',\n  '#3300CC', '#3300FF', '#3333CC', '#3333FF', '#3366CC', '#3366FF', '#3399CC',\n  '#3399FF', '#33CC00', '#33CC33', '#33CC66', '#33CC99', '#33CCCC', '#33CCFF',\n  '#6600CC', '#6600FF', '#6633CC', '#6633FF', '#66CC00', '#66CC33', '#9900CC',\n  '#9900FF', '#9933CC', '#9933FF', '#99CC00', '#99CC33', '#CC0000', '#CC0033',\n  '#CC0066', '#CC0099', '#CC00CC', '#CC00FF', '#CC3300', '#CC3333', '#CC3366',\n  '#CC3399', '#CC33CC', '#CC33FF', '#CC6600', '#CC6633', '#CC9900', '#CC9933',\n  '#CCCC00', '#CCCC33', '#FF0000', '#FF0033', '#FF0066', '#FF0099', '#FF00CC',\n  '#FF00FF', '#FF3300', '#FF3333', '#FF3366', '#FF3399', '#FF33CC', '#FF33FF',\n  '#FF6600', '#FF6633', '#FF9900', '#FF9933', '#FFCC00', '#FFCC33'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\nfunction useColors() {\n  // NB: In an Electron preload script, document will be defined but not fully\n  // initialized. Since we know we're in Chrome, we'll just detect this case\n  // explicitly\n  if (typeof window !== 'undefined' && window.process && window.process.type === 'renderer') {\n    return true;\n  }\n\n  // Internet Explorer and Edge do not support colors.\n  if (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\\/(\\d+)/)) {\n    return false;\n  }\n\n  // is webkit? http://stackoverflow.com/a/16459606/376773\n  // document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n  return (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n    // is firebug? http://stackoverflow.com/a/398120/376773\n    (typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n    // is firefox >= v31?\n    // https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n    (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n    // double check webkit in userAgent just in case we are in a worker\n    (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nexports.formatters.j = function(v) {\n  try {\n    return JSON.stringify(v);\n  } catch (err) {\n    return '[UnexpectedJSONParseError]: ' + err.message;\n  }\n};\n\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n  var useColors = this.useColors;\n\n  args[0] = (useColors ? '%c' : '')\n    + this.namespace\n    + (useColors ? ' %c' : ' ')\n    + args[0]\n    + (useColors ? '%c ' : ' ')\n    + '+' + exports.humanize(this.diff);\n\n  if (!useColors) return;\n\n  var c = 'color: ' + this.color;\n  args.splice(1, 0, c, 'color: inherit')\n\n  // the final \"%c\" is somewhat tricky, because there could be other\n  // arguments passed either before or after the %c, so we need to\n  // figure out the correct index to insert the CSS into\n  var index = 0;\n  var lastC = 0;\n  args[0].replace(/%[a-zA-Z%]/g, function(match) {\n    if ('%%' === match) return;\n    index++;\n    if ('%c' === match) {\n      // we only are interested in the *last* %c\n      // (the user may have provided their own)\n      lastC = index;\n    }\n  });\n\n  args.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.log()` when available.\n * No-op when `console.log` is not a \"function\".\n *\n * @api public\n */\n\nfunction log() {\n  // this hackery is required for IE8/9, where\n  // the `console.log` function doesn't have 'apply'\n  return 'object' === typeof console\n    && console.log\n    && Function.prototype.apply.call(console.log, console, arguments);\n}\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\n\nfunction save(namespaces) {\n  try {\n    if (null == namespaces) {\n      exports.storage.removeItem('debug');\n    } else {\n      exports.storage.debug = namespaces;\n    }\n  } catch(e) {}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\n\nfunction load() {\n  var r;\n  try {\n    r = exports.storage.debug;\n  } catch(e) {}\n\n  // If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n  if (!r && typeof process !== 'undefined' && 'env' in process) {\n    r = process.env.DEBUG;\n  }\n\n  return r;\n}\n\n/**\n * Enable namespaces listed in `localStorage.debug` initially.\n */\n\nexports.enable(load());\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n  try {\n    return window.localStorage;\n  } catch (e) {}\n}\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8)))\n\n/***/ }),\n/* 569 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = createDebug.debug = createDebug['default'] = createDebug;\nexports.coerce = coerce;\nexports.disable = disable;\nexports.enable = enable;\nexports.enabled = enabled;\nexports.humanize = __webpack_require__(570);\n\n/**\n * Active `debug` instances.\n */\nexports.instances = [];\n\n/**\n * The currently active debug mode names, and names to skip.\n */\n\nexports.names = [];\nexports.skips = [];\n\n/**\n * Map of special \"%n\" handling functions, for the debug \"format\" argument.\n *\n * Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n */\n\nexports.formatters = {};\n\n/**\n * Select a color.\n * @param {String} namespace\n * @return {Number}\n * @api private\n */\n\nfunction selectColor(namespace) {\n  var hash = 0, i;\n\n  for (i in namespace) {\n    hash  = ((hash << 5) - hash) + namespace.charCodeAt(i);\n    hash |= 0; // Convert to 32bit integer\n  }\n\n  return exports.colors[Math.abs(hash) % exports.colors.length];\n}\n\n/**\n * Create a debugger with the given `namespace`.\n *\n * @param {String} namespace\n * @return {Function}\n * @api public\n */\n\nfunction createDebug(namespace) {\n\n  var prevTime;\n\n  function debug() {\n    // disabled?\n    if (!debug.enabled) return;\n\n    var self = debug;\n\n    // set `diff` timestamp\n    var curr = +new Date();\n    var ms = curr - (prevTime || curr);\n    self.diff = ms;\n    self.prev = prevTime;\n    self.curr = curr;\n    prevTime = curr;\n\n    // turn the `arguments` into a proper Array\n    var args = new Array(arguments.length);\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i];\n    }\n\n    args[0] = exports.coerce(args[0]);\n\n    if ('string' !== typeof args[0]) {\n      // anything else let's inspect with %O\n      args.unshift('%O');\n    }\n\n    // apply any `formatters` transformations\n    var index = 0;\n    args[0] = args[0].replace(/%([a-zA-Z%])/g, function(match, format) {\n      // if we encounter an escaped % then don't increase the array index\n      if (match === '%%') return match;\n      index++;\n      var formatter = exports.formatters[format];\n      if ('function' === typeof formatter) {\n        var val = args[index];\n        match = formatter.call(self, val);\n\n        // now we need to remove `args[index]` since it's inlined in the `format`\n        args.splice(index, 1);\n        index--;\n      }\n      return match;\n    });\n\n    // apply env-specific formatting (colors, etc.)\n    exports.formatArgs.call(self, args);\n\n    var logFn = debug.log || exports.log || console.log.bind(console);\n    logFn.apply(self, args);\n  }\n\n  debug.namespace = namespace;\n  debug.enabled = exports.enabled(namespace);\n  debug.useColors = exports.useColors();\n  debug.color = selectColor(namespace);\n  debug.destroy = destroy;\n\n  // env-specific initialization logic for debug instances\n  if ('function' === typeof exports.init) {\n    exports.init(debug);\n  }\n\n  exports.instances.push(debug);\n\n  return debug;\n}\n\nfunction destroy () {\n  var index = exports.instances.indexOf(this);\n  if (index !== -1) {\n    exports.instances.splice(index, 1);\n    return true;\n  } else {\n    return false;\n  }\n}\n\n/**\n * Enables a debug mode by namespaces. This can include modes\n * separated by a colon and wildcards.\n *\n * @param {String} namespaces\n * @api public\n */\n\nfunction enable(namespaces) {\n  exports.save(namespaces);\n\n  exports.names = [];\n  exports.skips = [];\n\n  var i;\n  var split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n  var len = split.length;\n\n  for (i = 0; i < len; i++) {\n    if (!split[i]) continue; // ignore empty strings\n    namespaces = split[i].replace(/\\*/g, '.*?');\n    if (namespaces[0] === '-') {\n      exports.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));\n    } else {\n      exports.names.push(new RegExp('^' + namespaces + '$'));\n    }\n  }\n\n  for (i = 0; i < exports.instances.length; i++) {\n    var instance = exports.instances[i];\n    instance.enabled = exports.enabled(instance.namespace);\n  }\n}\n\n/**\n * Disable debug output.\n *\n * @api public\n */\n\nfunction disable() {\n  exports.enable('');\n}\n\n/**\n * Returns true if the given mode name is enabled, false otherwise.\n *\n * @param {String} name\n * @return {Boolean}\n * @api public\n */\n\nfunction enabled(name) {\n  if (name[name.length - 1] === '*') {\n    return true;\n  }\n  var i, len;\n  for (i = 0, len = exports.skips.length; i < len; i++) {\n    if (exports.skips[i].test(name)) {\n      return false;\n    }\n  }\n  for (i = 0, len = exports.names.length; i < len; i++) {\n    if (exports.names[i].test(name)) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Coerce `val`.\n *\n * @param {Mixed} val\n * @return {Mixed}\n * @api private\n */\n\nfunction coerce(val) {\n  if (val instanceof Error) return val.stack || val.message;\n  return val;\n}\n\n\n/***/ }),\n/* 570 */\n/***/ (function(module, exports) {\n\n/**\n * Helpers.\n */\n\nvar s = 1000;\nvar m = s * 60;\nvar h = m * 60;\nvar d = h * 24;\nvar y = d * 365.25;\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} [options]\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function(val, options) {\n  options = options || {};\n  var type = typeof val;\n  if (type === 'string' && val.length > 0) {\n    return parse(val);\n  } else if (type === 'number' && isNaN(val) === false) {\n    return options.long ? fmtLong(val) : fmtShort(val);\n  }\n  throw new Error(\n    'val is not a non-empty string or a valid number. val=' +\n      JSON.stringify(val)\n  );\n};\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str);\n  if (str.length > 100) {\n    return;\n  }\n  var match = /^((?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(\n    str\n  );\n  if (!match) {\n    return;\n  }\n  var n = parseFloat(match[1]);\n  var type = (match[2] || 'ms').toLowerCase();\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y;\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d;\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h;\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m;\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s;\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  if (ms >= d) {\n    return Math.round(ms / d) + 'd';\n  }\n  if (ms >= h) {\n    return Math.round(ms / h) + 'h';\n  }\n  if (ms >= m) {\n    return Math.round(ms / m) + 'm';\n  }\n  if (ms >= s) {\n    return Math.round(ms / s) + 's';\n  }\n  return ms + 'ms';\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  return plural(ms, d, 'day') ||\n    plural(ms, h, 'hour') ||\n    plural(ms, m, 'minute') ||\n    plural(ms, s, 'second') ||\n    ms + ' ms';\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, n, name) {\n  if (ms < n) {\n    return;\n  }\n  if (ms < n * 1.5) {\n    return Math.floor(ms / n) + ' ' + name;\n  }\n  return Math.ceil(ms / n) + ' ' + name + 's';\n}\n\n\n/***/ }),\n/* 571 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar v1 = __webpack_require__(572);\nvar v4 = __webpack_require__(573);\n\nvar uuid = v4;\nuuid.v1 = v1;\nuuid.v4 = v4;\n\nmodule.exports = uuid;\n\n\n/***/ }),\n/* 572 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar rng = __webpack_require__(186);\nvar bytesToUuid = __webpack_require__(187);\n\n// **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\n\nvar _nodeId;\nvar _clockseq;\n\n// Previous uuid creation time\nvar _lastMSecs = 0;\nvar _lastNSecs = 0;\n\n// See https://github.com/broofa/node-uuid for API details\nfunction v1(options, buf, offset) {\n  var i = buf && offset || 0;\n  var b = buf || [];\n\n  options = options || {};\n  var node = options.node || _nodeId;\n  var clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq;\n\n  // node and clockseq need to be initialized to random values if they're not\n  // specified.  We do this lazily to minimize issues related to insufficient\n  // system entropy.  See #189\n  if (node == null || clockseq == null) {\n    var seedBytes = rng();\n    if (node == null) {\n      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)\n      node = _nodeId = [\n        seedBytes[0] | 0x01,\n        seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]\n      ];\n    }\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n    }\n  }\n\n  // UUID timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so\n  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n  var msecs = options.msecs !== undefined ? options.msecs : new Date().getTime();\n\n  // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n  var nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1;\n\n  // Time since last uuid creation (in msecs)\n  var dt = (msecs - _lastMSecs) + (nsecs - _lastNSecs)/10000;\n\n  // Per 4.2.1.2, Bump clockseq on clock regression\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  }\n\n  // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  }\n\n  // Per 4.2.1.2 Throw error if too many uuids are requested\n  if (nsecs >= 10000) {\n    throw new Error('uuid.v1(): Can\\'t create more than 10M uuids/sec');\n  }\n\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq;\n\n  // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n  msecs += 12219292800000;\n\n  // `time_low`\n  var tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff;\n\n  // `time_mid`\n  var tmh = (msecs / 0x100000000 * 10000) & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff;\n\n  // `time_high_and_version`\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n  b[i++] = tmh >>> 16 & 0xff;\n\n  // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n  b[i++] = clockseq >>> 8 | 0x80;\n\n  // `clock_seq_low`\n  b[i++] = clockseq & 0xff;\n\n  // `node`\n  for (var n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n\n  return buf ? buf : bytesToUuid(b);\n}\n\nmodule.exports = v1;\n\n\n/***/ }),\n/* 573 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar rng = __webpack_require__(186);\nvar bytesToUuid = __webpack_require__(187);\n\nfunction v4(options, buf, offset) {\n  var i = buf && offset || 0;\n\n  if (typeof(options) == 'string') {\n    buf = options === 'binary' ? new Array(16) : null;\n    options = null;\n  }\n  options = options || {};\n\n  var rnds = options.random || (options.rng || rng)();\n\n  // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n  rnds[6] = (rnds[6] & 0x0f) | 0x40;\n  rnds[8] = (rnds[8] & 0x3f) | 0x80;\n\n  // Copy bytes to buffer, if provided\n  if (buf) {\n    for (var ii = 0; ii < 16; ++ii) {\n      buf[i + ii] = rnds[ii];\n    }\n  }\n\n  return buf || bytesToUuid(rnds);\n}\n\nmodule.exports = v4;\n\n\n/***/ }),\n/* 574 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_pouchdb_binary_utils__ = __webpack_require__(123);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_pouchdb_collections__ = __webpack_require__(121);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__ = __webpack_require__(119);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_3_pouchdb_promise__ = __webpack_require__(120);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_4_levelup__ = __webpack_require__(575);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_4_levelup___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_4_levelup__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_5_sublevel_pouchdb__ = __webpack_require__(597);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_6_through2__ = __webpack_require__(613);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_6_through2___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_6_through2__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_7_argsarray__ = __webpack_require__(118);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_7_argsarray___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_7_argsarray__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_8_double_ended_queue__ = __webpack_require__(621);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_8_double_ended_queue___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_8_double_ended_queue__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_9_buffer_from__ = __webpack_require__(622);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_9_buffer_from___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_9_buffer_from__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_10_pouchdb_adapter_utils__ = __webpack_require__(643);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_11_pouchdb_merge__ = __webpack_require__(222);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_12_pouchdb_json__ = __webpack_require__(644);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_13_pouchdb_md5__ = __webpack_require__(221);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__ = __webpack_require__(122);\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfunction readAsBlobOrBuffer(storedObject, type) {\n  // In the browser, we've stored a binary string. This now comes back as a\n  // browserified Node-style Buffer (implemented as a typed array),\n  // but we want a Blob instead.\n  var byteArray = new Uint8Array(storedObject);\n  return Object(__WEBPACK_IMPORTED_MODULE_0_pouchdb_binary_utils__[\"c\" /* blob */])([byteArray], {type: type});\n}\n\n// In the browser, we store a binary string\nfunction prepareAttachmentForStorage(attData, cb) {\n  Object(__WEBPACK_IMPORTED_MODULE_0_pouchdb_binary_utils__[\"h\" /* readAsBinaryString */])(attData, cb);\n}\n\nfunction createEmptyBlobOrBuffer(type) {\n  return Object(__WEBPACK_IMPORTED_MODULE_0_pouchdb_binary_utils__[\"c\" /* blob */])([''], {type: type});\n}\n\n// similar to an idb or websql transaction object\n// designed to be passed around. basically just caches\n// things in-memory and then does a big batch() operation\n// when you're done\n\nfunction getCacheFor(transaction, store) {\n  var prefix = store.prefix()[0];\n  var cache = transaction._cache;\n  var subCache = cache.get(prefix);\n  if (!subCache) {\n    subCache = new __WEBPACK_IMPORTED_MODULE_1_pouchdb_collections__[\"a\" /* Map */]();\n    cache.set(prefix, subCache);\n  }\n  return subCache;\n}\n\nfunction LevelTransaction() {\n  this._batch = [];\n  this._cache = new __WEBPACK_IMPORTED_MODULE_1_pouchdb_collections__[\"a\" /* Map */]();\n}\n\nLevelTransaction.prototype.get = function (store, key, callback) {\n  var cache = getCacheFor(this, store);\n  var exists = cache.get(key);\n  if (exists) {\n    return Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"g\" /* nextTick */])(function () {\n      callback(null, exists);\n    });\n  } else if (exists === null) { // deleted marker\n    /* istanbul ignore next */\n    return Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"g\" /* nextTick */])(function () {\n      callback({name: 'NotFoundError'});\n    });\n  }\n  store.get(key, function (err, res) {\n    if (err) {\n      /* istanbul ignore else */\n      if (err.name === 'NotFoundError') {\n        cache.set(key, null);\n      }\n      return callback(err);\n    }\n    cache.set(key, res);\n    callback(null, res);\n  });\n};\n\nLevelTransaction.prototype.batch = function (batch) {\n  for (var i = 0, len = batch.length; i < len; i++) {\n    var operation = batch[i];\n\n    var cache = getCacheFor(this, operation.prefix);\n\n    if (operation.type === 'put') {\n      cache.set(operation.key, operation.value);\n    } else {\n      cache.set(operation.key, null);\n    }\n  }\n  this._batch = this._batch.concat(batch);\n};\n\nLevelTransaction.prototype.execute = function (db, callback) {\n\n  var keys = new __WEBPACK_IMPORTED_MODULE_1_pouchdb_collections__[\"b\" /* Set */]();\n  var uniqBatches = [];\n\n  // remove duplicates; last one wins\n  for (var i = this._batch.length - 1; i >= 0; i--) {\n    var operation = this._batch[i];\n    var lookupKey = operation.prefix.prefix()[0] + '\\xff' + operation.key;\n    if (keys.has(lookupKey)) {\n      continue;\n    }\n    keys.add(lookupKey);\n    uniqBatches.push(operation);\n  }\n\n  db.batch(uniqBatches, callback);\n};\n\nvar DOC_STORE = 'document-store';\nvar BY_SEQ_STORE = 'by-sequence';\nvar ATTACHMENT_STORE = 'attach-store';\nvar BINARY_STORE = 'attach-binary-store';\nvar LOCAL_STORE = 'local-store';\nvar META_STORE = 'meta-store';\n\n// leveldb barks if we try to open a db multiple times\n// so we cache opened connections here for initstore()\nvar dbStores = new __WEBPACK_IMPORTED_MODULE_1_pouchdb_collections__[\"a\" /* Map */]();\n\n// store the value of update_seq in the by-sequence store the key name will\n// never conflict, since the keys in the by-sequence store are integers\nvar UPDATE_SEQ_KEY = '_local_last_update_seq';\nvar DOC_COUNT_KEY = '_local_doc_count';\nvar UUID_KEY = '_local_uuid';\n\nvar MD5_PREFIX = 'md5-';\n\nvar safeJsonEncoding = {\n  encode: __WEBPACK_IMPORTED_MODULE_12_pouchdb_json__[\"b\" /* safeJsonStringify */],\n  decode: __WEBPACK_IMPORTED_MODULE_12_pouchdb_json__[\"a\" /* safeJsonParse */],\n  buffer: false,\n  type: 'cheap-json'\n};\n\nvar levelChanges = new __WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"b\" /* changesHandler */]();\n\n// winningRev and deleted are performance-killers, but\n// in newer versions of PouchDB, they are cached on the metadata\nfunction getWinningRev(metadata) {\n  return 'winningRev' in metadata ?\n    metadata.winningRev : Object(__WEBPACK_IMPORTED_MODULE_11_pouchdb_merge__[\"i\" /* winningRev */])(metadata);\n}\n\nfunction getIsDeleted(metadata, winningRev$$1) {\n  return 'deleted' in metadata ?\n    metadata.deleted : Object(__WEBPACK_IMPORTED_MODULE_10_pouchdb_adapter_utils__[\"b\" /* isDeleted */])(metadata, winningRev$$1);\n}\n\nfunction fetchAttachment(att, stores, opts) {\n  var type = att.content_type;\n  return new __WEBPACK_IMPORTED_MODULE_3_pouchdb_promise__[\"a\" /* default */](function (resolve, reject) {\n    stores.binaryStore.get(att.digest, function (err, buffer) {\n      var data;\n      if (err) {\n        /* istanbul ignore if */\n        if (err.name !== 'NotFoundError') {\n          return reject(err);\n        } else {\n          // empty\n          if (!opts.binary) {\n            data = '';\n          } else {\n            data = Object(__WEBPACK_IMPORTED_MODULE_0_pouchdb_binary_utils__[\"b\" /* binaryStringToBlobOrBuffer */])('', type);\n          }\n        }\n      } else { // non-empty\n        if (opts.binary) {\n          data = readAsBlobOrBuffer(buffer, type);\n        } else {\n          data = buffer.toString('base64');\n        }\n      }\n      delete att.stub;\n      delete att.length;\n      att.data = data;\n      resolve();\n    });\n  });\n}\n\nfunction fetchAttachments(results, stores, opts) {\n  var atts = [];\n  results.forEach(function (row) {\n    if (!(row.doc && row.doc._attachments)) {\n      return;\n    }\n    var attNames = Object.keys(row.doc._attachments);\n    attNames.forEach(function (attName) {\n      var att = row.doc._attachments[attName];\n      if (!('data' in att)) {\n        atts.push(att);\n      }\n    });\n  });\n\n  return __WEBPACK_IMPORTED_MODULE_3_pouchdb_promise__[\"a\" /* default */].all(atts.map(function (att) {\n    return fetchAttachment(att, stores, opts);\n  }));\n}\n\nfunction LevelPouch(opts, callback) {\n  opts = Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"c\" /* clone */])(opts);\n  var api = this;\n  var instanceId;\n  var stores = {};\n  var revLimit = opts.revs_limit;\n  var db;\n  var name = opts.name;\n  // TODO: this is undocumented and unused probably\n  /* istanbul ignore else */\n  if (typeof opts.createIfMissing === 'undefined') {\n    opts.createIfMissing = true;\n  }\n\n  var leveldown = opts.db;\n\n  var dbStore;\n  var leveldownName = Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"e\" /* functionName */])(leveldown);\n  if (dbStores.has(leveldownName)) {\n    dbStore = dbStores.get(leveldownName);\n  } else {\n    dbStore = new __WEBPACK_IMPORTED_MODULE_1_pouchdb_collections__[\"a\" /* Map */]();\n    dbStores.set(leveldownName, dbStore);\n  }\n  if (dbStore.has(name)) {\n    db = dbStore.get(name);\n    afterDBCreated();\n  } else {\n    dbStore.set(name, Object(__WEBPACK_IMPORTED_MODULE_5_sublevel_pouchdb__[\"a\" /* default */])(__WEBPACK_IMPORTED_MODULE_4_levelup___default()(leveldown(name), opts, function (err) {\n      /* istanbul ignore if */\n      if (err) {\n        dbStore.delete(name);\n        return callback(err);\n      }\n      db = dbStore.get(name);\n      db._docCount  = -1;\n      db._queue = new __WEBPACK_IMPORTED_MODULE_8_double_ended_queue___default.a();\n      /* istanbul ignore else */\n      if (typeof opts.migrate === 'object') { // migration for leveldown\n        opts.migrate.doMigrationOne(name, db, afterDBCreated);\n      } else {\n        afterDBCreated();\n      }\n    })));\n  }\n\n  function afterDBCreated() {\n    stores.docStore = db.sublevel(DOC_STORE, {valueEncoding: safeJsonEncoding});\n    stores.bySeqStore = db.sublevel(BY_SEQ_STORE, {valueEncoding: 'json'});\n    stores.attachmentStore =\n      db.sublevel(ATTACHMENT_STORE, {valueEncoding: 'json'});\n    stores.binaryStore = db.sublevel(BINARY_STORE, {valueEncoding: 'binary'});\n    stores.localStore = db.sublevel(LOCAL_STORE, {valueEncoding: 'json'});\n    stores.metaStore = db.sublevel(META_STORE, {valueEncoding: 'json'});\n    /* istanbul ignore else */\n    if (typeof opts.migrate === 'object') { // migration for leveldown\n      opts.migrate.doMigrationTwo(db, stores, afterLastMigration);\n    } else {\n      afterLastMigration();\n    }\n  }\n\n  function afterLastMigration() {\n    stores.metaStore.get(UPDATE_SEQ_KEY, function (err, value) {\n      if (typeof db._updateSeq === 'undefined') {\n        db._updateSeq = value || 0;\n      }\n      stores.metaStore.get(DOC_COUNT_KEY, function (err, value) {\n        db._docCount = !err ? value : 0;\n        stores.metaStore.get(UUID_KEY, function (err, value) {\n          instanceId = !err ? value : Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"i\" /* uuid */])();\n          stores.metaStore.put(UUID_KEY, instanceId, function () {\n            Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"g\" /* nextTick */])(function () {\n              callback(null, api);\n            });\n          });\n        });\n      });\n    });\n  }\n\n  function countDocs(callback) {\n    /* istanbul ignore if */\n    if (db.isClosed()) {\n      return callback(new Error('database is closed'));\n    }\n    return callback(null, db._docCount); // use cached value\n  }\n\n  api._remote = false;\n  /* istanbul ignore next */\n  api.type = function () {\n    return 'leveldb';\n  };\n\n  api._id = function (callback) {\n    callback(null, instanceId);\n  };\n\n  api._info = function (callback) {\n    var res = {\n      doc_count: db._docCount,\n      update_seq: db._updateSeq,\n      backend_adapter: Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"e\" /* functionName */])(leveldown)\n    };\n    return Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"g\" /* nextTick */])(function () {\n      callback(null, res);\n    });\n  };\n\n  function tryCode(fun, args) {\n    try {\n      fun.apply(null, args);\n    } catch (err) {\n      args[args.length - 1](err);\n    }\n  }\n\n  function executeNext() {\n    var firstTask = db._queue.peekFront();\n\n    if (firstTask.type === 'read') {\n      runReadOperation(firstTask);\n    } else { // write, only do one at a time\n      runWriteOperation(firstTask);\n    }\n  }\n\n  function runReadOperation(firstTask) {\n    // do multiple reads at once simultaneously, because it's safe\n\n    var readTasks = [firstTask];\n    var i = 1;\n    var nextTask = db._queue.get(i);\n    while (typeof nextTask !== 'undefined' && nextTask.type === 'read') {\n      readTasks.push(nextTask);\n      i++;\n      nextTask = db._queue.get(i);\n    }\n\n    var numDone = 0;\n\n    readTasks.forEach(function (readTask) {\n      var args = readTask.args;\n      var callback = args[args.length - 1];\n      args[args.length - 1] = __WEBPACK_IMPORTED_MODULE_7_argsarray___default()(function (cbArgs) {\n        callback.apply(null, cbArgs);\n        if (++numDone === readTasks.length) {\n          Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"g\" /* nextTick */])(function () {\n            // all read tasks have finished\n            readTasks.forEach(function () {\n              db._queue.shift();\n            });\n            if (db._queue.length) {\n              executeNext();\n            }\n          });\n        }\n      });\n      tryCode(readTask.fun, args);\n    });\n  }\n\n  function runWriteOperation(firstTask) {\n    var args = firstTask.args;\n    var callback = args[args.length - 1];\n    args[args.length - 1] = __WEBPACK_IMPORTED_MODULE_7_argsarray___default()(function (cbArgs) {\n      callback.apply(null, cbArgs);\n      Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"g\" /* nextTick */])(function () {\n        db._queue.shift();\n        if (db._queue.length) {\n          executeNext();\n        }\n      });\n    });\n    tryCode(firstTask.fun, args);\n  }\n\n  // all read/write operations to the database are done in a queue,\n  // similar to how websql/idb works. this avoids problems such\n  // as e.g. compaction needing to have a lock on the database while\n  // it updates stuff. in the future we can revisit this.\n  function writeLock(fun) {\n    return __WEBPACK_IMPORTED_MODULE_7_argsarray___default()(function (args) {\n      db._queue.push({\n        fun: fun,\n        args: args,\n        type: 'write'\n      });\n\n      if (db._queue.length === 1) {\n        Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"g\" /* nextTick */])(executeNext);\n      }\n    });\n  }\n\n  // same as the writelock, but multiple can run at once\n  function readLock(fun) {\n    return __WEBPACK_IMPORTED_MODULE_7_argsarray___default()(function (args) {\n      db._queue.push({\n        fun: fun,\n        args: args,\n        type: 'read'\n      });\n\n      if (db._queue.length === 1) {\n        Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"g\" /* nextTick */])(executeNext);\n      }\n    });\n  }\n\n  function formatSeq(n) {\n    return ('0000000000000000' + n).slice(-16);\n  }\n\n  function parseSeq(s) {\n    return parseInt(s, 10);\n  }\n\n  api._get = readLock(function (id, opts, callback) {\n    opts = Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"c\" /* clone */])(opts);\n\n    stores.docStore.get(id, function (err, metadata) {\n\n      if (err || !metadata) {\n        return callback(Object(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"f\" /* MISSING_DOC */], 'missing'));\n      }\n\n      var rev;\n      if (!opts.rev) {\n        rev = getWinningRev(metadata);\n        var deleted = getIsDeleted(metadata, rev);\n        if (deleted) {\n          return callback(Object(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"f\" /* MISSING_DOC */], \"deleted\"));\n        }\n      } else {\n        rev = opts.latest ? Object(__WEBPACK_IMPORTED_MODULE_11_pouchdb_merge__[\"e\" /* latest */])(opts.rev, metadata) : opts.rev;\n      }\n\n      var seq = metadata.rev_map[rev];\n\n      stores.bySeqStore.get(formatSeq(seq), function (err, doc) {\n        if (!doc) {\n          return callback(Object(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"f\" /* MISSING_DOC */]));\n        }\n        /* istanbul ignore if */\n        if ('_id' in doc && doc._id !== metadata.id) {\n          // this failing implies something very wrong\n          return callback(new Error('wrong doc returned'));\n        }\n        doc._id = metadata.id;\n        if ('_rev' in doc) {\n          /* istanbul ignore if */\n          if (doc._rev !== rev) {\n            // this failing implies something very wrong\n            return callback(new Error('wrong doc returned'));\n          }\n        } else {\n          // we didn't always store this\n          doc._rev = rev;\n        }\n        return callback(null, {doc: doc, metadata: metadata});\n      });\n    });\n  });\n\n  // not technically part of the spec, but if putAttachment has its own\n  // method...\n  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n    var digest = attachment.digest;\n    var type = attachment.content_type;\n\n    stores.binaryStore.get(digest, function (err, attach) {\n      if (err) {\n        /* istanbul ignore if */\n        if (err.name !== 'NotFoundError') {\n          return callback(err);\n        }\n        // Empty attachment\n        return callback(null, opts.binary ? createEmptyBlobOrBuffer(type) : '');\n      }\n\n      if (opts.binary) {\n        callback(null, readAsBlobOrBuffer(attach, type));\n      } else {\n        callback(null, attach.toString('base64'));\n      }\n    });\n  };\n\n  api._bulkDocs = writeLock(function (req, opts, callback) {\n    var newEdits = opts.new_edits;\n    var results = new Array(req.docs.length);\n    var fetchedDocs = new __WEBPACK_IMPORTED_MODULE_1_pouchdb_collections__[\"a\" /* Map */]();\n    var stemmedRevs = new __WEBPACK_IMPORTED_MODULE_1_pouchdb_collections__[\"a\" /* Map */]();\n\n    var txn = new LevelTransaction();\n    var docCountDelta = 0;\n    var newUpdateSeq = db._updateSeq;\n\n    // parse the docs and give each a sequence number\n    var userDocs = req.docs;\n    var docInfos = userDocs.map(function (doc) {\n      if (doc._id && Object(__WEBPACK_IMPORTED_MODULE_10_pouchdb_adapter_utils__[\"c\" /* isLocalId */])(doc._id)) {\n        return doc;\n      }\n      var newDoc = Object(__WEBPACK_IMPORTED_MODULE_10_pouchdb_adapter_utils__[\"d\" /* parseDoc */])(doc, newEdits);\n\n      if (newDoc.metadata && !newDoc.metadata.rev_map) {\n        newDoc.metadata.rev_map = {};\n      }\n\n      return newDoc;\n    });\n    var infoErrors = docInfos.filter(function (doc) {\n      return doc.error;\n    });\n\n    if (infoErrors.length) {\n      return callback(infoErrors[0]);\n    }\n\n    // verify any stub attachments as a precondition test\n\n    function verifyAttachment(digest, callback) {\n      txn.get(stores.attachmentStore, digest, function (levelErr) {\n        if (levelErr) {\n          var err = Object(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"h\" /* MISSING_STUB */],\n                                'unknown stub attachment with digest ' +\n                                digest);\n          callback(err);\n        } else {\n          callback();\n        }\n      });\n    }\n\n    function verifyAttachments(finish) {\n      var digests = [];\n      userDocs.forEach(function (doc) {\n        if (doc && doc._attachments) {\n          Object.keys(doc._attachments).forEach(function (filename) {\n            var att = doc._attachments[filename];\n            if (att.stub) {\n              digests.push(att.digest);\n            }\n          });\n        }\n      });\n      if (!digests.length) {\n        return finish();\n      }\n      var numDone = 0;\n      var err;\n\n      digests.forEach(function (digest) {\n        verifyAttachment(digest, function (attErr) {\n          if (attErr && !err) {\n            err = attErr;\n          }\n\n          if (++numDone === digests.length) {\n            finish(err);\n          }\n        });\n      });\n    }\n\n    function fetchExistingDocs(finish) {\n      var numDone = 0;\n      var overallErr;\n      function checkDone() {\n        if (++numDone === userDocs.length) {\n          return finish(overallErr);\n        }\n      }\n\n      userDocs.forEach(function (doc) {\n        if (doc._id && Object(__WEBPACK_IMPORTED_MODULE_10_pouchdb_adapter_utils__[\"c\" /* isLocalId */])(doc._id)) {\n          // skip local docs\n          return checkDone();\n        }\n        txn.get(stores.docStore, doc._id, function (err, info) {\n          if (err) {\n            /* istanbul ignore if */\n            if (err.name !== 'NotFoundError') {\n              overallErr = err;\n            }\n          } else {\n            fetchedDocs.set(doc._id, info);\n          }\n          checkDone();\n        });\n      });\n    }\n\n    function compact(revsMap, callback) {\n      var promise = __WEBPACK_IMPORTED_MODULE_3_pouchdb_promise__[\"a\" /* default */].resolve();\n      revsMap.forEach(function (revs, docId) {\n        // TODO: parallelize, for now need to be sequential to\n        // pass orphaned attachment tests\n        promise = promise.then(function () {\n          return new __WEBPACK_IMPORTED_MODULE_3_pouchdb_promise__[\"a\" /* default */](function (resolve, reject) {\n            api._doCompactionNoLock(docId, revs, {ctx: txn}, function (err) {\n              /* istanbul ignore if */\n              if (err) {\n                return reject(err);\n              }\n              resolve();\n            });\n          });\n        });\n      });\n\n      promise.then(function () {\n        callback();\n      }, callback);\n    }\n\n    function autoCompact(callback) {\n      var revsMap = new __WEBPACK_IMPORTED_MODULE_1_pouchdb_collections__[\"a\" /* Map */]();\n      fetchedDocs.forEach(function (metadata, docId) {\n        revsMap.set(docId, Object(__WEBPACK_IMPORTED_MODULE_11_pouchdb_merge__[\"b\" /* compactTree */])(metadata));\n      });\n      compact(revsMap, callback);\n    }\n\n    function finish() {\n      compact(stemmedRevs, function (error) {\n        /* istanbul ignore if */\n        if (error) {\n          complete(error);\n        }\n        if (api.auto_compaction) {\n          return autoCompact(complete);\n        }\n        complete();\n      });\n    }\n\n    function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n                      isUpdate, delta, resultsIdx, callback2) {\n      docCountDelta += delta;\n\n      var err = null;\n      var recv = 0;\n\n      docInfo.metadata.winningRev = winningRev$$1;\n      docInfo.metadata.deleted = winningRevIsDeleted;\n\n      docInfo.data._id = docInfo.metadata.id;\n      docInfo.data._rev = docInfo.metadata.rev;\n\n      if (newRevIsDeleted) {\n        docInfo.data._deleted = true;\n      }\n\n      if (docInfo.stemmedRevs.length) {\n        stemmedRevs.set(docInfo.metadata.id, docInfo.stemmedRevs);\n      }\n\n      var attachments = docInfo.data._attachments ?\n        Object.keys(docInfo.data._attachments) :\n        [];\n\n      function attachmentSaved(attachmentErr) {\n        recv++;\n        if (!err) {\n          /* istanbul ignore if */\n          if (attachmentErr) {\n            err = attachmentErr;\n            callback2(err);\n          } else if (recv === attachments.length) {\n            finish();\n          }\n        }\n      }\n\n      function onMD5Load(doc, key, data, attachmentSaved) {\n        return function (result) {\n          saveAttachment(doc, MD5_PREFIX + result, key, data, attachmentSaved);\n        };\n      }\n\n      function doMD5(doc, key, attachmentSaved) {\n        return function (data) {\n          Object(__WEBPACK_IMPORTED_MODULE_13_pouchdb_md5__[\"a\" /* binaryMd5 */])(data, onMD5Load(doc, key, data, attachmentSaved));\n        };\n      }\n\n      for (var i = 0; i < attachments.length; i++) {\n        var key = attachments[i];\n        var att = docInfo.data._attachments[key];\n\n        if (att.stub) {\n          // still need to update the refs mapping\n          var id = docInfo.data._id;\n          var rev = docInfo.data._rev;\n          saveAttachmentRefs(id, rev, att.digest, attachmentSaved);\n          continue;\n        }\n        var data;\n        if (typeof att.data === 'string') {\n          // input is assumed to be a base64 string\n          try {\n            data = Object(__WEBPACK_IMPORTED_MODULE_0_pouchdb_binary_utils__[\"a\" /* atob */])(att.data);\n          } catch (e) {\n            callback(Object(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"a\" /* BAD_ARG */],\n                     'Attachment is not a valid base64 string'));\n            return;\n          }\n          doMD5(docInfo, key, attachmentSaved)(data);\n        } else {\n          prepareAttachmentForStorage(att.data,\n            doMD5(docInfo, key, attachmentSaved));\n        }\n      }\n\n      function finish() {\n        var seq = docInfo.metadata.rev_map[docInfo.metadata.rev];\n        /* istanbul ignore if */\n        if (seq) {\n          // check that there aren't any existing revisions with the same\n          // revision id, else we shouldn't do anything\n          return callback2();\n        }\n        seq = ++newUpdateSeq;\n        docInfo.metadata.rev_map[docInfo.metadata.rev] =\n          docInfo.metadata.seq = seq;\n        var seqKey = formatSeq(seq);\n        var batch = [{\n          key: seqKey,\n          value: docInfo.data,\n          prefix: stores.bySeqStore,\n          type: 'put'\n        }, {\n          key: docInfo.metadata.id,\n          value: docInfo.metadata,\n          prefix: stores.docStore,\n          type: 'put'\n        }];\n        txn.batch(batch);\n        results[resultsIdx] = {\n          ok: true,\n          id: docInfo.metadata.id,\n          rev: docInfo.metadata.rev\n        };\n        fetchedDocs.set(docInfo.metadata.id, docInfo.metadata);\n        callback2();\n      }\n\n      if (!attachments.length) {\n        finish();\n      }\n    }\n\n    // attachments are queued per-digest, otherwise the refs could be\n    // overwritten by concurrent writes in the same bulkDocs session\n    var attachmentQueues = {};\n\n    function saveAttachmentRefs(id, rev, digest, callback) {\n\n      function fetchAtt() {\n        return new __WEBPACK_IMPORTED_MODULE_3_pouchdb_promise__[\"a\" /* default */](function (resolve, reject) {\n          txn.get(stores.attachmentStore, digest, function (err, oldAtt) {\n            /* istanbul ignore if */\n            if (err && err.name !== 'NotFoundError') {\n              return reject(err);\n            }\n            resolve(oldAtt);\n          });\n        });\n      }\n\n      function saveAtt(oldAtt) {\n        var ref = [id, rev].join('@');\n        var newAtt = {};\n\n        if (oldAtt) {\n          if (oldAtt.refs) {\n            // only update references if this attachment already has them\n            // since we cannot migrate old style attachments here without\n            // doing a full db scan for references\n            newAtt.refs = oldAtt.refs;\n            newAtt.refs[ref] = true;\n          }\n        } else {\n          newAtt.refs = {};\n          newAtt.refs[ref] = true;\n        }\n\n        return new __WEBPACK_IMPORTED_MODULE_3_pouchdb_promise__[\"a\" /* default */](function (resolve) {\n          txn.batch([{\n            type: 'put',\n            prefix: stores.attachmentStore,\n            key: digest,\n            value: newAtt\n          }]);\n          resolve(!oldAtt);\n        });\n      }\n\n      // put attachments in a per-digest queue, to avoid two docs with the same\n      // attachment overwriting each other\n      var queue = attachmentQueues[digest] || __WEBPACK_IMPORTED_MODULE_3_pouchdb_promise__[\"a\" /* default */].resolve();\n      attachmentQueues[digest] = queue.then(function () {\n        return fetchAtt().then(saveAtt).then(function (isNewAttachment) {\n          callback(null, isNewAttachment);\n        }, callback);\n      });\n    }\n\n    function saveAttachment(docInfo, digest, key, data, callback) {\n      var att = docInfo.data._attachments[key];\n      delete att.data;\n      att.digest = digest;\n      att.length = data.length;\n      var id = docInfo.metadata.id;\n      var rev = docInfo.metadata.rev;\n      att.revpos = parseInt(rev, 10);\n\n      saveAttachmentRefs(id, rev, digest, function (err, isNewAttachment) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        // do not try to store empty attachments\n        if (data.length === 0) {\n          return callback(err);\n        }\n        if (!isNewAttachment) {\n          // small optimization - don't bother writing it again\n          return callback(err);\n        }\n        txn.batch([{\n          type: 'put',\n          prefix: stores.binaryStore,\n          key: digest,\n          value: __WEBPACK_IMPORTED_MODULE_9_buffer_from___default()(data, 'binary')\n        }]);\n        callback();\n      });\n    }\n\n    function complete(err) {\n      /* istanbul ignore if */\n      if (err) {\n        return Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"g\" /* nextTick */])(function () {\n          callback(err);\n        });\n      }\n      txn.batch([\n        {\n          prefix: stores.metaStore,\n          type: 'put',\n          key: UPDATE_SEQ_KEY,\n          value: newUpdateSeq\n        },\n        {\n          prefix: stores.metaStore,\n          type: 'put',\n          key: DOC_COUNT_KEY,\n          value: db._docCount + docCountDelta\n        }\n      ]);\n      txn.execute(db, function (err) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        db._docCount += docCountDelta;\n        db._updateSeq = newUpdateSeq;\n        levelChanges.notify(name);\n        Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"g\" /* nextTick */])(function () {\n          callback(null, results);\n        });\n      });\n    }\n\n    if (!docInfos.length) {\n      return callback(null, []);\n    }\n\n    verifyAttachments(function (err) {\n      if (err) {\n        return callback(err);\n      }\n      fetchExistingDocs(function (err) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        Object(__WEBPACK_IMPORTED_MODULE_10_pouchdb_adapter_utils__[\"e\" /* processDocs */])(revLimit, docInfos, api, fetchedDocs, txn, results,\n                    writeDoc, opts, finish);\n      });\n    });\n  });\n  api._allDocs = function (opts, callback) {\n    if ('keys' in opts) {\n      return Object(__WEBPACK_IMPORTED_MODULE_10_pouchdb_adapter_utils__[\"a\" /* allDocsKeysQuery */])(this, opts);\n    }\n    return readLock(function (opts, callback) {\n      opts = Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"c\" /* clone */])(opts);\n      countDocs(function (err, docCount) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        var readstreamOpts = {};\n        var skip = opts.skip || 0;\n        if (opts.startkey) {\n          readstreamOpts.gte = opts.startkey;\n        }\n        if (opts.endkey) {\n          readstreamOpts.lte = opts.endkey;\n        }\n        if (opts.key) {\n          readstreamOpts.gte = readstreamOpts.lte = opts.key;\n        }\n        if (opts.descending) {\n          readstreamOpts.reverse = true;\n          // switch start and ends\n          var tmp = readstreamOpts.lte;\n          readstreamOpts.lte = readstreamOpts.gte;\n          readstreamOpts.gte = tmp;\n        }\n        var limit;\n        if (typeof opts.limit === 'number') {\n          limit = opts.limit;\n        }\n        if (limit === 0 ||\n            ('gte' in readstreamOpts && 'lte' in readstreamOpts &&\n            readstreamOpts.gte > readstreamOpts.lte)) {\n          // should return 0 results when start is greater than end.\n          // normally level would \"fix\" this for us by reversing the order,\n          // so short-circuit instead\n          var returnVal = {\n            total_rows: docCount,\n            offset: opts.skip,\n            rows: []\n          };\n          /* istanbul ignore if */\n          if (opts.update_seq) {\n            returnVal.update_seq = db._updateSeq;\n          }\n          return callback(null, returnVal);\n        }\n        var results = [];\n        var docstream = stores.docStore.readStream(readstreamOpts);\n\n        var throughStream = Object(__WEBPACK_IMPORTED_MODULE_6_through2__[\"obj\"])(function (entry, _, next) {\n          var metadata = entry.value;\n          // winningRev and deleted are performance-killers, but\n          // in newer versions of PouchDB, they are cached on the metadata\n          var winningRev$$1 = getWinningRev(metadata);\n          var deleted = getIsDeleted(metadata, winningRev$$1);\n          if (!deleted) {\n            if (skip-- > 0) {\n              next();\n              return;\n            } else if (typeof limit === 'number' && limit-- <= 0) {\n              docstream.unpipe();\n              docstream.destroy();\n              next();\n              return;\n            }\n          } else if (opts.deleted !== 'ok') {\n            next();\n            return;\n          }\n          function allDocsInner(data) {\n            var doc = {\n              id: metadata.id,\n              key: metadata.id,\n              value: {\n                rev: winningRev$$1\n              }\n            };\n            if (opts.include_docs) {\n              doc.doc = data;\n              doc.doc._rev = doc.value.rev;\n              if (opts.conflicts) {\n                var conflicts = Object(__WEBPACK_IMPORTED_MODULE_11_pouchdb_merge__[\"a\" /* collectConflicts */])(metadata);\n                if (conflicts.length) {\n                  doc.doc._conflicts = conflicts;\n                }\n              }\n              for (var att in doc.doc._attachments) {\n                if (doc.doc._attachments.hasOwnProperty(att)) {\n                  doc.doc._attachments[att].stub = true;\n                }\n              }\n            }\n            if (opts.inclusive_end === false && metadata.id === opts.endkey) {\n              return next();\n            } else if (deleted) {\n              if (opts.deleted === 'ok') {\n                doc.value.deleted = true;\n                doc.doc = null;\n              } else {\n                /* istanbul ignore next */\n                return next();\n              }\n            }\n            results.push(doc);\n            next();\n          }\n          if (opts.include_docs) {\n            var seq = metadata.rev_map[winningRev$$1];\n            stores.bySeqStore.get(formatSeq(seq), function (err, data) {\n              allDocsInner(data);\n            });\n          }\n          else {\n            allDocsInner();\n          }\n        }, function (next) {\n          __WEBPACK_IMPORTED_MODULE_3_pouchdb_promise__[\"a\" /* default */].resolve().then(function () {\n            if (opts.include_docs && opts.attachments) {\n              return fetchAttachments(results, stores, opts);\n            }\n          }).then(function () {\n            var returnVal = {\n              total_rows: docCount,\n              offset: opts.skip,\n              rows: results\n            };\n\n            /* istanbul ignore if */\n            if (opts.update_seq) {\n              returnVal.update_seq = db._updateSeq;\n            }\n            callback(null, returnVal);\n          }, callback);\n          next();\n        }).on('unpipe', function () {\n          throughStream.end();\n        });\n\n        docstream.on('error', callback);\n\n        docstream.pipe(throughStream);\n      });\n    })(opts, callback);\n  };\n\n  api._changes = function (opts) {\n    opts = Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"c\" /* clone */])(opts);\n\n    if (opts.continuous) {\n      var id = name + ':' + Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"i\" /* uuid */])();\n      levelChanges.addListener(name, id, api, opts);\n      levelChanges.notify(name);\n      return {\n        cancel: function () {\n          levelChanges.removeListener(name, id);\n        }\n      };\n    }\n\n    var descending = opts.descending;\n    var results = [];\n    var lastSeq = opts.since || 0;\n    var called = 0;\n    var streamOpts = {\n      reverse: descending\n    };\n    var limit;\n    if ('limit' in opts && opts.limit > 0) {\n      limit = opts.limit;\n    }\n    if (!streamOpts.reverse) {\n      streamOpts.start = formatSeq(opts.since || 0);\n    }\n\n    var docIds = opts.doc_ids && new __WEBPACK_IMPORTED_MODULE_1_pouchdb_collections__[\"b\" /* Set */](opts.doc_ids);\n    var filter = Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"d\" /* filterChange */])(opts);\n    var docIdsToMetadata = new __WEBPACK_IMPORTED_MODULE_1_pouchdb_collections__[\"a\" /* Map */]();\n\n    var returnDocs;\n    if ('return_docs' in opts) {\n      returnDocs = opts.return_docs;\n    } else if ('returnDocs' in opts) {\n      // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n      returnDocs = opts.returnDocs;\n    } else {\n      returnDocs = true;\n    }\n\n    function complete() {\n      opts.done = true;\n      if (returnDocs && opts.limit) {\n        /* istanbul ignore if */\n        if (opts.limit < results.length) {\n          results.length = opts.limit;\n        }\n      }\n      changeStream.unpipe(throughStream);\n      changeStream.destroy();\n      if (!opts.continuous && !opts.cancelled) {\n        if (opts.include_docs && opts.attachments) {\n          fetchAttachments(results, stores, opts).then(function () {\n            opts.complete(null, {results: results, last_seq: lastSeq});\n          });\n        } else {\n          opts.complete(null, {results: results, last_seq: lastSeq});\n        }\n      }\n    }\n    var changeStream = stores.bySeqStore.readStream(streamOpts);\n    var throughStream = Object(__WEBPACK_IMPORTED_MODULE_6_through2__[\"obj\"])(function (data, _, next) {\n      if (limit && called >= limit) {\n        complete();\n        return next();\n      }\n      if (opts.cancelled || opts.done) {\n        return next();\n      }\n\n      var seq = parseSeq(data.key);\n      var doc = data.value;\n\n      if (seq === opts.since && !descending) {\n        // couchdb ignores `since` if descending=true\n        return next();\n      }\n\n      if (docIds && !docIds.has(doc._id)) {\n        return next();\n      }\n\n      var metadata;\n\n      function onGetMetadata(metadata) {\n        var winningRev$$1 = getWinningRev(metadata);\n\n        function onGetWinningDoc(winningDoc) {\n\n          var change = opts.processChange(winningDoc, metadata, opts);\n          change.seq = metadata.seq;\n\n          var filtered = filter(change);\n          if (typeof filtered === 'object') {\n            return opts.complete(filtered);\n          }\n\n          if (filtered) {\n            called++;\n\n            if (opts.attachments && opts.include_docs) {\n              // fetch attachment immediately for the benefit\n              // of live listeners\n              fetchAttachments([change], stores, opts).then(function () {\n                opts.onChange(change);\n              });\n            } else {\n              opts.onChange(change);\n            }\n\n            if (returnDocs) {\n              results.push(change);\n            }\n          }\n          next();\n        }\n\n        if (metadata.seq !== seq) {\n          // some other seq is later\n          return next();\n        }\n\n        lastSeq = seq;\n\n        if (winningRev$$1 === doc._rev) {\n          return onGetWinningDoc(doc);\n        }\n\n        // fetch the winner\n\n        var winningSeq = metadata.rev_map[winningRev$$1];\n\n        stores.bySeqStore.get(formatSeq(winningSeq), function (err, doc) {\n          onGetWinningDoc(doc);\n        });\n      }\n\n      metadata = docIdsToMetadata.get(doc._id);\n      if (metadata) { // cached\n        return onGetMetadata(metadata);\n      }\n      // metadata not cached, have to go fetch it\n      stores.docStore.get(doc._id, function (err, metadata) {\n        /* istanbul ignore if */\n        if (opts.cancelled || opts.done || db.isClosed() ||\n          Object(__WEBPACK_IMPORTED_MODULE_10_pouchdb_adapter_utils__[\"c\" /* isLocalId */])(metadata.id)) {\n          return next();\n        }\n        docIdsToMetadata.set(doc._id, metadata);\n        onGetMetadata(metadata);\n      });\n    }, function (next) {\n      if (opts.cancelled) {\n        return next();\n      }\n      if (returnDocs && opts.limit) {\n        /* istanbul ignore if */\n        if (opts.limit < results.length) {\n          results.length = opts.limit;\n        }\n      }\n\n      next();\n    }).on('unpipe', function () {\n      throughStream.end();\n      complete();\n    });\n    changeStream.pipe(throughStream);\n    return {\n      cancel: function () {\n        opts.cancelled = true;\n        complete();\n      }\n    };\n  };\n\n  api._close = function (callback) {\n    /* istanbul ignore if */\n    if (db.isClosed()) {\n      return callback(Object(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"i\" /* NOT_OPEN */]));\n    }\n    db.close(function (err) {\n      /* istanbul ignore if */\n      if (err) {\n        callback(err);\n      } else {\n        dbStore.delete(name);\n        callback();\n      }\n    });\n  };\n\n  api._getRevisionTree = function (docId, callback) {\n    stores.docStore.get(docId, function (err, metadata) {\n      if (err) {\n        callback(Object(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"f\" /* MISSING_DOC */]));\n      } else {\n        callback(null, metadata.rev_tree);\n      }\n    });\n  };\n\n  api._doCompaction = writeLock(function (docId, revs, opts, callback) {\n    api._doCompactionNoLock(docId, revs, opts, callback);\n  });\n\n  // the NoLock version is for use by bulkDocs\n  api._doCompactionNoLock = function (docId, revs, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n\n    if (!revs.length) {\n      return callback();\n    }\n    var txn = opts.ctx || new LevelTransaction();\n\n    txn.get(stores.docStore, docId, function (err, metadata) {\n      /* istanbul ignore if */\n      if (err) {\n        return callback(err);\n      }\n      var seqs = revs.map(function (rev) {\n        var seq = metadata.rev_map[rev];\n        delete metadata.rev_map[rev];\n        return seq;\n      });\n      Object(__WEBPACK_IMPORTED_MODULE_11_pouchdb_merge__[\"h\" /* traverseRevTree */])(metadata.rev_tree, function (isLeaf, pos,\n                                                         revHash, ctx, opts) {\n        var rev = pos + '-' + revHash;\n        if (revs.indexOf(rev) !== -1) {\n          opts.status = 'missing';\n        }\n      });\n\n      var batch = [];\n      batch.push({\n        key: metadata.id,\n        value: metadata,\n        type: 'put',\n        prefix: stores.docStore\n      });\n\n      var digestMap = {};\n      var numDone = 0;\n      var overallErr;\n      function checkDone(err) {\n        /* istanbul ignore if */\n        if (err) {\n          overallErr = err;\n        }\n        if (++numDone === revs.length) { // done\n          /* istanbul ignore if */\n          if (overallErr) {\n            return callback(overallErr);\n          }\n          deleteOrphanedAttachments();\n        }\n      }\n\n      function finish(err) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        txn.batch(batch);\n        if (opts.ctx) {\n          // don't execute immediately\n          return callback();\n        }\n        txn.execute(db, callback);\n      }\n\n      function deleteOrphanedAttachments() {\n        var possiblyOrphanedAttachments = Object.keys(digestMap);\n        if (!possiblyOrphanedAttachments.length) {\n          return finish();\n        }\n        var numDone = 0;\n        var overallErr;\n        function checkDone(err) {\n          /* istanbul ignore if */\n          if (err) {\n            overallErr = err;\n          }\n          if (++numDone === possiblyOrphanedAttachments.length) {\n            finish(overallErr);\n          }\n        }\n        var refsToDelete = new __WEBPACK_IMPORTED_MODULE_1_pouchdb_collections__[\"a\" /* Map */]();\n        revs.forEach(function (rev) {\n          refsToDelete.set(docId + '@' + rev, true);\n        });\n        possiblyOrphanedAttachments.forEach(function (digest) {\n          txn.get(stores.attachmentStore, digest, function (err, attData) {\n            /* istanbul ignore if */\n            if (err) {\n              if (err.name === 'NotFoundError') {\n                return checkDone();\n              } else {\n                return checkDone(err);\n              }\n            }\n            var refs = Object.keys(attData.refs || {}).filter(function (ref) {\n              return !refsToDelete.has(ref);\n            });\n            var newRefs = {};\n            refs.forEach(function (ref) {\n              newRefs[ref] = true;\n            });\n            if (refs.length) { // not orphaned\n              batch.push({\n                key: digest,\n                type: 'put',\n                value: {refs: newRefs},\n                prefix: stores.attachmentStore\n              });\n            } else { // orphaned, can safely delete\n              batch = batch.concat([{\n                key: digest,\n                type: 'del',\n                prefix: stores.attachmentStore\n              }, {\n                key: digest,\n                type: 'del',\n                prefix: stores.binaryStore\n              }]);\n            }\n            checkDone();\n          });\n        });\n      }\n\n      seqs.forEach(function (seq) {\n        batch.push({\n          key: formatSeq(seq),\n          type: 'del',\n          prefix: stores.bySeqStore\n        });\n        txn.get(stores.bySeqStore, formatSeq(seq), function (err, doc) {\n          /* istanbul ignore if */\n          if (err) {\n            if (err.name === 'NotFoundError') {\n              return checkDone();\n            } else {\n              return checkDone(err);\n            }\n          }\n          var atts = Object.keys(doc._attachments || {});\n          atts.forEach(function (attName) {\n            var digest = doc._attachments[attName].digest;\n            digestMap[digest] = true;\n          });\n          checkDone();\n        });\n      });\n    });\n  };\n\n  api._getLocal = function (id, callback) {\n    stores.localStore.get(id, function (err, doc) {\n      if (err) {\n        callback(Object(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"f\" /* MISSING_DOC */]));\n      } else {\n        callback(null, doc);\n      }\n    });\n  };\n\n  api._putLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    if (opts.ctx) {\n      api._putLocalNoLock(doc, opts, callback);\n    } else {\n      api._putLocalWithLock(doc, opts, callback);\n    }\n  };\n\n  api._putLocalWithLock = writeLock(function (doc, opts, callback) {\n    api._putLocalNoLock(doc, opts, callback);\n  });\n\n  // the NoLock version is for use by bulkDocs\n  api._putLocalNoLock = function (doc, opts, callback) {\n    delete doc._revisions; // ignore this, trust the rev\n    var oldRev = doc._rev;\n    var id = doc._id;\n\n    var txn = opts.ctx || new LevelTransaction();\n\n    txn.get(stores.localStore, id, function (err, resp) {\n      if (err && oldRev) {\n        return callback(Object(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"k\" /* REV_CONFLICT */]));\n      }\n      if (resp && resp._rev !== oldRev) {\n        return callback(Object(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"k\" /* REV_CONFLICT */]));\n      }\n      doc._rev =\n          oldRev ? '0-' + (parseInt(oldRev.split('-')[1], 10) + 1) : '0-1';\n      var batch = [\n        {\n          type: 'put',\n          prefix: stores.localStore,\n          key: id,\n          value: doc\n        }\n      ];\n\n      txn.batch(batch);\n      var ret = {ok: true, id: doc._id, rev: doc._rev};\n\n      if (opts.ctx) {\n        // don't execute immediately\n        return callback(null, ret);\n      }\n      txn.execute(db, function (err) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        callback(null, ret);\n      });\n    });\n  };\n\n  api._removeLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    if (opts.ctx) {\n      api._removeLocalNoLock(doc, opts, callback);\n    } else {\n      api._removeLocalWithLock(doc, opts, callback);\n    }\n  };\n\n  api._removeLocalWithLock = writeLock(function (doc, opts, callback) {\n    api._removeLocalNoLock(doc, opts, callback);\n  });\n\n  // the NoLock version is for use by bulkDocs\n  api._removeLocalNoLock = function (doc, opts, callback) {\n    var txn = opts.ctx || new LevelTransaction();\n    txn.get(stores.localStore, doc._id, function (err, resp) {\n      if (err) {\n        /* istanbul ignore if */\n        if (err.name !== 'NotFoundError') {\n          return callback(err);\n        } else {\n          return callback(Object(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"f\" /* MISSING_DOC */]));\n        }\n      }\n      if (resp._rev !== doc._rev) {\n        return callback(Object(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_14_pouchdb_errors__[\"k\" /* REV_CONFLICT */]));\n      }\n      txn.batch([{\n        prefix: stores.localStore,\n        type: 'del',\n        key: doc._id\n      }]);\n      var ret = {ok: true, id: doc._id, rev: '0-0'};\n      if (opts.ctx) {\n        // don't execute immediately\n        return callback(null, ret);\n      }\n      txn.execute(db, function (err) {\n        /* istanbul ignore if */\n        if (err) {\n          return callback(err);\n        }\n        callback(null, ret);\n      });\n    });\n  };\n\n  // close and delete open leveldb stores\n  api._destroy = function (opts, callback) {\n    var dbStore;\n    var leveldownName = Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_utils__[\"e\" /* functionName */])(leveldown);\n    /* istanbul ignore else */\n    if (dbStores.has(leveldownName)) {\n      dbStore = dbStores.get(leveldownName);\n    } else {\n      return callDestroy(name, callback);\n    }\n\n    /* istanbul ignore else */\n    if (dbStore.has(name)) {\n      levelChanges.removeAllListeners(name);\n\n      dbStore.get(name).close(function () {\n        dbStore.delete(name);\n        callDestroy(name, callback);\n      });\n    } else {\n      callDestroy(name, callback);\n    }\n  };\n  function callDestroy(name, cb) {\n    leveldown.destroy(name, cb);\n  }\n}\n\n/* harmony default export */ __webpack_exports__[\"a\"] = (LevelPouch);\n\n\n/***/ }),\n/* 575 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process) {/* Copyright (c) 2012-2017 LevelUP contributors\n * See list at <https://github.com/level/levelup#contributing>\n * MIT License\n * <https://github.com/level/levelup/blob/master/LICENSE.md>\n */\n\nvar EventEmitter = __webpack_require__(23).EventEmitter\nvar inherits = __webpack_require__(65).inherits\nvar extend = __webpack_require__(66)\nvar DeferredLevelDOWN = __webpack_require__(578)\nvar IteratorStream = __webpack_require__(584)\nvar Batch = __webpack_require__(592)\nvar errors = __webpack_require__(197)\nvar assert = __webpack_require__(596)\nvar promisify = __webpack_require__(198)\n\nvar WriteError = errors.WriteError\nvar ReadError = errors.ReadError\nvar NotFoundError = errors.NotFoundError\nvar OpenError = errors.OpenError\nvar InitializationError = errors.InitializationError\n\n// Possible AbstractLevelDOWN#status values:\n//  - 'new'     - newly created, not opened or closed\n//  - 'opening' - waiting for the database to be opened, post open()\n//  - 'open'    - successfully opened the database, available for use\n//  - 'closing' - waiting for the database to be closed, post close()\n//  - 'closed'  - database has been successfully closed, should not be\n//                 used except for another open() operation\n\nfunction LevelUP (db, options, callback) {\n  if (!(this instanceof LevelUP)) {\n    return new LevelUP(db, options, callback)\n  }\n\n  var error\n\n  EventEmitter.call(this)\n  this.setMaxListeners(Infinity)\n\n  if (typeof options === 'function') {\n    callback = options\n    options = {}\n  }\n\n  options = options || {}\n\n  if (!db || typeof db !== 'object') {\n    error = new InitializationError('Must provide db')\n    if (typeof callback === 'function') {\n      return process.nextTick(callback, error)\n    }\n    throw error\n  }\n\n  assert.equal(typeof db.status, 'string', '.status required, old abstract-leveldown')\n\n  this.options = getOptions(options)\n  this._db = db\n  this.db = new DeferredLevelDOWN(db)\n  this.open(callback)\n}\n\nLevelUP.prototype.emit = EventEmitter.prototype.emit\nLevelUP.prototype.once = EventEmitter.prototype.once\ninherits(LevelUP, EventEmitter)\n\nLevelUP.prototype.open = function (callback) {\n  var self = this\n  var promise\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  if (this.isOpen()) {\n    process.nextTick(callback, null, self)\n    return promise\n  }\n\n  if (this._isOpening()) {\n    this.once('open', function () { callback(null, self) })\n    return promise\n  }\n\n  this.emit('opening')\n\n  this.db.open(this.options, function (err) {\n    if (err) {\n      return callback(new OpenError(err))\n    }\n    self.db = self._db\n    callback(null, self)\n    self.emit('open')\n    self.emit('ready')\n  })\n\n  return promise\n}\n\nLevelUP.prototype.close = function (callback) {\n  var self = this\n  var promise\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  if (this.isOpen()) {\n    this.db.close(function () {\n      self.emit('closed')\n      callback.apply(null, arguments)\n    })\n    this.emit('closing')\n    this.db = new DeferredLevelDOWN(this._db)\n  } else if (this.isClosed()) {\n    process.nextTick(callback)\n  } else if (this.db.status === 'closing') {\n    this.once('closed', callback)\n  } else if (this._isOpening()) {\n    this.once('open', function () {\n      self.close(callback)\n    })\n  }\n\n  return promise\n}\n\nLevelUP.prototype.isOpen = function () {\n  return this.db.status === 'open'\n}\n\nLevelUP.prototype._isOpening = function () {\n  return this.db.status === 'opening'\n}\n\nLevelUP.prototype.isClosed = function () {\n  return (/^clos|new/).test(this.db.status)\n}\n\nLevelUP.prototype.get = function (key, options, callback) {\n  if (key === null || key === undefined) {\n    throw new ReadError('get() requires a key argument')\n  }\n\n  var promise\n\n  callback = getCallback(options, callback)\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  if (maybeError(this, callback)) { return promise }\n\n  options = getOptions(options)\n\n  this.db.get(key, options, function (err, value) {\n    if (err) {\n      if ((/notfound/i).test(err) || err.notFound) {\n        err = new NotFoundError('Key not found in database [' + key + ']', err)\n      } else {\n        err = new ReadError(err)\n      }\n      return callback(err)\n    }\n    callback(null, value)\n  })\n\n  return promise\n}\n\nLevelUP.prototype.put = function (key, value, options, callback) {\n  if (key === null || key === undefined) {\n    throw new WriteError('put() requires a key argument')\n  }\n\n  var self = this\n  var promise\n\n  callback = getCallback(options, callback)\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  if (maybeError(this, callback)) { return promise }\n\n  options = getOptions(options)\n\n  this.db.put(key, value, options, function (err) {\n    if (err) {\n      return callback(new WriteError(err))\n    }\n    self.emit('put', key, value)\n    callback()\n  })\n\n  return promise\n}\n\nLevelUP.prototype.del = function (key, options, callback) {\n  if (key === null || key === undefined) {\n    throw new WriteError('del() requires a key argument')\n  }\n\n  var self = this\n  var promise\n\n  callback = getCallback(options, callback)\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  if (maybeError(this, callback)) { return promise }\n\n  options = getOptions(options)\n\n  this.db.del(key, options, function (err) {\n    if (err) {\n      return callback(new WriteError(err))\n    }\n    self.emit('del', key)\n    callback()\n  })\n\n  return promise\n}\n\nLevelUP.prototype.batch = function (arr, options, callback) {\n  if (!arguments.length) {\n    return new Batch(this)\n  }\n\n  if (!Array.isArray(arr)) {\n    throw new WriteError('batch() requires an array argument')\n  }\n\n  var self = this\n  var promise\n\n  callback = getCallback(options, callback)\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  if (maybeError(this, callback)) { return promise }\n\n  options = getOptions(options)\n\n  arr = arr.map(function (op) {\n    if (!op.type && op.key !== undefined && op.value !== undefined) { op.type = 'put' }\n    return op\n  })\n\n  this.db.batch(arr, options, function (err) {\n    if (err) {\n      return callback(new WriteError(err))\n    }\n    self.emit('batch', arr)\n    callback()\n  })\n\n  return promise\n}\n\nLevelUP.prototype.readStream =\nLevelUP.prototype.createReadStream = function (options) {\n  options = extend({ keys: true, values: true }, options)\n  if (typeof options.limit !== 'number') { options.limit = -1 }\n  return new IteratorStream(this.db.iterator(options), options)\n}\n\nLevelUP.prototype.keyStream =\nLevelUP.prototype.createKeyStream = function (options) {\n  return this.createReadStream(extend(options, { keys: true, values: false }))\n}\n\nLevelUP.prototype.valueStream =\nLevelUP.prototype.createValueStream = function (options) {\n  return this.createReadStream(extend(options, { keys: false, values: true }))\n}\n\nLevelUP.prototype.toString = function () {\n  return 'LevelUP'\n}\n\nfunction getCallback (options, callback) {\n  return typeof options === 'function' ? options : callback\n}\n\nfunction getOptions (options) {\n  return typeof options === 'object' && options !== null ? options : {}\n}\n\nfunction maybeError (db, callback) {\n  if (!db._isOpening() && !db.isOpen()) {\n    process.nextTick(callback, new ReadError('Database is not open'))\n    return true\n  }\n}\n\nLevelUP.errors = errors\nmodule.exports = LevelUP.default = LevelUP\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8)))\n\n/***/ }),\n/* 576 */\n/***/ (function(module, exports) {\n\nmodule.exports = function isBuffer(arg) {\n  return arg && typeof arg === 'object'\n    && typeof arg.copy === 'function'\n    && typeof arg.fill === 'function'\n    && typeof arg.readUInt8 === 'function';\n}\n\n/***/ }),\n/* 577 */\n/***/ (function(module, exports) {\n\nif (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n\n\n/***/ }),\n/* 578 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(Buffer) {var util = __webpack_require__(65)\nvar AbstractLevelDOWN = __webpack_require__(188).AbstractLevelDOWN\nvar DeferredIterator = __webpack_require__(583)\nvar deferrables = 'put get del batch approximateSize'.split(' ')\n\nfunction DeferredLevelDOWN (db) {\n  AbstractLevelDOWN.call(this, '')\n  this._db = db\n  this._operations = []\n  this._iterators = []\n}\n\nutil.inherits(DeferredLevelDOWN, AbstractLevelDOWN)\n\nDeferredLevelDOWN.prototype._open = function (options, callback) {\n  var self = this\n\n  this._db.open(options, function (err) {\n    if (err) return callback(err)\n\n    self._operations.forEach(function (op) {\n      self._db[op.method].apply(self._db, op.args)\n    })\n    self._operations = []\n    self._iterators.forEach(function (it) {\n      it.setDb(self._db)\n    })\n    self._iterators = []\n    open(self)\n    callback()\n  })\n}\n\nDeferredLevelDOWN.prototype._close = function (callback) {\n  var self = this\n\n  this._db.close(function (err) {\n    if (err) return callback(err)\n    closed(self)\n    callback()\n  })\n}\n\nfunction open (obj) {\n  deferrables.concat('iterator').forEach(function (m) {\n    obj['_' + m] = function () {\n      return this._db[m].apply(this._db, arguments)\n    }\n  })\n}\n\nfunction closed (obj) {\n  deferrables.forEach(function (m) {\n    obj['_' + m] = function () {\n      this._operations.push({ method: m, args: arguments })\n    }\n  })\n  obj._iterator = function (options) {\n    var it = new DeferredIterator(options)\n    this._iterators.push(it)\n    return it\n  }\n}\n\nclosed(DeferredLevelDOWN.prototype)\n\nDeferredLevelDOWN.prototype._isBuffer = function (obj) {\n  return Buffer.isBuffer(obj)\n}\n\nDeferredLevelDOWN.prototype._serializeKey = function (key) {\n  return key\n}\n\nDeferredLevelDOWN.prototype._serializeValue = function (value) {\n  return value\n}\n\nmodule.exports = DeferredLevelDOWN\nmodule.exports.DeferredIterator = DeferredIterator\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(24).Buffer))\n\n/***/ }),\n/* 579 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nexports.byteLength = byteLength\nexports.toByteArray = toByteArray\nexports.fromByteArray = fromByteArray\n\nvar lookup = []\nvar revLookup = []\nvar Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array\n\nvar code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\nfor (var i = 0, len = code.length; i < len; ++i) {\n  lookup[i] = code[i]\n  revLookup[code.charCodeAt(i)] = i\n}\n\n// Support decoding URL-safe base64 strings, as Node.js does.\n// See: https://en.wikipedia.org/wiki/Base64#URL_applications\nrevLookup['-'.charCodeAt(0)] = 62\nrevLookup['_'.charCodeAt(0)] = 63\n\nfunction getLens (b64) {\n  var len = b64.length\n\n  if (len % 4 > 0) {\n    throw new Error('Invalid string. Length must be a multiple of 4')\n  }\n\n  // Trim off extra bytes after placeholder bytes are found\n  // See: https://github.com/beatgammit/base64-js/issues/42\n  var validLen = b64.indexOf('=')\n  if (validLen === -1) validLen = len\n\n  var placeHoldersLen = validLen === len\n    ? 0\n    : 4 - (validLen % 4)\n\n  return [validLen, placeHoldersLen]\n}\n\n// base64 is 4/3 + up to two characters of the original data\nfunction byteLength (b64) {\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction _byteLength (b64, validLen, placeHoldersLen) {\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction toByteArray (b64) {\n  var tmp\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n\n  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))\n\n  var curByte = 0\n\n  // if there are placeholders, only get up to the last complete 4 chars\n  var len = placeHoldersLen > 0\n    ? validLen - 4\n    : validLen\n\n  for (var i = 0; i < len; i += 4) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 18) |\n      (revLookup[b64.charCodeAt(i + 1)] << 12) |\n      (revLookup[b64.charCodeAt(i + 2)] << 6) |\n      revLookup[b64.charCodeAt(i + 3)]\n    arr[curByte++] = (tmp >> 16) & 0xFF\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 2) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 2) |\n      (revLookup[b64.charCodeAt(i + 1)] >> 4)\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 1) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 10) |\n      (revLookup[b64.charCodeAt(i + 1)] << 4) |\n      (revLookup[b64.charCodeAt(i + 2)] >> 2)\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  return arr\n}\n\nfunction tripletToBase64 (num) {\n  return lookup[num >> 18 & 0x3F] +\n    lookup[num >> 12 & 0x3F] +\n    lookup[num >> 6 & 0x3F] +\n    lookup[num & 0x3F]\n}\n\nfunction encodeChunk (uint8, start, end) {\n  var tmp\n  var output = []\n  for (var i = start; i < end; i += 3) {\n    tmp =\n      ((uint8[i] << 16) & 0xFF0000) +\n      ((uint8[i + 1] << 8) & 0xFF00) +\n      (uint8[i + 2] & 0xFF)\n    output.push(tripletToBase64(tmp))\n  }\n  return output.join('')\n}\n\nfunction fromByteArray (uint8) {\n  var tmp\n  var len = uint8.length\n  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes\n  var parts = []\n  var maxChunkLength = 16383 // must be multiple of 3\n\n  // go through the array every three bytes, we'll deal with trailing stuff later\n  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {\n    parts.push(encodeChunk(\n      uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)\n    ))\n  }\n\n  // pad the end with zeros, but make sure to not forget the extra bytes\n  if (extraBytes === 1) {\n    tmp = uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 2] +\n      lookup[(tmp << 4) & 0x3F] +\n      '=='\n    )\n  } else if (extraBytes === 2) {\n    tmp = (uint8[len - 2] << 8) + uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 10] +\n      lookup[(tmp >> 4) & 0x3F] +\n      lookup[(tmp << 2) & 0x3F] +\n      '='\n    )\n  }\n\n  return parts.join('')\n}\n\n\n/***/ }),\n/* 580 */\n/***/ (function(module, exports) {\n\nexports.read = function (buffer, offset, isLE, mLen, nBytes) {\n  var e, m\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var nBits = -7\n  var i = isLE ? (nBytes - 1) : 0\n  var d = isLE ? -1 : 1\n  var s = buffer[offset + i]\n\n  i += d\n\n  e = s & ((1 << (-nBits)) - 1)\n  s >>= (-nBits)\n  nBits += eLen\n  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  m = e & ((1 << (-nBits)) - 1)\n  e >>= (-nBits)\n  nBits += mLen\n  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  if (e === 0) {\n    e = 1 - eBias\n  } else if (e === eMax) {\n    return m ? NaN : ((s ? -1 : 1) * Infinity)\n  } else {\n    m = m + Math.pow(2, mLen)\n    e = e - eBias\n  }\n  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)\n}\n\nexports.write = function (buffer, value, offset, isLE, mLen, nBytes) {\n  var e, m, c\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)\n  var i = isLE ? 0 : (nBytes - 1)\n  var d = isLE ? 1 : -1\n  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0\n\n  value = Math.abs(value)\n\n  if (isNaN(value) || value === Infinity) {\n    m = isNaN(value) ? 1 : 0\n    e = eMax\n  } else {\n    e = Math.floor(Math.log(value) / Math.LN2)\n    if (value * (c = Math.pow(2, -e)) < 1) {\n      e--\n      c *= 2\n    }\n    if (e + eBias >= 1) {\n      value += rt / c\n    } else {\n      value += rt * Math.pow(2, 1 - eBias)\n    }\n    if (value * c >= 2) {\n      e++\n      c /= 2\n    }\n\n    if (e + eBias >= eMax) {\n      m = 0\n      e = eMax\n    } else if (e + eBias >= 1) {\n      m = ((value * c) - 1) * Math.pow(2, mLen)\n      e = e + eBias\n    } else {\n      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)\n      e = 0\n    }\n  }\n\n  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}\n\n  e = (e << mLen) | m\n  eLen += mLen\n  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}\n\n  buffer[offset + i - d] |= s * 128\n}\n\n\n/***/ }),\n/* 581 */\n/***/ (function(module, exports) {\n\nvar toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n\n\n/***/ }),\n/* 582 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar AbstractLevelDOWN = __webpack_require__(189)\n\nfunction isLevelDOWN (db) {\n  if (!db || typeof db !== 'object')\n    return false\n  return Object.keys(AbstractLevelDOWN.prototype).filter(function (name) {\n    // TODO remove approximateSize check when method is gone\n    return name[0] != '_' && name != 'approximateSize'\n  }).every(function (name) {\n    return typeof db[name] == 'function'\n  })\n}\n\nmodule.exports = isLevelDOWN\n\n\n/***/ }),\n/* 583 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar util = __webpack_require__(65)\nvar AbstractIterator = __webpack_require__(188).AbstractIterator\n\nfunction DeferredIterator (options) {\n  AbstractIterator.call(this, options)\n\n  this._options = options\n  this._iterator = null\n  this._operations = []\n}\n\nutil.inherits(DeferredIterator, AbstractIterator)\n\nDeferredIterator.prototype.setDb = function (db) {\n  var it = this._iterator = db.iterator(this._options)\n  this._operations.forEach(function (op) {\n    it[op.method].apply(it, op.args)\n  })\n}\n\nDeferredIterator.prototype._operation = function (method, args) {\n  if (this._iterator) return this._iterator[method].apply(this._iterator, args)\n  this._operations.push({ method: method, args: args })\n}\n\n'next end'.split(' ').forEach(function (m) {\n  DeferredIterator.prototype['_' + m] = function () {\n    this._operation(m, arguments)\n  }\n})\n\nmodule.exports = DeferredIterator\n\n\n/***/ }),\n/* 584 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar inherits = __webpack_require__(6)\nvar Readable = __webpack_require__(585).Readable\nvar extend = __webpack_require__(66)\n\nmodule.exports = ReadStream\ninherits(ReadStream, Readable)\n\nfunction ReadStream (iterator, options) {\n  if (!(this instanceof ReadStream)) return new ReadStream(iterator, options)\n  options = options || {}\n  Readable.call(this, extend(options, {\n    objectMode: true\n  }))\n  this._iterator = iterator\n  this._destroyed = false\n  this._options = options\n  this.on('end', this._cleanup.bind(this))\n}\n\nReadStream.prototype._read = function () {\n  var self = this\n  var options = this._options\n  if (this._destroyed) return\n\n  this._iterator.next(function (err, key, value) {\n    if (self._destroyed) return\n    if (err) return self.emit('error', err)\n    if (key === undefined && value === undefined) {\n      self.push(null)\n    } else if (options.keys !== false && options.values === false) {\n      self.push(key)\n    } else if (options.keys === false && options.values !== false) {\n      self.push(value)\n    } else {\n      self.push({ key: key, value: value })\n    }\n  })\n}\n\nReadStream.prototype.destroy =\nReadStream.prototype._cleanup = function () {\n  var self = this\n  if (this._destroyed) return\n  this._destroyed = true\n\n  this._iterator.end(function (err) {\n    if (err) return self.emit('error', err)\n    self.emit('close')\n  })\n}\n\n\n/***/ }),\n/* 585 */\n/***/ (function(module, exports, __webpack_require__) {\n\nexports = module.exports = __webpack_require__(192);\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = __webpack_require__(195);\nexports.Duplex = __webpack_require__(60);\nexports.Transform = __webpack_require__(196);\nexports.PassThrough = __webpack_require__(591);\n\n\n/***/ }),\n/* 586 */\n/***/ (function(module, exports) {\n\nvar toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n\n\n/***/ }),\n/* 587 */\n/***/ (function(module, exports) {\n\n/* (ignored) */\n\n/***/ }),\n/* 588 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = __webpack_require__(35).Buffer;\nvar util = __webpack_require__(589);\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}\n\n/***/ }),\n/* 589 */\n/***/ (function(module, exports) {\n\n/* (ignored) */\n\n/***/ }),\n/* 590 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(global, process) {(function (global, undefined) {\n    \"use strict\";\n\n    if (global.setImmediate) {\n        return;\n    }\n\n    var nextHandle = 1; // Spec says greater than zero\n    var tasksByHandle = {};\n    var currentlyRunningATask = false;\n    var doc = global.document;\n    var registerImmediate;\n\n    function setImmediate(callback) {\n      // Callback can either be a function or a string\n      if (typeof callback !== \"function\") {\n        callback = new Function(\"\" + callback);\n      }\n      // Copy function arguments\n      var args = new Array(arguments.length - 1);\n      for (var i = 0; i < args.length; i++) {\n          args[i] = arguments[i + 1];\n      }\n      // Store and register the task\n      var task = { callback: callback, args: args };\n      tasksByHandle[nextHandle] = task;\n      registerImmediate(nextHandle);\n      return nextHandle++;\n    }\n\n    function clearImmediate(handle) {\n        delete tasksByHandle[handle];\n    }\n\n    function run(task) {\n        var callback = task.callback;\n        var args = task.args;\n        switch (args.length) {\n        case 0:\n            callback();\n            break;\n        case 1:\n            callback(args[0]);\n            break;\n        case 2:\n            callback(args[0], args[1]);\n            break;\n        case 3:\n            callback(args[0], args[1], args[2]);\n            break;\n        default:\n            callback.apply(undefined, args);\n            break;\n        }\n    }\n\n    function runIfPresent(handle) {\n        // From the spec: \"Wait until any invocations of this algorithm started before this one have completed.\"\n        // So if we're currently running a task, we'll need to delay this invocation.\n        if (currentlyRunningATask) {\n            // Delay by doing a setTimeout. setImmediate was tried instead, but in Firefox 7 it generated a\n            // \"too much recursion\" error.\n            setTimeout(runIfPresent, 0, handle);\n        } else {\n            var task = tasksByHandle[handle];\n            if (task) {\n                currentlyRunningATask = true;\n                try {\n                    run(task);\n                } finally {\n                    clearImmediate(handle);\n                    currentlyRunningATask = false;\n                }\n            }\n        }\n    }\n\n    function installNextTickImplementation() {\n        registerImmediate = function(handle) {\n            process.nextTick(function () { runIfPresent(handle); });\n        };\n    }\n\n    function canUsePostMessage() {\n        // The test against `importScripts` prevents this implementation from being installed inside a web worker,\n        // where `global.postMessage` means something completely different and can't be used for this purpose.\n        if (global.postMessage && !global.importScripts) {\n            var postMessageIsAsynchronous = true;\n            var oldOnMessage = global.onmessage;\n            global.onmessage = function() {\n                postMessageIsAsynchronous = false;\n            };\n            global.postMessage(\"\", \"*\");\n            global.onmessage = oldOnMessage;\n            return postMessageIsAsynchronous;\n        }\n    }\n\n    function installPostMessageImplementation() {\n        // Installs an event handler on `global` for the `message` event: see\n        // * https://developer.mozilla.org/en/DOM/window.postMessage\n        // * http://www.whatwg.org/specs/web-apps/current-work/multipage/comms.html#crossDocumentMessages\n\n        var messagePrefix = \"setImmediate$\" + Math.random() + \"$\";\n        var onGlobalMessage = function(event) {\n            if (event.source === global &&\n                typeof event.data === \"string\" &&\n                event.data.indexOf(messagePrefix) === 0) {\n                runIfPresent(+event.data.slice(messagePrefix.length));\n            }\n        };\n\n        if (global.addEventListener) {\n            global.addEventListener(\"message\", onGlobalMessage, false);\n        } else {\n            global.attachEvent(\"onmessage\", onGlobalMessage);\n        }\n\n        registerImmediate = function(handle) {\n            global.postMessage(messagePrefix + handle, \"*\");\n        };\n    }\n\n    function installMessageChannelImplementation() {\n        var channel = new MessageChannel();\n        channel.port1.onmessage = function(event) {\n            var handle = event.data;\n            runIfPresent(handle);\n        };\n\n        registerImmediate = function(handle) {\n            channel.port2.postMessage(handle);\n        };\n    }\n\n    function installReadyStateChangeImplementation() {\n        var html = doc.documentElement;\n        registerImmediate = function(handle) {\n            // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n            // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n            var script = doc.createElement(\"script\");\n            script.onreadystatechange = function () {\n                runIfPresent(handle);\n                script.onreadystatechange = null;\n                html.removeChild(script);\n                script = null;\n            };\n            html.appendChild(script);\n        };\n    }\n\n    function installSetTimeoutImplementation() {\n        registerImmediate = function(handle) {\n            setTimeout(runIfPresent, 0, handle);\n        };\n    }\n\n    // If supported, we should attach to the prototype of global, since that is where setTimeout et al. live.\n    var attachTo = Object.getPrototypeOf && Object.getPrototypeOf(global);\n    attachTo = attachTo && attachTo.setTimeout ? attachTo : global;\n\n    // Don't get fooled by e.g. browserify environments.\n    if ({}.toString.call(global.process) === \"[object process]\") {\n        // For Node.js before 0.9\n        installNextTickImplementation();\n\n    } else if (canUsePostMessage()) {\n        // For non-IE10 modern browsers\n        installPostMessageImplementation();\n\n    } else if (global.MessageChannel) {\n        // For web workers, where supported\n        installMessageChannelImplementation();\n\n    } else if (doc && \"onreadystatechange\" in doc.createElement(\"script\")) {\n        // For IE 68\n        installReadyStateChangeImplementation();\n\n    } else {\n        // For older browsers\n        installSetTimeoutImplementation();\n    }\n\n    attachTo.setImmediate = setImmediate;\n    attachTo.clearImmediate = clearImmediate;\n}(typeof self === \"undefined\" ? typeof global === \"undefined\" ? this : global : self));\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12), __webpack_require__(8)))\n\n/***/ }),\n/* 591 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n\n\nmodule.exports = PassThrough;\n\nvar Transform = __webpack_require__(196);\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};\n\n/***/ }),\n/* 592 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* Copyright (c) 2012-2017 LevelUP contributors\n * See list at <https://github.com/level/levelup#contributing>\n * MIT License\n * <https://github.com/level/levelup/blob/master/LICENSE.md>\n */\n\nvar WriteError = __webpack_require__(197).WriteError\nvar promisify = __webpack_require__(198)\n\nfunction Batch (levelup) {\n  this._levelup = levelup\n  this.batch = levelup.db.batch()\n  this.ops = []\n  this.length = 0\n}\n\nBatch.prototype.put = function (key, value) {\n  try {\n    this.batch.put(key, value)\n  } catch (e) {\n    throw new WriteError(e)\n  }\n\n  this.ops.push({ type: 'put', key: key, value: value })\n  this.length++\n\n  return this\n}\n\nBatch.prototype.del = function (key) {\n  try {\n    this.batch.del(key)\n  } catch (err) {\n    throw new WriteError(err)\n  }\n\n  this.ops.push({ type: 'del', key: key })\n  this.length++\n\n  return this\n}\n\nBatch.prototype.clear = function () {\n  try {\n    this.batch.clear()\n  } catch (err) {\n    throw new WriteError(err)\n  }\n\n  this.ops = []\n  this.length = 0\n\n  return this\n}\n\nBatch.prototype.write = function (callback) {\n  var levelup = this._levelup\n  var ops = this.ops\n  var promise\n\n  if (!callback) {\n    callback = promisify()\n    promise = callback.promise\n  }\n\n  try {\n    this.batch.write(function (err) {\n      if (err) { return callback(new WriteError(err)) }\n      levelup.emit('batch', ops)\n      callback()\n    })\n  } catch (err) {\n    throw new WriteError(err)\n  }\n\n  return promise\n}\n\nmodule.exports = Batch\n\n\n/***/ }),\n/* 593 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar all = module.exports.all = [\n  {\n    errno: -2,\n    code: 'ENOENT',\n    description: 'no such file or directory'\n  },\n  {\n    errno: -1,\n    code: 'UNKNOWN',\n    description: 'unknown error'\n  },\n  {\n    errno: 0,\n    code: 'OK',\n    description: 'success'\n  },\n  {\n    errno: 1,\n    code: 'EOF',\n    description: 'end of file'\n  },\n  {\n    errno: 2,\n    code: 'EADDRINFO',\n    description: 'getaddrinfo error'\n  },\n  {\n    errno: 3,\n    code: 'EACCES',\n    description: 'permission denied'\n  },\n  {\n    errno: 4,\n    code: 'EAGAIN',\n    description: 'resource temporarily unavailable'\n  },\n  {\n    errno: 5,\n    code: 'EADDRINUSE',\n    description: 'address already in use'\n  },\n  {\n    errno: 6,\n    code: 'EADDRNOTAVAIL',\n    description: 'address not available'\n  },\n  {\n    errno: 7,\n    code: 'EAFNOSUPPORT',\n    description: 'address family not supported'\n  },\n  {\n    errno: 8,\n    code: 'EALREADY',\n    description: 'connection already in progress'\n  },\n  {\n    errno: 9,\n    code: 'EBADF',\n    description: 'bad file descriptor'\n  },\n  {\n    errno: 10,\n    code: 'EBUSY',\n    description: 'resource busy or locked'\n  },\n  {\n    errno: 11,\n    code: 'ECONNABORTED',\n    description: 'software caused connection abort'\n  },\n  {\n    errno: 12,\n    code: 'ECONNREFUSED',\n    description: 'connection refused'\n  },\n  {\n    errno: 13,\n    code: 'ECONNRESET',\n    description: 'connection reset by peer'\n  },\n  {\n    errno: 14,\n    code: 'EDESTADDRREQ',\n    description: 'destination address required'\n  },\n  {\n    errno: 15,\n    code: 'EFAULT',\n    description: 'bad address in system call argument'\n  },\n  {\n    errno: 16,\n    code: 'EHOSTUNREACH',\n    description: 'host is unreachable'\n  },\n  {\n    errno: 17,\n    code: 'EINTR',\n    description: 'interrupted system call'\n  },\n  {\n    errno: 18,\n    code: 'EINVAL',\n    description: 'invalid argument'\n  },\n  {\n    errno: 19,\n    code: 'EISCONN',\n    description: 'socket is already connected'\n  },\n  {\n    errno: 20,\n    code: 'EMFILE',\n    description: 'too many open files'\n  },\n  {\n    errno: 21,\n    code: 'EMSGSIZE',\n    description: 'message too long'\n  },\n  {\n    errno: 22,\n    code: 'ENETDOWN',\n    description: 'network is down'\n  },\n  {\n    errno: 23,\n    code: 'ENETUNREACH',\n    description: 'network is unreachable'\n  },\n  {\n    errno: 24,\n    code: 'ENFILE',\n    description: 'file table overflow'\n  },\n  {\n    errno: 25,\n    code: 'ENOBUFS',\n    description: 'no buffer space available'\n  },\n  {\n    errno: 26,\n    code: 'ENOMEM',\n    description: 'not enough memory'\n  },\n  {\n    errno: 27,\n    code: 'ENOTDIR',\n    description: 'not a directory'\n  },\n  {\n    errno: 28,\n    code: 'EISDIR',\n    description: 'illegal operation on a directory'\n  },\n  {\n    errno: 29,\n    code: 'ENONET',\n    description: 'machine is not on the network'\n  },\n  {\n    errno: 31,\n    code: 'ENOTCONN',\n    description: 'socket is not connected'\n  },\n  {\n    errno: 32,\n    code: 'ENOTSOCK',\n    description: 'socket operation on non-socket'\n  },\n  {\n    errno: 33,\n    code: 'ENOTSUP',\n    description: 'operation not supported on socket'\n  },\n  {\n    errno: 34,\n    code: 'ENOENT',\n    description: 'no such file or directory'\n  },\n  {\n    errno: 35,\n    code: 'ENOSYS',\n    description: 'function not implemented'\n  },\n  {\n    errno: 36,\n    code: 'EPIPE',\n    description: 'broken pipe'\n  },\n  {\n    errno: 37,\n    code: 'EPROTO',\n    description: 'protocol error'\n  },\n  {\n    errno: 38,\n    code: 'EPROTONOSUPPORT',\n    description: 'protocol not supported'\n  },\n  {\n    errno: 39,\n    code: 'EPROTOTYPE',\n    description: 'protocol wrong type for socket'\n  },\n  {\n    errno: 40,\n    code: 'ETIMEDOUT',\n    description: 'connection timed out'\n  },\n  {\n    errno: 41,\n    code: 'ECHARSET',\n    description: 'invalid Unicode character'\n  },\n  {\n    errno: 42,\n    code: 'EAIFAMNOSUPPORT',\n    description: 'address family for hostname not supported'\n  },\n  {\n    errno: 44,\n    code: 'EAISERVICE',\n    description: 'servname not supported for ai_socktype'\n  },\n  {\n    errno: 45,\n    code: 'EAISOCKTYPE',\n    description: 'ai_socktype not supported'\n  },\n  {\n    errno: 46,\n    code: 'ESHUTDOWN',\n    description: 'cannot send after transport endpoint shutdown'\n  },\n  {\n    errno: 47,\n    code: 'EEXIST',\n    description: 'file already exists'\n  },\n  {\n    errno: 48,\n    code: 'ESRCH',\n    description: 'no such process'\n  },\n  {\n    errno: 49,\n    code: 'ENAMETOOLONG',\n    description: 'name too long'\n  },\n  {\n    errno: 50,\n    code: 'EPERM',\n    description: 'operation not permitted'\n  },\n  {\n    errno: 51,\n    code: 'ELOOP',\n    description: 'too many symbolic links encountered'\n  },\n  {\n    errno: 52,\n    code: 'EXDEV',\n    description: 'cross-device link not permitted'\n  },\n  {\n    errno: 53,\n    code: 'ENOTEMPTY',\n    description: 'directory not empty'\n  },\n  {\n    errno: 54,\n    code: 'ENOSPC',\n    description: 'no space left on device'\n  },\n  {\n    errno: 55,\n    code: 'EIO',\n    description: 'i/o error'\n  },\n  {\n    errno: 56,\n    code: 'EROFS',\n    description: 'read-only file system'\n  },\n  {\n    errno: 57,\n    code: 'ENODEV',\n    description: 'no such device'\n  },\n  {\n    errno: 58,\n    code: 'ESPIPE',\n    description: 'invalid seek'\n  },\n  {\n    errno: 59,\n    code: 'ECANCELED',\n    description: 'operation canceled'\n  }\n]\n\nmodule.exports.errno = {}\nmodule.exports.code = {}\n\nall.forEach(function (error) {\n  module.exports.errno[error.errno] = error\n  module.exports.code[error.code] = error\n})\n\nmodule.exports.custom = __webpack_require__(594)(module.exports)\nmodule.exports.create = module.exports.custom.createError\n\n\n/***/ }),\n/* 594 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar prr = __webpack_require__(595)\n\nfunction init (type, message, cause) {\n  if (!!message && typeof message != 'string') {\n    message = message.message || message.name\n  }\n  prr(this, {\n      type    : type\n    , name    : type\n      // can be passed just a 'cause'\n    , cause   : typeof message != 'string' ? message : cause\n    , message : message\n  }, 'ewr')\n}\n\n// generic prototype, not intended to be actually used - helpful for `instanceof`\nfunction CustomError (message, cause) {\n  Error.call(this)\n  if (Error.captureStackTrace)\n    Error.captureStackTrace(this, this.constructor)\n  init.call(this, 'CustomError', message, cause)\n}\n\nCustomError.prototype = new Error()\n\nfunction createError (errno, type, proto) {\n  var err = function (message, cause) {\n    init.call(this, type, message, cause)\n    //TODO: the specificity here is stupid, errno should be available everywhere\n    if (type == 'FilesystemError') {\n      this.code    = this.cause.code\n      this.path    = this.cause.path\n      this.errno   = this.cause.errno\n      this.message =\n        (errno.errno[this.cause.errno]\n          ? errno.errno[this.cause.errno].description\n          : this.cause.message)\n        + (this.cause.path ? ' [' + this.cause.path + ']' : '')\n    }\n    Error.call(this)\n    if (Error.captureStackTrace)\n      Error.captureStackTrace(this, err)\n  }\n  err.prototype = !!proto ? new proto() : new CustomError()\n  return err\n}\n\nmodule.exports = function (errno) {\n  var ce = function (type, proto) {\n    return createError(errno, type, proto)\n  }\n  return {\n      CustomError     : CustomError\n    , FilesystemError : ce('FilesystemError')\n    , createError     : ce\n  }\n}\n\n\n/***/ }),\n/* 595 */\n/***/ (function(module, exports) {\n\n/*!\n  * prr\n  * (c) 2013 Rod Vagg <rod@vagg.org>\n  * https://github.com/rvagg/prr\n  * License: MIT\n  */\n\n(function (name, context, definition) {\n  if (typeof module != 'undefined' && module.exports)\n    module.exports = definition()\n  else\n    context[name] = definition()\n})('prr', this, function() {\n\n  var setProperty = typeof Object.defineProperty == 'function'\n      ? function (obj, key, options) {\n          Object.defineProperty(obj, key, options)\n          return obj\n        }\n      : function (obj, key, options) { // < es5\n          obj[key] = options.value\n          return obj\n        }\n\n    , makeOptions = function (value, options) {\n        var oo = typeof options == 'object'\n          , os = !oo && typeof options == 'string'\n          , op = function (p) {\n              return oo\n                ? !!options[p]\n                : os\n                  ? options.indexOf(p[0]) > -1\n                  : false\n            }\n\n        return {\n            enumerable   : op('enumerable')\n          , configurable : op('configurable')\n          , writable     : op('writable')\n          , value        : value\n        }\n      }\n\n    , prr = function (obj, key, value, options) {\n        var k\n\n        options = makeOptions(value, options)\n\n        if (typeof key == 'object') {\n          for (k in key) {\n            if (Object.hasOwnProperty.call(key, k)) {\n              options.value = key[k]\n              setProperty(obj, k, options)\n            }\n          }\n          return obj\n        }\n\n        return setProperty(obj, key, options)\n      }\n\n  return prr\n})\n\n/***/ }),\n/* 596 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global) {\n\n// compare and isBuffer taken from https://github.com/feross/buffer/blob/680e9e5e488f22aac27599a57dc844a6315928dd/index.js\n// original notice:\n\n/*!\n * The buffer module from node.js, for the browser.\n *\n * @author   Feross Aboukhadijeh <feross@feross.org> <http://feross.org>\n * @license  MIT\n */\nfunction compare(a, b) {\n  if (a === b) {\n    return 0;\n  }\n\n  var x = a.length;\n  var y = b.length;\n\n  for (var i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (a[i] !== b[i]) {\n      x = a[i];\n      y = b[i];\n      break;\n    }\n  }\n\n  if (x < y) {\n    return -1;\n  }\n  if (y < x) {\n    return 1;\n  }\n  return 0;\n}\nfunction isBuffer(b) {\n  if (global.Buffer && typeof global.Buffer.isBuffer === 'function') {\n    return global.Buffer.isBuffer(b);\n  }\n  return !!(b != null && b._isBuffer);\n}\n\n// based on node assert, original notice:\n\n// http://wiki.commonjs.org/wiki/Unit_Testing/1.0\n//\n// THIS IS NOT TESTED NOR LIKELY TO WORK OUTSIDE V8!\n//\n// Originally from narwhal.js (http://narwhaljs.org)\n// Copyright (c) 2009 Thomas Robinson <280north.com>\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the 'Software'), to\n// deal in the Software without restriction, including without limitation the\n// rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n// sell copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n// ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n// WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar util = __webpack_require__(65);\nvar hasOwn = Object.prototype.hasOwnProperty;\nvar pSlice = Array.prototype.slice;\nvar functionsHaveNames = (function () {\n  return function foo() {}.name === 'foo';\n}());\nfunction pToString (obj) {\n  return Object.prototype.toString.call(obj);\n}\nfunction isView(arrbuf) {\n  if (isBuffer(arrbuf)) {\n    return false;\n  }\n  if (typeof global.ArrayBuffer !== 'function') {\n    return false;\n  }\n  if (typeof ArrayBuffer.isView === 'function') {\n    return ArrayBuffer.isView(arrbuf);\n  }\n  if (!arrbuf) {\n    return false;\n  }\n  if (arrbuf instanceof DataView) {\n    return true;\n  }\n  if (arrbuf.buffer && arrbuf.buffer instanceof ArrayBuffer) {\n    return true;\n  }\n  return false;\n}\n// 1. The assert module provides functions that throw\n// AssertionError's when particular conditions are not met. The\n// assert module must conform to the following interface.\n\nvar assert = module.exports = ok;\n\n// 2. The AssertionError is defined in assert.\n// new assert.AssertionError({ message: message,\n//                             actual: actual,\n//                             expected: expected })\n\nvar regex = /\\s*function\\s+([^\\(\\s]*)\\s*/;\n// based on https://github.com/ljharb/function.prototype.name/blob/adeeeec8bfcc6068b187d7d9fb3d5bb1d3a30899/implementation.js\nfunction getName(func) {\n  if (!util.isFunction(func)) {\n    return;\n  }\n  if (functionsHaveNames) {\n    return func.name;\n  }\n  var str = func.toString();\n  var match = str.match(regex);\n  return match && match[1];\n}\nassert.AssertionError = function AssertionError(options) {\n  this.name = 'AssertionError';\n  this.actual = options.actual;\n  this.expected = options.expected;\n  this.operator = options.operator;\n  if (options.message) {\n    this.message = options.message;\n    this.generatedMessage = false;\n  } else {\n    this.message = getMessage(this);\n    this.generatedMessage = true;\n  }\n  var stackStartFunction = options.stackStartFunction || fail;\n  if (Error.captureStackTrace) {\n    Error.captureStackTrace(this, stackStartFunction);\n  } else {\n    // non v8 browsers so we can have a stacktrace\n    var err = new Error();\n    if (err.stack) {\n      var out = err.stack;\n\n      // try to strip useless frames\n      var fn_name = getName(stackStartFunction);\n      var idx = out.indexOf('\\n' + fn_name);\n      if (idx >= 0) {\n        // once we have located the function frame\n        // we need to strip out everything before it (and its line)\n        var next_line = out.indexOf('\\n', idx + 1);\n        out = out.substring(next_line + 1);\n      }\n\n      this.stack = out;\n    }\n  }\n};\n\n// assert.AssertionError instanceof Error\nutil.inherits(assert.AssertionError, Error);\n\nfunction truncate(s, n) {\n  if (typeof s === 'string') {\n    return s.length < n ? s : s.slice(0, n);\n  } else {\n    return s;\n  }\n}\nfunction inspect(something) {\n  if (functionsHaveNames || !util.isFunction(something)) {\n    return util.inspect(something);\n  }\n  var rawname = getName(something);\n  var name = rawname ? ': ' + rawname : '';\n  return '[Function' +  name + ']';\n}\nfunction getMessage(self) {\n  return truncate(inspect(self.actual), 128) + ' ' +\n         self.operator + ' ' +\n         truncate(inspect(self.expected), 128);\n}\n\n// At present only the three keys mentioned above are used and\n// understood by the spec. Implementations or sub modules can pass\n// other keys to the AssertionError's constructor - they will be\n// ignored.\n\n// 3. All of the following functions must throw an AssertionError\n// when a corresponding condition is not met, with a message that\n// may be undefined if not provided.  All assertion methods provide\n// both the actual and expected values to the assertion error for\n// display purposes.\n\nfunction fail(actual, expected, message, operator, stackStartFunction) {\n  throw new assert.AssertionError({\n    message: message,\n    actual: actual,\n    expected: expected,\n    operator: operator,\n    stackStartFunction: stackStartFunction\n  });\n}\n\n// EXTENSION! allows for well behaved errors defined elsewhere.\nassert.fail = fail;\n\n// 4. Pure assertion tests whether a value is truthy, as determined\n// by !!guard.\n// assert.ok(guard, message_opt);\n// This statement is equivalent to assert.equal(true, !!guard,\n// message_opt);. To test strictly for the value true, use\n// assert.strictEqual(true, guard, message_opt);.\n\nfunction ok(value, message) {\n  if (!value) fail(value, true, message, '==', assert.ok);\n}\nassert.ok = ok;\n\n// 5. The equality assertion tests shallow, coercive equality with\n// ==.\n// assert.equal(actual, expected, message_opt);\n\nassert.equal = function equal(actual, expected, message) {\n  if (actual != expected) fail(actual, expected, message, '==', assert.equal);\n};\n\n// 6. The non-equality assertion tests for whether two objects are not equal\n// with != assert.notEqual(actual, expected, message_opt);\n\nassert.notEqual = function notEqual(actual, expected, message) {\n  if (actual == expected) {\n    fail(actual, expected, message, '!=', assert.notEqual);\n  }\n};\n\n// 7. The equivalence assertion tests a deep equality relation.\n// assert.deepEqual(actual, expected, message_opt);\n\nassert.deepEqual = function deepEqual(actual, expected, message) {\n  if (!_deepEqual(actual, expected, false)) {\n    fail(actual, expected, message, 'deepEqual', assert.deepEqual);\n  }\n};\n\nassert.deepStrictEqual = function deepStrictEqual(actual, expected, message) {\n  if (!_deepEqual(actual, expected, true)) {\n    fail(actual, expected, message, 'deepStrictEqual', assert.deepStrictEqual);\n  }\n};\n\nfunction _deepEqual(actual, expected, strict, memos) {\n  // 7.1. All identical values are equivalent, as determined by ===.\n  if (actual === expected) {\n    return true;\n  } else if (isBuffer(actual) && isBuffer(expected)) {\n    return compare(actual, expected) === 0;\n\n  // 7.2. If the expected value is a Date object, the actual value is\n  // equivalent if it is also a Date object that refers to the same time.\n  } else if (util.isDate(actual) && util.isDate(expected)) {\n    return actual.getTime() === expected.getTime();\n\n  // 7.3 If the expected value is a RegExp object, the actual value is\n  // equivalent if it is also a RegExp object with the same source and\n  // properties (`global`, `multiline`, `lastIndex`, `ignoreCase`).\n  } else if (util.isRegExp(actual) && util.isRegExp(expected)) {\n    return actual.source === expected.source &&\n           actual.global === expected.global &&\n           actual.multiline === expected.multiline &&\n           actual.lastIndex === expected.lastIndex &&\n           actual.ignoreCase === expected.ignoreCase;\n\n  // 7.4. Other pairs that do not both pass typeof value == 'object',\n  // equivalence is determined by ==.\n  } else if ((actual === null || typeof actual !== 'object') &&\n             (expected === null || typeof expected !== 'object')) {\n    return strict ? actual === expected : actual == expected;\n\n  // If both values are instances of typed arrays, wrap their underlying\n  // ArrayBuffers in a Buffer each to increase performance\n  // This optimization requires the arrays to have the same type as checked by\n  // Object.prototype.toString (aka pToString). Never perform binary\n  // comparisons for Float*Arrays, though, since e.g. +0 === -0 but their\n  // bit patterns are not identical.\n  } else if (isView(actual) && isView(expected) &&\n             pToString(actual) === pToString(expected) &&\n             !(actual instanceof Float32Array ||\n               actual instanceof Float64Array)) {\n    return compare(new Uint8Array(actual.buffer),\n                   new Uint8Array(expected.buffer)) === 0;\n\n  // 7.5 For all other Object pairs, including Array objects, equivalence is\n  // determined by having the same number of owned properties (as verified\n  // with Object.prototype.hasOwnProperty.call), the same set of keys\n  // (although not necessarily the same order), equivalent values for every\n  // corresponding key, and an identical 'prototype' property. Note: this\n  // accounts for both named and indexed properties on Arrays.\n  } else if (isBuffer(actual) !== isBuffer(expected)) {\n    return false;\n  } else {\n    memos = memos || {actual: [], expected: []};\n\n    var actualIndex = memos.actual.indexOf(actual);\n    if (actualIndex !== -1) {\n      if (actualIndex === memos.expected.indexOf(expected)) {\n        return true;\n      }\n    }\n\n    memos.actual.push(actual);\n    memos.expected.push(expected);\n\n    return objEquiv(actual, expected, strict, memos);\n  }\n}\n\nfunction isArguments(object) {\n  return Object.prototype.toString.call(object) == '[object Arguments]';\n}\n\nfunction objEquiv(a, b, strict, actualVisitedObjects) {\n  if (a === null || a === undefined || b === null || b === undefined)\n    return false;\n  // if one is a primitive, the other must be same\n  if (util.isPrimitive(a) || util.isPrimitive(b))\n    return a === b;\n  if (strict && Object.getPrototypeOf(a) !== Object.getPrototypeOf(b))\n    return false;\n  var aIsArgs = isArguments(a);\n  var bIsArgs = isArguments(b);\n  if ((aIsArgs && !bIsArgs) || (!aIsArgs && bIsArgs))\n    return false;\n  if (aIsArgs) {\n    a = pSlice.call(a);\n    b = pSlice.call(b);\n    return _deepEqual(a, b, strict);\n  }\n  var ka = objectKeys(a);\n  var kb = objectKeys(b);\n  var key, i;\n  // having the same number of owned properties (keys incorporates\n  // hasOwnProperty)\n  if (ka.length !== kb.length)\n    return false;\n  //the same set of keys (although not necessarily the same order),\n  ka.sort();\n  kb.sort();\n  //~~~cheap key test\n  for (i = ka.length - 1; i >= 0; i--) {\n    if (ka[i] !== kb[i])\n      return false;\n  }\n  //equivalent values for every corresponding key, and\n  //~~~possibly expensive deep test\n  for (i = ka.length - 1; i >= 0; i--) {\n    key = ka[i];\n    if (!_deepEqual(a[key], b[key], strict, actualVisitedObjects))\n      return false;\n  }\n  return true;\n}\n\n// 8. The non-equivalence assertion tests for any deep inequality.\n// assert.notDeepEqual(actual, expected, message_opt);\n\nassert.notDeepEqual = function notDeepEqual(actual, expected, message) {\n  if (_deepEqual(actual, expected, false)) {\n    fail(actual, expected, message, 'notDeepEqual', assert.notDeepEqual);\n  }\n};\n\nassert.notDeepStrictEqual = notDeepStrictEqual;\nfunction notDeepStrictEqual(actual, expected, message) {\n  if (_deepEqual(actual, expected, true)) {\n    fail(actual, expected, message, 'notDeepStrictEqual', notDeepStrictEqual);\n  }\n}\n\n\n// 9. The strict equality assertion tests strict equality, as determined by ===.\n// assert.strictEqual(actual, expected, message_opt);\n\nassert.strictEqual = function strictEqual(actual, expected, message) {\n  if (actual !== expected) {\n    fail(actual, expected, message, '===', assert.strictEqual);\n  }\n};\n\n// 10. The strict non-equality assertion tests for strict inequality, as\n// determined by !==.  assert.notStrictEqual(actual, expected, message_opt);\n\nassert.notStrictEqual = function notStrictEqual(actual, expected, message) {\n  if (actual === expected) {\n    fail(actual, expected, message, '!==', assert.notStrictEqual);\n  }\n};\n\nfunction expectedException(actual, expected) {\n  if (!actual || !expected) {\n    return false;\n  }\n\n  if (Object.prototype.toString.call(expected) == '[object RegExp]') {\n    return expected.test(actual);\n  }\n\n  try {\n    if (actual instanceof expected) {\n      return true;\n    }\n  } catch (e) {\n    // Ignore.  The instanceof check doesn't work for arrow functions.\n  }\n\n  if (Error.isPrototypeOf(expected)) {\n    return false;\n  }\n\n  return expected.call({}, actual) === true;\n}\n\nfunction _tryBlock(block) {\n  var error;\n  try {\n    block();\n  } catch (e) {\n    error = e;\n  }\n  return error;\n}\n\nfunction _throws(shouldThrow, block, expected, message) {\n  var actual;\n\n  if (typeof block !== 'function') {\n    throw new TypeError('\"block\" argument must be a function');\n  }\n\n  if (typeof expected === 'string') {\n    message = expected;\n    expected = null;\n  }\n\n  actual = _tryBlock(block);\n\n  message = (expected && expected.name ? ' (' + expected.name + ').' : '.') +\n            (message ? ' ' + message : '.');\n\n  if (shouldThrow && !actual) {\n    fail(actual, expected, 'Missing expected exception' + message);\n  }\n\n  var userProvidedMessage = typeof message === 'string';\n  var isUnwantedException = !shouldThrow && util.isError(actual);\n  var isUnexpectedException = !shouldThrow && actual && !expected;\n\n  if ((isUnwantedException &&\n      userProvidedMessage &&\n      expectedException(actual, expected)) ||\n      isUnexpectedException) {\n    fail(actual, expected, 'Got unwanted exception' + message);\n  }\n\n  if ((shouldThrow && actual && expected &&\n      !expectedException(actual, expected)) || (!shouldThrow && actual)) {\n    throw actual;\n  }\n}\n\n// 11. Expected to throw an error:\n// assert.throws(block, Error_opt, message_opt);\n\nassert.throws = function(block, /*optional*/error, /*optional*/message) {\n  _throws(true, block, error, message);\n};\n\n// EXTENSION! This is annoying to write outside this module.\nassert.doesNotThrow = function(block, /*optional*/error, /*optional*/message) {\n  _throws(false, block, error, message);\n};\n\nassert.ifError = function(err) { if (err) throw err; };\n\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    if (hasOwn.call(obj, key)) keys.push(key);\n  }\n  return keys;\n};\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12)))\n\n/***/ }),\n/* 597 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_ltgt__ = __webpack_require__(598);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_ltgt___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_0_ltgt__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_inherits__ = __webpack_require__(6);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_inherits___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_1_inherits__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2_events__ = __webpack_require__(23);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2_events___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_2_events__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_3_readable_stream__ = __webpack_require__(599);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_3_readable_stream___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_3_readable_stream__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_4_level_codec__ = __webpack_require__(611);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_4_level_codec___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_4_level_codec__);\n\n\n\n\n\n\nfunction isFunction(f) {\n  return 'function' === typeof f;\n}\n\nfunction getPrefix(db) {\n  if (isFunction(db.prefix)) {\n    return db.prefix();\n  }\n  return db;\n}\n\nfunction clone(_obj) {\n  var obj = {};\n  for (var k in _obj) {\n    obj[k] = _obj[k];\n  }\n  return obj;\n}\n\nfunction nut(db, precodec, codec) {\n  function encodePrefix(prefix, key, opts1, opts2) {\n    return precodec.encode([ prefix, codec.encodeKey(key, opts1, opts2 ) ]);\n  }\n\n  function addEncodings(op, prefix) {\n    if (prefix && prefix.options) {\n      op.keyEncoding =\n        op.keyEncoding || prefix.options.keyEncoding;\n      op.valueEncoding =\n        op.valueEncoding || prefix.options.valueEncoding;\n    }\n    return op;\n  }\n\n  db.open(function () { /* no-op */});\n\n  return {\n    apply: function (ops, opts, cb) {\n      opts = opts || {};\n\n      var batch = [];\n      var i = -1;\n      var len = ops.length;\n\n      while (++i < len) {\n        var op = ops[i];\n        addEncodings(op, op.prefix);\n        op.prefix = getPrefix(op.prefix);\n        batch.push({\n          key: encodePrefix(op.prefix, op.key, opts, op),\n          value: op.type !== 'del' && codec.encodeValue(op.value, opts, op),\n          type: op.type\n        });\n      }\n      db.db.batch(batch, opts, cb);\n    },\n    get: function (key, prefix, opts, cb) {\n      opts.asBuffer = codec.valueAsBuffer(opts);\n      return db.db.get(\n        encodePrefix(prefix, key, opts),\n        opts,\n        function (err, value) {\n          if (err) {\n            cb(err);\n          } else {\n            cb(null, codec.decodeValue(value, opts));\n          }\n        }\n      );\n    },\n    createDecoder: function (opts) {\n      return function (key, value) {\n        return {\n          key: codec.decodeKey(precodec.decode(key)[1], opts),\n          value: codec.decodeValue(value, opts)\n        };\n      };\n    },\n    isClosed: function isClosed() {\n      return db.isClosed();\n    },\n    close: function close(cb) {\n      return db.close(cb);\n    },\n    iterator: function (_opts) {\n      var opts = clone(_opts || {});\n      var prefix = _opts.prefix || [];\n\n      function encodeKey(key) {\n        return encodePrefix(prefix, key, opts, {});\n      }\n\n      __WEBPACK_IMPORTED_MODULE_0_ltgt___default.a.toLtgt(_opts, opts, encodeKey, precodec.lowerBound, precodec.upperBound);\n\n      // if these legacy values are in the options, remove them\n\n      opts.prefix = null;\n\n      //************************************************\n      //hard coded defaults, for now...\n      //TODO: pull defaults and encoding out of levelup.\n      opts.keyAsBuffer = opts.valueAsBuffer = false;\n      //************************************************\n\n\n      //this is vital, otherwise limit: undefined will\n      //create an empty stream.\n      /* istanbul ignore next */\n      if ('number' !== typeof opts.limit) {\n        opts.limit = -1;\n      }\n\n      opts.keyAsBuffer = precodec.buffer;\n      opts.valueAsBuffer = codec.valueAsBuffer(opts);\n\n      function wrapIterator(iterator) {\n        return {\n          next: function (cb) {\n            return iterator.next(cb);\n          },\n          end: function (cb) {\n            iterator.end(cb);\n          }\n        };\n      }\n\n      return wrapIterator(db.db.iterator(opts));\n    }\n  };\n}\n\nfunction NotFoundError() {\n  Error.call(this);\n}\n\n__WEBPACK_IMPORTED_MODULE_1_inherits___default()(NotFoundError, Error);\n\nNotFoundError.prototype.name = 'NotFoundError';\n\nvar EventEmitter = __WEBPACK_IMPORTED_MODULE_2_events___default.a.EventEmitter;\nvar version = \"6.5.4\";\n\nvar NOT_FOUND_ERROR = new NotFoundError();\n\nvar sublevel = function (nut, prefix, createStream, options) {\n  var emitter = new EventEmitter();\n  emitter.sublevels = {};\n  emitter.options = options;\n\n  emitter.version = version;\n\n  emitter.methods = {};\n  prefix = prefix || [];\n\n  function mergeOpts(opts) {\n    var o = {};\n    var k;\n    if (options) {\n      for (k in options) {\n        if (typeof options[k] !== 'undefined') {\n          o[k] = options[k];\n        }\n      }\n    }\n    if (opts) {\n      for (k in opts) {\n        if (typeof opts[k] !== 'undefined') {\n          o[k] = opts[k];\n        }\n      }\n    }\n    return o;\n  }\n\n  emitter.put = function (key, value, opts, cb) {\n    if ('function' === typeof opts) {\n      cb = opts;\n      opts = {};\n    }\n\n    nut.apply([{\n      key: key, value: value,\n      prefix: prefix.slice(), type: 'put'\n    }], mergeOpts(opts), function (err) {\n      /* istanbul ignore next */\n      if (err) {\n        return cb(err);\n      }\n      emitter.emit('put', key, value);\n      cb(null);\n    });\n  };\n\n  emitter.prefix = function () {\n    return prefix.slice();\n  };\n\n  emitter.batch = function (ops, opts, cb) {\n    if ('function' === typeof opts) {\n      cb = opts;\n      opts = {};\n    }\n\n    ops = ops.map(function (op) {\n      return {\n        key: op.key,\n        value: op.value,\n        prefix: op.prefix || prefix,\n        keyEncoding: op.keyEncoding,    // *\n        valueEncoding: op.valueEncoding,  // * (TODO: encodings on sublevel)\n        type: op.type\n      };\n    });\n\n    nut.apply(ops, mergeOpts(opts), function (err) {\n      /* istanbul ignore next */\n      if (err) {\n        return cb(err);\n      }\n      emitter.emit('batch', ops);\n      cb(null);\n    });\n  };\n\n  emitter.get = function (key, opts, cb) {\n    /* istanbul ignore else */\n    if ('function' === typeof opts) {\n      cb = opts;\n      opts = {};\n    }\n    nut.get(key, prefix, mergeOpts(opts), function (err, value) {\n      if (err) {\n        cb(NOT_FOUND_ERROR);\n      } else {\n        cb(null, value);\n      }\n    });\n  };\n\n  emitter.sublevel = function (name, opts) {\n    return emitter.sublevels[name] =\n      emitter.sublevels[name] || sublevel(nut, prefix.concat(name), createStream, mergeOpts(opts));\n  };\n\n  emitter.readStream = emitter.createReadStream = function (opts) {\n    opts = mergeOpts(opts);\n    opts.prefix = prefix;\n    var stream;\n    var it = nut.iterator(opts);\n\n    stream = createStream(opts, nut.createDecoder(opts));\n    stream.setIterator(it);\n\n    return stream;\n  };\n\n  emitter.close = function (cb) {\n    nut.close(cb);\n  };\n\n  emitter.isOpen = nut.isOpen;\n  emitter.isClosed = nut.isClosed;\n\n  return emitter;\n};\n\n/* Copyright (c) 2012-2014 LevelUP contributors\n * See list at <https://github.com/rvagg/node-levelup#contributing>\n * MIT License <https://github.com/rvagg/node-levelup/blob/master/LICENSE.md>\n */\n\n// NOTE: we are fixed to readable-stream@1.0.x for now\n// for pure Streams2 across Node versions\nvar Readable = __WEBPACK_IMPORTED_MODULE_3_readable_stream___default.a.Readable;\n\nfunction ReadStream(options, makeData) {\n  if (!(this instanceof ReadStream)) {\n    return new ReadStream(options, makeData);\n  }\n\n  Readable.call(this, { objectMode: true, highWaterMark: options.highWaterMark });\n\n  // purely to keep `db` around until we're done so it's not GCed if the user doesn't keep a ref\n\n  this._waiting = false;\n  this._options = options;\n  this._makeData = makeData;\n}\n\n__WEBPACK_IMPORTED_MODULE_1_inherits___default()(ReadStream, Readable);\n\nReadStream.prototype.setIterator = function (it) {\n  this._iterator = it;\n  /* istanbul ignore if */\n  if (this._destroyed) {\n    return it.end(function () {});\n  }\n  /* istanbul ignore if */\n  if (this._waiting) {\n    this._waiting = false;\n    return this._read();\n  }\n  return this;\n};\n\nReadStream.prototype._read = function read() {\n  var self = this;\n  /* istanbul ignore if */\n  if (self._destroyed) {\n    return;\n  }\n  /* istanbul ignore if */\n  if (!self._iterator) {\n    return this._waiting = true;\n  }\n\n  self._iterator.next(function (err, key, value) {\n    if (err || (key === undefined && value === undefined)) {\n      if (!err && !self._destroyed) {\n        self.push(null);\n      }\n      return self._cleanup(err);\n    }\n\n\n    value = self._makeData(key, value);\n    if (!self._destroyed) {\n      self.push(value);\n    }\n  });\n};\n\nReadStream.prototype._cleanup = function (err) {\n  if (this._destroyed) {\n    return;\n  }\n\n  this._destroyed = true;\n\n  var self = this;\n  /* istanbul ignore if */\n  if (err && err.message !== 'iterator has ended') {\n    self.emit('error', err);\n  }\n\n  /* istanbul ignore else */\n  if (self._iterator) {\n    self._iterator.end(function () {\n      self._iterator = null;\n      self.emit('close');\n    });\n  } else {\n    self.emit('close');\n  }\n};\n\nReadStream.prototype.destroy = function () {\n  this._cleanup();\n};\n\nvar precodec = {\n  encode: function (decodedKey) {\n    return '\\xff' + decodedKey[0] + '\\xff' + decodedKey[1];\n  },\n  decode: function (encodedKeyAsBuffer) {\n    var str = encodedKeyAsBuffer.toString();\n    var idx = str.indexOf('\\xff', 1);\n    return [str.substring(1, idx), str.substring(idx + 1)];\n  },\n  lowerBound: '\\x00',\n  upperBound: '\\xff'\n};\n\nvar codec = new __WEBPACK_IMPORTED_MODULE_4_level_codec___default.a();\n\nfunction sublevelPouch(db) {\n  return sublevel(nut(db, precodec, codec), [], ReadStream, db.options);\n}\n\n/* harmony default export */ __webpack_exports__[\"a\"] = (sublevelPouch);\n\n\n/***/ }),\n/* 598 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(Buffer) {\nexports.compare = function (a, b) {\n\n  if(Buffer.isBuffer(a)) {\n    var l = Math.min(a.length, b.length)\n    for(var i = 0; i < l; i++) {\n      var cmp = a[i] - b[i]\n      if(cmp) return cmp\n    }\n    return a.length - b.length\n  }\n\n  return a < b ? -1 : a > b ? 1 : 0\n}\n\nfunction has(obj, key) {\n  return Object.hasOwnProperty.call(obj, key)\n}\n\n// to be compatible with the current abstract-leveldown tests\n// nullish or empty strings.\n// I could use !!val but I want to permit numbers and booleans,\n// if possible.\n\nfunction isDef (val) {\n  return val !== undefined && val !== ''\n}\n\nfunction has (range, name) {\n  return Object.hasOwnProperty.call(range, name)\n}\n\nfunction hasKey(range, name) {\n  return Object.hasOwnProperty.call(range, name) && name\n}\n\nvar lowerBoundKey = exports.lowerBoundKey = function (range) {\n    return (\n       hasKey(range, 'gt')\n    || hasKey(range, 'gte')\n    || hasKey(range, 'min')\n    || (range.reverse ? hasKey(range, 'end') : hasKey(range, 'start'))\n    || undefined\n    )\n}\n\nvar lowerBound = exports.lowerBound = function (range, def) {\n  var k = lowerBoundKey(range)\n  return k ? range[k] : def\n}\n\nvar lowerBoundInclusive = exports.lowerBoundInclusive = function (range) {\n  return has(range, 'gt') ? false : true\n}\n\nvar upperBoundInclusive = exports.upperBoundInclusive =\n  function (range) {\n    return (has(range, 'lt') /*&& !range.maxEx*/) ? false : true\n  }\n\nvar lowerBoundExclusive = exports.lowerBoundExclusive =\n  function (range) {\n    return !lowerBoundInclusive(range)\n  }\n\nvar upperBoundExclusive = exports.upperBoundExclusive =\n  function (range) {\n    return !upperBoundInclusive(range)\n  }\n\nvar upperBoundKey = exports.upperBoundKey = function (range) {\n    return (\n       hasKey(range, 'lt')\n    || hasKey(range, 'lte')\n    || hasKey(range, 'max')\n    || (range.reverse ? hasKey(range, 'start') : hasKey(range, 'end'))\n    || undefined\n    )\n}\n\nvar upperBound = exports.upperBound = function (range, def) {\n  var k = upperBoundKey(range)\n  return k ? range[k] : def\n}\n\nexports.start = function (range, def) {\n  return range.reverse ? upperBound(range, def) : lowerBound(range, def)\n}\nexports.end = function (range, def) {\n  return range.reverse ? lowerBound(range, def) : upperBound(range, def)\n}\nexports.startInclusive = function (range) {\n  return (\n    range.reverse\n  ? upperBoundInclusive(range)\n  : lowerBoundInclusive(range)\n  )\n}\nexports.endInclusive = function (range) {\n  return (\n    range.reverse\n  ? lowerBoundInclusive(range)\n  : upperBoundInclusive(range)\n  )\n}\n\nfunction id (e) { return e }\n\nexports.toLtgt = function (range, _range, map, lower, upper) {\n  _range = _range || {}\n  map = map || id\n  var defaults = arguments.length > 3\n  var lb = exports.lowerBoundKey(range)\n  var ub = exports.upperBoundKey(range)\n  if(lb) {\n    if(lb === 'gt') _range.gt = map(range.gt, false)\n    else            _range.gte = map(range[lb], false)\n  }\n  else if(defaults)\n    _range.gte = map(lower, false)\n\n  if(ub) {\n    if(ub === 'lt') _range.lt = map(range.lt, true)\n    else            _range.lte = map(range[ub], true)\n  }\n  else if(defaults)\n    _range.lte = map(upper, true)\n\n  if(range.reverse != null)\n    _range.reverse = !!range.reverse\n\n  //if range was used mutably\n  //(in level-sublevel it's part of an options object\n  //that has more properties on it.)\n  if(has(_range, 'max'))   delete _range.max\n  if(has(_range, 'min'))   delete _range.min\n  if(has(_range, 'start')) delete _range.start\n  if(has(_range, 'end'))   delete _range.end\n\n  return _range\n}\n\nexports.contains = function (range, key, compare) {\n  compare = compare || exports.compare\n\n  var lb = lowerBound(range)\n  if(isDef(lb)) {\n    var cmp = compare(key, lb)\n    if(cmp < 0 || (cmp === 0 && lowerBoundExclusive(range)))\n      return false\n  }\n\n  var ub = upperBound(range)\n  if(isDef(ub)) {\n    var cmp = compare(key, ub)\n    if(cmp > 0 || (cmp === 0) && upperBoundExclusive(range))\n      return false\n  }\n\n  return true\n}\n\nexports.filter = function (range, compare) {\n  return function (key) {\n    return exports.contains(range, key, compare)\n  }\n}\n\n\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(24).Buffer))\n\n/***/ }),\n/* 599 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar Stream = __webpack_require__(126); // hack to fix a circular dependency issue when used with browserify\nexports = module.exports = __webpack_require__(203);\nexports.Stream = Stream;\nexports.Readable = exports;\nexports.Writable = __webpack_require__(204);\nexports.Duplex = __webpack_require__(129);\nexports.Transform = __webpack_require__(205);\nexports.PassThrough = __webpack_require__(610);\n\n\n/***/ }),\n/* 600 */\n/***/ (function(module, exports) {\n\nvar toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n\n\n/***/ }),\n/* 601 */\n/***/ (function(module, exports) {\n\n/* (ignored) */\n\n/***/ }),\n/* 602 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = __webpack_require__(35).Buffer;\nvar util = __webpack_require__(603);\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}\n\n/***/ }),\n/* 603 */\n/***/ (function(module, exports) {\n\n/* (ignored) */\n\n/***/ }),\n/* 604 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n\n\nmodule.exports = PassThrough;\n\nvar Transform = __webpack_require__(202);\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};\n\n/***/ }),\n/* 605 */\n/***/ (function(module, exports, __webpack_require__) {\n\nmodule.exports = __webpack_require__(128);\n\n\n/***/ }),\n/* 606 */\n/***/ (function(module, exports, __webpack_require__) {\n\nmodule.exports = __webpack_require__(53);\n\n\n/***/ }),\n/* 607 */\n/***/ (function(module, exports, __webpack_require__) {\n\nmodule.exports = __webpack_require__(127).Transform\n\n\n/***/ }),\n/* 608 */\n/***/ (function(module, exports, __webpack_require__) {\n\nmodule.exports = __webpack_require__(127).PassThrough\n\n\n/***/ }),\n/* 609 */\n/***/ (function(module, exports) {\n\nmodule.exports = Array.isArray || function (arr) {\n  return Object.prototype.toString.call(arr) == '[object Array]';\n};\n\n\n/***/ }),\n/* 610 */\n/***/ (function(module, exports, __webpack_require__) {\n\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\nmodule.exports = PassThrough;\n\nvar Transform = __webpack_require__(205);\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough))\n    return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function(chunk, encoding, cb) {\n  cb(null, chunk);\n};\n\n\n/***/ }),\n/* 611 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar encodings = __webpack_require__(612);\n\nmodule.exports = Codec;\n\nfunction Codec(opts){\n  this.opts = opts || {};\n  this.encodings = encodings;\n}\n\nCodec.prototype._encoding = function(encoding){\n  if (typeof encoding == 'string') encoding = encodings[encoding];\n  if (!encoding) encoding = encodings.id;\n  return encoding;\n};\n\nCodec.prototype._keyEncoding = function(opts, batchOpts){\n  return this._encoding(batchOpts && batchOpts.keyEncoding\n    || opts && opts.keyEncoding\n    || this.opts.keyEncoding);\n};\n\nCodec.prototype._valueEncoding = function(opts, batchOpts){\n  return this._encoding(\n    batchOpts && (batchOpts.valueEncoding || batchOpts.encoding)\n    || opts && (opts.valueEncoding || opts.encoding)\n    || (this.opts.valueEncoding || this.opts.encoding));\n};\n\nCodec.prototype.encodeKey = function(key, opts, batchOpts){\n  return this._keyEncoding(opts, batchOpts).encode(key);\n};\n\nCodec.prototype.encodeValue = function(value, opts, batchOpts){\n  return this._valueEncoding(opts, batchOpts).encode(value);\n};\n\nCodec.prototype.decodeKey = function(key, opts){\n  return this._keyEncoding(opts).decode(key);\n};\n\nCodec.prototype.decodeValue = function(value, opts){\n  return this._valueEncoding(opts).decode(value);\n};\n\nCodec.prototype.encodeBatch = function(ops, opts){\n  var self = this;\n\n  return ops.map(function(_op){\n    var op = {\n      type: _op.type,\n      key: self.encodeKey(_op.key, opts, _op)\n    };\n    if (self.keyAsBuffer(opts, _op)) op.keyEncoding = 'binary';\n    if (_op.prefix) op.prefix = _op.prefix;\n    if ('value' in _op) {\n      op.value = self.encodeValue(_op.value, opts, _op);\n      if (self.valueAsBuffer(opts, _op)) op.valueEncoding = 'binary';\n    }\n    return op;\n  });\n};\n\nvar ltgtKeys = ['lt', 'gt', 'lte', 'gte', 'start', 'end'];\n\nCodec.prototype.encodeLtgt = function(ltgt){\n  var self = this;\n  var ret = {};\n  Object.keys(ltgt).forEach(function(key){\n    ret[key] = ltgtKeys.indexOf(key) > -1\n      ? self.encodeKey(ltgt[key], ltgt)\n      : ltgt[key]\n  });\n  return ret;\n};\n\nCodec.prototype.createStreamDecoder = function(opts){\n  var self = this;\n\n  if (opts.keys && opts.values) {\n    return function(key, value){\n      return {\n        key: self.decodeKey(key, opts),\n        value: self.decodeValue(value, opts)\n      };\n    };\n  } else if (opts.keys) {\n    return function(key) {\n      return self.decodeKey(key, opts);\n    }; \n  } else if (opts.values) {\n    return function(_, value){\n      return self.decodeValue(value, opts);\n    }\n  } else {\n    return function(){};\n  }\n};\n\nCodec.prototype.keyAsBuffer = function(opts){\n  return this._keyEncoding(opts).buffer;\n};\n\nCodec.prototype.valueAsBuffer = function(opts){\n  return this._valueEncoding(opts).buffer;\n};\n\n\n\n/***/ }),\n/* 612 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(Buffer) {exports.utf8 = exports['utf-8'] = {\n  encode: function(data){\n    return isBinary(data)\n      ? data\n      : String(data);\n  },\n  decode: function(data){\n    return typeof data === 'string'\n      ? data\n      : String(data)\n  },\n  buffer: false,\n  type: 'utf8'\n};\n\nexports.json = {\n  encode: JSON.stringify,\n  decode: JSON.parse,\n  buffer: false,\n  type: 'json'\n};\n\nexports.binary = {\n  encode: function(data){\n    return isBinary(data)\n      ? data\n      : new Buffer(data);      \n  },\n  decode: identity,\n  buffer: true,\n  type: 'binary'\n};\n\nexports.none = {\n  encode: identity,\n  decode: identity,\n  buffer: false,\n  type: 'id'\n};\n\nexports.id = exports.none;\n\nvar bufferEncodings = [\n  'hex',\n  'ascii',\n  'base64',\n  'ucs2',\n  'ucs-2',\n  'utf16le',\n  'utf-16le'\n];\n\nbufferEncodings.forEach(function(type){\n  exports[type] = {\n    encode: function(data){\n      return isBinary(data)\n        ? data\n        : new Buffer(data, type);\n    },\n    decode: function(buffer){\n      return buffer.toString(type);\n    },\n    buffer: true,\n    type: type\n  };\n});\n\nfunction identity(value){\n  return value;\n}\n\nfunction isBinary(data){\n  return data === undefined\n    || data === null\n    || Buffer.isBuffer(data);\n}\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(24).Buffer))\n\n/***/ }),\n/* 613 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process) {var Transform = __webpack_require__(614)\n  , inherits  = __webpack_require__(65).inherits\n  , xtend     = __webpack_require__(66)\n\nfunction DestroyableTransform(opts) {\n  Transform.call(this, opts)\n  this._destroyed = false\n}\n\ninherits(DestroyableTransform, Transform)\n\nDestroyableTransform.prototype.destroy = function(err) {\n  if (this._destroyed) return\n  this._destroyed = true\n  \n  var self = this\n  process.nextTick(function() {\n    if (err)\n      self.emit('error', err)\n    self.emit('close')\n  })\n}\n\n// a noop _transform function\nfunction noop (chunk, enc, callback) {\n  callback(null, chunk)\n}\n\n\n// create a new export function, used by both the main export and\n// the .ctor export, contains common logic for dealing with arguments\nfunction through2 (construct) {\n  return function (options, transform, flush) {\n    if (typeof options == 'function') {\n      flush     = transform\n      transform = options\n      options   = {}\n    }\n\n    if (typeof transform != 'function')\n      transform = noop\n\n    if (typeof flush != 'function')\n      flush = null\n\n    return construct(options, transform, flush)\n  }\n}\n\n\n// main export, just make me a transform stream!\nmodule.exports = through2(function (options, transform, flush) {\n  var t2 = new DestroyableTransform(options)\n\n  t2._transform = transform\n\n  if (flush)\n    t2._flush = flush\n\n  return t2\n})\n\n\n// make me a reusable prototype that I can `new`, or implicitly `new`\n// with a constructor call\nmodule.exports.ctor = through2(function (options, transform, flush) {\n  function Through2 (override) {\n    if (!(this instanceof Through2))\n      return new Through2(override)\n\n    this.options = xtend(options, override)\n\n    DestroyableTransform.call(this, this.options)\n  }\n\n  inherits(Through2, DestroyableTransform)\n\n  Through2.prototype._transform = transform\n\n  if (flush)\n    Through2.prototype._flush = flush\n\n  return Through2\n})\n\n\nmodule.exports.obj = through2(function (options, transform, flush) {\n  var t2 = new DestroyableTransform(xtend({ objectMode: true, highWaterMark: 16 }, options))\n\n  t2._transform = transform\n\n  if (flush)\n    t2._flush = flush\n\n  return t2\n})\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8)))\n\n/***/ }),\n/* 614 */\n/***/ (function(module, exports, __webpack_require__) {\n\nmodule.exports = __webpack_require__(615).Transform\n\n\n/***/ }),\n/* 615 */\n/***/ (function(module, exports, __webpack_require__) {\n\nexports = module.exports = __webpack_require__(206);\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = __webpack_require__(209);\nexports.Duplex = __webpack_require__(61);\nexports.Transform = __webpack_require__(210);\nexports.PassThrough = __webpack_require__(620);\n\n\n/***/ }),\n/* 616 */\n/***/ (function(module, exports) {\n\nvar toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n\n\n/***/ }),\n/* 617 */\n/***/ (function(module, exports) {\n\n/* (ignored) */\n\n/***/ }),\n/* 618 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = __webpack_require__(35).Buffer;\nvar util = __webpack_require__(619);\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}\n\n/***/ }),\n/* 619 */\n/***/ (function(module, exports) {\n\n/* (ignored) */\n\n/***/ }),\n/* 620 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n\n\nmodule.exports = PassThrough;\n\nvar Transform = __webpack_require__(210);\n\n/*<replacement>*/\nvar util = __webpack_require__(13);\nutil.inherits = __webpack_require__(6);\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};\n\n/***/ }),\n/* 621 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * Copyright (c) 2013 Petka Antonov\n * \n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:</p>\n * \n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n * \n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n * THE SOFTWARE.\n */\n\nfunction Deque(capacity) {\n    this._capacity = getCapacity(capacity);\n    this._length = 0;\n    this._front = 0;\n    if (isArray(capacity)) {\n        var len = capacity.length;\n        for (var i = 0; i < len; ++i) {\n            this[i] = capacity[i];\n        }\n        this._length = len;\n    }\n}\n\nDeque.prototype.toArray = function Deque$toArray() {\n    var len = this._length;\n    var ret = new Array(len);\n    var front = this._front;\n    var capacity = this._capacity;\n    for (var j = 0; j < len; ++j) {\n        ret[j] = this[(front + j) & (capacity - 1)];\n    }\n    return ret;\n};\n\nDeque.prototype.push = function Deque$push(item) {\n    var argsLength = arguments.length;\n    var length = this._length;\n    if (argsLength > 1) {\n        var capacity = this._capacity;\n        if (length + argsLength > capacity) {\n            for (var i = 0; i < argsLength; ++i) {\n                this._checkCapacity(length + 1);\n                var j = (this._front + length) & (this._capacity - 1);\n                this[j] = arguments[i];\n                length++;\n                this._length = length;\n            }\n            return length;\n        }\n        else {\n            var j = this._front;\n            for (var i = 0; i < argsLength; ++i) {\n                this[(j + length) & (capacity - 1)] = arguments[i];\n                j++;\n            }\n            this._length = length + argsLength;\n            return length + argsLength;\n        }\n\n    }\n\n    if (argsLength === 0) return length;\n\n    this._checkCapacity(length + 1);\n    var i = (this._front + length) & (this._capacity - 1);\n    this[i] = item;\n    this._length = length + 1;\n    return length + 1;\n};\n\nDeque.prototype.pop = function Deque$pop() {\n    var length = this._length;\n    if (length === 0) {\n        return void 0;\n    }\n    var i = (this._front + length - 1) & (this._capacity - 1);\n    var ret = this[i];\n    this[i] = void 0;\n    this._length = length - 1;\n    return ret;\n};\n\nDeque.prototype.shift = function Deque$shift() {\n    var length = this._length;\n    if (length === 0) {\n        return void 0;\n    }\n    var front = this._front;\n    var ret = this[front];\n    this[front] = void 0;\n    this._front = (front + 1) & (this._capacity - 1);\n    this._length = length - 1;\n    return ret;\n};\n\nDeque.prototype.unshift = function Deque$unshift(item) {\n    var length = this._length;\n    var argsLength = arguments.length;\n\n\n    if (argsLength > 1) {\n        var capacity = this._capacity;\n        if (length + argsLength > capacity) {\n            for (var i = argsLength - 1; i >= 0; i--) {\n                this._checkCapacity(length + 1);\n                var capacity = this._capacity;\n                var j = (((( this._front - 1 ) &\n                    ( capacity - 1) ) ^ capacity ) - capacity );\n                this[j] = arguments[i];\n                length++;\n                this._length = length;\n                this._front = j;\n            }\n            return length;\n        }\n        else {\n            var front = this._front;\n            for (var i = argsLength - 1; i >= 0; i--) {\n                var j = (((( front - 1 ) &\n                    ( capacity - 1) ) ^ capacity ) - capacity );\n                this[j] = arguments[i];\n                front = j;\n            }\n            this._front = front;\n            this._length = length + argsLength;\n            return length + argsLength;\n        }\n    }\n\n    if (argsLength === 0) return length;\n\n    this._checkCapacity(length + 1);\n    var capacity = this._capacity;\n    var i = (((( this._front - 1 ) &\n        ( capacity - 1) ) ^ capacity ) - capacity );\n    this[i] = item;\n    this._length = length + 1;\n    this._front = i;\n    return length + 1;\n};\n\nDeque.prototype.peekBack = function Deque$peekBack() {\n    var length = this._length;\n    if (length === 0) {\n        return void 0;\n    }\n    var index = (this._front + length - 1) & (this._capacity - 1);\n    return this[index];\n};\n\nDeque.prototype.peekFront = function Deque$peekFront() {\n    if (this._length === 0) {\n        return void 0;\n    }\n    return this[this._front];\n};\n\nDeque.prototype.get = function Deque$get(index) {\n    var i = index;\n    if ((i !== (i | 0))) {\n        return void 0;\n    }\n    var len = this._length;\n    if (i < 0) {\n        i = i + len;\n    }\n    if (i < 0 || i >= len) {\n        return void 0;\n    }\n    return this[(this._front + i) & (this._capacity - 1)];\n};\n\nDeque.prototype.isEmpty = function Deque$isEmpty() {\n    return this._length === 0;\n};\n\nDeque.prototype.clear = function Deque$clear() {\n    var len = this._length;\n    var front = this._front;\n    var capacity = this._capacity;\n    for (var j = 0; j < len; ++j) {\n        this[(front + j) & (capacity - 1)] = void 0;\n    }\n    this._length = 0;\n    this._front = 0;\n};\n\nDeque.prototype.toString = function Deque$toString() {\n    return this.toArray().toString();\n};\n\nDeque.prototype.valueOf = Deque.prototype.toString;\nDeque.prototype.removeFront = Deque.prototype.shift;\nDeque.prototype.removeBack = Deque.prototype.pop;\nDeque.prototype.insertFront = Deque.prototype.unshift;\nDeque.prototype.insertBack = Deque.prototype.push;\nDeque.prototype.enqueue = Deque.prototype.push;\nDeque.prototype.dequeue = Deque.prototype.shift;\nDeque.prototype.toJSON = Deque.prototype.toArray;\n\nObject.defineProperty(Deque.prototype, \"length\", {\n    get: function() {\n        return this._length;\n    },\n    set: function() {\n        throw new RangeError(\"\");\n    }\n});\n\nDeque.prototype._checkCapacity = function Deque$_checkCapacity(size) {\n    if (this._capacity < size) {\n        this._resizeTo(getCapacity(this._capacity * 1.5 + 16));\n    }\n};\n\nDeque.prototype._resizeTo = function Deque$_resizeTo(capacity) {\n    var oldCapacity = this._capacity;\n    this._capacity = capacity;\n    var front = this._front;\n    var length = this._length;\n    if (front + length > oldCapacity) {\n        var moveItemsCount = (front + length) & (oldCapacity - 1);\n        arrayMove(this, 0, this, oldCapacity, moveItemsCount);\n    }\n};\n\n\nvar isArray = Array.isArray;\n\nfunction arrayMove(src, srcIndex, dst, dstIndex, len) {\n    for (var j = 0; j < len; ++j) {\n        dst[j + dstIndex] = src[j + srcIndex];\n        src[j + srcIndex] = void 0;\n    }\n}\n\nfunction pow2AtLeast(n) {\n    n = n >>> 0;\n    n = n - 1;\n    n = n | (n >> 1);\n    n = n | (n >> 2);\n    n = n | (n >> 4);\n    n = n | (n >> 8);\n    n = n | (n >> 16);\n    return n + 1;\n}\n\nfunction getCapacity(capacity) {\n    if (typeof capacity !== \"number\") {\n        if (isArray(capacity)) {\n            capacity = capacity.length;\n        }\n        else {\n            return 16;\n        }\n    }\n    return pow2AtLeast(\n        Math.min(\n            Math.max(16, capacity), 1073741824)\n    );\n}\n\nmodule.exports = Deque;\n\n\n/***/ }),\n/* 622 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(Buffer) {var isArrayBuffer = __webpack_require__(623)\n\nvar isModern = (\n  typeof Buffer.alloc === 'function' &&\n  typeof Buffer.allocUnsafe === 'function' &&\n  typeof Buffer.from === 'function'\n)\n\nfunction fromArrayBuffer (obj, byteOffset, length) {\n  byteOffset >>>= 0\n\n  var maxLength = obj.byteLength - byteOffset\n\n  if (maxLength < 0) {\n    throw new RangeError(\"'offset' is out of bounds\")\n  }\n\n  if (length === undefined) {\n    length = maxLength\n  } else {\n    length >>>= 0\n\n    if (length > maxLength) {\n      throw new RangeError(\"'length' is out of bounds\")\n    }\n  }\n\n  return isModern\n    ? Buffer.from(obj.slice(byteOffset, byteOffset + length))\n    : new Buffer(new Uint8Array(obj.slice(byteOffset, byteOffset + length)))\n}\n\nfunction fromString (string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  return isModern\n    ? Buffer.from(string, encoding)\n    : new Buffer(string, encoding)\n}\n\nfunction bufferFrom (value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (isArrayBuffer(value)) {\n    return fromArrayBuffer(value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(value, encodingOrOffset)\n  }\n\n  return isModern\n    ? Buffer.from(value)\n    : new Buffer(value)\n}\n\nmodule.exports = bufferFrom\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(24).Buffer))\n\n/***/ }),\n/* 623 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Detect whether or not an object is an ArrayBuffer.\n * @version 1.7.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module is-array-buffer-x\n */\n\n/* global ArrayBuffer */\n\n\n\nvar attempt = __webpack_require__(130);\nvar isObjectLike = __webpack_require__(624);\nvar hasABuf = typeof ArrayBuffer === 'function';\nvar bLength = false;\nvar toStringTag;\nvar aBufTag;\n\nif (hasABuf) {\n  if (__webpack_require__(216)) {\n    var getOwnPropertyDescriptor = __webpack_require__(629);\n    var descriptor = getOwnPropertyDescriptor(ArrayBuffer.prototype, 'byteLength');\n    if (descriptor && typeof descriptor.get === 'function') {\n      var res = attempt(function () {\n        return new ArrayBuffer(4);\n      });\n\n      if (res.threw === false && isObjectLike(res.value)) {\n        res = attempt.call(res.value, descriptor.get);\n        bLength = res.threw === false && typeof res.value === 'number' && descriptor.get;\n      }\n    }\n  }\n\n  if (bLength === false) {\n    toStringTag = __webpack_require__(214);\n    aBufTag = '[object ArrayBuffer]';\n  }\n}\n\n/**\n * Determine if an `object` is an `ArrayBuffer`.\n *\n * @param {*} object - The object to test.\n * @returns {boolean} `true` if the `object` is an `ArrayBuffer`,\n *  else false`.\n * @example\n * var isArrayBuffer = require('is-array-buffer-x');\n *\n * isArrayBuffer(new ArrayBuffer(4)); // true\n * isArrayBuffer(null); // false\n * isArrayBuffer([]); // false\n */\nmodule.exports = function isArrayBuffer(object) {\n  if (hasABuf === false || isObjectLike(object) === false) {\n    return false;\n  }\n\n  if (bLength === false) {\n    return toStringTag(object) === aBufTag;\n  }\n\n  var result = attempt.call(object, bLength);\n  return result.threw === false && typeof result.value === 'number';\n};\n\n\n/***/ }),\n/* 624 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Determine if a value is object like.\n * @version 1.7.1\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module is-object-like-x\n */\n\n\n\nvar isFunction = __webpack_require__(211);\nvar isPrimitive = __webpack_require__(628);\n\n/**\n * Checks if `value` is object-like. A value is object-like if it's not a\n * primitive and not a function.\n *\n * @param {*} value - The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n * var isObjectLike = require('is-object-like-x');\n *\n * isObjectLike({});\n * // => true\n *\n * isObjectLike([1, 2, 3]);\n * // => true\n *\n * isObjectLike(_.noop);\n * // => false\n *\n * isObjectLike(null);\n * // => false\n */\nmodule.exports = function isObjectLike(value) {\n  return isPrimitive(value) === false && isFunction(value, true) === false;\n};\n\n\n/***/ }),\n/* 625 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Trims and replaces sequences of whitespace characters by a single space.\n * @version 3.0.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module normalize-space-x\n */\n\n\n\nvar libTrim = __webpack_require__(217);\nvar trim2016 = libTrim.trim2016;\nvar trim2018 = libTrim.trim2018;\nvar Rx = __webpack_require__(38).RegExp;\nvar libWhiteSpace = __webpack_require__(68);\nvar reNormalize2016 = new Rx('[' + libWhiteSpace.string2016 + ']+', 'g');\nvar reNormalize2018 = new Rx('[' + libWhiteSpace.string2018 + ']+', 'g');\nvar replace = ''.replace;\n\nvar $normalizeSpace2016 = function normalizeSpace2016(string) {\n  return replace.call(trim2016(string), reNormalize2016, ' ');\n};\n\nvar $normalizeSpace2018 = function normalizeSpace2018(string) {\n  return replace.call(trim2018(string), reNormalize2018, ' ');\n};\n\nmodule.exports = {\n  /**\n   * Reference to normalizeSpace2018.\n   */\n  normalizeSpace: $normalizeSpace2018,\n\n  /**\n   * This method strips leading and trailing white-space from a string,\n   * replaces sequences of whitespace characters by a single space,\n   * and returns the resulting string. (ES2016)\n   *\n   * @param {string} string - The string to be normalized.\n   * @throws {TypeError} If string is null or undefined or not coercible.\n   * @returns {string} The normalized string.\n   * @example\n   * var normalizeSpace = require('normalize-space-x');\n   *\n   * normalizeSpace(' \\t\\na \\t\\nb \\t\\n') === 'a b'; // true\n   */\n  normalizeSpace2016: $normalizeSpace2016,\n\n  /**\n   * This method strips leading and trailing white-space from a string,\n   * replaces sequences of whitespace characters by a single space,\n   * and returns the resulting string. (ES2018)\n   *\n   * @param {string} string - The string to be normalized.\n   * @throws {TypeError} If string is null or undefined or not coercible.\n   * @returns {string} The normalized string.\n   * @example\n   * var normalizeSpace = require('normalize-space-x');\n   *\n   * normalizeSpace(' \\t\\na \\t\\nb \\t\\n') === 'a b'; // true\n   */\n  normalizeSpace2018: $normalizeSpace2018\n};\n\n\n/***/ }),\n/* 626 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file This method removes whitespace from the right end of a string.\n * @version 3.0.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module trim-right-x\n */\n\n\n\nvar requireCoercibleToString = __webpack_require__(134);\nvar Rx = __webpack_require__(38).RegExp;\nvar reRight2016 = new Rx('[' + __webpack_require__(68).string2016 + ']+$');\nvar reRight2018 = new Rx('[' + __webpack_require__(68).string2018 + ']+$');\nvar replace = ''.replace;\n\nvar $trimRight2016 = function trimRight2016(string) {\n  return replace.call(requireCoercibleToString(string), reRight2016, '');\n};\n\nvar $trimRight2018 = function trimRight2018(string) {\n  return replace.call(requireCoercibleToString(string), reRight2018, '');\n};\n\nmodule.exports = {\n  /**\n   * A reference to trimRight2018.\n   */\n  trimRight: $trimRight2018,\n\n  /**\n   * This method removes whitespace from the right end of a string. (ES2016)\n   *\n   * @param {string} string - The string to trim the right end whitespace from.\n   * @throws {TypeError} If string is null or undefined or not coercible.\n   * @returns {string} The right trimmed string.\n   * @example\n   * var trimRight = require('trim-right-x');\n   *\n   * trimRight(' \\t\\na \\t\\n') === ' \\t\\na'; // true\n   */\n  trimRight2016: $trimRight2016,\n\n  /**\n   * This method removes whitespace from the right end of a string. (ES2018)\n   *\n   * @param {string} string - The string to trim the right end whitespace from.\n   * @throws {TypeError} If string is null or undefined or not coercible.\n   * @returns {string} The right trimmed string.\n   * @example\n   * var trimRight = require('trim-right-x');\n   *\n   * trimRight(' \\t\\na \\t\\n') === ' \\t\\na'; // true\n   */\n  trimRight2018: $trimRight2018\n};\n\n\n/***/ }),\n/* 627 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Replace the comments in a string.\n * @version 2.0.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module replace-comments-x\n */\n\n\n\nvar toStr = __webpack_require__(85);\nvar requireCoercibleToString = __webpack_require__(134);\nvar STRIP_COMMENTS = /((\\/\\/.*$)|(\\/\\*[\\s\\S]*?\\*\\/))/mg;\nvar replace = ''.replace;\n\n/**\n * This method replaces comments in a string.\n *\n * @param {string} string - The string to be stripped.\n * @param {string} [replacement] - The string to be used as a replacement.\n * @throws {TypeError} If string is null or undefined or not coercible.\n * @throws {TypeError} If replacement is not coercible.\n * @returns {string} The new string with the comments replaced.\n * @example\n * var replaceComments = require('replace-comments-x');\n *\n * replaceComments(test;/* test * /, ''), // 'test;'\n * replaceComments(test; // test, ''), // 'test;'\n */\nmodule.exports = function replaceComments(string) {\n  return replace.call(requireCoercibleToString(string), STRIP_COMMENTS, arguments.length > 1 ? toStr(arguments[1]) : '');\n};\n\n\n/***/ }),\n/* 628 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/*!\n * is-primitive <https://github.com/jonschlinkert/is-primitive>\n *\n * Copyright (c) 2014-2017, Jon Schlinkert.\n * Released under the MIT License.\n */\n\n\n\nmodule.exports = function isPrimitive(val) {\n  switch (typeof val) {\n    case 'boolean':\n    case 'number':\n    case 'string':\n    case 'symbol':\n    case 'undefined':\n      return true;\n    default: {\n      return val === null;\n    }\n  }\n};\n\n\n/***/ }),\n/* 629 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Sham for ES6 Object.getOwnPropertyDescriptor\n * @version 3.2.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module object-get-own-property-descriptor-x\n */\n\n\n\nvar toObject = __webpack_require__(137);\nvar toPropertyKey = __webpack_require__(138);\nvar isFalsey = __webpack_require__(213);\nvar attempt = __webpack_require__(130);\n\nvar nativeGOPD = typeof Object.getOwnPropertyDescriptor === 'function' && Object.getOwnPropertyDescriptor;\nvar getOPDFallback1;\nvar getOPDFallback2;\n\n// ES5 15.2.3.3\n// http://es5.github.com/#x15.2.3.3\n\nvar doesGOPDWork = function (object, prop) {\n  object[toPropertyKey(prop)] = 0;\n  var testResult = attempt(nativeGOPD, object, prop);\n  return testResult.threw === false && testResult.value.value === 0;\n};\n\n// check whether getOwnPropertyDescriptor works if it's given. Otherwise, shim partially.\nvar $getOwnPropertyDescriptor;\nif (nativeGOPD) {\n  var doc = typeof document !== 'undefined' && document;\n  var getOPDWorksOnDom = doc ? doesGOPDWork(doc.createElement('div'), 'sentinel') : true;\n  if (getOPDWorksOnDom) {\n    var res = attempt(nativeGOPD, Object('abc'), 1);\n    var worksWithStr = res.threw === false && res.value && res.value.value === 'b';\n    if (worksWithStr) {\n      var getOPDWorksOnObject = doesGOPDWork({}, 'sentinel');\n      if (getOPDWorksOnObject) {\n        var worksWithPrim = attempt(nativeGOPD, 42, 'name').threw === false;\n        var worksWithObjSym = __webpack_require__(67) && doesGOPDWork({}, Object(Symbol('')));\n        // eslint-disable-next-line max-depth\n        if (worksWithObjSym) {\n          // eslint-disable-next-line max-depth\n          if (worksWithPrim) {\n            $getOwnPropertyDescriptor = nativeGOPD;\n          } else {\n            $getOwnPropertyDescriptor = function getOwnPropertyDescriptor(object, property) {\n              return nativeGOPD(toObject(object), property);\n            };\n          }\n        } else if (worksWithPrim) {\n          $getOwnPropertyDescriptor = function getOwnPropertyDescriptor(object, property) {\n            return nativeGOPD(object, toPropertyKey(property));\n          };\n        } else {\n          $getOwnPropertyDescriptor = function getOwnPropertyDescriptor(object, property) {\n            return nativeGOPD(toObject(object), toPropertyKey(property));\n          };\n        }\n      } else {\n        getOPDFallback1 = nativeGOPD;\n      }\n    } else {\n      getOPDFallback2 = nativeGOPD;\n    }\n  }\n}\n\nif (isFalsey($getOwnPropertyDescriptor) || getOPDFallback1 || getOPDFallback2) {\n  var owns = __webpack_require__(631);\n  var isPrimitive = __webpack_require__(132);\n  var isString = __webpack_require__(632);\n  var isIndex = __webpack_require__(633);\n  var propertyIsEnumerable = __webpack_require__(642);\n  var prototypeOfObject = Object.prototype;\n\n  // If JS engine supports accessors creating shortcuts.\n  var lookupGetter;\n  var lookupSetter;\n  var supportsAccessors = owns(prototypeOfObject, '__defineGetter__');\n  if (supportsAccessors) {\n    // eslint-disable-next-line no-underscore-dangle\n    var lg = prototypeOfObject.__lookupGetter__;\n    // eslint-disable-next-line no-underscore-dangle\n    var ls = prototypeOfObject.__lookupSetter__;\n    lookupGetter = function (object, property) {\n      return lg.call(object, property);\n    };\n\n    lookupSetter = function (object, property) {\n      return ls.call(object, property);\n    };\n  }\n\n  $getOwnPropertyDescriptor = function getOwnPropertyDescriptor(object, property) {\n    var obj = toObject(object);\n    var propKey = toPropertyKey(property);\n\n    var result;\n    // make a valiant attempt to use the real getOwnPropertyDescriptor for I8's DOM elements.\n    if (getOPDFallback1) {\n      result = attempt.call(Object, getOPDFallback1, obj, propKey);\n      if (result.threw === false) {\n        return result.value;\n      }\n      // try the shim if the real one doesn't work\n    }\n\n    var isStringIndex = isString(obj) && isIndex(propKey, obj.length);\n    if (getOPDFallback2 && isStringIndex === false) {\n      result = attempt.call(Object, getOPDFallback2, obj, propKey);\n      if (result.threw === false) {\n        return result.value;\n      }\n      // try the shim if the real one doesn't work\n    }\n\n    var descriptor;\n    // If object does not owns property return undefined immediately.\n    if (isStringIndex === false && owns(obj, propKey) === false) {\n      return descriptor;\n    }\n\n    // If object has a property then it's for sure `configurable`, and\n    // probably `enumerable`. Detect enumerability though.\n    descriptor = {\n      configurable: isPrimitive(object) === false && isStringIndex === false,\n      enumerable: propertyIsEnumerable(obj, propKey)\n    };\n\n    // If JS engine supports accessor properties then property may be a\n    // getter or setter.\n    if (supportsAccessors) {\n      // Unfortunately `__lookupGetter__` will return a getter even\n      // if object has own non getter property along with a same named\n      // inherited getter. To avoid misbehavior we temporary remove\n      // `__proto__` so that `__lookupGetter__` will return getter only\n      // if it's owned by an object.\n      // eslint-disable-next-line no-proto\n      var prototype = obj.__proto__;\n      var notPrototypeOfObject = obj !== prototypeOfObject;\n      // avoid recursion problem, breaking in Opera Mini when\n      // Object.getOwnPropertyDescriptor(Object.prototype, 'toString')\n      // or any other Object.prototype accessor\n      if (notPrototypeOfObject) {\n        // eslint-disable-next-line no-proto\n        obj.__proto__ = prototypeOfObject;\n      }\n\n      var getter = lookupGetter(obj, propKey);\n      var setter = lookupSetter(obj, propKey);\n\n      if (notPrototypeOfObject) {\n        // Once we have getter and setter we can put values back.\n        // eslint-disable-next-line no-proto\n        obj.__proto__ = prototype;\n      }\n\n      if (getter || setter) {\n        if (getter) {\n          descriptor.get = getter;\n        }\n\n        if (setter) {\n          descriptor.set = setter;\n        }\n\n        // If it was accessor property we're done and return here\n        // in order to avoid adding `value` to the descriptor.\n        return descriptor;\n      }\n    }\n\n    // If we got this far we know that object has an own property that is\n    // not an accessor so we set it as a value and return descriptor.\n    if (isStringIndex) {\n      descriptor.value = obj.charAt(propKey);\n      descriptor.writable = false;\n    } else {\n      descriptor.value = obj[propKey];\n      descriptor.writable = true;\n    }\n\n    return descriptor;\n  };\n}\n\n/**\n * This method returns a property descriptor for an own property (that is,\n * one directly present on an object and not in the object's prototype chain)\n * of a given object.\n *\n * @param {*} object - The object in which to look for the property.\n * @param {*} property - The name of the property whose description is to be retrieved.\n * @returns {Object} A property descriptor of the given property if it exists on the object, undefined otherwise.\n * @example\n * var getOwnPropertyDescriptor = require('object-get-own-property-descriptor-x');\n * var obj = { bar: 42 };\n * var d = getOwnPropertyDescriptor(o, 'bar');\n * // d is {\n * //   configurable: true,\n * //   enumerable: true,\n * //   value: 42,\n * //   writable: true\n * // }\n */\nmodule.exports = $getOwnPropertyDescriptor;\n\n\n/***/ }),\n/* 630 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nvar getDay = Date.prototype.getDay;\nvar tryDateObject = function tryDateObject(value) {\n\ttry {\n\t\tgetDay.call(value);\n\t\treturn true;\n\t} catch (e) {\n\t\treturn false;\n\t}\n};\n\nvar toStr = Object.prototype.toString;\nvar dateClass = '[object Date]';\nvar hasToStringTag = typeof Symbol === 'function' && typeof Symbol.toStringTag === 'symbol';\n\nmodule.exports = function isDateObject(value) {\n\tif (typeof value !== 'object' || value === null) { return false; }\n\treturn hasToStringTag ? tryDateObject(value) : toStr.call(value) === dateClass;\n};\n\n\n/***/ }),\n/* 631 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Used to determine whether an object has an own property with the specified property key.\n * @see {@link http://www.ecma-international.org/ecma-262/6.0/#sec-hasownproperty|7.3.11 HasOwnProperty (O, P)}\n * @version 3.2.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module has-own-property-x\n */\n\n\n\nvar toObject = __webpack_require__(137);\nvar toPropertyKey = __webpack_require__(138);\nvar hop = __webpack_require__(38).Object.prototype.hasOwnProperty;\n\n/**\n * The `hasOwnProperty` method returns a boolean indicating whether\n * the `object` has the specified `property`. Does not attempt to fix known\n * issues in older browsers, but does ES6ify the method.\n *\n * @param {!Object} object - The object to test.\n * @throws {TypeError} If object is null or undefined.\n * @param {string|Symbol} property - The name or Symbol of the property to test.\n * @returns {boolean} `true` if the property is set on `object`, else `false`.\n * @example\n * var hasOwnProperty = require('has-own-property-x');\n * var o = {\n *   foo: 'bar'\n * };\n *\n *\n * hasOwnProperty(o, 'bar'); // false\n * hasOwnProperty(o, 'foo'); // true\n * hasOwnProperty(undefined, 'foo');\n *                   // TypeError: Cannot convert undefined or null to object\n */\nmodule.exports = function hasOwnProperty(object, property) {\n  return hop.call(toObject(object), toPropertyKey(property));\n};\n\n\n/***/ }),\n/* 632 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nvar strValue = String.prototype.valueOf;\nvar tryStringObject = function tryStringObject(value) {\n\ttry {\n\t\tstrValue.call(value);\n\t\treturn true;\n\t} catch (e) {\n\t\treturn false;\n\t}\n};\nvar toStr = Object.prototype.toString;\nvar strClass = '[object String]';\nvar hasToStringTag = typeof Symbol === 'function' && typeof Symbol.toStringTag === 'symbol';\n\nmodule.exports = function isString(value) {\n\tif (typeof value === 'string') { return true; }\n\tif (typeof value !== 'object') { return false; }\n\treturn hasToStringTag ? tryStringObject(value) : toStr.call(value) === strClass;\n};\n\n\n/***/ }),\n/* 633 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Determine whether the passed value is a zero based index.\n * @version 1.1.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module is-index-x\n */\n\n\n\nvar safeToString = __webpack_require__(634);\nvar toInteger = __webpack_require__(635).toInteger2018;\nvar toNumber = __webpack_require__(86).toNumber2018;\nvar mathClamp = __webpack_require__(640);\nvar MAX_SAFE_INTEGER = __webpack_require__(641);\nvar reIsUint = /^(?:0|[1-9]\\d*)$/;\nvar rxTest = reIsUint.test;\n\n/**\n * This method determines whether the passed value is a zero based index.\n * JavaScript arrays are zero-indexed: the first element of an array is at\n * index 0, and the last element is at the index equal to the value of the\n * array's length property minus 1.\n *\n * @param {number|string} value - The value to be tested for being a zero based index.\n * @param {number} [length=MAX_SAFE_INTEGER] - The length that sets the upper bound.\n * @returns {boolean} A Boolean indicating whether or not the given value is a\n * zero based index within bounds.\n * @example\n * var isIndex = require('is-index-x');\n *\n * isIndex(0);                    // true\n * isIndex(1);                    // true\n * isIndex('10');                 // true\n *\n * isIndex(-100000);              // false\n * isIndex(Math.pow(2, 53));      // false\n * isIndex(0.1);                  // false\n * isIndex(Math.PI);              // false\n * isIndex(NaN);                  // false\n * isIndex(Infinity);             // false\n * isIndex(-Infinity);            // false\n * isIndex(true);                 // false\n * isIndex(false);                // false\n * isIndex([1]);                  // false\n * isIndex(10, 10);               // false\n */\nmodule.exports = function isIndex(value) {\n  var string = safeToString(value);\n  if (rxTest.call(reIsUint, string) === false) {\n    return false;\n  }\n\n  var number = toNumber(string);\n  if (arguments.length > 1) {\n    return number < mathClamp(toInteger(arguments[1]), MAX_SAFE_INTEGER);\n  }\n\n  return number < MAX_SAFE_INTEGER;\n};\n\n\n/***/ }),\n/* 634 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file ES6 abstract ToString with Symbol conversion support.\n * @see {@link http://www.ecma-international.org/ecma-262/6.0/#sec-tostring|7.1.12 ToString ( argument )}\n * @version 1.0.2\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module to-string-symbols-supported-x\n */\n\n\n\nvar castString = __webpack_require__(38).String;\nvar pToString = __webpack_require__(67) && Symbol.prototype.toString;\nvar isSymbol = typeof pToString === 'function' && __webpack_require__(136);\n\n/**\n * The abstract operation ToString converts argument to a value of type String,\n * however the specification states that if the argument is a Symbol then a\n * 'TypeError' is thrown. This version also allows Symbols be converted to\n * a string. Other uncoercible exotics will still throw though.\n *\n * @param {*} value - The value to convert to a string.\n * @returns {string} The converted value.\n * @example\n * var toStringSymbolsSupported = require('to-string-symbols-supported-x');\n *\n * toStringSymbolsSupported(); // 'undefined'\n * toStringSymbolsSupported(null); // 'null'\n * toStringSymbolsSupported('abc'); // 'abc'\n * toStringSymbolsSupported(true); // 'true'\n * toStringSymbolsSupported(Symbol('foo')); // 'Symbol('foo')'\n * toStringSymbolsSupported(Object(Symbol('foo'))); // 'Symbol('foo')'\n * toStringSymbolsSupported(Object.create(null)); // TypeError\n */\nmodule.exports = function toStringSymbolsSupported(value) {\n  return isSymbol && isSymbol(value) ? pToString.call(value) : castString(value);\n};\n\n\n/***/ }),\n/* 635 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file ToInteger converts 'argument' to an integral numeric value.\n * @see {@link http://www.ecma-international.org/ecma-262/6.0/#sec-tointeger|7.1.4 ToInteger ( argument )}\n * @version 3.0.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module to-integer-x\n */\n\n\n\nvar libToNumber = __webpack_require__(86);\nvar toNumber2016 = libToNumber.toNumber2016;\nvar toNumber2018 = libToNumber.toNumber2018;\nvar numberIsNaN = __webpack_require__(139);\nvar numberIsFinite = __webpack_require__(637);\nvar libMathSign = __webpack_require__(639);\nvar mathSign2016 = libMathSign.sign2016;\nvar mathSign2018 = libMathSign.sign2018;\nvar mathFloor = Math.floor;\nvar mathAbs = Math.abs;\n\nvar $toInteger2016 = function toInteger2016(value) {\n  var number = toNumber2016(value);\n  if (numberIsNaN(number)) {\n    return 0;\n  }\n\n  if (number === 0 || numberIsFinite(number) === false) {\n    return number;\n  }\n\n  return mathSign2016(number) * mathFloor(mathAbs(number));\n};\n\nvar $toInteger2018 = function toInteger2018(value) {\n  var number = toNumber2018(value);\n  if (numberIsNaN(number)) {\n    return 0;\n  }\n\n  if (number === 0 || numberIsFinite(number) === false) {\n    return number;\n  }\n\n  return mathSign2018(number) * mathFloor(mathAbs(number));\n};\n\nmodule.exports = {\n  /**\n   * Reference to toInteger2018.\n   */\n  toInteger: $toInteger2018,\n\n  /**\n   * Converts `value` to an integer. (ES2016)\n   *\n   * @param {*} value - The value to convert.\n   * @returns {number} Returns the converted integer.\n   *\n   * @example\n   * var toInteger = require('to-integer-x').toInteger2016;\n   * toInteger(3); // 3\n   * toInteger(Number.MIN_VALUE); // 0\n   * toInteger(Infinity); // 1.7976931348623157e+308\n   * toInteger('3'); // 3\n   */\n  toInteger2016: $toInteger2016,\n\n  /**\n   * Converts `value` to an integer. (ES2018)\n   *\n   * @param {*} value - The value to convert.\n   * @returns {number} Returns the converted integer.\n   *\n   * @example\n   * var toInteger = require('to-integer-x').toInteger2018;\n   * toInteger(3); // 3\n   * toInteger(Number.MIN_VALUE); // 0\n   * toInteger(Infinity); // 1.7976931348623157e+308\n   * toInteger('3'); // 3\n   */\n  toInteger2018: $toInteger2018\n};\n\n\n/***/ }),\n/* 636 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Parses a string argument and returns an integer of the specified radix.\n * @version 2.0.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module parse-int-x\n */\n\n\n\nvar nativeParseInt = parseInt;\nvar NAN = __webpack_require__(220);\nvar toStr = __webpack_require__(85);\nvar trimLeft2016 = __webpack_require__(133).trimLeft2016;\nvar trimLeft2018 = __webpack_require__(133).trimLeft2018;\nvar chachedCtrs = __webpack_require__(38);\nvar castNumber = chachedCtrs.Number;\nvar charAt = chachedCtrs.String.prototype.charAt;\nvar hexRegex = /^[-+]?0[xX]/;\nvar test = hexRegex.test;\n\nvar $parseInt2016 = function parseInt2016(string, radix) {\n  var str = trimLeft2016(toStr(string));\n\n  return nativeParseInt(str, castNumber(radix) || (test.call(hexRegex, str) ? 16 : 10));\n};\n\nvar $parseInt2018 = function parseInt2018(string, radix) {\n  var str = trimLeft2018(toStr(string));\n  if (charAt.call(str, 0) === '\\u180E') {\n    return NAN;\n  }\n\n  return nativeParseInt(str, castNumber(radix) || (test.call(hexRegex, str) ? 16 : 10));\n};\n\nmodule.exports = {\n  /**\n   * Reference to parseInt2018.\n   */\n  parseInt: $parseInt2018,\n\n  /**\n   * This method parses a string argument and returns an integer of the specified\n   * radix (the base in mathematical numeral systems). (ES2016)\n   *\n   * @param {string} string - The value to parse. If the string argument is not a\n   *  string, then it is converted to a string (using the ToString abstract\n   *  operation). Leading whitespace in the string argument is ignored.\n   * @param {number} radix - An integer between 2 and 36 that represents the radix\n   *  (the base in mathematical numeral systems) of the above mentioned string.\n   *  Specify 10 for the decimal numeral system commonly used by humans. Always\n   *  specify this parameter to eliminate reader confusion and to guarantee\n   *  predictable behavior. Different implementations produce different results\n   *  when a radix is not specified, usually defaulting the value to 10.\n   * @throws {TypeError} If target is a Symbol or is not coercible.\n   * @returns {number} An integer number parsed from the given string. If the first\n   *  character cannot be converted to a number, NaN is returned.\n   * @example\n   * var $parseInt = require('parse-int-x').parseInt2016;\n   *\n   * // The following examples all return 15\n   * $parseInt(' 0xF', 16);\n   * $parseInt(' F', 16);\n   * $parseInt('17', 8);\n   * $parseInt(021, 8);\n   * $parseInt('015', 10);   // $parseInt(015, 10); will return 15\n   * $parseInt(15.99, 10);\n   * $parseInt('15,123', 10);\n   * $parseInt('FXX123', 16);\n   * $parseInt('1111', 2);\n   * $parseInt('15 * 3', 10);\n   * $parseInt('15e2', 10);\n   * $parseInt('15px', 10);\n   * $parseInt('12', 13);\n   *\n   * //The following examples all return NaN:\n   * $parseInt('Hello', 8); // Not a number at all\n   * $parseInt('546', 2);   // Digits are not valid for binary representations\n   */\n  parseInt2016: $parseInt2016,\n\n  /**\n   * This method parses a string argument and returns an integer of the specified\n   * radix (the base in mathematical numeral systems). (ES2018)\n   *\n   * @param {string} string - The value to parse. If the string argument is not a\n   *  string, then it is converted to a string (using the ToString abstract\n   *  operation). Leading whitespace in the string argument is ignored.\n   * @param {number} radix - An integer between 2 and 36 that represents the radix\n   *  (the base in mathematical numeral systems) of the above mentioned string.\n   *  Specify 10 for the decimal numeral system commonly used by humans. Always\n   *  specify this parameter to eliminate reader confusion and to guarantee\n   *  predictable behavior. Different implementations produce different results\n   *  when a radix is not specified, usually defaulting the value to 10.\n   * @throws {TypeError} If target is a Symbol or is not coercible.\n   * @returns {number} An integer number parsed from the given string. If the first\n   *  character cannot be converted to a number, NaN is returned.\n   * @example\n   * var $parseInt = require('parse-int-x').parseInt2018;\n   *\n   * // The following examples all return 15\n   * $parseInt(' 0xF', 16);\n   * $parseInt(' F', 16);\n   * $parseInt('17', 8);\n   * $parseInt(021, 8);\n   * $parseInt('015', 10);   // $parseInt(015, 10); will return 15\n   * $parseInt(15.99, 10);\n   * $parseInt('15,123', 10);\n   * $parseInt('FXX123', 16);\n   * $parseInt('1111', 2);\n   * $parseInt('15 * 3', 10);\n   * $parseInt('15e2', 10);\n   * $parseInt('15px', 10);\n   * $parseInt('12', 13);\n   *\n   * //The following examples all return NaN:\n   * $parseInt('Hello', 8); // Not a number at all\n   * $parseInt('546', 2);   // Digits are not valid for binary representations\n   */\n  parseInt2018: $parseInt2018\n};\n\n\n/***/ }),\n/* 637 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file ES6-compliant shim for Number.isFinite.\n * @see {@link http://www.ecma-international.org/ecma-262/6.0/#sec-number.isfinite|20.1.2.2 Number.isFinite ( number )}\n * @version 3.0.4\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module is-finite-x\n */\n\n\n\nvar numberIsNaN = __webpack_require__(139);\nvar INFINITY = __webpack_require__(638);\n\n/**\n * This method determines whether the passed value is a finite number.\n *\n * @param {*} number - The value to be tested for finiteness.\n * @returns {boolean} A Boolean indicating whether or not the given value is a finite number.\n * @example\n * var numIsFinite = require('is-finite-x');\n *\n * numIsFinite(Infinity);  // false\n * numIsFinite(NaN);       // false\n * numIsFinite(-Infinity); // false\n *\n * numIsFinite(0);         // true\n * numIsFinite(2e64);      // true\n *\n * numIsFinite('0');       // false, would've been true with\n *                         // global isFinite('0')\n * numIsFinite(null);      // false, would've been true with\n */\nmodule.exports = function isFinite(number) {\n  return typeof number === 'number' && numberIsNaN(number) === false && number !== INFINITY && number !== -INFINITY;\n};\n\n\n/***/ }),\n/* 638 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file The constant value Infinity.\n * @version 1.0.2\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module infinity-x\n */\n\n\n\n/**\n * The constant value Infinity derived mathematically by 1 / 0.\n *\n * @type number\n * @example\n * var INFINITY = require('infinity-x');\n *\n * INFINITY === Infinity; // true\n * -INFINITY === -Infinity; // true\n * INFINITY === -Infinity; // false\n */\nmodule.exports = 1 / 0;\n\n\n/***/ }),\n/* 639 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Shim for Math.sign.\n * @see {@link http://www.ecma-international.org/ecma-262/6.0/#sec-math.sign|20.2.2.29 Math.sign(x)}\n * @version 3.0.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module math-sign-x\n */\n\n\n\nvar libToNumber = __webpack_require__(86);\nvar toNumber2016 = libToNumber.toNumber2016;\nvar toNumber2018 = libToNumber.toNumber2018;\nvar numberIsNaN = __webpack_require__(139);\n\nvar $sign2016 = function sign2016(x) {\n  var n = toNumber2016(x);\n  if (n === 0 || numberIsNaN(n)) {\n    return n;\n  }\n\n  return n > 0 ? 1 : -1;\n};\n\nvar $sign2018 = function sign2018(x) {\n  var n = toNumber2018(x);\n  if (n === 0 || numberIsNaN(n)) {\n    return n;\n  }\n\n  return n > 0 ? 1 : -1;\n};\n\nmodule.exports = {\n  /**\n   * Reference to sign2018.\n   */\n  sign: $sign2018,\n\n  /**\n   * This method returns the sign of a number, indicating whether the number is positive,\n   * negative or zero. (ES2016)\n   *\n   * @param {*} x - A number.\n   * @returns {number} A number representing the sign of the given argument. If the argument\n   * is a positive number, negative number, positive zero or negative zero, the function will\n   * return 1, -1, 0 or -0 respectively. Otherwise, NaN is returned.\n   * @example\n   * var mathSign = require('math-sign-x').sign2016;\n   *\n   * mathSign(3);     //  1\n   * mathSign(-3);    // -1\n   * mathSign('-3');  // -1\n   * mathSign(0);     //  0\n   * mathSign(-0);    // -0\n   * mathSign(NaN);   // NaN\n   * mathSign('foo'); // NaN\n   * mathSign();      // NaN\n   */\n  sign2016: $sign2016,\n\n  /**\n   * This method returns the sign of a number, indicating whether the number is positive,\n   * negative or zero. (ES2018)\n   *\n   * @param {*} x - A number.\n   * @returns {number} A number representing the sign of the given argument. If the argument\n   * is a positive number, negative number, positive zero or negative zero, the function will\n   * return 1, -1, 0 or -0 respectively. Otherwise, NaN is returned.\n   * @example\n   * var mathSign = require('math-sign-x').sign2018;\n   *\n   * mathSign(3);     //  1\n   * mathSign(-3);    // -1\n   * mathSign('-3');  // -1\n   * mathSign(0);     //  0\n   * mathSign(-0);    // -0\n   * mathSign(NaN);   // NaN\n   * mathSign('foo'); // NaN\n   * mathSign();      // NaN\n   */\n  sign2018: $sign2018\n};\n\n\n/***/ }),\n/* 640 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Clamp a number to limits.\n * @version 1.2.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module math-clamp-x\n */\n\n\n\nvar toNumber = __webpack_require__(86).toNumber2018;\n\n/**\n * This method clamp a number to min and max limits inclusive.\n *\n * @param {number} value - The number to be clamped.\n * @param {number} [min=0] - The minimum number.\n * @param {number} max - The maximum number.\n * @throws {RangeError} If min > max.\n * @return {number} The clamped number.\n * @example\n * var mathClamp = require('math-clamp-x');\n */\nmodule.exports = function clamp(value) {\n  var number = toNumber(value);\n  var argsLength = arguments.length;\n  if (argsLength < 2) {\n    return number;\n  }\n\n  var min = toNumber(arguments[1]);\n  var max;\n  if (argsLength < 3) {\n    max = min;\n    min = 0;\n  } else {\n    max = toNumber(arguments[2]);\n  }\n\n  if (min > max) {\n    throw new RangeError('\"min\" must be less than \"max\"');\n  }\n\n  if (number < min) {\n    return min;\n  }\n\n  if (number > max) {\n    return max;\n  }\n\n  return number;\n};\n\n\n/***/ }),\n/* 641 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nmodule.exports = 9007199254740991;\n\n\n/***/ }),\n/* 642 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/**\n * @file Indicates whether the specified property is enumerable.\n * @version 1.1.0\n * @author Xotic750 <Xotic750@gmail.com>\n * @copyright  Xotic750\n * @license {@link <https://opensource.org/licenses/MIT> MIT}\n * @module property-is-enumerable-x\n */\n\n\n\nvar toPropertyKey = __webpack_require__(138);\nvar toObject = __webpack_require__(137);\nvar propIsEnumerable = Object.prototype.propertyIsEnumerable;\n\n/**\n * This method returns a Boolean indicating whether the specified property is\n * enumerable. Does not attempt to fix bugs in IE<9 or old Opera, otherwise it\n * does ES6ify the method.\n *\n * @param {!Object} object - The object on which to test the property.\n * @param {string|Symbol} property - The name of the property to test.\n * @throws {TypeError} If target is null or undefined.\n * @returns {boolean} A Boolean indicating whether the specified property is\n *  enumerable.\n * @example\n * var propertyIsEnumerable = require('property-is-enumerable-x');\n *\n * var o = {};\n * var a = [];\n * o.prop = 'is enumerable';\n * a[0] = 'is enumerable';\n *\n * propertyIsEnumerable(o, 'prop'); // true\n * propertyIsEnumerable(a, 0); // true\n */\nmodule.exports = function propertyIsEnumerable(object, property) {\n  return propIsEnumerable.call(toObject(object), toPropertyKey(property));\n};\n\n\n/***/ }),\n/* 643 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return allDocsKeysQuery; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"d\", function() { return parseDoc; });\n/* unused harmony export preprocessAttachments */\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"e\", function() { return processDocs; });\n/* unused harmony export updateDoc */\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_pouchdb_promise__ = __webpack_require__(120);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_pouchdb_utils__ = __webpack_require__(119);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__ = __webpack_require__(122);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_3_pouchdb_binary_utils__ = __webpack_require__(123);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_4_pouchdb_md5__ = __webpack_require__(221);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__ = __webpack_require__(222);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_6_pouchdb_collections__ = __webpack_require__(121);\n/* unused harmony reexport invalidIdError */\n/* harmony reexport (binding) */ __webpack_require__.d(__webpack_exports__, \"b\", function() { return __WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"c\"]; });\n/* harmony reexport (binding) */ __webpack_require__.d(__webpack_exports__, \"c\", function() { return __WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"d\"]; });\n/* unused harmony reexport normalizeDdocFunctionName */\n/* unused harmony reexport parseDdocFunctionName */\n\n\n\n\n\n\n\n\nfunction allDocsKeysQuery(api, opts) {\n  var keys = opts.keys;\n  var finalResults = {\n    offset: opts.skip\n  };\n  return __WEBPACK_IMPORTED_MODULE_0_pouchdb_promise__[\"a\" /* default */].all(keys.map(function (key) {\n    var subOpts = Object(__WEBPACK_IMPORTED_MODULE_1_pouchdb_utils__[\"a\" /* assign */])({key: key, deleted: 'ok'}, opts);\n    ['limit', 'skip', 'keys'].forEach(function (optKey) {\n      delete subOpts[optKey];\n    });\n    return new __WEBPACK_IMPORTED_MODULE_0_pouchdb_promise__[\"a\" /* default */](function (resolve, reject) {\n      api._allDocs(subOpts, function (err, res) {\n        /* istanbul ignore if */\n        if (err) {\n          return reject(err);\n        }\n        /* istanbul ignore if */\n        if (opts.update_seq && res.update_seq !== undefined) {\n          finalResults.update_seq = res.update_seq;\n        }\n        finalResults.total_rows = res.total_rows;\n        resolve(res.rows[0] || {key: key, error: 'not_found'});\n      });\n    });\n  })).then(function (results) {\n    finalResults.rows = results;\n    return finalResults;\n  });\n}\n\nfunction toObject(array) {\n  return array.reduce(function (obj, item) {\n    obj[item] = true;\n    return obj;\n  }, {});\n}\n// List of top level reserved words for doc\nvar reservedWords = toObject([\n  '_id',\n  '_rev',\n  '_attachments',\n  '_deleted',\n  '_revisions',\n  '_revs_info',\n  '_conflicts',\n  '_deleted_conflicts',\n  '_local_seq',\n  '_rev_tree',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats',\n  // Specific to Couchbase Sync Gateway\n  '_removed'\n]);\n\n// List of reserved words that should end up the document\nvar dataWords = toObject([\n  '_attachments',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats'\n]);\n\nfunction parseRevisionInfo(rev$$1) {\n  if (!/^\\d+-./.test(rev$$1)) {\n    return Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"e\" /* INVALID_REV */]);\n  }\n  var idx = rev$$1.indexOf('-');\n  var left = rev$$1.substring(0, idx);\n  var right = rev$$1.substring(idx + 1);\n  return {\n    prefix: parseInt(left, 10),\n    id: right\n  };\n}\n\nfunction makeRevTreeFromRevisions(revisions, opts) {\n  var pos = revisions.start - revisions.ids.length + 1;\n\n  var revisionIds = revisions.ids;\n  var ids = [revisionIds[0], opts, []];\n\n  for (var i = 1, len = revisionIds.length; i < len; i++) {\n    ids = [revisionIds[i], {status: 'missing'}, [ids]];\n  }\n\n  return [{\n    pos: pos,\n    ids: ids\n  }];\n}\n\n// Preprocess documents, parse their revisions, assign an id and a\n// revision for new writes that are missing them, etc\nfunction parseDoc(doc, newEdits) {\n\n  var nRevNum;\n  var newRevId;\n  var revInfo;\n  var opts = {status: 'available'};\n  if (doc._deleted) {\n    opts.deleted = true;\n  }\n\n  if (newEdits) {\n    if (!doc._id) {\n      doc._id = Object(__WEBPACK_IMPORTED_MODULE_1_pouchdb_utils__[\"i\" /* uuid */])();\n    }\n    newRevId = Object(__WEBPACK_IMPORTED_MODULE_1_pouchdb_utils__[\"h\" /* rev */])();\n    if (doc._rev) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      doc._rev_tree = [{\n        pos: revInfo.prefix,\n        ids: [revInfo.id, {status: 'missing'}, [[newRevId, opts, []]]]\n      }];\n      nRevNum = revInfo.prefix + 1;\n    } else {\n      doc._rev_tree = [{\n        pos: 1,\n        ids : [newRevId, opts, []]\n      }];\n      nRevNum = 1;\n    }\n  } else {\n    if (doc._revisions) {\n      doc._rev_tree = makeRevTreeFromRevisions(doc._revisions, opts);\n      nRevNum = doc._revisions.start;\n      newRevId = doc._revisions.ids[0];\n    }\n    if (!doc._rev_tree) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      nRevNum = revInfo.prefix;\n      newRevId = revInfo.id;\n      doc._rev_tree = [{\n        pos: nRevNum,\n        ids: [newRevId, opts, []]\n      }];\n    }\n  }\n\n  Object(__WEBPACK_IMPORTED_MODULE_1_pouchdb_utils__[\"f\" /* invalidIdError */])(doc._id);\n\n  doc._rev = nRevNum + '-' + newRevId;\n\n  var result = {metadata : {}, data : {}};\n  for (var key in doc) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(doc, key)) {\n      var specialKey = key[0] === '_';\n      if (specialKey && !reservedWords[key]) {\n        var error = Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"c\" /* DOC_VALIDATION */], key);\n        error.message = __WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"c\" /* DOC_VALIDATION */].message + ': ' + key;\n        throw error;\n      } else if (specialKey && !dataWords[key]) {\n        result.metadata[key.slice(1)] = doc[key];\n      } else {\n        result.data[key] = doc[key];\n      }\n    }\n  }\n  return result;\n}\n\nfunction parseBase64(data) {\n  try {\n    return Object(__WEBPACK_IMPORTED_MODULE_3_pouchdb_binary_utils__[\"a\" /* atob */])(data);\n  } catch (e) {\n    var err = Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"a\" /* BAD_ARG */],\n      'Attachment is not a valid base64 string');\n    return {error: err};\n  }\n}\n\nfunction preprocessString(att, blobType, callback) {\n  var asBinary = parseBase64(att.data);\n  if (asBinary.error) {\n    return callback(asBinary.error);\n  }\n\n  att.length = asBinary.length;\n  if (blobType === 'blob') {\n    att.data = Object(__WEBPACK_IMPORTED_MODULE_3_pouchdb_binary_utils__[\"b\" /* binaryStringToBlobOrBuffer */])(asBinary, att.content_type);\n  } else if (blobType === 'base64') {\n    att.data = Object(__WEBPACK_IMPORTED_MODULE_3_pouchdb_binary_utils__[\"f\" /* btoa */])(asBinary);\n  } else { // binary\n    att.data = asBinary;\n  }\n  Object(__WEBPACK_IMPORTED_MODULE_4_pouchdb_md5__[\"a\" /* binaryMd5 */])(asBinary, function (result) {\n    att.digest = 'md5-' + result;\n    callback();\n  });\n}\n\nfunction preprocessBlob(att, blobType, callback) {\n  Object(__WEBPACK_IMPORTED_MODULE_4_pouchdb_md5__[\"a\" /* binaryMd5 */])(att.data, function (md5) {\n    att.digest = 'md5-' + md5;\n    // size is for blobs (browser), length is for buffers (node)\n    att.length = att.data.size || att.data.length || 0;\n    if (blobType === 'binary') {\n      Object(__WEBPACK_IMPORTED_MODULE_3_pouchdb_binary_utils__[\"e\" /* blobOrBufferToBinaryString */])(att.data, function (binString) {\n        att.data = binString;\n        callback();\n      });\n    } else if (blobType === 'base64') {\n      Object(__WEBPACK_IMPORTED_MODULE_3_pouchdb_binary_utils__[\"d\" /* blobOrBufferToBase64 */])(att.data, function (b64) {\n        att.data = b64;\n        callback();\n      });\n    } else {\n      callback();\n    }\n  });\n}\n\nfunction preprocessAttachment(att, blobType, callback) {\n  if (att.stub) {\n    return callback();\n  }\n  if (typeof att.data === 'string') { // input is a base64 string\n    preprocessString(att, blobType, callback);\n  } else { // input is a blob\n    preprocessBlob(att, blobType, callback);\n  }\n}\n\nfunction preprocessAttachments(docInfos, blobType, callback) {\n\n  if (!docInfos.length) {\n    return callback();\n  }\n\n  var docv = 0;\n  var overallErr;\n\n  docInfos.forEach(function (docInfo) {\n    var attachments = docInfo.data && docInfo.data._attachments ?\n      Object.keys(docInfo.data._attachments) : [];\n    var recv = 0;\n\n    if (!attachments.length) {\n      return done();\n    }\n\n    function processedAttachment(err) {\n      overallErr = err;\n      recv++;\n      if (recv === attachments.length) {\n        done();\n      }\n    }\n\n    for (var key in docInfo.data._attachments) {\n      if (docInfo.data._attachments.hasOwnProperty(key)) {\n        preprocessAttachment(docInfo.data._attachments[key],\n          blobType, processedAttachment);\n      }\n    }\n  });\n\n  function done() {\n    docv++;\n    if (docInfos.length === docv) {\n      if (overallErr) {\n        callback(overallErr);\n      } else {\n        callback();\n      }\n    }\n  }\n}\n\nfunction updateDoc(revLimit, prev, docInfo, results,\n                   i, cb, writeDoc, newEdits) {\n\n  if (Object(__WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"g\" /* revExists */])(prev.rev_tree, docInfo.metadata.rev)) {\n    results[i] = docInfo;\n    return cb();\n  }\n\n  // sometimes this is pre-calculated. historically not always\n  var previousWinningRev = prev.winningRev || Object(__WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"i\" /* winningRev */])(prev);\n  var previouslyDeleted = 'deleted' in prev ? prev.deleted :\n    Object(__WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"c\" /* isDeleted */])(prev, previousWinningRev);\n  var deleted = 'deleted' in docInfo.metadata ? docInfo.metadata.deleted :\n    Object(__WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"c\" /* isDeleted */])(docInfo.metadata);\n  var isRoot = /^1-/.test(docInfo.metadata.rev);\n\n  if (previouslyDeleted && !deleted && newEdits && isRoot) {\n    var newDoc = docInfo.data;\n    newDoc._rev = previousWinningRev;\n    newDoc._id = docInfo.metadata.id;\n    docInfo = parseDoc(newDoc, newEdits);\n  }\n\n  var merged = Object(__WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"f\" /* merge */])(prev.rev_tree, docInfo.metadata.rev_tree[0], revLimit);\n\n  var inConflict = newEdits && ((\n    (previouslyDeleted && deleted && merged.conflicts !== 'new_leaf') ||\n    (!previouslyDeleted && merged.conflicts !== 'new_leaf') ||\n    (previouslyDeleted && !deleted && merged.conflicts === 'new_branch')));\n\n  if (inConflict) {\n    var err = Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"k\" /* REV_CONFLICT */]);\n    results[i] = err;\n    return cb();\n  }\n\n  var newRev = docInfo.metadata.rev;\n  docInfo.metadata.rev_tree = merged.tree;\n  docInfo.stemmedRevs = merged.stemmedRevs || [];\n  /* istanbul ignore else */\n  if (prev.rev_map) {\n    docInfo.metadata.rev_map = prev.rev_map; // used only by leveldb\n  }\n\n  // recalculate\n  var winningRev$$1 = Object(__WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"i\" /* winningRev */])(docInfo.metadata);\n  var winningRevIsDeleted = Object(__WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"c\" /* isDeleted */])(docInfo.metadata, winningRev$$1);\n\n  // calculate the total number of documents that were added/removed,\n  // from the perspective of total_rows/doc_count\n  var delta = (previouslyDeleted === winningRevIsDeleted) ? 0 :\n    previouslyDeleted < winningRevIsDeleted ? -1 : 1;\n\n  var newRevIsDeleted;\n  if (newRev === winningRev$$1) {\n    // if the new rev is the same as the winning rev, we can reuse that value\n    newRevIsDeleted = winningRevIsDeleted;\n  } else {\n    // if they're not the same, then we need to recalculate\n    newRevIsDeleted = Object(__WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"c\" /* isDeleted */])(docInfo.metadata, newRev);\n  }\n\n  writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n    true, delta, i, cb);\n}\n\nfunction rootIsMissing(docInfo) {\n  return docInfo.metadata.rev_tree[0].ids[1].status === 'missing';\n}\n\nfunction processDocs(revLimit, docInfos, api, fetchedDocs, tx, results,\n                     writeDoc, opts, overallCallback) {\n\n  // Default to 1000 locally\n  revLimit = revLimit || 1000;\n\n  function insertDoc(docInfo, resultsIdx, callback) {\n    // Cant insert new deleted documents\n    var winningRev$$1 = Object(__WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"i\" /* winningRev */])(docInfo.metadata);\n    var deleted = Object(__WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"c\" /* isDeleted */])(docInfo.metadata, winningRev$$1);\n    if ('was_delete' in opts && deleted) {\n      results[resultsIdx] = Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"f\" /* MISSING_DOC */], 'deleted');\n      return callback();\n    }\n\n    // 4712 - detect whether a new document was inserted with a _rev\n    var inConflict = newEdits && rootIsMissing(docInfo);\n\n    if (inConflict) {\n      var err = Object(__WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"l\" /* createError */])(__WEBPACK_IMPORTED_MODULE_2_pouchdb_errors__[\"k\" /* REV_CONFLICT */]);\n      results[resultsIdx] = err;\n      return callback();\n    }\n\n    var delta = deleted ? 0 : 1;\n\n    writeDoc(docInfo, winningRev$$1, deleted, deleted, false,\n      delta, resultsIdx, callback);\n  }\n\n  var newEdits = opts.new_edits;\n  var idsToDocs = new __WEBPACK_IMPORTED_MODULE_6_pouchdb_collections__[\"a\" /* Map */]();\n\n  var docsDone = 0;\n  var docsToDo = docInfos.length;\n\n  function checkAllDocsDone() {\n    if (++docsDone === docsToDo && overallCallback) {\n      overallCallback();\n    }\n  }\n\n  docInfos.forEach(function (currentDoc, resultsIdx) {\n\n    if (currentDoc._id && Object(__WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"d\" /* isLocalId */])(currentDoc._id)) {\n      var fun = currentDoc._deleted ? '_removeLocal' : '_putLocal';\n      api[fun](currentDoc, {ctx: tx}, function (err, res) {\n        results[resultsIdx] = err || res;\n        checkAllDocsDone();\n      });\n      return;\n    }\n\n    var id = currentDoc.metadata.id;\n    if (idsToDocs.has(id)) {\n      docsToDo--; // duplicate\n      idsToDocs.get(id).push([currentDoc, resultsIdx]);\n    } else {\n      idsToDocs.set(id, [[currentDoc, resultsIdx]]);\n    }\n  });\n\n  // in the case of new_edits, the user can provide multiple docs\n  // with the same id. these need to be processed sequentially\n  idsToDocs.forEach(function (docs, id) {\n    var numDone = 0;\n\n    function docWritten() {\n      if (++numDone < docs.length) {\n        nextDoc();\n      } else {\n        checkAllDocsDone();\n      }\n    }\n    function nextDoc() {\n      var value = docs[numDone];\n      var currentDoc = value[0];\n      var resultsIdx = value[1];\n\n      if (fetchedDocs.has(id)) {\n        updateDoc(revLimit, fetchedDocs.get(id), currentDoc, results,\n          resultsIdx, docWritten, writeDoc, newEdits);\n      } else {\n        // Ensure stemming applies to new writes as well\n        var merged = Object(__WEBPACK_IMPORTED_MODULE_5_pouchdb_merge__[\"f\" /* merge */])([], currentDoc.metadata.rev_tree[0], revLimit);\n        currentDoc.metadata.rev_tree = merged.tree;\n        currentDoc.stemmedRevs = merged.stemmedRevs || [];\n        insertDoc(currentDoc, resultsIdx, docWritten);\n      }\n    }\n    nextDoc();\n  });\n}\n\n\n\n\n/***/ }),\n/* 644 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return safeJsonParse; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"b\", function() { return safeJsonStringify; });\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_vuvuzela__ = __webpack_require__(184);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_vuvuzela___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_0_vuvuzela__);\n\n\nfunction safeJsonParse(str) {\n  // This try/catch guards against stack overflow errors.\n  // JSON.parse() is faster than vuvuzela.parse() but vuvuzela\n  // cannot overflow.\n  try {\n    return JSON.parse(str);\n  } catch (e) {\n    /* istanbul ignore next */\n    return __WEBPACK_IMPORTED_MODULE_0_vuvuzela___default.a.parse(str);\n  }\n}\n\nfunction safeJsonStringify(json) {\n  try {\n    return JSON.stringify(json);\n  } catch (e) {\n    /* istanbul ignore next */\n    return __WEBPACK_IMPORTED_MODULE_0_vuvuzela___default.a.stringify(json);\n  }\n}\n\n\n\n\n/***/ }),\n/* 645 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(Buffer) {var inherits          = __webpack_require__(6)\n  , AbstractLevelDOWN = __webpack_require__(223).AbstractLevelDOWN\n  , AbstractIterator  = __webpack_require__(223).AbstractIterator\n  , ltgt              = __webpack_require__(647)\n  , createRBT = __webpack_require__(648)\n  , globalStore       = {}\n\n// In Node, use global.setImmediate. In the browser, use a consistent\n// microtask library to give consistent microtask experience to all browsers\nvar setImmediate = __webpack_require__(649)\n\nfunction gt(value) {\n  return ltgt.compare(value, this._end) > 0\n}\n\nfunction gte(value) {\n  return ltgt.compare(value, this._end) >= 0\n}\n\nfunction lt(value) {\n  return ltgt.compare(value, this._end) < 0\n}\n\nfunction lte(value) {\n  return ltgt.compare(value, this._end) <= 0\n}\n\n\nfunction MemIterator (db, options) {\n  AbstractIterator.call(this, db)\n  this._limit   = options.limit\n\n  if (this._limit === -1)\n    this._limit = Infinity\n\n  var tree = db._store[db._location]\n\n  this.keyAsBuffer = options.keyAsBuffer !== false\n  this.valueAsBuffer = options.valueAsBuffer !== false\n  this._reverse   = options.reverse\n  this._options = options\n  this._done = 0\n\n  if (!this._reverse) {\n    this._incr = 'next'\n    this._start = ltgt.lowerBound(options)\n    this._end = ltgt.upperBound(options)\n\n    if (typeof this._start === 'undefined')\n      this._tree = tree.begin\n    else if (ltgt.lowerBoundInclusive(options))\n      this._tree = tree.ge(this._start)\n    else\n      this._tree = tree.gt(this._start)\n\n    if (this._end) {\n      if (ltgt.upperBoundInclusive(options))\n        this._test = lte\n      else\n        this._test = lt\n    }\n\n  } else {\n    this._incr = 'prev'\n    this._start = ltgt.upperBound(options)\n    this._end = ltgt.lowerBound(options)\n\n    if (typeof this._start === 'undefined')\n      this._tree = tree.end\n    else if (ltgt.upperBoundInclusive(options))\n      this._tree = tree.le(this._start)\n    else\n      this._tree = tree.lt(this._start)\n\n    if (this._end) {\n      if (ltgt.lowerBoundInclusive(options))\n        this._test = gte\n      else\n        this._test = gt\n    }\n\n  }\n\n}\n\ninherits(MemIterator, AbstractIterator)\n\nMemIterator.prototype._next = function (callback) {\n  var key\n    , value\n\n  if (this._done++ >= this._limit)\n    return setImmediate(callback)\n\n  if (!this._tree.valid)\n    return setImmediate(callback)\n\n  key = this._tree.key\n  value = this._tree.value\n\n  if (!this._test(key))\n    return setImmediate(callback)\n\n  if (this.keyAsBuffer)\n    key = new Buffer(key)\n\n  if (this.valueAsBuffer)\n    value = new Buffer(value)\n\n  this._tree[this._incr]()\n\n  setImmediate(function callNext() {\n    callback(null, key, value)\n  })\n}\n\nMemIterator.prototype._test = function () {return true}\n\nfunction MemDOWN (location) {\n  if (!(this instanceof MemDOWN))\n    return new MemDOWN(location)\n\n  AbstractLevelDOWN.call(this, typeof location == 'string' ? location : '')\n\n  this._location = this.location ? ('$' + this.location) : '_tree'\n  this._store = this.location ? globalStore: this\n  this._store[this._location] = this._store[this._location] || createRBT(ltgt.compare)\n}\n\nMemDOWN.clearGlobalStore = function (strict) {\n  if (strict) {\n    Object.keys(globalStore).forEach(function (key) {\n      delete globalStore[key]\n    })\n  } else {\n    globalStore = {}\n  }\n}\n\ninherits(MemDOWN, AbstractLevelDOWN)\n\nMemDOWN.prototype._open = function (options, callback) {\n  var self = this\n  setImmediate(function callNext() { callback(null, self) })\n}\n\nMemDOWN.prototype._put = function (key, value, options, callback) {\n  if (typeof value === 'undefined' || value === null) value = ''\n\n  var iter = this._store[this._location].find(key)\n\n  if (iter.valid) {\n    this._store[this._location] = iter.update(value)\n  } else {\n    this._store[this._location] = this._store[this._location].insert(key, value)\n  }\n\n  setImmediate(callback)\n}\n\nMemDOWN.prototype._get = function (key, options, callback) {\n  var value = this._store[this._location].get(key)\n\n  if (typeof value === 'undefined') {\n    // 'NotFound' error, consistent with LevelDOWN API\n    return setImmediate(function callNext() { callback(new Error('NotFound')) })\n  }\n\n  if (options.asBuffer !== false && !this._isBuffer(value))\n    value = new Buffer(String(value))\n\n  setImmediate(function callNext () {\n    callback(null, value)\n  })\n\n}\n\nMemDOWN.prototype._del = function (key, options, callback) {\n  this._store[this._location] = this._store[this._location].remove(key)\n  setImmediate(callback)\n}\n\nMemDOWN.prototype._batch = function (array, options, callback) {\n  var i = -1\n    , key\n    , value\n    , iter\n    , len = array.length\n    , tree = this._store[this._location]\n\n  while (++i < len) {\n    if (!array[i])\n      continue\n\n    key = this._isBuffer(array[i].key) ? array[i].key : String(array[i].key)\n    iter = tree.find(key)\n\n    if (array[i].type === 'put') {\n      value = this._isBuffer(array[i].value) ? array[i].value : String(array[i].value)\n      tree = iter.valid ? iter.update(value) : tree.insert(key, value)\n    } else {\n      tree = iter.remove()\n    }\n  }\n\n  this._store[this._location] = tree\n\n  setImmediate(callback)\n}\n\nMemDOWN.prototype._iterator = function (options) {\n  return new MemIterator(this, options)\n}\n\nMemDOWN.prototype._isBuffer = function (obj) {\n  return Buffer.isBuffer(obj)\n}\n\nMemDOWN.destroy = function (name, callback) {\n  var key = '$' + name\n\n  if (key in globalStore)\n    delete globalStore[key]\n\n  setImmediate(callback)\n}\n\nmodule.exports = MemDOWN\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(24).Buffer))\n\n/***/ }),\n/* 646 */\n/***/ (function(module, exports, __webpack_require__) {\n\nvar AbstractLevelDOWN = __webpack_require__(224)\n\nfunction isLevelDOWN (db) {\n  if (!db || typeof db !== 'object')\n    return false\n  return Object.keys(AbstractLevelDOWN.prototype).filter(function (name) {\n    // TODO remove approximateSize check when method is gone\n    return name[0] != '_' && name != 'approximateSize'\n  }).every(function (name) {\n    return typeof db[name] == 'function'\n  })\n}\n\nmodule.exports = isLevelDOWN\n\n\n/***/ }),\n/* 647 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(Buffer) {\nexports.compare = function (a, b) {\n\n  if(Buffer.isBuffer(a)) {\n    var l = Math.min(a.length, b.length)\n    for(var i = 0; i < l; i++) {\n      var cmp = a[i] - b[i]\n      if(cmp) return cmp\n    }\n    return a.length - b.length\n  }\n\n  return a < b ? -1 : a > b ? 1 : 0\n}\n\nfunction has(obj, key) {\n  return Object.hasOwnProperty.call(obj, key)\n}\n\n// to be compatible with the current abstract-leveldown tests\n// nullish or empty strings.\n// I could use !!val but I want to permit numbers and booleans,\n// if possible.\n\nfunction isDef (val) {\n  return val !== undefined && val !== ''\n}\n\nfunction has (range, name) {\n  return Object.hasOwnProperty.call(range, name)\n}\n\nfunction hasKey(range, name) {\n  return Object.hasOwnProperty.call(range, name) && name\n}\n\nvar lowerBoundKey = exports.lowerBoundKey = function (range) {\n    return (\n       hasKey(range, 'gt')\n    || hasKey(range, 'gte')\n    || hasKey(range, 'min')\n    || (range.reverse ? hasKey(range, 'end') : hasKey(range, 'start'))\n    || undefined\n    )\n}\n\nvar lowerBound = exports.lowerBound = function (range) {\n  var k = lowerBoundKey(range)\n  return k && range[k]\n}\n\nvar lowerBoundInclusive = exports.lowerBoundInclusive = function (range) {\n  return has(range, 'gt') ? false : true\n}\n\nvar upperBoundInclusive = exports.upperBoundInclusive =\n  function (range) {\n    return (has(range, 'lt') /*&& !range.maxEx*/) ? false : true\n  }\n\nvar lowerBoundExclusive = exports.lowerBoundExclusive =\n  function (range) {\n    return !lowerBoundInclusive(range)\n  }\n\nvar upperBoundExclusive = exports.upperBoundExclusive =\n  function (range) {\n    return !upperBoundInclusive(range)\n  }\n\nvar upperBoundKey = exports.upperBoundKey = function (range) {\n    return (\n       hasKey(range, 'lt')\n    || hasKey(range, 'lte')\n    || hasKey(range, 'max')\n    || (range.reverse ? hasKey(range, 'start') : hasKey(range, 'end'))\n    || undefined\n    )\n}\n\nvar upperBound = exports.upperBound = function (range) {\n  var k = upperBoundKey(range)\n  return k && range[k]\n}\n\nfunction id (e) { return e }\n\nexports.toLtgt = function (range, _range, map, lower, upper) {\n  _range = _range || {}\n  map = map || id\n  var defaults = arguments.length > 3\n  var lb = exports.lowerBoundKey(range)\n  var ub = exports.upperBoundKey(range)\n  if(lb) {\n    if(lb === 'gt') _range.gt = map(range.gt, false)\n    else            _range.gte = map(range[lb], false)\n  }\n  else if(defaults)\n    _range.gte = map(lower, false)\n\n  if(ub) {\n    if(ub === 'lt') _range.lt = map(range.lt, true)\n    else            _range.lte = map(range[ub], true)\n  }\n  else if(defaults)\n    _range.lte = map(upper, true)\n\n  if(range.reverse != null)\n    _range.reverse = !!range.reverse\n\n  //if range was used mutably\n  //(in level-sublevel it's part of an options object\n  //that has more properties on it.)\n  if(has(_range, 'max'))   delete _range.max\n  if(has(_range, 'min'))   delete _range.min\n  if(has(_range, 'start')) delete _range.start\n  if(has(_range, 'end'))   delete _range.end\n\n  return _range\n}\n\nexports.contains = function (range, key, compare) {\n  compare = compare || exports.compare\n\n  var lb = lowerBound(range)\n  if(isDef(lb)) {\n    var cmp = compare(key, lb)\n    if(cmp < 0 || (cmp === 0 && lowerBoundExclusive(range)))\n      return false\n  }\n\n  var ub = upperBound(range)\n  if(isDef(ub)) {\n    var cmp = compare(key, ub)\n    if(cmp > 0 || (cmp === 0) && upperBoundExclusive(range))\n      return false\n  }\n\n  return true\n}\n\nexports.filter = function (range, compare) {\n  return function (key) {\n    return exports.contains(range, key, compare)\n  }\n}\n\n\n\n\n\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(24).Buffer))\n\n/***/ }),\n/* 648 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nmodule.exports = createRBTree\n\nvar RED   = 0\nvar BLACK = 1\n\nfunction RBNode(color, key, value, left, right, count) {\n  this._color = color\n  this.key = key\n  this.value = value\n  this.left = left\n  this.right = right\n  this._count = count\n}\n\nfunction cloneNode(node) {\n  return new RBNode(node._color, node.key, node.value, node.left, node.right, node._count)\n}\n\nfunction repaint(color, node) {\n  return new RBNode(color, node.key, node.value, node.left, node.right, node._count)\n}\n\nfunction recount(node) {\n  node._count = 1 + (node.left ? node.left._count : 0) + (node.right ? node.right._count : 0)\n}\n\nfunction RedBlackTree(compare, root) {\n  this._compare = compare\n  this.root = root\n}\n\nvar proto = RedBlackTree.prototype\n\nObject.defineProperty(proto, \"keys\", {\n  get: function() {\n    var result = []\n    this.forEach(function(k,v) {\n      result.push(k)\n    })\n    return result\n  }\n})\n\nObject.defineProperty(proto, \"values\", {\n  get: function() {\n    var result = []\n    this.forEach(function(k,v) {\n      result.push(v)\n    })\n    return result\n  }\n})\n\n//Returns the number of nodes in the tree\nObject.defineProperty(proto, \"length\", {\n  get: function() {\n    if(this.root) {\n      return this.root._count\n    }\n    return 0\n  }\n})\n\n//Insert a new item into the tree\nproto.insert = function(key, value) {\n  var cmp = this._compare\n  //Find point to insert new node at\n  var n = this.root\n  var n_stack = []\n  var d_stack = []\n  while(n) {\n    var d = cmp(key, n.key)\n    n_stack.push(n)\n    d_stack.push(d)\n    if(d <= 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  //Rebuild path to leaf node\n  n_stack.push(new RBNode(RED, key, value, null, null, 1))\n  for(var s=n_stack.length-2; s>=0; --s) {\n    var n = n_stack[s]\n    if(d_stack[s] <= 0) {\n      n_stack[s] = new RBNode(n._color, n.key, n.value, n_stack[s+1], n.right, n._count+1)\n    } else {\n      n_stack[s] = new RBNode(n._color, n.key, n.value, n.left, n_stack[s+1], n._count+1)\n    }\n  }\n  //Rebalance tree using rotations\n  //console.log(\"start insert\", key, d_stack)\n  for(var s=n_stack.length-1; s>1; --s) {\n    var p = n_stack[s-1]\n    var n = n_stack[s]\n    if(p._color === BLACK || n._color === BLACK) {\n      break\n    }\n    var pp = n_stack[s-2]\n    if(pp.left === p) {\n      if(p.left === n) {\n        var y = pp.right\n        if(y && y._color === RED) {\n          //console.log(\"LLr\")\n          p._color = BLACK\n          pp.right = repaint(BLACK, y)\n          pp._color = RED\n          s -= 1\n        } else {\n          //console.log(\"LLb\")\n          pp._color = RED\n          pp.left = p.right\n          p._color = BLACK\n          p.right = pp\n          n_stack[s-2] = p\n          n_stack[s-1] = n\n          recount(pp)\n          recount(p)\n          if(s >= 3) {\n            var ppp = n_stack[s-3]\n            if(ppp.left === pp) {\n              ppp.left = p\n            } else {\n              ppp.right = p\n            }\n          }\n          break\n        }\n      } else {\n        var y = pp.right\n        if(y && y._color === RED) {\n          //console.log(\"LRr\")\n          p._color = BLACK\n          pp.right = repaint(BLACK, y)\n          pp._color = RED\n          s -= 1\n        } else {\n          //console.log(\"LRb\")\n          p.right = n.left\n          pp._color = RED\n          pp.left = n.right\n          n._color = BLACK\n          n.left = p\n          n.right = pp\n          n_stack[s-2] = n\n          n_stack[s-1] = p\n          recount(pp)\n          recount(p)\n          recount(n)\n          if(s >= 3) {\n            var ppp = n_stack[s-3]\n            if(ppp.left === pp) {\n              ppp.left = n\n            } else {\n              ppp.right = n\n            }\n          }\n          break\n        }\n      }\n    } else {\n      if(p.right === n) {\n        var y = pp.left\n        if(y && y._color === RED) {\n          //console.log(\"RRr\", y.key)\n          p._color = BLACK\n          pp.left = repaint(BLACK, y)\n          pp._color = RED\n          s -= 1\n        } else {\n          //console.log(\"RRb\")\n          pp._color = RED\n          pp.right = p.left\n          p._color = BLACK\n          p.left = pp\n          n_stack[s-2] = p\n          n_stack[s-1] = n\n          recount(pp)\n          recount(p)\n          if(s >= 3) {\n            var ppp = n_stack[s-3]\n            if(ppp.right === pp) {\n              ppp.right = p\n            } else {\n              ppp.left = p\n            }\n          }\n          break\n        }\n      } else {\n        var y = pp.left\n        if(y && y._color === RED) {\n          //console.log(\"RLr\")\n          p._color = BLACK\n          pp.left = repaint(BLACK, y)\n          pp._color = RED\n          s -= 1\n        } else {\n          //console.log(\"RLb\")\n          p.left = n.right\n          pp._color = RED\n          pp.right = n.left\n          n._color = BLACK\n          n.right = p\n          n.left = pp\n          n_stack[s-2] = n\n          n_stack[s-1] = p\n          recount(pp)\n          recount(p)\n          recount(n)\n          if(s >= 3) {\n            var ppp = n_stack[s-3]\n            if(ppp.right === pp) {\n              ppp.right = n\n            } else {\n              ppp.left = n\n            }\n          }\n          break\n        }\n      }\n    }\n  }\n  //Return new tree\n  n_stack[0]._color = BLACK\n  return new RedBlackTree(cmp, n_stack[0])\n}\n\n\n//Visit all nodes inorder\nfunction doVisitFull(visit, node) {\n  if(node.left) {\n    var v = doVisitFull(visit, node.left)\n    if(v) { return v }\n  }\n  var v = visit(node.key, node.value)\n  if(v) { return v }\n  if(node.right) {\n    return doVisitFull(visit, node.right)\n  }\n}\n\n//Visit half nodes in order\nfunction doVisitHalf(lo, compare, visit, node) {\n  var l = compare(lo, node.key)\n  if(l <= 0) {\n    if(node.left) {\n      var v = doVisitHalf(lo, compare, visit, node.left)\n      if(v) { return v }\n    }\n    var v = visit(node.key, node.value)\n    if(v) { return v }\n  }\n  if(node.right) {\n    return doVisitHalf(lo, compare, visit, node.right)\n  }\n}\n\n//Visit all nodes within a range\nfunction doVisit(lo, hi, compare, visit, node) {\n  var l = compare(lo, node.key)\n  var h = compare(hi, node.key)\n  var v\n  if(l <= 0) {\n    if(node.left) {\n      v = doVisit(lo, hi, compare, visit, node.left)\n      if(v) { return v }\n    }\n    if(h > 0) {\n      v = visit(node.key, node.value)\n      if(v) { return v }\n    }\n  }\n  if(h > 0 && node.right) {\n    return doVisit(lo, hi, compare, visit, node.right)\n  }\n}\n\n\nproto.forEach = function rbTreeForEach(visit, lo, hi) {\n  if(!this.root) {\n    return\n  }\n  switch(arguments.length) {\n    case 1:\n      return doVisitFull(visit, this.root)\n    break\n\n    case 2:\n      return doVisitHalf(lo, this._compare, visit, this.root)\n    break\n\n    case 3:\n      if(this._compare(lo, hi) >= 0) {\n        return\n      }\n      return doVisit(lo, hi, this._compare, visit, this.root)\n    break\n  }\n}\n\n//First item in list\nObject.defineProperty(proto, \"begin\", {\n  get: function() {\n    var stack = []\n    var n = this.root\n    while(n) {\n      stack.push(n)\n      n = n.left\n    }\n    return new RedBlackTreeIterator(this, stack)\n  }\n})\n\n//Last item in list\nObject.defineProperty(proto, \"end\", {\n  get: function() {\n    var stack = []\n    var n = this.root\n    while(n) {\n      stack.push(n)\n      n = n.right\n    }\n    return new RedBlackTreeIterator(this, stack)\n  }\n})\n\n//Find the ith item in the tree\nproto.at = function(idx) {\n  if(idx < 0) {\n    return new RedBlackTreeIterator(this, [])\n  }\n  var n = this.root\n  var stack = []\n  while(true) {\n    stack.push(n)\n    if(n.left) {\n      if(idx < n.left._count) {\n        n = n.left\n        continue\n      }\n      idx -= n.left._count\n    }\n    if(!idx) {\n      return new RedBlackTreeIterator(this, stack)\n    }\n    idx -= 1\n    if(n.right) {\n      if(idx >= n.right._count) {\n        break\n      }\n      n = n.right\n    } else {\n      break\n    }\n  }\n  return new RedBlackTreeIterator(this, [])\n}\n\nproto.ge = function(key) {\n  var cmp = this._compare\n  var n = this.root\n  var stack = []\n  var last_ptr = 0\n  while(n) {\n    var d = cmp(key, n.key)\n    stack.push(n)\n    if(d <= 0) {\n      last_ptr = stack.length\n    }\n    if(d <= 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  stack.length = last_ptr\n  return new RedBlackTreeIterator(this, stack)\n}\n\nproto.gt = function(key) {\n  var cmp = this._compare\n  var n = this.root\n  var stack = []\n  var last_ptr = 0\n  while(n) {\n    var d = cmp(key, n.key)\n    stack.push(n)\n    if(d < 0) {\n      last_ptr = stack.length\n    }\n    if(d < 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  stack.length = last_ptr\n  return new RedBlackTreeIterator(this, stack)\n}\n\nproto.lt = function(key) {\n  var cmp = this._compare\n  var n = this.root\n  var stack = []\n  var last_ptr = 0\n  while(n) {\n    var d = cmp(key, n.key)\n    stack.push(n)\n    if(d > 0) {\n      last_ptr = stack.length\n    }\n    if(d <= 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  stack.length = last_ptr\n  return new RedBlackTreeIterator(this, stack)\n}\n\nproto.le = function(key) {\n  var cmp = this._compare\n  var n = this.root\n  var stack = []\n  var last_ptr = 0\n  while(n) {\n    var d = cmp(key, n.key)\n    stack.push(n)\n    if(d >= 0) {\n      last_ptr = stack.length\n    }\n    if(d < 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  stack.length = last_ptr\n  return new RedBlackTreeIterator(this, stack)\n}\n\n//Finds the item with key if it exists\nproto.find = function(key) {\n  var cmp = this._compare\n  var n = this.root\n  var stack = []\n  while(n) {\n    var d = cmp(key, n.key)\n    stack.push(n)\n    if(d === 0) {\n      return new RedBlackTreeIterator(this, stack)\n    }\n    if(d <= 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  return new RedBlackTreeIterator(this, [])\n}\n\n//Removes item with key from tree\nproto.remove = function(key) {\n  var iter = this.find(key)\n  if(iter) {\n    return iter.remove()\n  }\n  return this\n}\n\n//Returns the item at `key`\nproto.get = function(key) {\n  var cmp = this._compare\n  var n = this.root\n  while(n) {\n    var d = cmp(key, n.key)\n    if(d === 0) {\n      return n.value\n    }\n    if(d <= 0) {\n      n = n.left\n    } else {\n      n = n.right\n    }\n  }\n  return\n}\n\n//Iterator for red black tree\nfunction RedBlackTreeIterator(tree, stack) {\n  this.tree = tree\n  this._stack = stack\n}\n\nvar iproto = RedBlackTreeIterator.prototype\n\n//Test if iterator is valid\nObject.defineProperty(iproto, \"valid\", {\n  get: function() {\n    return this._stack.length > 0\n  }\n})\n\n//Node of the iterator\nObject.defineProperty(iproto, \"node\", {\n  get: function() {\n    if(this._stack.length > 0) {\n      return this._stack[this._stack.length-1]\n    }\n    return null\n  },\n  enumerable: true\n})\n\n//Makes a copy of an iterator\niproto.clone = function() {\n  return new RedBlackTreeIterator(this.tree, this._stack.slice())\n}\n\n//Swaps two nodes\nfunction swapNode(n, v) {\n  n.key = v.key\n  n.value = v.value\n  n.left = v.left\n  n.right = v.right\n  n._color = v._color\n  n._count = v._count\n}\n\n//Fix up a double black node in a tree\nfunction fixDoubleBlack(stack) {\n  var n, p, s, z\n  for(var i=stack.length-1; i>=0; --i) {\n    n = stack[i]\n    if(i === 0) {\n      n._color = BLACK\n      return\n    }\n    //console.log(\"visit node:\", n.key, i, stack[i].key, stack[i-1].key)\n    p = stack[i-1]\n    if(p.left === n) {\n      //console.log(\"left child\")\n      s = p.right\n      if(s.right && s.right._color === RED) {\n        //console.log(\"case 1: right sibling child red\")\n        s = p.right = cloneNode(s)\n        z = s.right = cloneNode(s.right)\n        p.right = s.left\n        s.left = p\n        s.right = z\n        s._color = p._color\n        n._color = BLACK\n        p._color = BLACK\n        z._color = BLACK\n        recount(p)\n        recount(s)\n        if(i > 1) {\n          var pp = stack[i-2]\n          if(pp.left === p) {\n            pp.left = s\n          } else {\n            pp.right = s\n          }\n        }\n        stack[i-1] = s\n        return\n      } else if(s.left && s.left._color === RED) {\n        //console.log(\"case 1: left sibling child red\")\n        s = p.right = cloneNode(s)\n        z = s.left = cloneNode(s.left)\n        p.right = z.left\n        s.left = z.right\n        z.left = p\n        z.right = s\n        z._color = p._color\n        p._color = BLACK\n        s._color = BLACK\n        n._color = BLACK\n        recount(p)\n        recount(s)\n        recount(z)\n        if(i > 1) {\n          var pp = stack[i-2]\n          if(pp.left === p) {\n            pp.left = z\n          } else {\n            pp.right = z\n          }\n        }\n        stack[i-1] = z\n        return\n      }\n      if(s._color === BLACK) {\n        if(p._color === RED) {\n          //console.log(\"case 2: black sibling, red parent\", p.right.value)\n          p._color = BLACK\n          p.right = repaint(RED, s)\n          return\n        } else {\n          //console.log(\"case 2: black sibling, black parent\", p.right.value)\n          p.right = repaint(RED, s)\n          continue  \n        }\n      } else {\n        //console.log(\"case 3: red sibling\")\n        s = cloneNode(s)\n        p.right = s.left\n        s.left = p\n        s._color = p._color\n        p._color = RED\n        recount(p)\n        recount(s)\n        if(i > 1) {\n          var pp = stack[i-2]\n          if(pp.left === p) {\n            pp.left = s\n          } else {\n            pp.right = s\n          }\n        }\n        stack[i-1] = s\n        stack[i] = p\n        if(i+1 < stack.length) {\n          stack[i+1] = n\n        } else {\n          stack.push(n)\n        }\n        i = i+2\n      }\n    } else {\n      //console.log(\"right child\")\n      s = p.left\n      if(s.left && s.left._color === RED) {\n        //console.log(\"case 1: left sibling child red\", p.value, p._color)\n        s = p.left = cloneNode(s)\n        z = s.left = cloneNode(s.left)\n        p.left = s.right\n        s.right = p\n        s.left = z\n        s._color = p._color\n        n._color = BLACK\n        p._color = BLACK\n        z._color = BLACK\n        recount(p)\n        recount(s)\n        if(i > 1) {\n          var pp = stack[i-2]\n          if(pp.right === p) {\n            pp.right = s\n          } else {\n            pp.left = s\n          }\n        }\n        stack[i-1] = s\n        return\n      } else if(s.right && s.right._color === RED) {\n        //console.log(\"case 1: right sibling child red\")\n        s = p.left = cloneNode(s)\n        z = s.right = cloneNode(s.right)\n        p.left = z.right\n        s.right = z.left\n        z.right = p\n        z.left = s\n        z._color = p._color\n        p._color = BLACK\n        s._color = BLACK\n        n._color = BLACK\n        recount(p)\n        recount(s)\n        recount(z)\n        if(i > 1) {\n          var pp = stack[i-2]\n          if(pp.right === p) {\n            pp.right = z\n          } else {\n            pp.left = z\n          }\n        }\n        stack[i-1] = z\n        return\n      }\n      if(s._color === BLACK) {\n        if(p._color === RED) {\n          //console.log(\"case 2: black sibling, red parent\")\n          p._color = BLACK\n          p.left = repaint(RED, s)\n          return\n        } else {\n          //console.log(\"case 2: black sibling, black parent\")\n          p.left = repaint(RED, s)\n          continue  \n        }\n      } else {\n        //console.log(\"case 3: red sibling\")\n        s = cloneNode(s)\n        p.left = s.right\n        s.right = p\n        s._color = p._color\n        p._color = RED\n        recount(p)\n        recount(s)\n        if(i > 1) {\n          var pp = stack[i-2]\n          if(pp.right === p) {\n            pp.right = s\n          } else {\n            pp.left = s\n          }\n        }\n        stack[i-1] = s\n        stack[i] = p\n        if(i+1 < stack.length) {\n          stack[i+1] = n\n        } else {\n          stack.push(n)\n        }\n        i = i+2\n      }\n    }\n  }\n}\n\n//Removes item at iterator from tree\niproto.remove = function() {\n  var stack = this._stack\n  if(stack.length === 0) {\n    return this.tree\n  }\n  //First copy path to node\n  var cstack = new Array(stack.length)\n  var n = stack[stack.length-1]\n  cstack[cstack.length-1] = new RBNode(n._color, n.key, n.value, n.left, n.right, n._count)\n  for(var i=stack.length-2; i>=0; --i) {\n    var n = stack[i]\n    if(n.left === stack[i+1]) {\n      cstack[i] = new RBNode(n._color, n.key, n.value, cstack[i+1], n.right, n._count)\n    } else {\n      cstack[i] = new RBNode(n._color, n.key, n.value, n.left, cstack[i+1], n._count)\n    }\n  }\n\n  //Get node\n  n = cstack[cstack.length-1]\n  //console.log(\"start remove: \", n.value)\n\n  //If not leaf, then swap with previous node\n  if(n.left && n.right) {\n    //console.log(\"moving to leaf\")\n\n    //First walk to previous leaf\n    var split = cstack.length\n    n = n.left\n    while(n.right) {\n      cstack.push(n)\n      n = n.right\n    }\n    //Copy path to leaf\n    var v = cstack[split-1]\n    cstack.push(new RBNode(n._color, v.key, v.value, n.left, n.right, n._count))\n    cstack[split-1].key = n.key\n    cstack[split-1].value = n.value\n\n    //Fix up stack\n    for(var i=cstack.length-2; i>=split; --i) {\n      n = cstack[i]\n      cstack[i] = new RBNode(n._color, n.key, n.value, n.left, cstack[i+1], n._count)\n    }\n    cstack[split-1].left = cstack[split]\n  }\n  //console.log(\"stack=\", cstack.map(function(v) { return v.value }))\n\n  //Remove leaf node\n  n = cstack[cstack.length-1]\n  if(n._color === RED) {\n    //Easy case: removing red leaf\n    //console.log(\"RED leaf\")\n    var p = cstack[cstack.length-2]\n    if(p.left === n) {\n      p.left = null\n    } else if(p.right === n) {\n      p.right = null\n    }\n    cstack.pop()\n    for(var i=0; i<cstack.length; ++i) {\n      cstack[i]._count--\n    }\n    return new RedBlackTree(this.tree._compare, cstack[0])\n  } else {\n    if(n.left || n.right) {\n      //Second easy case:  Single child black parent\n      //console.log(\"BLACK single child\")\n      if(n.left) {\n        swapNode(n, n.left)\n      } else if(n.right) {\n        swapNode(n, n.right)\n      }\n      //Child must be red, so repaint it black to balance color\n      n._color = BLACK\n      for(var i=0; i<cstack.length-1; ++i) {\n        cstack[i]._count--\n      }\n      return new RedBlackTree(this.tree._compare, cstack[0])\n    } else if(cstack.length === 1) {\n      //Third easy case: root\n      //console.log(\"ROOT\")\n      return new RedBlackTree(this.tree._compare, null)\n    } else {\n      //Hard case: Repaint n, and then do some nasty stuff\n      //console.log(\"BLACK leaf no children\")\n      for(var i=0; i<cstack.length; ++i) {\n        cstack[i]._count--\n      }\n      var parent = cstack[cstack.length-2]\n      fixDoubleBlack(cstack)\n      //Fix up links\n      if(parent.left === n) {\n        parent.left = null\n      } else {\n        parent.right = null\n      }\n    }\n  }\n  return new RedBlackTree(this.tree._compare, cstack[0])\n}\n\n//Returns key\nObject.defineProperty(iproto, \"key\", {\n  get: function() {\n    if(this._stack.length > 0) {\n      return this._stack[this._stack.length-1].key\n    }\n    return\n  },\n  enumerable: true\n})\n\n//Returns value\nObject.defineProperty(iproto, \"value\", {\n  get: function() {\n    if(this._stack.length > 0) {\n      return this._stack[this._stack.length-1].value\n    }\n    return\n  },\n  enumerable: true\n})\n\n\n//Returns the position of this iterator in the sorted list\nObject.defineProperty(iproto, \"index\", {\n  get: function() {\n    var idx = 0\n    var stack = this._stack\n    if(stack.length === 0) {\n      var r = this.tree.root\n      if(r) {\n        return r._count\n      }\n      return 0\n    } else if(stack[stack.length-1].left) {\n      idx = stack[stack.length-1].left._count\n    }\n    for(var s=stack.length-2; s>=0; --s) {\n      if(stack[s+1] === stack[s].right) {\n        ++idx\n        if(stack[s].left) {\n          idx += stack[s].left._count\n        }\n      }\n    }\n    return idx\n  },\n  enumerable: true\n})\n\n//Advances iterator to next element in list\niproto.next = function() {\n  var stack = this._stack\n  if(stack.length === 0) {\n    return\n  }\n  var n = stack[stack.length-1]\n  if(n.right) {\n    n = n.right\n    while(n) {\n      stack.push(n)\n      n = n.left\n    }\n  } else {\n    stack.pop()\n    while(stack.length > 0 && stack[stack.length-1].right === n) {\n      n = stack[stack.length-1]\n      stack.pop()\n    }\n  }\n}\n\n//Checks if iterator is at end of tree\nObject.defineProperty(iproto, \"hasNext\", {\n  get: function() {\n    var stack = this._stack\n    if(stack.length === 0) {\n      return false\n    }\n    if(stack[stack.length-1].right) {\n      return true\n    }\n    for(var s=stack.length-1; s>0; --s) {\n      if(stack[s-1].left === stack[s]) {\n        return true\n      }\n    }\n    return false\n  }\n})\n\n//Update value\niproto.update = function(value) {\n  var stack = this._stack\n  if(stack.length === 0) {\n    throw new Error(\"Can't update empty node!\")\n  }\n  var cstack = new Array(stack.length)\n  var n = stack[stack.length-1]\n  cstack[cstack.length-1] = new RBNode(n._color, n.key, value, n.left, n.right, n._count)\n  for(var i=stack.length-2; i>=0; --i) {\n    n = stack[i]\n    if(n.left === stack[i+1]) {\n      cstack[i] = new RBNode(n._color, n.key, n.value, cstack[i+1], n.right, n._count)\n    } else {\n      cstack[i] = new RBNode(n._color, n.key, n.value, n.left, cstack[i+1], n._count)\n    }\n  }\n  return new RedBlackTree(this.tree._compare, cstack[0])\n}\n\n//Moves iterator backward one element\niproto.prev = function() {\n  var stack = this._stack\n  if(stack.length === 0) {\n    return\n  }\n  var n = stack[stack.length-1]\n  if(n.left) {\n    n = n.left\n    while(n) {\n      stack.push(n)\n      n = n.right\n    }\n  } else {\n    stack.pop()\n    while(stack.length > 0 && stack[stack.length-1].left === n) {\n      n = stack[stack.length-1]\n      stack.pop()\n    }\n  }\n}\n\n//Checks if iterator is at start of tree\nObject.defineProperty(iproto, \"hasPrev\", {\n  get: function() {\n    var stack = this._stack\n    if(stack.length === 0) {\n      return false\n    }\n    if(stack[stack.length-1].left) {\n      return true\n    }\n    for(var s=stack.length-1; s>0; --s) {\n      if(stack[s-1].right === stack[s]) {\n        return true\n      }\n    }\n    return false\n  }\n})\n\n//Default comparison function\nfunction defaultCompare(a, b) {\n  if(a < b) {\n    return -1\n  }\n  if(a > b) {\n    return 1\n  }\n  return 0\n}\n\n//Build a tree\nfunction createRBTree(compare) {\n  return new RedBlackTree(compare || defaultCompare, null)\n}\n\n/***/ }),\n/* 649 */\n/***/ (function(module, exports, __webpack_require__) {\n\nmodule.exports = __webpack_require__(650)\n\n\n/***/ }),\n/* 650 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar types = [\n  __webpack_require__(651),\n  __webpack_require__(652),\n  __webpack_require__(653),\n  __webpack_require__(654),\n  __webpack_require__(655)\n];\nvar draining;\nvar currentQueue;\nvar queueIndex = -1;\nvar queue = [];\nvar scheduled = false;\nfunction cleanUpNextTick() {\n  if (!draining || !currentQueue) {\n    return;\n  }\n  draining = false;\n  if (currentQueue.length) {\n    queue = currentQueue.concat(queue);\n  } else {\n    queueIndex = -1;\n  }\n  if (queue.length) {\n    nextTick();\n  }\n}\n\n//named nextTick for less confusing stack traces\nfunction nextTick() {\n  if (draining) {\n    return;\n  }\n  scheduled = false;\n  draining = true;\n  var len = queue.length;\n  var timeout = setTimeout(cleanUpNextTick);\n  while (len) {\n    currentQueue = queue;\n    queue = [];\n    while (currentQueue && ++queueIndex < len) {\n      currentQueue[queueIndex].run();\n    }\n    queueIndex = -1;\n    len = queue.length;\n  }\n  currentQueue = null;\n  queueIndex = -1;\n  draining = false;\n  clearTimeout(timeout);\n}\nvar scheduleDrain;\nvar i = -1;\nvar len = types.length;\nwhile (++i < len) {\n  if (types[i] && types[i].test && types[i].test()) {\n    scheduleDrain = types[i].install(nextTick);\n    break;\n  }\n}\n// v8 likes predictible objects\nfunction Item(fun, array) {\n  this.fun = fun;\n  this.array = array;\n}\nItem.prototype.run = function () {\n  var fun = this.fun;\n  var array = this.array;\n  switch (array.length) {\n  case 0:\n    return fun();\n  case 1:\n    return fun(array[0]);\n  case 2:\n    return fun(array[0], array[1]);\n  case 3:\n    return fun(array[0], array[1], array[2]);\n  default:\n    return fun.apply(null, array);\n  }\n\n};\nmodule.exports = immediate;\nfunction immediate(task) {\n  var args = new Array(arguments.length - 1);\n  if (arguments.length > 1) {\n    for (var i = 1; i < arguments.length; i++) {\n      args[i - 1] = arguments[i];\n    }\n  }\n  queue.push(new Item(task, args));\n  if (!scheduled && !draining) {\n    scheduled = true;\n    scheduleDrain();\n  }\n}\n\n\n/***/ }),\n/* 651 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(process) {\nexports.test = function () {\n  // Don't get fooled by e.g. browserify environments.\n  return (typeof process !== 'undefined') && !process.browser;\n};\n\nexports.install = function (func) {\n  return function () {\n    process.nextTick(func);\n  };\n};\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(8)))\n\n/***/ }),\n/* 652 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global) {\n//based off rsvp https://github.com/tildeio/rsvp.js\n//license https://github.com/tildeio/rsvp.js/blob/master/LICENSE\n//https://github.com/tildeio/rsvp.js/blob/master/lib/rsvp/asap.js\n\nvar Mutation = global.MutationObserver || global.WebKitMutationObserver;\n\nexports.test = function () {\n  return Mutation;\n};\n\nexports.install = function (handle) {\n  var called = 0;\n  var observer = new Mutation(handle);\n  var element = global.document.createTextNode('');\n  observer.observe(element, {\n    characterData: true\n  });\n  return function () {\n    element.data = (called = ++called % 2);\n  };\n};\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12)))\n\n/***/ }),\n/* 653 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global) {\n\nexports.test = function () {\n  if (global.setImmediate) {\n    // we can only get here in IE10\n    // which doesn't handel postMessage well\n    return false;\n  }\n  return typeof global.MessageChannel !== 'undefined';\n};\n\nexports.install = function (func) {\n  var channel = new global.MessageChannel();\n  channel.port1.onmessage = func;\n  return function () {\n    channel.port2.postMessage(0);\n  };\n};\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12)))\n\n/***/ }),\n/* 654 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global) {\n\nexports.test = function () {\n  return 'document' in global && 'onreadystatechange' in global.document.createElement('script');\n};\n\nexports.install = function (handle) {\n  return function () {\n\n    // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n    // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n    var scriptEl = global.document.createElement('script');\n    scriptEl.onreadystatechange = function () {\n      handle();\n\n      scriptEl.onreadystatechange = null;\n      scriptEl.parentNode.removeChild(scriptEl);\n      scriptEl = null;\n    };\n    global.document.documentElement.appendChild(scriptEl);\n\n    return handle;\n  };\n};\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12)))\n\n/***/ }),\n/* 655 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nexports.test = function () {\n  return true;\n};\n\nexports.install = function (t) {\n  return function () {\n    setTimeout(t, 0);\n  };\n};\n\n/***/ })\n/******/ ]);"],"file":"scripts/npm-c1e8447cfd.js","sourceRoot":"/source/"}